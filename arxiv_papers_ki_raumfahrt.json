[
  {
    "api_id": 0,
    "title": "Resonant Oscillations and Tidal Heating in Coalescing Binary Neutron\n  Stars",
    "summary": "Tidal interaction in a coalescing neutron star binary can resonantly excite\nthe g-mode oscillations of the neutron star when the frequency of the tidal\ndriving force equals the intrinsic g-mode frequencies. We study the g-mode\noscillations of cold neutron stars using recent microscopic nuclear equations\nof state, where we determine self-consistently the sound speed and\nBrunt-V\\\"ais\\\"al\\\"a frequency in the nuclear liquid core. The properties of the\ng-modes associated with the stable stratification of the core depend\nsensitively on the pressure-density relation as well as the symmetry energy of\nthe dense nuclear matter. The frequencies of the first ten g-modes lie\napproximately in the range of $10-100$ Hz. Resonant excitations of these\ng-modes during the last few minutes of the binary coalescence result in energy\ntransfer and angular momentum transfer from the binary orbit to the neutron\nstar. The angular momentum transfer is possible because a dynamical tidal lag\ndevelops even in the absence of fluid viscosity. However, since the coupling\nbetween the g-mode and the tidal potential is rather weak, the amount of energy\ntransfer during a resonance and the induced orbital phase error are very small.\nResonant excitations of the g-modes play an important role in tidal heating of\nbinary neutron stars. Without the resonances, viscous dissipation is effective\nonly when the stars are close to contact. The resonant oscillations result in\ndissipation at much larger orbital separation. The actual amount of tidal\nheating depends on the viscosity of the neutron star. Using the microscopic\nviscosity, we find that the binary neutron stars are heated to a temperature\n$\\sim 10^8$ K before they come into contact.",
    "published": "1994-04-25T01:31:08Z",
    "updated": "1994-04-25T01:31:08Z",
    "authors": [
      "Dong Lai"
    ],
    "link": "http://arxiv.org/abs/astro-ph/9404062v1",
    "pdf_link": "http://arxiv.org/pdf/astro-ph/9404062v1"
  },
  {
    "api_id": 1,
    "title": "Adaptive Problem-solving for Large-scale Scheduling Problems: A Case\n  Study",
    "summary": "Although most scheduling problems are NP-hard, domain specific techniques\nperform well in practice but are quite expensive to construct. In adaptive\nproblem-solving solving, domain specific knowledge is acquired automatically\nfor a general problem solver with a flexible control architecture. In this\napproach, a learning system explores a space of possible heuristic methods for\none well-suited to the eccentricities of the given domain and problem\ndistribution. In this article, we discuss an application of the approach to\nscheduling satellite communications. Using problem distributions based on\nactual mission requirements, our approach identifies strategies that not only\ndecrease the amount of CPU time required to produce schedules, but also\nincrease the percentage of problems that are solvable within computational\nresource limitations.",
    "published": "1996-05-01T00:00:00Z",
    "updated": "1996-05-01T00:00:00Z",
    "authors": [
      "J. Gratch",
      "S. Chien"
    ],
    "link": "http://arxiv.org/abs/cs/9605104v1",
    "pdf_link": "http://arxiv.org/pdf/cs/9605104v1"
  },
  {
    "api_id": 2,
    "title": "ASCA Observation of the polar RX J1802.1+1804",
    "summary": "We present X-ray data of RX J1802.1+1804 obtained by ASCA. Although it shows\na clear orbital intensity modulation with an amplitude of nearly 100% below 0.5\nkeV in ROSAT data, the ASCA light curves are nearly flat except for a possible\ndip lasting about one-tenth of the orbital period. We discuss this within the\nmodel assumption of a stream-eclipsing geometry as derived from the ROSAT\nobservations. The ASCA X-ray spectrum can be represented by a two temperature\noptically thin thermal plasma emission model with temperatures of ~1keV and >7\nkeV, suggesting postshock cooling as observed in EX Hya. A remarkable feature\nof the spectrum is the strong iron K_alpha emission line whose equivalent width\nis ~4 keV. To account for this, an iron abundance of greater than at least 1.3\ntimes Solar is required. A combined spectral analysis of the ROSAT PSPC and\nASCA data indicates that the N_H-corrected flux ratio of the soft blackbody\n(0.1-2.4 keV) to the hard optically thin thermal plasma emission (2-10 keV) is\nas large as ~10^4.",
    "published": "1998-05-15T12:19:12Z",
    "updated": "1998-05-15T12:19:12Z",
    "authors": [
      "M. Ishida",
      "J. Greiner",
      "R. A. Remillard",
      "C. Motch"
    ],
    "link": "http://arxiv.org/abs/astro-ph/9805211v1",
    "pdf_link": "http://arxiv.org/pdf/astro-ph/9805211v1"
  },
  {
    "api_id": 3,
    "title": "S 10943 Vulpeculae: A New ROSAT Selected Dwarf Nova, probably of SU\n  Ursae Majoris Subclass",
    "summary": "We have identified the ROSAT all-sky survey source RX J1953.1+2115 with a\nnewly discovered dwarf novae (named S 10943 Vulpeculae) with a recurrence time\nof 83.6 days. With the expected period of ~2.8 hrs (based on the measured\nsuperhump period of 2.871 hrs) S 10943 Vul would be the SU Ursae Majoris star\nwith the second largest superhump (and orbital) period known (together with TU\nMen).",
    "published": "1998-08-19T11:56:47Z",
    "updated": "1998-08-19T11:56:47Z",
    "authors": [
      "G. A. Richter",
      "J. Greiner",
      "P. Kroll"
    ],
    "link": "http://arxiv.org/abs/astro-ph/9808192v1",
    "pdf_link": "http://arxiv.org/pdf/astro-ph/9808192v1"
  },
  {
    "api_id": 4,
    "title": "RX J1016.9-4103: A new soft X-ray polar in the period gap",
    "summary": "We have discovered a new AM Her system as the optical counterpart of the\nROSAT All-Sky-Survey source RX J1016.9-4103 (= 1RXS J101659.4-410332). The\nX-ray spectrum is very soft and the X-ray intensity is strongly modulated with\nthe orbital period. Optical photometric and spectroscopic follow-up\nobservations reveal a synchronously rotating binary with an orbital period of\n134 min, placing RX J1016.9-4103 in the period gap. The strength of the TiO\nbands suggests a secondary spectral type later than M3 V and a distance of\n615+/-150 pc. Based on two clearly visible broad humps in the optical spectrum\n(interpreted as cyclotron features) a magnetic field strength of 52 MG is\ndeduced thus proving the polar classification.",
    "published": "1998-09-09T07:16:32Z",
    "updated": "1998-09-09T07:16:32Z",
    "authors": [
      "Jochen Greiner",
      "Robert Schwarz"
    ],
    "link": "http://arxiv.org/abs/astro-ph/9809104v1",
    "pdf_link": "http://arxiv.org/pdf/astro-ph/9809104v1"
  },
  {
    "api_id": 5,
    "title": "HST/WFPC2 and VLT/ISAAC observations of PROPLYDS in the giant HII region\n  NGC 3603",
    "summary": "We report the discovery of three proplyd-like structures in the giant HII\nregion NGC 3603. The emission nebulae are clearly resolved in narrow-band and\nbroad-band HST/WFPC2 observations in the optical and broad-band VLT/ISAAC\nobservations in the near-infrared. All three nebulae are tadpole shaped, with\nthe bright ionization front at the head facing the central cluster and a\nfainter ionization front around the tail pointing away from the cluster.\nTypical sizes are 6,000 A.U. x 20,000 A.U. The nebulae share the overall\nmorphology of the proplyds (``PROto PLanetarY DiskS'') in Orion, but are 20 to\n30 times larger in size. Additional faint filaments located between the nebulae\nand the central ionizing cluster can be interpreted as bow shocks resulting\nfrom the interaction of the fast winds from the high-mass stars in the cluster\nwith the evaporation flow from the proplyds. The striking similarity of the\ntadpole shaped emission nebulae in NGC 3603 to the proplyds in Orion suggests\nthat the physical structure of both types of objects might be the same. We\npresent 2D radiation hydrodynamical simulations of an externally illuminated\nstar-disk-envelope system, which was still in its main accretion phase when\nfirst exposed to ionizing radiation from the central cluster. The simulations\nreproduce the overall morphology of the proplyds in NGC 3603 very well, but\nalso indicate that mass-loss rates of up to 10^-5 Mo/yr are required in order\nto explain the size of the proplyds. (abbreviated)",
    "published": "1999-10-05T01:25:42Z",
    "updated": "1999-10-05T01:25:42Z",
    "authors": [
      "W. Brandner",
      "E. K. Grebel",
      "Y. -H. Chu",
      "H. Dottori",
      "B. Brandl",
      "S. Richling",
      "H. W. Yorke",
      "S. D. Points",
      "H. Zinnecker"
    ],
    "link": "http://arxiv.org/abs/astro-ph/9910074v1",
    "pdf_link": "http://arxiv.org/pdf/astro-ph/9910074v1"
  },
  {
    "api_id": 6,
    "title": "Structure from Motion: Theoretical Foundations of a Novel Approach Using\n  Custom Built Invariants",
    "summary": "We rephrase the problem of 3D reconstruction from images in terms of\nintersections of projections of orbits of custom built Lie groups actions. We\nthen use an algorithmic method based on moving frames \"a la Fels-Olver\" to\nobtain a fundamental set of invariants of these groups actions. The invariants\nare used to define a set of equations to be solved by the points of the 3D\nobject, providing a new technique for recovering 3D structure from motion.",
    "published": "2002-01-22T21:00:35Z",
    "updated": "2002-01-22T21:00:35Z",
    "authors": [
      "Pierre-Louis Bazin",
      "Mireille Boutin"
    ],
    "link": "http://arxiv.org/abs/cs/0201019v1",
    "pdf_link": "http://arxiv.org/pdf/cs/0201019v1"
  },
  {
    "api_id": 7,
    "title": "The structure and evolution of M51-type galaxies",
    "summary": "We discuss the integrated kinematic parameters of 20 M51-type binary\ngalaxies. A comparison of the orbital masses of the galaxies with the sum of\nthe individual masses suggests that moderately massive dark halos surround\nbright spiral galaxies. The relative velocities of the galaxies in binary\nsystems were found to decrease with increasing relative luminosity of the\nsatellite. We obtained evidence that the Tully-Fisher relation for binary\nmembers could be flatter than that for local field galaxies. An enhanced star\nformation rate in the binary members may be responsible for this effect. In\nmost binary systems, the direction of orbital motion of the satellite coincides\nwith the direction of rotation of the main galaxy. Seven candidates for distant\nM51-type objects were found in the Northern and Southern Hubble Deep Fields. A\ncomparison of this number with the statistics of nearby galaxies provides\nevidence for the rapid evolution of the space density of M51-type galaxies with\nredshift Z. We assume that M51-type binary systems could be formed through the\ncapture of a satellite by a massive spiral galaxy. It is also possible that the\nmain galaxy and its satellite in some of the systems have a common cosmological\norigin.",
    "published": "2003-05-24T13:25:58Z",
    "updated": "2003-05-24T13:25:58Z",
    "authors": [
      "V. P. Reshetnikov",
      "S. A. Klimanov"
    ],
    "link": "http://arxiv.org/abs/astro-ph/0305480v1",
    "pdf_link": "http://arxiv.org/pdf/astro-ph/0305480v1"
  },
  {
    "api_id": 8,
    "title": "Cleaning sky survey databases using Hough Transform and Renewal String\n  approaches",
    "summary": "Large astronomical databases obtained from sky surveys such as the\nSuperCOSMOS Sky Survey (SSS) invariably suffer from spurious records coming\nfrom artefactual effects of the telescope, satellites and junk objects in orbit\naround earth and physical defects on the photographic plate or CCD. Though\nrelatively small in number these spurious records present a significant problem\nin many situations where they can become a large proportion of the records\npotentially of interest to a given astronomer. Accurate and robust techniques\nare needed for locating and flagging such spurious objects, and we are\nundertaking a programme investigating the use of machine learning techniques in\nthis context. In this paper we focus on the four most common causes of unwanted\nrecords in the SSS: satellite or aeroplane tracks, scratches, fibres and other\nlinear phenomena introduced to the plate, circular halos around bright stars\ndue to internal reflections within the telescope and diffraction spikes near to\nbright stars. Appropriate techniques are developed for the detection of each of\nthese. The methods are applied to the SSS data to develop a dataset of spurious\nobject detections, along with confidence measures, which can allow these\nunwanted data to be removed from consideration. These methods are general and\ncan be adapted to other astronomical survey data.",
    "published": "2003-09-21T15:55:25Z",
    "updated": "2003-09-21T15:55:25Z",
    "authors": [
      "A. J. Storkey",
      "N. C. Hambly",
      "C. K. I. Williams",
      "R. G. Mann"
    ],
    "link": "http://arxiv.org/abs/astro-ph/0309565v1",
    "pdf_link": "http://arxiv.org/pdf/astro-ph/0309565v1"
  },
  {
    "api_id": 9,
    "title": "Global Superdiffusion of Weak Chaos",
    "summary": "A class of kicked rotors is introduced, exhibiting accelerator-mode islands\n(AIs) and {\\em global} superdiffusion for {\\em arbitrarily weak} chaos. The\ncorresponding standard maps are shown to be exactly related to generalized web\nmaps taken modulo an ``oblique cylinder''. Then, in a case that the web-map\norbit structure is periodic in the phase plane, the AIs are essentially {\\em\nnormal} web islands folded back into the cylinder. As a consequence, chaotic\norbits sticking around the AI boundary are accelerated {\\em only} when they\ntraverse tiny {\\em ``acceleration spots''}. This leads to chaotic flights\nhaving a quasiregular {\\em steplike} structure. The global weak-chaos\nsuperdiffusion is thus basically different in nature from the strong-chaos one\nin the usual standard and web maps.",
    "published": "2003-04-24T19:56:51Z",
    "updated": "2003-10-20T19:48:02Z",
    "authors": [
      "Itzhack Dana"
    ],
    "link": "http://arxiv.org/abs/nlin/0304048v2",
    "pdf_link": "http://arxiv.org/pdf/nlin/0304048v2"
  },
  {
    "api_id": 10,
    "title": "Integrating existing cone-shaped and projection-based cardinal direction\n  relations and a TCSP-like decidable generalisation",
    "summary": "We consider the integration of existing cone-shaped and projection-based\ncalculi of cardinal direction relations, well-known in QSR. The more general,\nintegrating language we consider is based on convex constraints of the\nqualitative form $r(x,y)$, $r$ being a cone-shaped or projection-based cardinal\ndirection atomic relation, or of the quantitative form $(\\alpha ,\\beta)(x,y)$,\nwith $\\alpha ,\\beta\\in [0,2\\pi)$ and $(\\beta -\\alpha)\\in [0,\\pi ]$: the meaning\nof the quantitative constraint, in particular, is that point $x$ belongs to the\n(convex) cone-shaped area rooted at $y$, and bounded by angles $\\alpha$ and\n$\\beta$. The general form of a constraint is a disjunction of the form\n$[r_1\\vee...\\vee r_{n_1}\\vee (\\alpha_1,\\beta_1)\\vee...\\vee (\\alpha\n_{n_2},\\beta_{n_2})](x,y)$, with $r_i(x,y)$, $i=1... n_1$, and $(\\alpha\n_i,\\beta_i)(x,y)$, $i=1... n_2$, being convex constraints as described above:\nthe meaning of such a general constraint is that, for some $i=1... n_1$,\n$r_i(x,y)$ holds, or, for some $i=1... n_2$, $(\\alpha_i,\\beta_i)(x,y)$ holds. A\nconjunction of such general constraints is a $\\tcsp$-like CSP, which we will\nrefer to as an $\\scsp$ (Spatial Constraint Satisfaction Problem). An effective\nsolution search algorithm for an $\\scsp$ will be described, which uses (1)\nconstraint propagation, based on a composition operation to be defined, as the\nfiltering method during the search, and (2) the Simplex algorithm, guaranteeing\ncompleteness, at the leaves of the search tree. The approach is particularly\nsuited for large-scale high-level vision, such as, e.g., satellite-like\nsurveillance of a geographic area.",
    "published": "2003-11-28T04:06:56Z",
    "updated": "2003-11-28T04:06:56Z",
    "authors": [
      "Amar Isli"
    ],
    "link": "http://arxiv.org/abs/cs/0311051v1",
    "pdf_link": "http://arxiv.org/pdf/cs/0311051v1"
  },
  {
    "api_id": 11,
    "title": "Self-Organising Networks for Classification: developing Applications to\n  Science Analysis for Astroparticle Physics",
    "summary": "Physics analysis in astroparticle experiments requires the capability of\nrecognizing new phenomena; in order to establish what is new, it is important\nto develop tools for automatic classification, able to compare the final result\nwith data from different detectors. A typical example is the problem of Gamma\nRay Burst detection, classification, and possible association to known sources:\nfor this task physicists will need in the next years tools to associate data\nfrom optical databases, from satellite experiments (EGRET, GLAST), and from\nCherenkov telescopes (MAGIC, HESS, CANGAROO, VERITAS).",
    "published": "2004-02-09T19:44:33Z",
    "updated": "2004-02-09T19:44:33Z",
    "authors": [
      "A. De Angelis",
      "P. Boinee",
      "M. Frailis",
      "E. Milotti"
    ],
    "link": "http://arxiv.org/abs/cs/0402014v1",
    "pdf_link": "http://arxiv.org/pdf/cs/0402014v1"
  },
  {
    "api_id": 12,
    "title": "Gravitational microlensing and dark matter problem in our Galaxy: 10\n  years later",
    "summary": "Foundations of standard theory of microlensing are described, namely we\nconsider microlensing stars in Galactic bulge, the Magellanic Clouds or other\nnearby galaxies. We suppose that gravitational microlenses lie between an Earth\nobserver and these stars. Criteria of an identification of microlensing events\nare discussed. We also consider such microlensing events which do not satisfy\nthese criteria (non-symmetrical light curves, chromatic effects, polarization\neffects). We describe results of MACHO collaboration observations towards the\nLarge Magellanic Cloud (LMC) and the Galactic bulge. Results of EROS\nobservations towards the LMC and OGLE observations towards the Galactic bulge\nare also presented. Future microlensing searches are discussed.",
    "published": "2004-03-26T17:45:52Z",
    "updated": "2004-03-26T17:45:52Z",
    "authors": [
      "Alexander F. Zakharov"
    ],
    "link": "http://arxiv.org/abs/astro-ph/0403619v1",
    "pdf_link": "http://arxiv.org/pdf/astro-ph/0403619v1"
  },
  {
    "api_id": 13,
    "title": "Entangled Quantum Networks",
    "summary": "We present some results from simulation of a network of nodes connected by\nc-NOT gates with nearest neighbors. Though initially we begin with pure states\nof varying boundary conditions, the updating with time quickly involves a\ncomplicated entanglement involving all or most nodes. As a normal c-NOT gate,\nthough unitary for a single pair of nodes, seems to be not so when used in a\nnetwork in a naive way, we use a manifestly unitary form of the transition\nmatrix with c?-NOT gates, which invert the phase as well as flipping the qubit.\nThis leads to complete entanglement of the net, but with variable coefficients\nfor the different components of the superposition. It is interesting to note\nthat by a simple logical back projection the original input state can be\nrecovered in most cases. We also prove that it is not possible for a sequence\nof unitary operators working on a net to make it move from an aperiodic regime\nto a periodic one, unlike some classical cases where phase-locking happens in\ncourse of evolution. However, we show that it is possible to introduce by hand\nperiodic orbits to sets of initial states, which may be useful in forming\ndynamic pattern recognition systems.",
    "published": "2002-03-04T16:06:31Z",
    "updated": "2004-06-29T20:01:12Z",
    "authors": [
      "Fariel Shafee"
    ],
    "link": "http://arxiv.org/abs/quant-ph/0203010v3",
    "pdf_link": "http://arxiv.org/pdf/quant-ph/0203010v3"
  },
  {
    "api_id": 14,
    "title": "Photoionization models of roundish galactic planetary nebulae in the\n  thick disk",
    "summary": "We present the result of photo-ionizing modelling of the three planetary\nnebulae (PNe) A 20, A 15 and MeWe 1-3. All three objects are roughly roundish,\nhighly excited and have a high galactic $z$. The PNe displayed low densities in\nthe shell, but relatively dense halos. A low metallicity and a relative high\nelectron temperature were found. Comparisons with radio observations confirmed\nthe obtained properties. The objects are very likely originating from thick\ndisk stellar progenitors. The distances found investigating the PNe shells are\nsomewhat lower than those derived spectroscopically with the central stars in\nthe past.",
    "published": "2004-10-07T20:50:17Z",
    "updated": "2004-10-07T20:50:17Z",
    "authors": [
      "M. Emprechtinger",
      "T. Rauch",
      "S. Kimeswenger"
    ],
    "link": "http://arxiv.org/abs/astro-ph/0410210v1",
    "pdf_link": "http://arxiv.org/pdf/astro-ph/0410210v1"
  },
  {
    "api_id": 15,
    "title": "A decision support system for ship identification based on the curvature\n  scale space representation",
    "summary": "In this paper, a decision support system for ship identification is\npresented. The system receives as input a silhouette of the vessel to be\nidentified, previously extracted from a side view of the object. This view\ncould have been acquired with imaging sensors operating at different spectral\nranges (CCD, FLIR, image intensifier). The input silhouette is preprocessed and\ncompared to those stored in a database, retrieving a small number of potential\nmatches ranked by their similarity to the target silhouette. This set of\npotential matches is presented to the system operator, who makes the final ship\nidentification. This system makes use of an evolved version of the Curvature\nScale Space (CSS) representation. In the proposed approach, it is curvature\nextrema, instead of zero crossings, that are tracked during silhouette\nevolution, hence improving robustness and enabling to cope successfully with\ncases where the standard CCS representation is found to be unstable. Also, the\nuse of local curvature was replaced with the more robust concept of lobe\nconcavity, with significant additional gains in performance. Experimental\nresults on actual operational imagery prove the excellent performance and\nrobustness of the developed method.",
    "published": "2005-10-11T08:43:04Z",
    "updated": "2005-10-11T08:43:04Z",
    "authors": [
      "Alvaro Enriquez de Luna",
      "Carlos Miravet",
      "Deitze Otaduy",
      "Carlos Dorronsoro"
    ],
    "link": "http://arxiv.org/abs/cs/0510026v1",
    "pdf_link": "http://arxiv.org/pdf/cs/0510026v1"
  },
  {
    "api_id": 16,
    "title": "N-Particle Dynamics of the Euler Equations for Planar Diffeomorphisms",
    "summary": "The Euler equations associated with diffeomorphism groups have received much\nrecent study because of their links with fluid dynamics, computer vision, and\nmechanics. In this paper, we consider the dynamics of $N$ point particles or\n`blobs' moving under the action of the Euler equations associated with the\ngroup of diffeomorphisms of the plane in a variety of different metrics. The 2\nbody problem is always integrable, and we analyze its phase portrait under\ndifferent metrics. In particular, we show that 2-body capturing orbits (in\nwhich the distances between the particles tend to 0 as $t \\to \\infty$) can\noccur when the kernel is sufficiently smooth and the relative initial velocity\nof the particles is sufficiently large. We compute the dynamics of these\n`dipoles' with respect to other test particles, and supplement the calculations\nwith simulations for larger $N$ that illustrate the different regimes.",
    "published": "2005-12-13T22:30:01Z",
    "updated": "2005-12-13T22:30:01Z",
    "authors": [
      "Robert I McLachlan",
      "Stephen Marsland"
    ],
    "link": "http://arxiv.org/abs/nlin/0512030v1",
    "pdf_link": "http://arxiv.org/pdf/nlin/0512030v1"
  },
  {
    "api_id": 17,
    "title": "The Perceptron Algorithm: Image and Signal Decomposition, Compression,\n  and Analysis by Iterative Gaussian Blurring",
    "summary": "A novel algorithm for tunable compression to within the precision of\nreproduction targets, or storage, is proposed. The new algorithm is termed the\n`Perceptron Algorithm', which utilises simple existing concepts in a novel way,\nhas multiple immediate commercial application aspects as well as it opens up a\nmultitude of fronts in computational science and technology. The aims of this\npaper are to present the concepts underlying the algorithm, observations by its\napplication to some example cases, and the identification of a multitude of\npotential areas of applications such as: image compression by orders of\nmagnitude, signal compression including sound as well, image analysis in a\nmultilayered detailed analysis, pattern recognition and matching and rapid\ndatabase searching (e.g. face recognition), motion analysis, biomedical\napplications e.g. in MRI and CAT scan image analysis and compression, as well\nas hints on the link of these ideas to the way how biological memory might work\nleading to new points of view in neural computation. Commercial applications of\nimmediate interest are the compression of images at the source (e.g.\nphotographic equipment, scanners, satellite imaging systems), DVD film\ncompression, pay-per-view downloads acceleration and many others identified in\nthe present paper at its conclusion and future work section.",
    "published": "2006-01-24T17:23:17Z",
    "updated": "2006-01-26T08:42:40Z",
    "authors": [
      "Vassilios S. Vassiliadis"
    ],
    "link": "http://arxiv.org/abs/cs/0601105v3",
    "pdf_link": "http://arxiv.org/pdf/cs/0601105v3"
  },
  {
    "api_id": 18,
    "title": "A higher-order active contour model of a `gas of circles' and its\n  application to tree crown extraction",
    "summary": "Many image processing problems involve identifying the region in the image\ndomain occupied by a given entity in the scene. Automatic solution of these\nproblems requires models that incorporate significant prior knowledge about the\nshape of the region. Many methods for including such knowledge run into\ndifficulties when the topology of the region is unknown a priori, for example\nwhen the entity is composed of an unknown number of similar objects.\nHigher-order active contours (HOACs) represent one method for the modelling of\nnon-trivial prior knowledge about shape without necessarily constraining region\ntopology, via the inclusion of non-local interactions between region boundary\npoints in the energy defining the model. The case of an unknown number of\ncircular objects arises in a number of domains, e.g. medical, biological,\nnanotechnological, and remote sensing imagery. Regions composed of an a priori\nunknown number of circles may be referred to as a `gas of circles'. In this\nreport, we present a HOAC model of a `gas of circles'. In order to guarantee\nstable circles, we conduct a stability analysis via a functional Taylor\nexpansion of the HOAC energy around a circular shape. This analysis fixes one\nof the model parameters in terms of the others and constrains the rest. In\nconjunction with a suitable likelihood energy, we apply the model to the\nextraction of tree crowns from aerial imagery, and show that the new model\noutperforms other techniques.",
    "published": "2006-11-22T13:44:11Z",
    "updated": "2006-11-22T13:44:11Z",
    "authors": [
      "Peter Horvath",
      "Ian Jermyn",
      "Zoltan Kato",
      "Josiane Zerubia"
    ],
    "link": "http://arxiv.org/abs/cs/0611115v1",
    "pdf_link": "http://arxiv.org/pdf/cs/0611115v1"
  },
  {
    "api_id": 19,
    "title": "Evocation and elaboration of solutions: Different types of\n  problem-solving actions. An empirical study on the design of an aerospace\n  artifact",
    "summary": "An observational study was conducted on a professional designer working on a\ndesign project in aerospace industry. The protocol data were analyzed in order\nto gain insight into the actions the designer used for the development of a\nsolution to the corresponding problem. Different processes are described: from\nthe \"simple\" evocation of a solution existing in memory, to the elaboration of\na \"new\" solution out of mnesic entities without any clear link to the current\nproblem. Control is addressed in so far as it concerns the priority among the\ndifferent types of development processes: the progression from evocation of a\n\"standard\" solution to elaboration of a \"new\" solution is supposed to\ncorrespond to the resulting order, that is, the one in which the designer's\nactivity proceeds. Short discussions of * the double status of \"problem\" and\n\"solution,\" * the problem/solution knowledge units in memory and their access,\nand * the different abstraction levels on which problem and solution\nrepresentations are developed, are illustrated by the results.",
    "published": "2006-11-30T22:49:11Z",
    "updated": "2006-11-30T22:49:11Z",
    "authors": [
      "Willemien Visser"
    ],
    "link": "http://arxiv.org/abs/cs/0612006v1",
    "pdf_link": "http://arxiv.org/pdf/cs/0612006v1"
  },
  {
    "api_id": 20,
    "title": "Fast Wavelet-Based Visual Classification",
    "summary": "We investigate a biologically motivated approach to fast visual\nclassification, directly inspired by the recent work of Serre et al.\nSpecifically, trading-off biological accuracy for computational efficiency, we\nexplore using wavelet and grouplet-like transforms to parallel the tuning of\nvisual cortex V1 and V2 cells, alternated with max operations to achieve scale\nand translation invariance. A feature selection procedure is applied during\nlearning to accelerate recognition. We introduce a simple attention-like\nfeedback mechanism, significantly improving recognition and robustness in\nmultiple-object scenes. In experiments, the proposed algorithm achieves or\nexceeds state-of-the-art success rate on object recognition, texture and\nsatellite image classification, language identification and sound\nclassification.",
    "published": "2008-06-08T10:15:04Z",
    "updated": "2008-06-08T10:15:04Z",
    "authors": [
      "Guoshen Yu",
      "Jean-Jacques Slotine"
    ],
    "link": "http://arxiv.org/abs/0806.1446v1",
    "pdf_link": "http://arxiv.org/pdf/0806.1446v1"
  },
  {
    "api_id": 21,
    "title": "An Image-Based Sensor System for Autonomous Rendez-Vous with\n  Uncooperative Satellites",
    "summary": "In this paper are described the image processing algorithms developed by\nSENER, Ingenieria y Sistemas to cope with the problem of image-based,\nautonomous rendez-vous (RV) with an orbiting satellite. The methods developed\nhave a direct application in the OLEV (Orbital Life Extension Extension\nVehicle) mission. OLEV is a commercial mission under development by a\nconsortium formed by Swedish Space Corporation, Kayser-Threde and SENER, aimed\nto extend the operational life of geostationary telecommunication satellites by\nsupplying them control, navigation and guidance services. OLEV is planned to\nuse a set of cameras to determine the angular position and distance to the\nclient satellite during the complete phases of rendez-vous and docking, thus\nenabling the operation with satellites not equipped with any specific\nnavigational aid to provide support during the approach. The ability to operate\nwith un-equipped client satellites significantly expands the range of\napplicability of the system under development, compared to other competing\nvideo technologies already tested in previous spatial missions, such as the\nones described here below.",
    "published": "2008-07-28T15:46:02Z",
    "updated": "2008-07-28T15:46:02Z",
    "authors": [
      "Carlos Miravet",
      "Luis Pascual",
      "Eloise Krouch",
      "Juan Manuel del Cura"
    ],
    "link": "http://arxiv.org/abs/0807.4478v1",
    "pdf_link": "http://arxiv.org/pdf/0807.4478v1"
  },
  {
    "api_id": 22,
    "title": "Simulated annealing for weighted polygon packing",
    "summary": "In this paper we present a new algorithm for a layout optimization problem:\nthis concerns the placement of weighted polygons inside a circular container,\nthe two objectives being to minimize imbalance of mass and to minimize the\nradius of the container. This problem carries real practical significance in\nindustrial applications (such as the design of satellites), as well as being of\nsignificant theoretical interest. Previous work has dealt with circular or\nrectangular objects, but here we deal with the more realistic case where\nobjects may be represented as polygons and the polygons are allowed to rotate.\nWe present a solution based on simulated annealing and first test it on\ninstances with known optima. Our results show that the algorithm obtains\ncontainer radii that are close to optimal. We also compare our method with\nexisting algorithms for the (special) rectangular case. Experimental results\nshow that our approach out-performs these methods in terms of solution quality.",
    "published": "2008-09-29T16:22:28Z",
    "updated": "2008-09-29T16:22:28Z",
    "authors": [
      "Yi-Chun Xu",
      "Ren-Bin Xiao",
      "Martyn Amos"
    ],
    "link": "http://arxiv.org/abs/0809.5005v1",
    "pdf_link": "http://arxiv.org/pdf/0809.5005v1"
  },
  {
    "api_id": 23,
    "title": "Machine learning techniques for astrophysical modelling and photometric\n  redshift estimation of quasars in optical sky surveys",
    "summary": "Machine learning techniques are utilised in several areas of astrophysical\nresearch today. This dissertation addresses the application of ML techniques to\ntwo classes of problems in astrophysics, namely, the analysis of individual\nastronomical phenomena over time and the automated, simultaneous analysis of\nthousands of objects in large optical sky surveys. Specifically investigated\nare (1) techniques to approximate the precise orbits of the satellites of\nJupiter and Saturn given Earth-based observations as well as (2) techniques to\nquickly estimate the distances of quasars observed in the Sloan Digital Sky\nSurvey. Learning methods considered include genetic algorithms, particle swarm\noptimisation, artificial neural networks, and radial basis function networks.\n  The first part of this dissertation demonstrates that GAs and PSO can both be\nefficiently used to model functions that are highly non-linear in several\ndimensions. It is subsequently demonstrated in the second part that ANNs and\nRBFNs can be used as effective predictors of spectroscopic redshift given\naccurate photometry, especially in combination with other learning-based\napproaches described in the literature. Careful application of these and other\nML techniques to problems in astronomy and astrophysics will contribute to a\nbetter understanding of stellar evolution, binary star systems, cosmology, and\nthe large-scale structure of the universe.",
    "published": "2008-11-04T14:31:47Z",
    "updated": "2009-01-06T19:49:42Z",
    "authors": [
      "N. Daniel Kumar"
    ],
    "link": "http://arxiv.org/abs/0811.0520v2",
    "pdf_link": "http://arxiv.org/pdf/0811.0520v2"
  },
  {
    "api_id": 24,
    "title": "Matrix Completion With Noise",
    "summary": "On the heels of compressed sensing, a remarkable new field has very recently\nemerged. This field addresses a broad range of problems of significant\npractical interest, namely, the recovery of a data matrix from what appears to\nbe incomplete, and perhaps even corrupted, information. In its simplest form,\nthe problem is to recover a matrix from a small sample of its entries, and\ncomes up in many areas of science and engineering including collaborative\nfiltering, machine learning, control, remote sensing, and computer vision to\nname a few.\n  This paper surveys the novel literature on matrix completion, which shows\nthat under some suitable conditions, one can recover an unknown low-rank matrix\nfrom a nearly minimal set of entries by solving a simple convex optimization\nproblem, namely, nuclear-norm minimization subject to data constraints.\nFurther, this paper introduces novel results showing that matrix completion is\nprovably accurate even when the few observed entries are corrupted with a small\namount of noise. A typical result is that one can recover an unknown n x n\nmatrix of low rank r from just about nr log^2 n noisy samples with an error\nwhich is proportional to the noise level. We present numerical results which\ncomplement our quantitative analysis and show that, in practice, nuclear norm\nminimization accurately fills in the many missing entries of large low-rank\nmatrices from just a few noisy samples. Some analogies between matrix\ncompletion and compressed sensing are discussed throughout.",
    "published": "2009-03-18T10:59:52Z",
    "updated": "2009-03-18T10:59:52Z",
    "authors": [
      "Emmanuel J. Candes",
      "Yaniv Plan"
    ],
    "link": "http://arxiv.org/abs/0903.3131v1",
    "pdf_link": "http://arxiv.org/pdf/0903.3131v1"
  },
  {
    "api_id": 25,
    "title": "Time manipulation technique for speeding up reinforcement learning in\n  simulations",
    "summary": "A technique for speeding up reinforcement learning algorithms by using time\nmanipulation is proposed. It is applicable to failure-avoidance control\nproblems running in a computer simulation. Turning the time of the simulation\nbackwards on failure events is shown to speed up the learning by 260% and\nimprove the state space exploration by 12% on the cart-pole balancing task,\ncompared to the conventional Q-learning and Actor-Critic algorithms.",
    "published": "2009-03-28T01:09:00Z",
    "updated": "2009-03-28T01:09:00Z",
    "authors": [
      "Petar Kormushev",
      "Kohei Nomoto",
      "Fangyan Dong",
      "Kaoru Hirota"
    ],
    "link": "http://arxiv.org/abs/0903.4930v1",
    "pdf_link": "http://arxiv.org/pdf/0903.4930v1"
  },
  {
    "api_id": 26,
    "title": "Fast Algorithms for Mining Interesting Frequent Itemsets without Minimum\n  Support",
    "summary": "Real world datasets are sparse, dirty and contain hundreds of items. In such\nsituations, discovering interesting rules (results) using traditional frequent\nitemset mining approach by specifying a user defined input support threshold is\nnot appropriate. Since without any domain knowledge, setting support threshold\nsmall or large can output nothing or a large number of redundant uninteresting\nresults. Recently a novel approach of mining only N-most/Top-K interesting\nfrequent itemsets has been proposed, which discovers the top N interesting\nresults without specifying any user defined support threshold. However, mining\ninteresting frequent itemsets without minimum support threshold are more costly\nin terms of itemset search space exploration and processing cost. Thereby, the\nefficiency of their mining highly depends upon three main factors (1) Database\nrepresentation approach used for itemset frequency counting, (2) Projection of\nrelevant transactions to lower level nodes of search space and (3) Algorithm\nimplementation technique. Therefore, to improve the efficiency of mining\nprocess, in this paper we present two novel algorithms called (N-MostMiner and\nTop-K-Miner) using the bit-vector representation approach which is very\nefficient in terms of itemset frequency counting and transactions projection.\nIn addition to this, several efficient implementation techniques of N-MostMiner\nand Top-K-Miner are also present which we experienced in our implementation.\nOur experimental results on benchmark datasets suggest that the NMostMiner and\nTop-K-Miner are very efficient in terms of processing time as compared to\ncurrent best algorithms BOMO and TFP.",
    "published": "2009-04-21T19:07:35Z",
    "updated": "2009-04-21T19:07:35Z",
    "authors": [
      "Shariq Bashir",
      "Zahoor Jan",
      "Abdul Rauf Baig"
    ],
    "link": "http://arxiv.org/abs/0904.3319v1",
    "pdf_link": "http://arxiv.org/pdf/0904.3319v1"
  },
  {
    "api_id": 27,
    "title": "The VOISE Algorithm: a Versatile Tool for Automatic Segmentation of\n  Astronomical Images",
    "summary": "The auroras on Jupiter and Saturn can be studied with a high sensitivity and\nresolution by the Hubble Space Telescope (HST) ultraviolet (UV) and\nfar-ultraviolet (FUV) Space Telescope spectrograph (STIS) and Advanced Camera\nfor Surveys (ACS) instruments. We present results of automatic detection and\nsegmentation of Jupiter's auroral emissions as observed by HST ACS instrument\nwith VOronoi Image SEgmentation (VOISE). VOISE is a dynamic algorithm for\npartitioning the underlying pixel grid of an image into regions according to a\nprescribed homogeneity criterion. The algorithm consists of an iterative\nprocedure that dynamically constructs a tessellation of the image plane based\non a Voronoi Diagram, until the intensity of the underlying image within each\nregion is classified as homogeneous. The computed tessellations allow the\nextraction of quantitative information about the auroral features such as mean\nintensity, latitudinal and longitudinal extents and length scales. These\noutputs thus represent a more automated and objective method of characterising\nauroral emissions than manual inspection.",
    "published": "2009-06-10T10:48:33Z",
    "updated": "2009-06-10T10:48:33Z",
    "authors": [
      "P. Guio",
      "N. Achilleos"
    ],
    "link": "http://arxiv.org/abs/0906.1905v1",
    "pdf_link": "http://arxiv.org/pdf/0906.1905v1"
  },
  {
    "api_id": 28,
    "title": "Segmentation of Facial Expressions Using Semi-Definite Programming and\n  Generalized Principal Component Analysis",
    "summary": "In this paper, we use semi-definite programming and generalized principal\ncomponent analysis (GPCA) to distinguish between two or more different facial\nexpressions. In the first step, semi-definite programming is used to reduce the\ndimension of the image data and \"unfold\" the manifold which the data points\n(corresponding to facial expressions) reside on. Next, GPCA is used to fit a\nseries of subspaces to the data points and associate each data point with a\nsubspace. Data points that belong to the same subspace are claimed to belong to\nthe same facial expression category. An example is provided.",
    "published": "2009-06-09T19:50:10Z",
    "updated": "2009-06-10T20:53:21Z",
    "authors": [
      "Behnood Gholami",
      "Allen R. Tannenbaum",
      "Wassim M. Haddad"
    ],
    "link": "http://arxiv.org/abs/0906.1763v2",
    "pdf_link": "http://arxiv.org/pdf/0906.1763v2"
  },
  {
    "api_id": 29,
    "title": "Orbital and physical parameters of eclipsing binaries from the ASAS\n  catalogue -- I. A sample of systems with components' masses between 1 and 2\n  M$_\\odot$",
    "summary": "We derive the absolute physical and orbital parameters for a sample of 18\ndetached eclipsing binaries from the \\emph{All Sky Automated Survey} (ASAS)\ndatabase based on the available photometry and our own radial velocity\nmeasurements. The radial velocities (RVs) are computed using spectra we\ncollected with the 3.9-m Anglo-Australian Telescope and its \\emph{University\nCollege London Echelle Spectrograph} and the 1.9-m SAAO Radcliffe telescope and\nits \\emph{Grating Instrument for Radiation Analysis with a Fibre Fed Echelle}.\nIn order to obtain as precise RVs as possible, most of the systems were\nobserved with an iodine cell available at the AAT/UCLES and/or analyzed using\nthe two-dimensional cross-correlation technique (TODCOR). The RVs were measured\nwith TODCOR using synthetic template spectra as references. However, for two\nobjects we used our own approach to the tomographic disentangling of the binary\nspectra to provide observed template spectra for the RV measurements and to\nimprove the RV precision even more. For one of these binaries, AI Phe, we were\nable to the obtain an orbital solution with an RV $rms$ of 62 and 24 m s$^{-1}$\nfor the primary and secondary respectively. For this system, the precision in\n$M \\sin^3{i}$ is 0.08%. For the analysis, we used the photometry available in\nthe ASAS database. We combined the RV and light curves using PHOEBE and JKTEBOP\ncodes to obtain the absolute physical parameters of the systems. Having precise\nRVs we were able to reach $\\sim$0.2 % precision (or better) in masses in\nseveral cases but in radii, due to the limited precision of the ASAS\nphotometry, we were able to reach a precision of only 1% in one case and 3-5 %\nin a few more cases. For the majority of our objects, the orbital and physical\nanalysis is presented for the first time.",
    "published": "2009-08-24T17:41:54Z",
    "updated": "2009-08-24T17:41:54Z",
    "authors": [
      "K. G. Hełminiak",
      "M. Konacki",
      "M. Ratajczak",
      "M. Muterspaugh"
    ],
    "link": "http://arxiv.org/abs/0908.3471v1",
    "pdf_link": "http://arxiv.org/pdf/0908.3471v1"
  },
  {
    "api_id": 30,
    "title": "Astroinformatics: A 21st Century Approach to Astronomy",
    "summary": "Data volumes from multiple sky surveys have grown from gigabytes into\nterabytes during the past decade, and will grow from terabytes into tens (or\nhundreds) of petabytes in the next decade. This exponential growth of new data\nboth enables and challenges effective astronomical research, requiring new\napproaches. Thus far, astronomy has tended to address these challenges in an\ninformal and ad hoc manner, with the necessary special expertise being assigned\nto e-Science or survey science. However, we see an even wider scope and\ntherefore promote a broader vision of this data-driven revolution in\nastronomical research. For astronomy to effectively cope with and reap the\nmaximum scientific return from existing and future large sky surveys,\nfacilities, and data-producing projects, we need our own information science\nspecialists. We therefore recommend the formal creation, recognition, and\nsupport of a major new discipline, which we call Astroinformatics.\nAstroinformatics includes a set of naturally-related specialties including data\norganization, data description, astronomical classification taxonomies,\nastronomical concept ontologies, data mining, machine learning, visualization,\nand astrostatistics. By virtue of its new stature, we propose that astronomy\nnow needs to integrate Astroinformatics as a formal sub-discipline within\nagency funding plans, university departments, research programs, graduate\ntraining, and undergraduate education. Now is the time for the recognition of\nAstroinformatics as an essential methodology of astronomical research. The\nfuture of astronomy depends on it.",
    "published": "2009-09-22T02:21:49Z",
    "updated": "2009-09-22T02:21:49Z",
    "authors": [
      "Kirk D. Borne"
    ],
    "link": "http://arxiv.org/abs/0909.3892v1",
    "pdf_link": "http://arxiv.org/pdf/0909.3892v1"
  },
  {
    "api_id": 31,
    "title": "A binary engine fuelling HD87643' s complex circumstellar environment,\n  using AMBER/VLTI",
    "summary": "Context. The star HD 87643, exhibiting the \"B[e] phenomenon\", has one of the\nmost extreme infrared excesses for this object class. It harbours a large\namount of both hot and cold dust, and is surrounded by an extended reflection\nnebula. Aims. One of our major goals was to investigate the presence of a\ncompanion in HD87643. In addition, the presence of close dusty material was\ntested through a combination of multi-wavelength high spatial 5Aresolution\nobservations. Methods. We observed HD 87643 with high spatial resolution\ntechniques, using the near-IR AMBER/VLTI interferometer with baselines ranging\nfrom 60 m to 130 m and the mid-IR MIDI/VLTI interferometer with baselines\nranging from 25 m to 65 m. These observations are complemented by NACO/VLT\nadaptive-optics-corrected images in the K and L-bands, ESO-2.2m optical\nWide-Field Imager large-scale images in the B, V and R-bands, Results. We\nreport the direct detection of a companion to HD 87643 by means of image\nsynthesis using the AMBER/VLTI instrument. The presence of the companion is\nconfirmed by the MIDI and NACO data, although with a lower confidence. The\ncompanion is separated by ~ 34 mas with a roughly north-south orientation. The\nperiod must be large (several tens of years) and hence the orbital parameters\nare not determined yet. Binarity with high eccentricity might be the key to\ninterpreting the extreme characteristics of this system, namely a dusty\ncircumstellar envelope around the primary, a compact dust nebulosity around the\nbinary system and a complex extended nebula witnessing past violent ejections.",
    "published": "2009-08-03T11:20:08Z",
    "updated": "2009-09-22T10:01:25Z",
    "authors": [
      "Florentin Millour",
      "Olivier Chesneau",
      "Marcelo Borges Fernandes",
      "Anthony Meilland",
      "Gilbert Mars",
      "C. Benoist",
      "E. Thiébaut",
      "Philippe Stee",
      "K. -H. Hofmann",
      "Fabien Baron",
      "John R. Young",
      "Philippe Bendjoya",
      "A. C. Carciofi",
      "Armando Domiciano De Souza",
      "Thomas Driebe",
      "Slobodan Jankov",
      "Pierre Kervella",
      "R. G. Petrov",
      "Sylvie Robbe-Dubois",
      "Farrokh Vakili",
      "L. B. F. M. Waters",
      "Gerd Weigelt"
    ],
    "link": "http://arxiv.org/abs/0908.0227v2",
    "pdf_link": "http://arxiv.org/pdf/0908.0227v2"
  },
  {
    "api_id": 32,
    "title": "Initialization Free Graph Based Clustering",
    "summary": "This paper proposes an original approach to cluster multi-component data\nsets, including an estimation of the number of clusters. From the construction\nof a minimal spanning tree with Prim's algorithm, and the assumption that the\nvertices are approximately distributed according to a Poisson distribution, the\nnumber of clusters is estimated by thresholding the Prim's trajectory. The\ncorresponding cluster centroids are then computed in order to initialize the\ngeneralized Lloyd's algorithm, also known as $K$-means, which allows to\ncircumvent initialization problems. Some results are derived for evaluating the\nfalse positive rate of our cluster detection algorithm, with the help of\napproximations relevant in Euclidean spaces. Metrics used for measuring\nsimilarity between multi-dimensional data points are based on symmetrical\ndivergences. The use of these informational divergences together with the\nproposed method leads to better results, compared to other clustering methods\nfor the problem of astrophysical data processing. Some applications of this\nmethod in the multi/hyper-spectral imagery domain to a satellite view of Paris\nand to an image of the Mars planet are also presented. In order to demonstrate\nthe usefulness of divergences in our problem, the method with informational\ndivergence as similarity measure is compared with the same method using\nclassical metrics. In the astrophysics application, we also compare the method\nwith the spectral clustering algorithms.",
    "published": "2009-09-24T09:35:10Z",
    "updated": "2009-09-24T09:35:10Z",
    "authors": [
      "Laurent Galluccio",
      "Olivier J. J. Michel",
      "Pierre Comon",
      "Eric Slezak",
      "Alfred O. Hero"
    ],
    "link": "http://arxiv.org/abs/0909.4395v1",
    "pdf_link": "http://arxiv.org/pdf/0909.4395v1"
  },
  {
    "api_id": 33,
    "title": "Proceedings 6th International Workshop on Local Search Techniques in\n  Constraint Satisfaction",
    "summary": "LSCS is a satellite workshop of the international conference on principles\nand practice of Constraint Programming (CP), since 2004. It is devoted to local\nsearch techniques in constraint satisfaction, and focuses on all aspects of\nlocal search techniques, including: design and implementation of new\nalgorithms, hybrid stochastic-systematic search, reactive search optimization,\nadaptive search, modeling for local-search, global constraints, flexibility and\nrobustness, learning methods, and specific applications.",
    "published": "2009-10-08T06:27:26Z",
    "updated": "2009-10-08T06:27:26Z",
    "authors": [
      "Yves Deville",
      "Christine Solnon"
    ],
    "link": "http://arxiv.org/abs/0910.1404v1",
    "pdf_link": "http://arxiv.org/pdf/0910.1404v1"
  },
  {
    "api_id": 34,
    "title": "The Cyborg Astrobiologist: Testing a Novelty-Detection Algorithm on Two\n  Mobile Exploration Systems at Rivas Vaciamadrid in Spain and at the Mars\n  Desert Research Station in Utah",
    "summary": "(ABRIDGED) In previous work, two platforms have been developed for testing\ncomputer-vision algorithms for robotic planetary exploration (McGuire et al.\n2004b,2005; Bartolo et al. 2007). The wearable-computer platform has been\ntested at geological and astrobiological field sites in Spain (Rivas\nVaciamadrid and Riba de Santiuste), and the phone-camera has been tested at a\ngeological field site in Malta. In this work, we (i) apply a Hopfield\nneural-network algorithm for novelty detection based upon color, (ii) integrate\na field-capable digital microscope on the wearable computer platform, (iii)\ntest this novelty detection with the digital microscope at Rivas Vaciamadrid,\n(iv) develop a Bluetooth communication mode for the phone-camera platform, in\norder to allow access to a mobile processing computer at the field sites, and\n(v) test the novelty detection on the Bluetooth-enabled phone-camera connected\nto a netbook computer at the Mars Desert Research Station in Utah. This systems\nengineering and field testing have together allowed us to develop a real-time\ncomputer-vision system that is capable, for example, of identifying lichens as\nnovel within a series of images acquired in semi-arid desert environments. We\nacquired sequences of images of geologic outcrops in Utah and Spain consisting\nof various rock types and colors to test this algorithm. The algorithm robustly\nrecognized previously-observed units by their color, while requiring only a\nsingle image or a few images to learn colors as familiar, demonstrating its\nfast learning capability.",
    "published": "2009-10-28T18:26:39Z",
    "updated": "2009-10-28T18:26:39Z",
    "authors": [
      "P. C. McGuire",
      "C. Gross",
      "L. Wendt",
      "A. Bonnici",
      "V. Souza-Egipsy",
      "J. Ormo",
      "E. Diaz-Martinez",
      "B. H. Foing",
      "R. Bose",
      "S. Walter",
      "M. Oesker",
      "J. Ontrup",
      "R. Haschke",
      "H. Ritter"
    ],
    "link": "http://arxiv.org/abs/0910.5454v1",
    "pdf_link": "http://arxiv.org/pdf/0910.5454v1"
  },
  {
    "api_id": 35,
    "title": "Designing fuzzy rule based classifier using self-organizing feature map\n  for analysis of multispectral satellite images",
    "summary": "We propose a novel scheme for designing fuzzy rule based classifier. An SOFM\nbased method is used for generating a set of prototypes which is used to\ngenerate a set of fuzzy rules. Each rule represents a region in the feature\nspace that we call the context of the rule. The rules are tuned with respect to\ntheir context. We justified that the reasoning scheme may be different in\ndifferent context leading to context sensitive inferencing. To realize context\nsensitive inferencing we used a softmin operator with a tunable parameter. The\nproposed scheme is tested on several multispectral satellite image data sets\nand the performance is found to be much better than the results reported in the\nliterature.",
    "published": "2009-11-23T14:26:00Z",
    "updated": "2009-11-23T14:26:00Z",
    "authors": [
      "Nikhil R. Pal",
      "Arijit Laha",
      "J. Das"
    ],
    "link": "http://arxiv.org/abs/0911.4414v1",
    "pdf_link": "http://arxiv.org/pdf/0911.4414v1"
  },
  {
    "api_id": 36,
    "title": "Land cover classification using fuzzy rules and aggregation of\n  contextual information through evidence theory",
    "summary": "Land cover classification using multispectral satellite image is a very\nchallenging task with numerous practical applications. We propose a multi-stage\nclassifier that involves fuzzy rule extraction from the training data and then\ngeneration of a possibilistic label vector for each pixel using the fuzzy rule\nbase. To exploit the spatial correlation of land cover types we propose four\ndifferent information aggregation methods which use the possibilistic class\nlabel of a pixel and those of its eight spatial neighbors for making the final\nclassification decision. Three of the aggregation methods use Dempster-Shafer\ntheory of evidence while the remaining one is modeled after the fuzzy k-NN\nrule. The proposed methods are tested with two benchmark seven channel\nsatellite images and the results are found to be quite satisfactory. They are\nalso compared with a Markov random field (MRF) model-based contextual\nclassification method and found to perform consistently better.",
    "published": "2009-11-23T14:33:27Z",
    "updated": "2009-11-23T14:33:27Z",
    "authors": [
      "Arijit Laha",
      "Nikhil R. Pal",
      "J. Das"
    ],
    "link": "http://arxiv.org/abs/0911.4416v1",
    "pdf_link": "http://arxiv.org/pdf/0911.4416v1"
  },
  {
    "api_id": 37,
    "title": "Biogeography based Satellite Image Classification",
    "summary": "Biogeography is the study of the geographical distribution of biological\norganisms. The mindset of the engineer is that we can learn from nature.\nBiogeography Based Optimization is a burgeoning nature inspired technique to\nfind the optimal solution of the problem. Satellite image classification is an\nimportant task because it is the only way we can know about the land cover map\nof inaccessible areas. Though satellite images have been classified in past by\nusing various techniques, the researchers are always finding alternative\nstrategies for satellite image classification so that they may be prepared to\nselect the most appropriate technique for the feature extraction task in hand.\nThis paper is focused on classification of the satellite image of a particular\nland cover using the theory of Biogeography based Optimization. The original\nBBO algorithm does not have the inbuilt property of clustering which is\nrequired during image classification. Hence modifications have been proposed to\nthe original algorithm and the modified algorithm is used to classify the\nsatellite image of a given region. The results indicate that highly accurate\nland cover features can be extracted effectively when the proposed algorithm is\nused.",
    "published": "2009-12-05T12:54:24Z",
    "updated": "2009-12-05T12:54:24Z",
    "authors": [
      "V. K. Panchal",
      "Parminder Singh",
      "Navdeep Kaur",
      "Harish Kundra"
    ],
    "link": "http://arxiv.org/abs/0912.1009v1",
    "pdf_link": "http://arxiv.org/pdf/0912.1009v1"
  },
  {
    "api_id": 38,
    "title": "A Formal Framework of Virtual Organisations as Agent Societies",
    "summary": "We propose a formal framework that supports a model of agent-based Virtual\nOrganisations (VOs) for service grids and provides an associated operational\nmodel for the creation of VOs. The framework is intended to be used for\ndescribing different service grid applications based on multiple agents and, as\na result, it abstracts away from any realisation choices of the service grid\napplication, the agents involved to support the applications and their\ninteractions. Within the proposed framework VOs are seen as emerging from\nsocieties of agents, where agents are abstractly characterised by goals and\nroles they can play within VOs. In turn, VOs are abstractly characterised by\nthe agents participating in them with specific roles, as well as the workflow\nof services and corresponding contracts suitable for achieving the goals of the\nparticipating agents. We illustrate the proposed framework with an earth\nobservation scenario.",
    "published": "2010-01-25T12:38:22Z",
    "updated": "2010-01-25T12:38:22Z",
    "authors": [
      "Jarred McGinnis",
      "Kostas Stathis",
      "Francesca Toni"
    ],
    "link": "http://arxiv.org/abs/1001.4405v1",
    "pdf_link": "http://arxiv.org/pdf/1001.4405v1"
  },
  {
    "api_id": 39,
    "title": "A Comparative Study of Removal Noise from Remote Sensing Image",
    "summary": "This paper attempts to undertake the study of three types of noise such as\nSalt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN).\nDifferent noise densities have been removed between 10% to 60% by using five\ntypes of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian\nFilter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The\nsame is applied to the Saturn remote sensing image and they are compared with\none another. The comparative study is conducted with the help of Mean Square\nErrors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base\nmethod for removal of noise from remote sensing image.",
    "published": "2010-02-05T08:34:39Z",
    "updated": "2010-02-05T08:34:39Z",
    "authors": [
      "Salem Saleh Al-amri",
      "N. V. Kalyankar",
      "S. D. Khamitkar"
    ],
    "link": "http://arxiv.org/abs/1002.1148v1",
    "pdf_link": "http://arxiv.org/pdf/1002.1148v1"
  },
  {
    "api_id": 40,
    "title": "An Intelligent System For Effective Forest Fire Detection Using Spatial\n  Data",
    "summary": "The explosive growth of spatial data and extensive utilization of spatial\ndatabases emphasize the necessity for the automated discovery of spatial\nknowledge. In modern times, spatial data mining has emerged as an area of\nvoluminous research. Forest fires are a chief environmental concern, causing\neconomical and ecological damage while endangering human lives across the\nworld. The fast or early detection of forest fires is a vital element for\ncontrolling such phenomenon. The application of remote sensing is at present a\nsignificant method for forest fires monitoring, particularly in vast and remote\nareas. Different methods have been presented by researchers for forest fire\ndetection. The motivation behind this research is to obtain beneficial\ninformation from images in the forest spatial data and use the same in the\ndetermination of regions at the risk of fires by utilizing Image Processing and\nArtificial Intelligence techniques. This paper presents an intelligent system\nto detect the presence of forest fires in the forest spatial data using\nArtificial Neural Networks. The digital images in the forest spatial data are\nconverted from RGB to XYZ color space and then segmented by employing\nanisotropic diffusion to identify the fire regions. Subsequently, Radial Basis\nFunction Neural Network is employed in the design of the intelligent system,\nwhich is trained with the color space values of the segmented fire regions.\nExtensive experimental assessments on publicly available spatial data\nillustrated the efficiency of the proposed system in effectively detecting\nforest fires.",
    "published": "2010-02-10T20:15:14Z",
    "updated": "2010-02-10T20:15:14Z",
    "authors": [
      "K. Angayarkkani",
      "N. Radhakrishnan"
    ],
    "link": "http://arxiv.org/abs/1002.2199v1",
    "pdf_link": "http://arxiv.org/pdf/1002.2199v1"
  },
  {
    "api_id": 41,
    "title": "Plugin procedure in segmentation and application to hyperspectral image\n  segmentation",
    "summary": "In this article we give our contribution to the problem of segmentation with\nplug-in procedures. We give general sufficient conditions under which plug in\nprocedure are efficient. We also give an algorithm that satisfy these\nconditions. We give an application of the used algorithm to hyperspectral\nimages segmentation. Hyperspectral images are images that have both spatial and\nspectral coherence with thousands of spectral bands on each pixel. In the\nproposed procedure we combine a reduction dimension technique and a spatial\nregularisation technique. This regularisation is based on the mixlet\nmodelisation of Kolaczyck and Al.",
    "published": "2010-02-19T13:48:57Z",
    "updated": "2010-02-19T13:48:57Z",
    "authors": [
      "R. Girard"
    ],
    "link": "http://arxiv.org/abs/1002.3744v1",
    "pdf_link": "http://arxiv.org/pdf/1002.3744v1"
  },
  {
    "api_id": 42,
    "title": "Supervised Classification Performance of Multispectral Images",
    "summary": "Nowadays government and private agencies use remote sensing imagery for a\nwide range of applications from military applications to farm development. The\nimages may be a panchromatic, multispectral, hyperspectral or even\nultraspectral of terra bytes. Remote sensing image classification is one\namongst the most significant application worlds for remote sensing. A few\nnumber of image classification algorithms have proved good precision in\nclassifying remote sensing data. But, of late, due to the increasing\nspatiotemporal dimensions of the remote sensing data, traditional\nclassification algorithms have exposed weaknesses necessitating further\nresearch in the field of remote sensing image classification. So an efficient\nclassifier is needed to classify the remote sensing images to extract\ninformation. We are experimenting with both supervised and unsupervised\nclassification. Here we compare the different classification methods and their\nperformances. It is found that Mahalanobis classifier performed the best in our\nclassification.",
    "published": "2010-02-22T03:12:14Z",
    "updated": "2010-02-22T03:12:14Z",
    "authors": [
      "K. Perumal",
      "R. Bhaskaran"
    ],
    "link": "http://arxiv.org/abs/1002.4046v1",
    "pdf_link": "http://arxiv.org/pdf/1002.4046v1"
  },
  {
    "api_id": 43,
    "title": "Agent Based Approaches to Engineering Autonomous Space Software",
    "summary": "Current approaches to the engineering of space software such as satellite\ncontrol systems are based around the development of feedback controllers using\npackages such as MatLab's Simulink toolbox. These provide powerful tools for\nengineering real time systems that adapt to changes in the environment but are\nlimited when the controller itself needs to be adapted.\n  We are investigating ways in which ideas from temporal logics and agent\nprogramming can be integrated with the use of such control systems to provide a\nmore powerful layer of autonomous decision making. This paper will discuss our\ninitial approaches to the engineering of such systems.",
    "published": "2010-03-02T15:38:48Z",
    "updated": "2010-03-02T15:38:48Z",
    "authors": [
      "Louise A. Dennis",
      "Michael Fisher",
      "Nicholas Lincoln",
      "Alexei Lisitsa",
      "Sandor M. Veres"
    ],
    "link": "http://arxiv.org/abs/1003.0617v1",
    "pdf_link": "http://arxiv.org/pdf/1003.0617v1"
  },
  {
    "api_id": 44,
    "title": "Land-cover Classification and Mapping for Eastern Himalayan State Sikkim",
    "summary": "Area of classifying satellite imagery has become a challenging task in\ncurrent era where there is tremendous growth in settlement i.e. construction of\nbuildings, roads, bridges, dam etc. This paper suggests an improvised k-means\nand Artificial Neural Network (ANN) classifier for land-cover mapping of\nEastern Himalayan state Sikkim. The improvised k-means algorithm shows\nsatisfactory results compared to existing methods that includes k-Nearest\nNeighbor and maximum likelihood classifier. The strength of the Artificial\nNeural Network (ANN) classifier lies in the fact that they are fast and have\ngood recognition rate and it's capability of self-learning compared to other\nclassification algorithms has made it widely accepted. Classifier based on ANN\nshows satisfactory and accurate result in comparison with the classical method.",
    "published": "2010-03-22T06:49:30Z",
    "updated": "2010-03-22T06:49:30Z",
    "authors": [
      "Ratika Pradhan",
      "Mohan P. Pradhan",
      "Ashish Bhusan",
      "Ronak K. Pradhan",
      "M. K. Ghose"
    ],
    "link": "http://arxiv.org/abs/1003.4087v1",
    "pdf_link": "http://arxiv.org/pdf/1003.4087v1"
  },
  {
    "api_id": 45,
    "title": "Proceedings FM-09 Workshop on Formal Methods for Aerospace",
    "summary": "The main workshop objective was to promote a holistic view and\ninterdisciplinary methods for design, verification and co-ordination of\naerospace systems, by combining formal methods with techniques from control\nengineering and artificial intelligence. The very demanding safety, robustness\nand performance requirements of these systems require unprecedented integration\nof heterogeneous techniques and models. The aim of FMA was to bring together\nactive researchers from all the above areas to discuss and present their work.",
    "published": "2010-03-28T12:03:53Z",
    "updated": "2010-03-28T12:03:53Z",
    "authors": [
      "Manuela Bujorianu",
      "Michael Fisher"
    ],
    "link": "http://arxiv.org/abs/1003.5363v1",
    "pdf_link": "http://arxiv.org/pdf/1003.5363v1"
  },
  {
    "api_id": 46,
    "title": "SAR Image Segmentation using Vector Quantization Technique on Entropy\n  Images",
    "summary": "The development and application of various remote sensing platforms result in\nthe production of huge amounts of satellite image data. Therefore, there is an\nincreasing need for effective querying and browsing in these image databases.\nIn order to take advantage and make good use of satellite images data, we must\nbe able to extract meaningful information from the imagery. Hence we proposed a\nnew algorithm for SAR image segmentation. In this paper we propose segmentation\nusing vector quantization technique on entropy image. Initially, we obtain\nentropy image and in second step we use Kekre's Fast Codebook Generation (KFCG)\nalgorithm for segmentation of the entropy image. Thereafter, a codebook of size\n128 was generated for the Entropy image. These code vectors were further\nclustered in 8 clusters using same KFCG algorithm and converted into 8 images.\nThese 8 images were displayed as a result. This approach does not lead to over\nsegmentation or under segmentation. We compared these results with well known\nGray Level Co-occurrence Matrix. The proposed algorithm gives better\nsegmentation with less complexity.",
    "published": "2010-04-11T11:05:33Z",
    "updated": "2010-04-11T11:05:33Z",
    "authors": [
      "H. B. Kekre",
      "Saylee Gharge",
      "Tanuja K. Sarode"
    ],
    "link": "http://arxiv.org/abs/1004.1789v1",
    "pdf_link": "http://arxiv.org/pdf/1004.1789v1"
  },
  {
    "api_id": 47,
    "title": "Deblured Gaussian Blurred Images",
    "summary": "This paper attempts to undertake the study of Restored Gaussian Blurred\nImages. by using four types of techniques of deblurring image as Wiener filter,\nRegularized filter, Lucy Richardson deconvlutin algorithm and Blind\ndeconvlution algorithm with an information of the Point Spread Function (PSF)\ncorrupted blurred image with Different values of Size and Alfa and then\ncorrupted by Gaussian noise. The same is applied to the remote sensing image\nand they are compared with one another, So as to choose the base technique for\nrestored or deblurring image.This paper also attempts to undertake the study of\nrestored Gaussian blurred image with no any information about the Point Spread\nFunction (PSF) by using same four techniques after execute the guess of the\nPSF, the number of iterations and the weight threshold of it. To choose the\nbase guesses for restored or deblurring image of this techniques.",
    "published": "2010-04-26T09:32:28Z",
    "updated": "2010-04-26T09:32:28Z",
    "authors": [
      "Salem Saleh Al-amri",
      "N. V. Kalyankar",
      "Khamitkar S. D"
    ],
    "link": "http://arxiv.org/abs/1004.4448v1",
    "pdf_link": "http://arxiv.org/pdf/1004.4448v1"
  },
  {
    "api_id": 48,
    "title": "Logical methods of object recognition on satellite images using spatial\n  constraints",
    "summary": "A logical approach to object recognition on image is proposed. The main idea\nof the approach is to perform the object recognition as a logical inference on\na set of rules describing an object shape.",
    "published": "2010-04-27T13:22:36Z",
    "updated": "2010-04-27T13:22:36Z",
    "authors": [
      "R. K. Fedorov"
    ],
    "link": "http://arxiv.org/abs/1004.4793v1",
    "pdf_link": "http://arxiv.org/pdf/1004.4793v1"
  },
  {
    "api_id": 49,
    "title": "Image Segmentation by Using Threshold Techniques",
    "summary": "This paper attempts to undertake the study of segmentation image techniques\nby using five threshold methods as Mean method, P-tile method, Histogram\nDependent Technique (HDT), Edge Maximization Technique (EMT) and visual\nTechnique and they are compared with one another so as to choose the best\ntechnique for threshold segmentation techniques image. These techniques applied\non three satellite images to choose base guesses for threshold segmentation\nimage.",
    "published": "2010-05-21T17:30:08Z",
    "updated": "2010-05-21T17:30:08Z",
    "authors": [
      "Salem Saleh Al-amri",
      "N. V. Kalyankar",
      "Khamitkar S. D."
    ],
    "link": "http://arxiv.org/abs/1005.4020v1",
    "pdf_link": "http://arxiv.org/pdf/1005.4020v1"
  },
  {
    "api_id": 50,
    "title": "Classification of LULC Change Detection using Remotely Sensed Data for\n  Coimbatore City, Tamilnadu, India",
    "summary": "Maps are used to describe far-off places . It is an aid for navigation and\nmilitary strategies. Mapping of the lands are important and the mapping work is\nbased on (i). Natural resource management & development (ii). Information\ntechnology ,(iii). Environmental development ,(iv). Facility management and\n(v). e-governance. The Landuse / Landcover system espoused by almost all\nOrganisations and scientists, engineers and remote sensing community who are\ninvolved in mapping of earth surface features, is a system which is derived\nfrom the united States Geological Survey (USGS) LULC classification system. The\napplication of RS and GIS involves influential of homogeneous zones, drift\nanalysis of land use integration of new area changes or change detection\netc.,National Remote Sensing Agency(NRSA) Govt. of India has devised a\ngeneralized LULC classification system respect to the Indian conditions based\non the various categories of Earth surface features , resolution of available\nsatellite data, capabilities of sensors and present and future applications.\nThe profusion information of the earth surface offered by the high resolution\nsatellite images for remote sensing applications. Using change detection\nmethodologies to extract the target changes in the areas from high resolution\nimages and rapidly updates geodatabase information processing.Traditionally,\nclassification approaches have focused on per-pixel technologies. Pixels within\nareas assumed to be automatically homogeneous are analyzed independently.",
    "published": "2010-05-23T18:16:49Z",
    "updated": "2010-05-23T18:16:49Z",
    "authors": [
      "Y. Babykalpana",
      "K. ThanushKodi"
    ],
    "link": "http://arxiv.org/abs/1005.4216v1",
    "pdf_link": "http://arxiv.org/pdf/1005.4216v1"
  },
  {
    "api_id": 51,
    "title": "Large gaps imputation in remote sensed imagery of the environment",
    "summary": "Imputation of missing data in large regions of satellite imagery is necessary\nwhen the acquired image has been damaged by shadows due to clouds, or\ninformation gaps produced by sensor failure.\n  The general approach for imputation of missing data, that could not be\nconsidered missed at random, suggests the use of other available data. Previous\nwork, like local linear histogram matching, take advantage of a co-registered\nolder image obtained by the same sensor, yielding good results in filling\nhomogeneous regions, but poor results if the scenes being combined have radical\ndifferences in target radiance due, for example, to the presence of sun glint\nor snow.\n  This study proposes three different alternatives for filling the data gaps.\nThe first two involves merging radiometric information from a lower resolution\nimage acquired at the same time, in the Fourier domain (Method A), and using\nlinear regression (Method B). The third method consider segmentation as the\nmain target of processing, and propose a method to fill the gaps in the map of\nclasses, avoiding direct imputation (Method C).\n  All the methods were compared by means of a large simulation study,\nevaluating performance with a multivariate response vector with four measures:\nQ, RMSE, Kappa and Overall Accuracy coefficients. Difference in performance\nwere tested with a MANOVA mixed model design with two main effects, imputation\nmethod and type of lower resolution extra data, and a blocking third factor\nwith a nested sub-factor, introduced by the real Landsat image and the\nsub-images that were used. Method B proved to be the best for all criteria.",
    "published": "2010-06-22T16:54:56Z",
    "updated": "2010-06-22T16:54:56Z",
    "authors": [
      "Valeria Rulloni",
      "Oscar Bustos",
      "Ana Georgina Flesia"
    ],
    "link": "http://arxiv.org/abs/1006.4330v1",
    "pdf_link": "http://arxiv.org/pdf/1006.4330v1"
  },
  {
    "api_id": 52,
    "title": "Registration of Brain Images using Fast Walsh Hadamard Transform",
    "summary": "A lot of image registration techniques have been developed with great\nsignificance for data analysis in medicine, astrophotography, satellite imaging\nand few other areas. This work proposes a method for medical image registration\nusing Fast Walsh Hadamard transform. This algorithm registers images of the\nsame or different modalities. Each image bit is lengthened in terms of Fast\nWalsh Hadamard basis functions. Each basis function is a notion of determining\nvarious aspects of local structure, e.g., horizontal edge, corner, etc. These\ncoefficients are normalized and used as numerals in a chosen number system\nwhich allows one to form a unique number for each type of local structure. The\nexperimental results show that Fast Walsh Hadamard transform accomplished\nbetter results than the conventional Walsh transform in the time domain. Also\nFast Walsh Hadamard transform is more reliable in medical image registration\nconsuming less time.",
    "published": "2010-07-07T04:49:16Z",
    "updated": "2010-07-07T04:49:16Z",
    "authors": [
      "D. Sasikala",
      "R. Neelaveni"
    ],
    "link": "http://arxiv.org/abs/1007.1048v1",
    "pdf_link": "http://arxiv.org/pdf/1007.1048v1"
  },
  {
    "api_id": 53,
    "title": "An svm multiclassifier approach to land cover mapping",
    "summary": "From the advent of the application of satellite imagery to land cover\nmapping, one of the growing areas of research interest has been in the area of\nimage classification. Image classifiers are algorithms used to extract land\ncover information from satellite imagery. Most of the initial research has\nfocussed on the development and application of algorithms to better existing\nand emerging classifiers. In this paper, a paradigm shift is proposed whereby a\ncommittee of classifiers is used to determine the final classification output.\nTwo of the key components of an ensemble system are that there should be\ndiversity among the classifiers and that there should be a mechanism through\nwhich the results are combined. In this paper, the members of the ensemble\nsystem include: Linear SVM, Gaussian SVM and Quadratic SVM. The final output\nwas determined through a simple majority vote of the individual classifiers.\nFrom the results obtained it was observed that the final derived map generated\nby an ensemble system can potentially improve on the results derived from the\nindividual classifiers making up the ensemble system. The ensemble system\nclassification accuracy was, in this case, better than the linear and quadratic\nSVM result. It was however less than that of the RBF SVM. Areas for further\nresearch could focus on improving the diversity of the ensemble system used in\nthis research.",
    "published": "2010-07-11T09:36:07Z",
    "updated": "2010-07-11T09:36:07Z",
    "authors": [
      "Gidudu Anthony",
      "Hulley Gregg",
      "Marwala Tshilidzi"
    ],
    "link": "http://arxiv.org/abs/1007.1766v1",
    "pdf_link": "http://arxiv.org/pdf/1007.1766v1"
  },
  {
    "api_id": 54,
    "title": "Resource-Optimal Planning For An Autonomous Planetary Vehicle",
    "summary": "Autonomous planetary vehicles, also known as rovers, are small autonomous\nvehicles equipped with a variety of sensors used to perform exploration and\nexperiments on a planet's surface. Rovers work in a partially unknown\nenvironment, with narrow energy/time/movement constraints and, typically, small\ncomputational resources that limit the complexity of on-line planning and\nscheduling, thus they represent a great challenge in the field of autonomous\nvehicles. Indeed, formal models for such vehicles usually involve hybrid\nsystems with nonlinear dynamics, which are difficult to handle by most of the\ncurrent planning algorithms and tools. Therefore, when offline planning of the\nvehicle activities is required, for example for rovers that operate without a\ncontinuous Earth supervision, such planning is often performed on simplified\nmodels that are not completely realistic. In this paper we show how the\nUPMurphi model checking based planning tool can be used to generate\nresource-optimal plans to control the engine of an autonomous planetary\nvehicle, working directly on its hybrid model and taking into account several\nsafety constraints, thus achieving very accurate results.",
    "published": "2010-07-29T07:27:25Z",
    "updated": "2010-07-29T07:27:25Z",
    "authors": [
      "Giuseppe Della Penna",
      "Benedetto Intrigila",
      "Daniele Magazzeni",
      "Fabio Mercorio"
    ],
    "link": "http://arxiv.org/abs/1007.5130v1",
    "pdf_link": "http://arxiv.org/pdf/1007.5130v1"
  },
  {
    "api_id": 55,
    "title": "Mesoscopic spin Hall effect along a potential step in graphene",
    "summary": "We consider a straight one-dimensional potential step created across a\ngraphene flake. Charge and spin transport through such a potential step are\nstudied in the presence of both intrinsic and extrinsic (Rashba) spin-orbit\ncoupling (SOC). At normal incidence electrons are completely reflected when the\nRashba interaction (with strength $\\lambda_R$) is dominant whereas they are\nperfectly transmitted if the two types of SOC are exactly balanced. At normal\nincidence, the transmission probability of the step is thus controlled\ncontinuously from 0 to 1 by tuning the ratio of the two types of SOC. Besides\nthe transport of charge in the direction normal to the barrier, we show the\nexistence of a spin transport along the barrier. The magnitude of the spin Hall\ncurrent is determined by a subtle interplay between the height of the potential\nstep and the position of Fermi energy. It is demonstrated that contributions\nfrom inter-band matrix elements and evanescent modes are dominant in spin\ntransport. Moreover, in the case of vanishing extrinsic SOC ($\\lambda_R =0$),\neach channel carries a conserved spin current, in contrast to the general case\nof a finite $\\lambda_R$, in which only integrated spin current is a conserved\nquantity. Finally, we provide a quasi-classical picture of the charge and spin\ntransport by imaging flow lines over the entire sample and Veselago lensing\n(negative refraction) in the case of a $p-n$ junction.",
    "published": "2010-09-15T05:50:25Z",
    "updated": "2010-09-15T05:50:25Z",
    "authors": [
      "Ai Yamakage",
      "Ken-Ichiro Imura",
      "Jérôme Cayssol",
      "Yoshio Kuramoto"
    ],
    "link": "http://arxiv.org/abs/1009.2842v1",
    "pdf_link": "http://arxiv.org/pdf/1009.2842v1"
  },
  {
    "api_id": 56,
    "title": "Monte Carlo model of electron energy degradation in a CO2 atmosphere",
    "summary": "A Monte Carlo model has been developed to study the degradation of <1000 eV\nelectrons in an atmosphere of CO2, which is one of the most abundant species in\nMars' and Venus' atmospheres. The e-CO2 cross sections are presented in an\nassembled set along with their analytical representations. Monte Carlo\nsimulations are carried out at several energies to calculate the \"yield\nspectra\", which embodied all the information related to electron degradation\nprocess and can be used to calculate \"yield\" (or population) for any inelastic\nprocess. The numerical yield spectra have been fitted analytically resulting in\nan analytical yield spectra (AYS). We have calculated the mean energy per ion\npair and efficiencies for various inelastic processes, including the double and\ndissociative double ionization of \\car\\ and negative ion formation. The energy\ndistribution of the secondary electrons produced per incident electron is also\npresented at few incident energies. The mean energy per ion pair for CO2 is\n37.5 (35.8) eV at 200 (1000) eV, compared to experimental value 32.7 eV at high\nenergies. Ionization is the dominant loss process at energies above 50 eV with\ncontribution of ~50%. Among the excitation processes, 13.6 eV and 12.4 eV\nstates are the dominant loss processes consuming ~28% energy above 200 eV.\nAround and below ionization threshold, 13.6 eV, 12.4 eV, and 11.1 eV, followed\nby 8.6 eV and 9.3 eV excitation states are important loss processes, while\nbelow 10 eV vibrational excitation dominates.",
    "published": "2010-11-19T11:20:52Z",
    "updated": "2010-11-19T11:20:52Z",
    "authors": [
      "Anil Bhardwaj",
      "Sonal Kumar Jain"
    ],
    "link": "http://arxiv.org/abs/1011.4398v1",
    "pdf_link": "http://arxiv.org/pdf/1011.4398v1"
  },
  {
    "api_id": 57,
    "title": "Support vector machines/relevance vector machine for remote sensing\n  classification: A review",
    "summary": "Kernel-based machine learning algorithms are based on mapping data from the\noriginal input feature space to a kernel feature space of higher dimensionality\nto solve a linear problem in that space. Over the last decade, kernel based\nclassification and regression approaches such as support vector machines have\nwidely been used in remote sensing as well as in various civil engineering\napplications. In spite of their better performance with different datasets,\nsupport vector machines still suffer from shortcomings such as\nvisualization/interpretation of model, choice of kernel and kernel specific\nparameter as well as the regularization parameter. Relevance vector machines\nare another kernel based approach being explored for classification and\nregression with in last few years. The advantages of the relevance vector\nmachines over the support vector machines is the availability of probabilistic\npredictions, using arbitrary kernel functions and not requiring setting of the\nregularization parameter. This paper presents a state-of-the-art review of SVM\nand RVM in remote sensing and provides some details of their use in other civil\nengineering application also.",
    "published": "2011-01-15T13:29:12Z",
    "updated": "2011-01-15T13:29:12Z",
    "authors": [
      "Mahesh Pal"
    ],
    "link": "http://arxiv.org/abs/1101.2987v1",
    "pdf_link": "http://arxiv.org/pdf/1101.2987v1"
  },
  {
    "api_id": 58,
    "title": "Kepler Eclipsing Binary Stars. I. Catalog and Principal Characterization\n  of 1879 Eclipsing Binaries in the First Data Release",
    "summary": "The Kepler space mission is devoted to finding Earth-size planets in\nhabitable zones orbiting other stars. Its large, 105-deg field-of-view features\nover 156,000 stars that are observed continuously to detect and characterize\nplanet transits. Yet this high-precision instrument holds great promise for\nother types of objects as well. Here we present a comprehensive catalog of\neclipsing binary stars observed by Kepler in the first 44 days of operation,\nthe data which are publicly available through MAST as of 6/15/2010. The catalog\ncontains 1879 unique objects. For each object we provide its Kepler ID (KID),\nephemeris (BJD0, P0), morphology type, physical parameters (Teff, log g,\nE(B-V), crowding), and principal parameters (T2/T1, q, fillout factor and sin i\nfor overcontacts, and T2/T1, (R1+R2)/a, e sin(w), e cos(w), and sin i for\ndetached binaries). We present statistics based on the determined periods and\nmeasure an average occurence rate of eclipsing binaries to be ~1.2% across the\nKepler field. We further discuss the distribution of binaries as function of\ngalactic latitude, and thoroughly explain the application of artificial\nintelligence to obtain principal parameters in a matter of seconds for the\nwhole sample. The catalog was envisioned to serve as a bridge between the now\npublic Kepler data and the scientific community interested in eclipsing binary\nstars.",
    "published": "2010-06-14T19:39:11Z",
    "updated": "2011-01-21T17:23:46Z",
    "authors": [
      "Andrej Prsa",
      "Natalie M. Batalha",
      "Robert W. Slawson",
      "Laurance R. Doyle",
      "William F. Welsh",
      "Jerome A. Orosz",
      "Sara Seager",
      "Michael Rucker",
      "Kimberly Mjaseth",
      "Scott G. Engle",
      "Kyle Conroy",
      "Jon M. Jenkins",
      "Douglas A. Caldwell",
      "David G. Koch",
      "William J. Borucki"
    ],
    "link": "http://arxiv.org/abs/1006.2815v2",
    "pdf_link": "http://arxiv.org/pdf/1006.2815v2"
  },
  {
    "api_id": 59,
    "title": "Disorder-Induced Multiple Transition involving Z2 Topological Insulator",
    "summary": "Effects of disorder on two-dimensional Z2 topological insulator are studied\nnumerically by the transfer matrix method. Based on the scaling analysis, the\nphase diagram is derived for a model of HgTe quantum well as a function of\ndisorder strength and magnitude of the energy gap. In the presence of sz\nnon-conserving spin-orbit coupling, a finite metallic region is found that\npartitions the two topologically distinct insulating phases. As disorder\nincreases, a narrow-gap topologically trivial insulator undergoes a series of\ntransitions; first to metal, second to topological insulator, third to metal,\nand finally back to trivial insulator. We show that this multiple transition is\na consequence of two disorder effects; renormalization of the band gap, and\nAnderson localization. The metallic region found in the scaling analysis\ncorresponds roughly to the region of finite density of states at the Fermi\nlevel evaluated in the self-consistent Born approximation.",
    "published": "2010-11-25T09:53:42Z",
    "updated": "2011-02-23T07:51:39Z",
    "authors": [
      "Ai Yamakage",
      "Kentaro Nomura",
      "Ken-Ichiro Imura",
      "Yoshio Kuramoto"
    ],
    "link": "http://arxiv.org/abs/1011.5576v2",
    "pdf_link": "http://arxiv.org/pdf/1011.5576v2"
  },
  {
    "api_id": 60,
    "title": "Automatic Open Space Area Extraction and Change Detection from High\n  Resolution Urban Satellite Images",
    "summary": "In this paper, we study efficient and reliable automatic extraction algorithm\nto find out the open space area from the high resolution urban satellite\nimagery, and to detect changes from the extracted open space area during the\nperiod 2003, 2006 and 2008. This automatic extraction and change detection\nalgorithm uses some filters, segmentation and grouping that are applied on\nsatellite images. The resultant images may be used to calculate the total\navailable open space area and the built up area. It may also be used to compare\nthe difference between present and past open space area using historical urban\nsatellite images of that same projection, which is an important geo spatial\ndata management application.",
    "published": "2011-03-25T07:02:09Z",
    "updated": "2011-03-25T07:02:09Z",
    "authors": [
      "B. G. Kodge",
      "P. S. Hiremath"
    ],
    "link": "http://arxiv.org/abs/1103.4913v1",
    "pdf_link": "http://arxiv.org/pdf/1103.4913v1"
  },
  {
    "api_id": 61,
    "title": "Fuzzy Rules and Evidence Theory for Satellite Image Analysis",
    "summary": "Design of a fuzzy rule based classifier is proposed. The performance of the\nclassifier for multispectral satellite image classification is improved using\nDempster- Shafer theory of evidence that exploits information of the\nneighboring pixels. The classifiers are tested rigorously with two known images\nand their performance are found to be better than the results available in the\nliterature. We also demonstrate the improvement of performance while using D-S\ntheory along with fuzzy rule based classifiers over the basic fuzzy rule based\nclassifiers for all the test cases.",
    "published": "2011-04-08T05:18:15Z",
    "updated": "2011-04-08T05:18:15Z",
    "authors": [
      "Arijit Laha",
      "J. Das"
    ],
    "link": "http://arxiv.org/abs/1104.1485v1",
    "pdf_link": "http://arxiv.org/pdf/1104.1485v1"
  },
  {
    "api_id": 62,
    "title": "PDDL2.1: An Extension to PDDL for Expressing Temporal Planning Domains",
    "summary": "In recent years research in the planning community has moved increasingly\ntoward s application of planners to realistic problems involving both time and\nmany typ es of resources. For example, interest in planning demonstrated by the\nspace res earch community has inspired work in observation scheduling,\nplanetary rover ex ploration and spacecraft control domains. Other temporal and\nresource-intensive domains including logistics planning, plant control and\nmanufacturing have also helped to focus the community on the modelling and\nreasoning issues that must be confronted to make planning technology meet the\nchallenges of application. The International Planning Competitions have acted\nas an important motivating fo rce behind the progress that has been made in\nplanning since 1998. The third com petition (held in 2002) set the planning\ncommunity the challenge of handling tim e and numeric resources. This\nnecessitated the development of a modelling langua ge capable of expressing\ntemporal and numeric properties of planning domains. In this paper we describe\nthe language, PDDL2.1, that was used in the competition. We describe the syntax\nof the language, its formal semantics and the validation of concurrent plans.\nWe observe that PDDL2.1 has considerable modelling power --- exceeding the\ncapabilities of current planning technology --- and presents a number of\nimportant challenges to the research community.",
    "published": "2011-06-22T20:20:10Z",
    "updated": "2011-06-22T20:20:10Z",
    "authors": [
      "M. Fox",
      "D. Long"
    ],
    "link": "http://arxiv.org/abs/1106.4561v1",
    "pdf_link": "http://arxiv.org/pdf/1106.4561v1"
  },
  {
    "api_id": 63,
    "title": "Structure and Complexity in Planning with Unary Operators",
    "summary": "Unary operator domains -- i.e., domains in which operators have a single\neffect -- arise naturally in many control problems. In its most general form,\nthe problem of STRIPS planning in unary operator domains is known to be as hard\nas the general STRIPS planning problem -- both are PSPACE-complete. However,\nunary operator domains induce a natural structure, called the domain's causal\ngraph. This graph relates between the preconditions and effect of each domain\noperator. Causal graphs were exploited by Williams and Nayak in order to\nanalyze plan generation for one of the controllers in NASA's Deep-Space One\nspacecraft. There, they utilized the fact that when this graph is acyclic, a\nserialization ordering over any subgoal can be obtained quickly. In this paper\nwe conduct a comprehensive study of the relationship between the structure of a\ndomain's causal graph and the complexity of planning in this domain. On the\npositive side, we show that a non-trivial polynomial time plan generation\nalgorithm exists for domains whose causal graph induces a polytree with a\nconstant bound on its node indegree. On the negative side, we show that even\nplan existence is hard when the graph is a directed-path singly connected DAG.\nMore generally, we show that the number of paths in the causal graph is closely\nrelated to the complexity of planning in the associated domain. Finally we\nrelate our results to the question of complexity of planning with serializable\nsubgoals.",
    "published": "2011-06-26T21:01:50Z",
    "updated": "2011-06-26T21:01:50Z",
    "authors": [
      "R. I. Brafman",
      "C. Domshlak"
    ],
    "link": "http://arxiv.org/abs/1106.5256v1",
    "pdf_link": "http://arxiv.org/pdf/1106.5256v1"
  },
  {
    "api_id": 64,
    "title": "Augmented Reality Implementation Methods in Mainstream Applications",
    "summary": "Augmented reality has became an useful tool in many areas from space\nexploration to military applications. Although used theoretical principles are\nwell known for almost a decade, the augmented reality is almost exclusively\nused in high budget solutions with a special hardware. However, in last few\nyears we could see rising popularity of many projects focused on deployment of\nthe augmented reality on different mobile devices. Our article is aimed on\ndevelopers who consider development of an augmented reality application for the\nmainstream market. Such developers will be forced to keep the application\nprice, therefore also the development price, at reasonable level. Usage of\nexisting image processing software library could bring a significant cut-down\nof the development costs. In the theoretical part of the article is presented\nan overview of the augmented reality application structure. Further, an\napproach for selection appropriate library as well as the review of the\nexisting software libraries focused in this area is described. The last part of\nthe article outlines our implementation of key parts of the augmented reality\napplication using the OpenCV library.",
    "published": "2011-06-28T05:57:37Z",
    "updated": "2011-06-28T05:57:37Z",
    "authors": [
      "David Prochazka",
      "Tomas Koubek"
    ],
    "link": "http://arxiv.org/abs/1106.5569v1",
    "pdf_link": "http://arxiv.org/pdf/1106.5569v1"
  },
  {
    "api_id": 65,
    "title": "Astroinformatics of galaxies and quasars: a new general method for\n  photometric redshifts estimation",
    "summary": "With the availability of the huge amounts of data produced by current and\nfuture large multi-band photometric surveys, photometric redshifts have become\na crucial tool for extragalactic astronomy and cosmology. In this paper we\npresent a novel method, called Weak Gated Experts (WGE), which allows to derive\nphotometric redshifts through a combination of data mining techniques.\n\\noindent The WGE, like many other machine learning techniques, is based on the\nexploitation of a spectroscopic knowledge base composed by sources for which a\nspectroscopic value of the redshift is available. This method achieves a\nvariance \\sigma^2(\\Delta z)=2.3x10^{-4} (\\sigma^2(\\Delta z) =0.08), where\n\\Delta z = z_{phot} - z_{spec}) for the reconstruction of the photometric\nredshifts for the optical galaxies from the SDSS and for the optical quasars\nrespectively, while the Root Mean Square (RMS) of the \\Delta z variable\ndistributions for the two experiments is respectively equal to 0.021 and 0.35.\nThe WGE provides also a mechanism for the estimation of the accuracy of each\nphotometric redshift. We also present and discuss the catalogs obtained for the\noptical SDSS galaxies, for the optical candidate quasars extracted from the DR7\nSDSS photometric dataset {The sample of SDSS sources on which the accuracy of\nthe reconstruction has been assessed is composed of bright sources, for a\nsubset of which spectroscopic redshifts have been measured.}, and for optical\nSDSS candidate quasars observed by GALEX in the UV range. The WGE method\nexploits the new technological paradigm provided by the Virtual Observatory and\nthe emerging field of Astroinformatics.",
    "published": "2011-07-15T20:21:50Z",
    "updated": "2011-07-15T20:21:50Z",
    "authors": [
      "Omar Laurino",
      "Raffaele D'Abrusco",
      "Giuseppe Longo",
      "Giuseppe Riccio"
    ],
    "link": "http://arxiv.org/abs/1107.3160v1",
    "pdf_link": "http://arxiv.org/pdf/1107.3160v1"
  },
  {
    "api_id": 66,
    "title": "Applying Advanced Spaceborne Thermal Emission and Reflection Radiometer\n  (ASTER) spectral indices for geological mapping and mineral identification on\n  the Tibetan Plateau",
    "summary": "The Tibetan Plateau holds clues to understanding the dynamics and mechanisms\nassociated with continental growth. Part of the region is characterized by\nzones of ophiolitic melange believed to represent the remnants of ancient\noceanic crust and underlying upper mantle emplaced during oceanic closures.\nHowever, due to the remoteness of the region and the inhospitable terrain many\nareas have not received detailed investigation. Increased spatial and spectral\nresolution of satellite sensors have made it possible to map in greater detail\nthe mineralogy and lithology than in the past. Recent work by Yoshiki Ninomiya\nof the Geological Survey of Japan has pioneered the use of several spectral\nindices for the mapping of quartzose, carbonate, and silicate rocks using\nAdvanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) thermal\ninfrared (TIR) data. In this study, ASTER TIR indices have been applied to a\nregion in western-central Tibet for the purposes of assessing their\neffectiveness for differentiating ophiolites and other lithologies. The results\nagree well with existing geological maps and other published data. The study\narea was chosen due to its diverse range of rock types, including an ophiolitic\nmelange, associated with the Bangong-Nujiang suture (BNS) that crops out on the\nnorthern shores of Lagkor Tso and Dong Tso (\"Tso\" is Tibetan for lake). The\ntechniques highlighted in this paper could be applied to other geographical\nregions where similar geological questions need to be resolved. The results of\nthis study aim to show the utility of ASTER TIR imagery for geological mapping\nin semi-arid and sparsely vegetated areas on the Tibetan Plateau.",
    "published": "2011-07-18T16:59:30Z",
    "updated": "2011-07-18T16:59:30Z",
    "authors": [
      "Robert Corrie",
      "Yoshiki Ninomiya",
      "Jonathan Aitchison"
    ],
    "link": "http://arxiv.org/abs/1107.3499v1",
    "pdf_link": "http://arxiv.org/pdf/1107.3499v1"
  },
  {
    "api_id": 67,
    "title": "Arithmetic and Frequency Filtering Methods of Pixel-Based Image Fusion\n  Techniques",
    "summary": "In remote sensing, image fusion technique is a useful tool used to fuse high\nspatial resolution panchromatic images (PAN) with lower spatial resolution\nmultispectral images (MS) to create a high spatial resolution multispectral of\nimage fusion (F) while preserving the spectral information in the multispectral\nimage (MS).There are many PAN sharpening techniques or Pixel-Based image fusion\ntechniques that have been developed to try to enhance the spatial resolution\nand the spectral property preservation of the MS. This paper attempts to\nundertake the study of image fusion, by using two types of pixel-based image\nfusion techniques i.e. Arithmetic Combination and Frequency Filtering Methods\nof Pixel-Based Image Fusion Techniques. The first type includes Brovey\nTransform (BT), Color Normalized Transformation (CN) and Multiplicative Method\n(MLT). The second type include High-Pass Filter Additive Method (HPFA),\nHigh-Frequency-Addition Method (HFA) High Frequency Modulation Method (HFM) and\nThe Wavelet transform-based fusion method (WT). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including Standard Deviation (SD),\nEntropy(En), Correlation Coefficient (CC), Signal-to Noise Ratio (SNR),\nNormalization Root Mean Square Error (NRMSE) and Deviation Index (DI) to\nestimate the quality and degree of information improvement of a fused image\nquantitatively.",
    "published": "2011-07-18T01:41:37Z",
    "updated": "2011-07-19T05:20:59Z",
    "authors": [
      "Firouz Abdullah Al-Wassai",
      "N. V. Kalyankar",
      "Ali A. Al-Zuky"
    ],
    "link": "http://arxiv.org/abs/1107.3348v2",
    "pdf_link": "http://arxiv.org/pdf/1107.3348v2"
  },
  {
    "api_id": 68,
    "title": "Image Deblurring Using Derivative Compressed Sensing for Optical Imaging\n  Application",
    "summary": "Reconstruction of multidimensional signals from the samples of their partial\nderivatives is known to be a standard problem in inverse theory. Such and\nsimilar problems routinely arise in numerous areas of applied sciences,\nincluding optical imaging, laser interferometry, computer vision, remote\nsensing and control. Though being ill-posed in nature, the above problem can be\nsolved in a unique and stable manner, provided proper regularization and\nrelevant boundary conditions. In this paper, however, a more challenging setup\nis addressed, in which one has to recover an image of interest from its noisy\nand blurry version, while the only information available about the imaging\nsystem at hand is the amplitude of the generalized pupil function (GPF) along\nwith partial observations of the gradient of GPF's phase. In this case, the\nphase-related information is collected using a simplified version of the\nShack-Hartmann interferometer, followed by recovering the entire phase by means\nof derivative compressed sensing. Subsequently, the estimated phase can be\ncombined with the amplitude of the GPF to produce an estimate of the point\nspread function (PSF), whose knowledge is essential for subsequent image\ndeconvolution. In summary, the principal contribution of this work is twofold.\nFirst, we demonstrate how to simplify the construction of the Shack-Hartmann\ninterferometer so as to make it less expensive and hence more accessible.\nSecond, it is shown by means of numerical experiments that the above\nsimplification and its associated solution scheme produce image reconstructions\nof the quality comparable to those obtained using dense sampling of the GPF\nphase.",
    "published": "2011-07-28T18:52:28Z",
    "updated": "2011-07-28T18:52:28Z",
    "authors": [
      "Mohammad Rostami",
      "Oleg Michailovich",
      "Zhou Wang"
    ],
    "link": "http://arxiv.org/abs/1107.5790v1",
    "pdf_link": "http://arxiv.org/pdf/1107.5790v1"
  },
  {
    "api_id": 69,
    "title": "Calculations of N2 triplet states vibrational populations and band\n  emissions in Venusian dayglow",
    "summary": "A model for N2 triplet states band emissions in the Venusian dayglow has been\ndeveloped for low and high solar activity conditions. Steady state\nphotoelectron fluxes and volume excitation rates for N2 triplet states have\nbeen calculated using the Analytical Yield Spectra (AYS) technique. Model\ncalculated photoelectron flux is in good agreement with Pioneer Venus\nOrbiter-observed electron flux. Since inter-state cascading is important for\nthe triplet states of N2, populations of different levels of N2 triplet states\nare calculated under statistical equilibrium considering direct electron impact\nexcitation, and cascading and quenching effects. Densities of all vibrational\nlevels of each triplet state are calculated in the model. Height-integrated\noverhead intensities of N2 triplet band emissions are calculated, the values\nfor Vegard-Kaplan (A^3Sigma_u^+ - X^1Pi_g^+), First Positive (B^3Pi_g -\nA^3Sigma_u^+), Second Positive (C^3Pi_u - B^3Pi_g), and Wu-Benesch (W^3Delta_u\n- B^3Pi_g) bands of N2, are 1.9 (3.2), 3 (6), 0.4 (0.8), and 0.5 (1.1) kR,\nrespectively, for solar minimum (maximum) conditions. The intensities of the\nthree strong Vegard-Kaplan bands (0, 5), (0, 6), and (0, 7) are 94 (160), 120\n(204), and 114 (194) R, respectively, for solar minimum (maximum) conditions.\nLimb profiles are calculated for VK (0, 4), (0, 5), (0, 6) and (0, 7) bands.\nThe calculated intensities on Venus are about a factor 10 higher than those on\nMars. The present study provides a motivation for a search of N2 triplet band\nemissions in the dayglow of Venus.",
    "published": "2011-08-03T04:36:37Z",
    "updated": "2011-08-03T04:36:37Z",
    "authors": [
      "Anil Bhardwaj",
      "Sonal Kumar Jain"
    ],
    "link": "http://arxiv.org/abs/1108.0737v1",
    "pdf_link": "http://arxiv.org/pdf/1108.0737v1"
  },
  {
    "api_id": 70,
    "title": "The Statistical methods of Pixel-Based Image Fusion Techniques",
    "summary": "There are many image fusion methods that can be used to produce\nhigh-resolution mutlispectral images from a high-resolution panchromatic (PAN)\nimage and low-resolution multispectral (MS) of remote sensed images. This paper\nattempts to undertake the study of image fusion techniques with different\nStatistical techniques for image fusion as Local Mean Matching (LMM), Local\nMean and Variance Matching (LMVM), Regression variable substitution (RVS),\nLocal Correlation Modeling (LCM) and they are compared with one another so as\nto choose the best technique, that can be applied on multi-resolution satellite\nimages. This paper also devotes to concentrate on the analytical techniques for\nevaluating the quality of image fusion (F) by using various methods including\nStandard Deviation (SD), Entropy(En), Correlation Coefficient (CC), Signal-to\nNoise Ratio (SNR), Normalization Root Mean Square Error (NRMSE) and Deviation\nIndex (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively.",
    "published": "2011-08-12T16:51:21Z",
    "updated": "2011-08-12T16:51:21Z",
    "authors": [
      "Firouz Abdullah Al-Wassai",
      "N. V. Kalyankar",
      "Ali A. Al-Zaky"
    ],
    "link": "http://arxiv.org/abs/1108.3250v1",
    "pdf_link": "http://arxiv.org/pdf/1108.3250v1"
  },
  {
    "api_id": 71,
    "title": "Multisensor Images Fusion Based on Feature-Level",
    "summary": "Until now, of highest relevance for remote sensing data processing and\nanalysis have been techniques for pixel level image fusion. So, This paper\nattempts to undertake the study of Feature-Level based image fusion. For this\npurpose, feature based fusion techniques, which are usually based on empirical\nor heuristic rules, are employed. Hence, in this paper we consider feature\nextraction (FE) for fusion. It aims at finding a transformation of the original\nspace that would produce such new features, which preserve or improve as much\nas possible. This study introduces three different types of Image fusion\ntechniques including Principal Component Analysis based Feature Fusion (PCA),\nSegment Fusion (SF) and Edge fusion (EF). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including (SD), (En), (CC), (SNR), (NRMSE)\nand (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively.",
    "published": "2011-08-20T07:43:46Z",
    "updated": "2011-08-20T07:43:46Z",
    "authors": [
      "Firouz Abdullah Al-Wassai",
      "N. V. Kalyankar",
      "Ali A. Al-Zaky"
    ],
    "link": "http://arxiv.org/abs/1108.4098v1",
    "pdf_link": "http://arxiv.org/pdf/1108.4098v1"
  },
  {
    "api_id": 72,
    "title": "Using Supervised Learning to Improve Monte Carlo Integral Estimation",
    "summary": "Monte Carlo (MC) techniques are often used to estimate integrals of a\nmultivariate function using randomly generated samples of the function. In\nlight of the increasing interest in uncertainty quantification and robust\ndesign applications in aerospace engineering, the calculation of expected\nvalues of such functions (e.g. performance measures) becomes important.\nHowever, MC techniques often suffer from high variance and slow convergence as\nthe number of samples increases. In this paper we present Stacked Monte Carlo\n(StackMC), a new method for post-processing an existing set of MC samples to\nimprove the associated integral estimate. StackMC is based on the supervised\nlearning techniques of fitting functions and cross validation. It should reduce\nthe variance of any type of Monte Carlo integral estimate (simple sampling,\nimportance sampling, quasi-Monte Carlo, MCMC, etc.) without adding bias. We\nreport on an extensive set of experiments confirming that the StackMC estimate\nof an integral is more accurate than both the associated unprocessed Monte\nCarlo estimate and an estimate based on a functional fit to the MC samples.\nThese experiments run over a wide variety of integration spaces, numbers of\nsample points, dimensions, and fitting functions. In particular, we apply\nStackMC in estimating the expected value of the fuel burn metric of future\ncommercial aircraft and in estimating sonic boom loudness measures. We compare\nthe efficiency of StackMC with that of more standard methods and show that for\nnegligible additional computational cost significant increases in accuracy are\ngained.",
    "published": "2011-08-24T16:22:55Z",
    "updated": "2011-08-24T16:22:55Z",
    "authors": [
      "Brendan Tracey",
      "David Wolpert",
      "Juan J. Alonso"
    ],
    "link": "http://arxiv.org/abs/1108.4879v1",
    "pdf_link": "http://arxiv.org/pdf/1108.4879v1"
  },
  {
    "api_id": 73,
    "title": "A Gaussian process framework for modelling instrumental systematics:\n  application to transmission spectroscopy",
    "summary": "Transmission spectroscopy, which consists of measuring the\nwavelength-dependent absorption of starlight by a planet's atmosphere during a\ntransit, is a powerful probe of atmospheric composition. However, the expected\nsignal is typically orders of magnitude smaller than instrumental systematics,\nand the results are crucially dependent on the treatment of the latter. In this\npaper, we propose a new method to infer transit parameters in the presence of\nsystematic noise using Gaussian processes, a technique widely used in the\nmachine learning community for Bayesian regression and classification problems.\nOur method makes use of auxiliary information about the state of the\ninstrument, but does so in a non-parametric manner, without imposing a specific\ndependence of the systematics on the instrumental parameters, and naturally\nallows for the correlated nature of the noise. We give an example application\nof the method to archival NICMOS transmission spectroscopy of the hot Jupiter\nHD 189733, which goes some way towards reconciling the controversy surrounding\nthis dataset in the literature. Finally, we provide an appendix giving a\ngeneral introduction to Gaussian processes for regression, in order to\nencourage their application to a wider range of problems.",
    "published": "2011-09-15T03:31:13Z",
    "updated": "2011-09-28T11:35:38Z",
    "authors": [
      "N. P. Gibson",
      "S. Aigrain",
      "S. Roberts",
      "T. M. Evans",
      "M. Osborne",
      "F. Pont"
    ],
    "link": "http://arxiv.org/abs/1109.3251v2",
    "pdf_link": "http://arxiv.org/pdf/1109.3251v2"
  },
  {
    "api_id": 74,
    "title": "Understanding Algorithm Performance on an Oversubscribed Scheduling\n  Application",
    "summary": "The best performing algorithms for a particular oversubscribed scheduling\napplication, Air Force Satellite Control Network (AFSCN) scheduling, appear to\nhave little in common. Yet, through careful experimentation and modeling of\nperformance in real problem instances, we can relate characteristics of the\nbest algorithms to characteristics of the application. In particular, we find\nthat plateaus dominate the search spaces (thus favoring algorithms that make\nlarger changes to solutions) and that some randomization in exploration is\ncritical to good performance (due to the lack of gradient information on the\nplateaus). Based on our explanations of algorithm performance, we develop a new\nalgorithm that combines characteristics of the best performers; the new\nalgorithms performance is better than the previous best. We show how hypothesis\ndriven experimentation and search modeling can both explain algorithm\nperformance and motivate the design of a new algorithm.",
    "published": "2011-10-12T18:21:07Z",
    "updated": "2011-10-12T18:21:07Z",
    "authors": [
      "L. Barbulescu",
      "A. E. Howe",
      "M. Roberts",
      "L. D. Whitley"
    ],
    "link": "http://arxiv.org/abs/1110.2735v1",
    "pdf_link": "http://arxiv.org/pdf/1110.2735v1"
  },
  {
    "api_id": 75,
    "title": "Impact of solar EUV flux on CO Cameron band and CO2+ UV doublet\n  emissions in the dayglow of Mars",
    "summary": "This study is aimed at making a calculation about the impact of the two most\ncommonly used solar EUV flux models -- SOLAR2000 (S2K) of \\cite{Tobiska04} and\nEUVAC model of \\cite{Richards94} -- on photoelectron fluxes, volume emission\nrates, ion densities and CO Cameron and CO$_2^+$ UV doublet band dayglow\nemissions on Mars in three solar activity conditions: minimum, moderate, and\nmaximum. Calculated limb intensities profiles are compared with SPICAM/Mars\nExpress and Mariner observations. Analytical yield spectrum (AYS) approach has\nbeen used to calculate photoelectron fluxes in Martian upper atmosphere.\nDensities of prominent ions and CO molecule in excited triplet a$^3\\Pi$ state\nare calculated using major ion-neutral reactions. Volume emission rates of CO\nCameron and CO$_2^+$ UV doublet bands have been calculated for dif{}ferent\nobservations (Viking condition, Mariner and Mars Express SPICAM observations)\non Mars. For the low solar activity condition, dayglow intensities calculated\nusing the S2K model are $\\sim$40% higher than those calculated using the EUVAC\nmodel. During high solar activity, due to the higher EUV fluxes at wavelengths\nbelow 250 \\AA\\ in the EUVAC model, intensities calculated using EUVAC model are\nslightly higher ($\\sim$20%) than those calculated using S2K model. Irrespective\nof the solar activity condition, production of Cameron band due to\nphotodissociative excitation of CO$_2$ is around 50% higher when S2K model is\nused. Altitude of peak limb brightness of CO Cameron and CO$_2^+$ UV doublet\nband is found to be independent of solar EUV flux models. Calculated limb\nintensities of CO Cameron and CO$_2^+$ UV doublet bands are on an average a\nfactor of $\\sim$2 and $\\sim$1.5, respectively, higher than the SPICAM Mars\nExpress observation, while they are consistent with the Mariner observations.",
    "published": "2011-10-18T04:20:08Z",
    "updated": "2011-10-18T04:20:08Z",
    "authors": [
      "Sonal Kumar Jain",
      "Anil Bhardwaj"
    ],
    "link": "http://arxiv.org/abs/1110.3870v1",
    "pdf_link": "http://arxiv.org/pdf/1110.3870v1"
  },
  {
    "api_id": 76,
    "title": "Towards an Automated Classification of Transient Events in Synoptic Sky\n  Surveys",
    "summary": "We describe the development of a system for an automated, iterative,\nreal-time classification of transient events discovered in synoptic sky\nsurveys. The system under development incorporates a number of Machine Learning\ntechniques, mostly using Bayesian approaches, due to the sparse nature,\nheterogeneity, and variable incompleteness of the available data. The\nclassifications are improved iteratively as the new measurements are obtained.\nOne novel feature is the development of an automated follow-up recommendation\nengine, that suggest those measurements that would be the most advantageous in\nterms of resolving classification ambiguities and/or characterization of the\nastrophysically most interesting objects, given a set of available follow-up\nassets and their cost functions. This illustrates the symbiotic relationship of\nastronomy and applied computer science through the emerging discipline of\nAstroInformatics.",
    "published": "2011-10-20T22:48:30Z",
    "updated": "2011-10-20T22:48:30Z",
    "authors": [
      "S. G. Djorgovski",
      "C. Donalek",
      "A. Mahabal",
      "B. Moghaddam",
      "M. Turmon",
      "M. Graham",
      "A. Drake",
      "N. Sharma",
      "Y. Chen"
    ],
    "link": "http://arxiv.org/abs/1110.4655v1",
    "pdf_link": "http://arxiv.org/pdf/1110.4655v1"
  },
  {
    "api_id": 77,
    "title": "Studying Satellite Image Quality Based on the Fusion Techniques",
    "summary": "Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. However,\nthe jury is still out on the benefits of a fused image compared to its original\nimages. There is also a lack of measures for assessing the objective quality of\nthe spatial resolution for the fusion methods. Therefore, an objective quality\nof the spatial resolution assessment for fusion images is required. So, this\nstudy attempts to develop a new qualitative assessment to evaluate the spatial\nquality of the pan sharpened images by many spatial quality metrics. Also, this\npaper deals with a comparison of various image fusion techniques based on pixel\nand feature fusion techniques.",
    "published": "2011-10-22T13:26:00Z",
    "updated": "2011-10-22T13:26:00Z",
    "authors": [
      "Firouz Abdullah Al-Wassai",
      "N. V. Kalyankar",
      "Ali A. Al-Zaky"
    ],
    "link": "http://arxiv.org/abs/1110.4970v1",
    "pdf_link": "http://arxiv.org/pdf/1110.4970v1"
  },
  {
    "api_id": 78,
    "title": "Discussion on \"Techniques for Massive-Data Machine Learning in\n  Astronomy\" by A. Gray",
    "summary": "Astronomy is increasingly encountering two fundamental truths: (1) The field\nis faced with the task of extracting useful information from extremely large,\ncomplex, and high dimensional datasets; (2) The techniques of astroinformatics\nand astrostatistics are the only way to make this tractable, and bring the\nrequired level of sophistication to the analysis. Thus, an approach which\nprovides these tools in a way that scales to these datasets is not just\ndesirable, it is vital. The expertise required spans not just astronomy, but\nalso computer science, statistics, and informatics. As a computer scientist and\nexpert in machine learning, Alex's contribution of expertise and a large number\nof fast algorithms designed to scale to large datasets, is extremely welcome.\nWe focus in this discussion on the questions raised by the practical\napplication of these algorithms to real astronomical datasets. That is, what is\nneeded to maximally leverage their potential to improve the science return?\nThis is not a trivial task. While computing and statistical expertise are\nrequired, so is astronomical expertise. Precedent has shown that, to-date, the\ncollaborations most productive in producing astronomical science results (e.g,\nthe Sloan Digital Sky Survey), have either involved astronomers expert in\ncomputer science and/or statistics, or astronomers involved in close, long-term\ncollaborations with experts in those fields. This does not mean that the\nastronomers are giving the most important input, but simply that their input is\ncrucial in guiding the effort in the most fruitful directions, and coping with\nthe issues raised by real data. Thus, the tools must be useable and\nunderstandable by those whose primary expertise is not computing or statistics,\neven though they may have quite extensive knowledge of those fields.",
    "published": "2011-10-26T00:22:36Z",
    "updated": "2011-10-26T00:22:36Z",
    "authors": [
      "Nicholas M. Ball"
    ],
    "link": "http://arxiv.org/abs/1110.5688v1",
    "pdf_link": "http://arxiv.org/pdf/1110.5688v1"
  },
  {
    "api_id": 79,
    "title": "Model Selection in Undirected Graphical Models with the Elastic Net",
    "summary": "Structure learning in random fields has attracted considerable attention due\nto its difficulty and importance in areas such as remote sensing, computational\nbiology, natural language processing, protein networks, and social network\nanalysis. We consider the problem of estimating the probabilistic graph\nstructure associated with a Gaussian Markov Random Field (GMRF), the Ising\nmodel and the Potts model, by extending previous work on $l_1$ regularized\nneighborhood estimation to include the elastic net $l_1+l_2$ penalty.\nAdditionally, we show numerical evidence that the edge density plays a role in\nthe graph recovery process. Finally, we introduce a novel method for augmenting\nneighborhood estimation by leveraging pair-wise neighborhood union estimates.",
    "published": "2011-11-02T16:40:40Z",
    "updated": "2011-11-02T16:40:40Z",
    "authors": [
      "Mihai Cucuringu",
      "Jesus Puente",
      "David Shue"
    ],
    "link": "http://arxiv.org/abs/1111.0559v1",
    "pdf_link": "http://arxiv.org/pdf/1111.0559v1"
  },
  {
    "api_id": 80,
    "title": "Constraint Satisfaction Tractability from Semi-lattice Operations on\n  Infinite Sets",
    "summary": "A famous result by Jeavons, Cohen, and Gyssens shows that every constraint\nsatisfaction problem (CSP) where the constraints are preserved by a\nsemi-lattice operation can be solved in polynomial time. This is one of the\nbasic facts for the so-called universal-algebraic approach to a systematic\ntheory of tractability and hardness in finite domain constraint satisfaction.\n  Not surprisingly, the theorem of Jeavons et al. fails for arbitrary infinite\ndomain CSPs. Many CSPs of practical interest, though, and in particular those\nCSPs that are motivated by qualitative reasoning calculi from Artificial\nIntelligence, can be formulated with constraint languages that are rather\nwell-behaved from a model-theoretic point of view. In particular, the\nautomorphism group of these constraint languages tends to be large in the sense\nthat the number of orbits of n-subsets of the automorphism group is bounded by\nsome function in n.\n  In this paper we present a generalization of the theorem by Jeavons et al. to\ninfinite domain CSPs where the number of orbits of n-subsets grows\nsub-exponentially in n, and prove that preservation under a semi-lattice\noperation for such CSPs implies polynomial-time tractability. Unlike the result\nof Jeavons et al., this includes many CSPs that cannot be solved by Datalog.",
    "published": "2011-11-28T21:27:19Z",
    "updated": "2011-11-28T21:27:19Z",
    "authors": [
      "Manuel Bodirsky",
      "Dugald Macpherson",
      "Johan Thapper"
    ],
    "link": "http://arxiv.org/abs/1111.6616v1",
    "pdf_link": "http://arxiv.org/pdf/1111.6616v1"
  },
  {
    "api_id": 81,
    "title": "Aggregation of Composite Solutions: strategies, models, examples",
    "summary": "The paper addresses aggregation issues for composite (modular) solutions. A\nsystemic view point is suggested for various aggregation problems. Several\nsolution structures are considered: sets, set morphologies, trees, etc. Mainly,\nthe aggregation approach is targeted to set morphologies. The aggregation\nproblems are based on basic structures as substructure, superstructure,\nmedian/consensus, and extended median/consensus. In the last case, preliminary\nstructure is built (e.g., substructure, median/consensus) and addition of\nsolution elements is considered while taking into account profit of the\nadditional elements and total resource constraint. Four aggregation strategies\nare examined: (i) extension strategy (designing a substructure of initial\nsolutions as \"system kernel\" and extension of the substructure by additional\nelements); (ii) compression strategy (designing a superstructure of initial\nsolutions and deletion of some its elements); (iii) combined strategy; and (iv)\nnew design strategy to build a new solution over an extended domain of solution\nelements. Numerical real-world examples (e.g., telemetry system, communication\nprotocol, student plan, security system, Web-based information system,\ninvestment, educational courses) illustrate the suggested aggregation approach.",
    "published": "2011-11-29T21:08:06Z",
    "updated": "2011-11-29T21:08:06Z",
    "authors": [
      "Mark Sh. Levin"
    ],
    "link": "http://arxiv.org/abs/1111.6983v1",
    "pdf_link": "http://arxiv.org/pdf/1111.6983v1"
  },
  {
    "api_id": 82,
    "title": "Improvement of BM3D Algorithm and Employment to Satellite and CFA Images\n  Denoising",
    "summary": "This paper proposes a new procedure in order to improve the performance of\nblock matching and 3-D filtering (BM3D) image denoising algorithm. It is\ndemonstrated that it is possible to achieve a better performance than that of\nBM3D algorithm in a variety of noise levels. This method changes BM3D algorithm\nparameter values according to noise level, removes prefiltering, which is used\nin high noise level; therefore Peak Signal-to-Noise Ratio (PSNR) and visual\nquality get improved, and BM3D complexities and processing time are reduced.\nThis improved BM3D algorithm is extended and used to denoise satellite and\ncolor filter array (CFA) images. Output results show that the performance has\nupgraded in comparison with current methods of denoising satellite and CFA\nimages. In this regard this algorithm is compared with Adaptive PCA algorithm,\nthat has led to superior performance for denoising CFA images, on the subject\nof PSNR and visual quality. Also the processing time has decreased\nsignificantly.",
    "published": "2011-12-11T18:57:10Z",
    "updated": "2011-12-11T18:57:10Z",
    "authors": [
      "'Omid Pakdelazar'",
      "'Gholamali Rezai-rad'"
    ],
    "link": "http://arxiv.org/abs/1112.2386v1",
    "pdf_link": "http://arxiv.org/pdf/1112.2386v1"
  },
  {
    "api_id": 83,
    "title": "Of `Cocktail Parties' and Exoplanets",
    "summary": "The characterisation of ever smaller and fainter extrasolar planets requires\nan intricate understanding of one's data and the analysis techniques used.\nCorrecting the raw data at the 10^-4 level of accuracy in flux is one of the\ncentral challenges. This can be difficult for instruments that do not feature a\ncalibration plan for such high precision measurements. Here, it is not always\nobvious how to de-correlate the data using auxiliary information of the\ninstrument and it becomes paramount to know how well one can disentangle\ninstrument systematics from one's data, given nothing but the data itself. We\npropose a non-parametric machine learning algorithm, based on the concept of\nindependent component analysis, to de-convolve the systematic noise and all\nnon-Gaussian signals from the desired astrophysical signal. Such a `blind'\nsignal de-mixing is commonly known as the `Cocktail Party problem' in\nsignal-processing. Given multiple simultaneous observations of the same\nexoplanetary eclipse, as in the case of spectrophotometry, we show that we can\noften disentangle systematic noise from the original light curve signal without\nthe use of any complementary information of the instrument. In this paper, we\nexplore these signal extraction techniques using simulated data and two data\nsets observed with the Hubble-NICMOS instrument. Another important application\nis the de-correlation of the exoplanetary signal from time-correlated stellar\nvariability. Using data obtained by the Kepler mission we show that the desired\nsignal can be de-convolved from the stellar noise using a single time series\nspanning several eclipse events. Such non-parametric techniques can provide\nimportant confirmations of the existent parametric corrections reported in the\nliterature, and their associated results. Additionally they can substantially\nimprove the precision exoplanetary light curve analysis in the future.",
    "published": "2011-06-10T09:21:50Z",
    "updated": "2011-12-13T16:29:51Z",
    "authors": [
      "Ingo P. Waldmann"
    ],
    "link": "http://arxiv.org/abs/1106.1989v2",
    "pdf_link": "http://arxiv.org/pdf/1106.1989v2"
  },
  {
    "api_id": 84,
    "title": "Classification under Data Contamination with Application to Remote\n  Sensing Image Mis-registration",
    "summary": "This work is motivated by the problem of image mis-registration in remote\nsensing and we are interested in determining the resulting loss in the accuracy\nof pattern classification. A statistical formulation is given where we propose\nto use data contamination to model and understand the phenomenon of image\nmis-registration. This model is widely applicable to many other types of errors\nas well, for example, measurement errors and gross errors etc. The impact of\ndata contamination on classification is studied under a statistical learning\ntheoretical framework. A closed-form asymptotic bound is established for the\nresulting loss in classification accuracy, which is less than\n$\\epsilon/(1-\\epsilon)$ for data contamination of an amount of $\\epsilon$. Our\nbound is sharper than similar bounds in the domain adaptation literature and,\nunlike such bounds, it applies to classifiers with an infinite\nVapnik-Chervonekis (VC) dimension. Extensive simulations have been conducted on\nboth synthetic and real datasets under various types of data contamination,\nincluding label flipping, feature swapping and the replacement of feature\nvalues with data generated from a random source such as a Gaussian or Cauchy\ndistribution. Our simulation results show that the bound we derive is fairly\ntight.",
    "published": "2011-01-19T00:41:43Z",
    "updated": "2012-01-05T18:04:10Z",
    "authors": [
      "Donghui Yan",
      "Peng Gong",
      "Aiyou Chen",
      "Liheng Zhong"
    ],
    "link": "http://arxiv.org/abs/1101.3594v2",
    "pdf_link": "http://arxiv.org/pdf/1101.3594v2"
  },
  {
    "api_id": 85,
    "title": "Task-Driven Adaptive Statistical Compressive Sensing of Gaussian Mixture\n  Models",
    "summary": "A framework for adaptive and non-adaptive statistical compressive sensing is\ndeveloped, where a statistical model replaces the standard sparsity model of\nclassical compressive sensing. We propose within this framework optimal\ntask-specific sensing protocols specifically and jointly designed for\nclassification and reconstruction. A two-step adaptive sensing paradigm is\ndeveloped, where online sensing is applied to detect the signal class in the\nfirst step, followed by a reconstruction step adapted to the detected class and\nthe observed samples. The approach is based on information theory, here\ntailored for Gaussian mixture models (GMMs), where an information-theoretic\nobjective relationship between the sensed signals and a representation of the\nspecific task of interest is maximized. Experimental results using synthetic\nsignals, Landsat satellite attributes, and natural images of different sizes\nand with different noise levels show the improvements achieved using the\nproposed framework when compared to more standard sensing protocols. The\nunderlying formulation can be applied beyond GMMs, at the price of higher\nmathematical and computational complexity.",
    "published": "2012-01-25T22:25:27Z",
    "updated": "2012-01-25T22:25:27Z",
    "authors": [
      "Julio M. Duarte-Carvajalino",
      "Guoshen Yu",
      "Lawrence Carin",
      "Guillermo Sapiro"
    ],
    "link": "http://arxiv.org/abs/1201.5404v1",
    "pdf_link": "http://arxiv.org/pdf/1201.5404v1"
  },
  {
    "api_id": 86,
    "title": "Combining Spatial and Telemetric Features for Learning Animal Movement\n  Models",
    "summary": "We introduce a new graphical model for tracking radio-tagged animals and\nlearning their movement patterns. The model provides a principled way to\ncombine radio telemetry data with an arbitrary set of userdefined, spatial\nfeatures. We describe an efficient stochastic gradient algorithm for fitting\nmodel parameters to data and demonstrate its effectiveness via asymptotic\nanalysis and synthetic experiments. We also apply our model to real datasets,\nand show that it outperforms the most popular radio telemetry software package\nused in ecology. We conclude that integration of different data sources under a\nsingle statistical framework, coupled with appropriate parameter and state\nestimation procedures, produces both accurate location estimates and an\ninterpretable statistical model of animal movement.",
    "published": "2012-03-15T11:17:56Z",
    "updated": "2012-03-15T11:17:56Z",
    "authors": [
      "Berk Kapicioglu",
      "Robert E. Schapire",
      "Martin Wikelski",
      "Tamara Broderick"
    ],
    "link": "http://arxiv.org/abs/1203.3486v1",
    "pdf_link": "http://arxiv.org/pdf/1203.3486v1"
  },
  {
    "api_id": 87,
    "title": "A Near-Term Quantum Computing Approach for Hard Computational Problems\n  in Space Exploration",
    "summary": "In this article, we show how to map a sampling of the hardest artificial\nintelligence problems in space exploration onto equivalent Ising models that\nthen can be attacked using quantum annealing implemented in D-Wave machine. We\noverview the existing results as well as propose new Ising model\nimplementations for quantum annealing. We review supervised and unsupervised\nlearning algorithms for classification and clustering with applications to\nfeature identification and anomaly detection. We introduce algorithms for data\nfusion and image matching for remote sensing applications. We overview planning\nproblems for space exploration mission applications and algorithms for\ndiagnostics and recovery with applications to deep space missions. We describe\ncombinatorial optimization algorithms for task assignment in the context of\nautonomous unmanned exploration. Finally, we discuss the ways to circumvent the\nlimitation of the Ising mapping using a \"blackbox\" approach based on ideas from\nprobabilistic computing. In this article we describe the architecture of the\nD-Wave One machine and report its benchmarks. Results on random ensemble of\nproblems in the range of up to 96 qubits show improved scaling for median core\nquantum annealing time compared with classical algorithms; whether this scaling\npersists for larger problem sizes is an open question. We also review previous\nresults of D-Wave One benchmarking studies for solving binary classification\nproblems with a quantum boosting algorithm which is shown to outperform\nAdaBoost. We review quantum algorithms for structured learning for multi-label\nclassification and introduce a hybrid classical/quantum approach for learning\nthe weights. Results of D-Wave One benchmarking studies for learning structured\nlabels on four different data sets show a better performance compared with an\nindependent Support Vector Machine approach with linear kernel.",
    "published": "2012-04-12T19:58:40Z",
    "updated": "2012-04-18T19:49:31Z",
    "authors": [
      "Vadim N. Smelyanskiy",
      "Eleanor G. Rieffel",
      "Sergey I. Knysh",
      "Colin P. Williams",
      "Mark W. Johnson",
      "Murray C. Thom",
      "William G. Macready",
      "Kristen L. Pudenz"
    ],
    "link": "http://arxiv.org/abs/1204.2821v2",
    "pdf_link": "http://arxiv.org/pdf/1204.2821v2"
  },
  {
    "api_id": 88,
    "title": "Knowledge revision in systems based on an informed tree search strategy\n  : application to cartographic generalisation",
    "summary": "Many real world problems can be expressed as optimisation problems. Solving\nthis kind of problems means to find, among all possible solutions, the one that\nmaximises an evaluation function. One approach to solve this kind of problem is\nto use an informed search strategy. The principle of this kind of strategy is\nto use problem-specific knowledge beyond the definition of the problem itself\nto find solutions more efficiently than with an uninformed strategy. This kind\nof strategy demands to define problem-specific knowledge (heuristics). The\nefficiency and the effectiveness of systems based on it directly depend on the\nused knowledge quality. Unfortunately, acquiring and maintaining such knowledge\ncan be fastidious. The objective of the work presented in this paper is to\npropose an automatic knowledge revision approach for systems based on an\ninformed tree search strategy. Our approach consists in analysing the system\nexecution logs and revising knowledge based on these logs by modelling the\nrevision problem as a knowledge space exploration problem. We present an\nexperiment we carried out in an application domain where informed search\nstrategies are often used: cartographic generalisation.",
    "published": "2012-04-23T08:03:06Z",
    "updated": "2012-04-23T08:03:06Z",
    "authors": [
      "Patrick Taillandier",
      "Cécile Duchêne",
      "Alexis Drogoul"
    ],
    "link": "http://arxiv.org/abs/1204.4991v1",
    "pdf_link": "http://arxiv.org/pdf/1204.4991v1"
  },
  {
    "api_id": 89,
    "title": "Hyperspectral Unmixing Overview: Geometrical, Statistical, and Sparse\n  Regression-Based Approaches",
    "summary": "Imaging spectrometers measure electromagnetic energy scattered in their\ninstantaneous field view in hundreds or thousands of spectral channels with\nhigher spectral resolution than multispectral cameras. Imaging spectrometers\nare therefore often referred to as hyperspectral cameras (HSCs). Higher\nspectral resolution enables material identification via spectroscopic analysis,\nwhich facilitates countless applications that require identifying materials in\nscenarios unsuitable for classical spectroscopic analysis. Due to low spatial\nresolution of HSCs, microscopic material mixing, and multiple scattering,\nspectra measured by HSCs are mixtures of spectra of materials in a scene. Thus,\naccurate estimation requires unmixing. Pixels are assumed to be mixtures of a\nfew materials, called endmembers. Unmixing involves estimating all or some of:\nthe number of endmembers, their spectral signatures, and their abundances at\neach pixel. Unmixing is a challenging, ill-posed inverse problem because of\nmodel inaccuracies, observation noise, environmental conditions, endmember\nvariability, and data set size. Researchers have devised and investigated many\nmodels searching for robust, stable, tractable, and accurate unmixing\nalgorithms. This paper presents an overview of unmixing methods from the time\nof Keshava and Mustard's unmixing tutorial [1] to the present. Mixing models\nare first discussed. Signal-subspace, geometrical, statistical, sparsity-based,\nand spatial-contextual unmixing algorithms are described. Mathematical problems\nand potential solutions are described. Algorithm characteristics are\nillustrated experimentally.",
    "published": "2012-02-28T17:30:39Z",
    "updated": "2012-04-24T11:52:08Z",
    "authors": [
      "José M. Bioucas-Dias",
      "Antonio Plaza",
      "Nicolas Dobigeon",
      "Mario Parente",
      "Qian Du",
      "Paul Gader",
      "Jocelyn Chanussot"
    ],
    "link": "http://arxiv.org/abs/1202.6294v2",
    "pdf_link": "http://arxiv.org/pdf/1202.6294v2"
  },
  {
    "api_id": 90,
    "title": "A novel statistical fusion rule for image fusion and its comparison in\n  non subsampled contourlet transform domain and wavelet domain",
    "summary": "Image fusion produces a single fused image from a set of input images. A new\nmethod for image fusion is proposed based on Weighted Average Merging Method\n(WAMM) in the NonSubsampled Contourlet Transform (NSCT) domain. A performance\nanalysis on various statistical fusion rules are also analysed both in NSCT and\nWavelet domain. Analysis has been made on medical images, remote sensing images\nand multi focus images. Experimental results shows that the proposed method,\nWAMM obtained better results in NSCT domain than the wavelet domain as it\npreserves more edges and keeps the visual quality intact in the fused image.",
    "published": "2012-05-08T09:52:46Z",
    "updated": "2012-05-08T09:52:46Z",
    "authors": [
      "Manu V T",
      "Philomina Simon"
    ],
    "link": "http://arxiv.org/abs/1205.1648v1",
    "pdf_link": "http://arxiv.org/pdf/1205.1648v1"
  },
  {
    "api_id": 91,
    "title": "Visualization techniques for data mining of Latur district satellite\n  imagery",
    "summary": "This study presents a new visualization tool for classification of satellite\nimagery. Visualization of feature space allows exploration of patterns in the\nimage data and insight into the classification process and related uncertainty.\nVisual Data Mining provides added value to image classifications as the user\ncan be involved in the classification process providing increased confidence in\nand understanding of the results. In this study, we present a prototype\nvisualization tool for visual data mining (VDM) of satellite imagery. The\nvisualization tool is showcased in a classification study of highresolution\nimageries of Latur district in Maharashtra state of India.",
    "published": "2011-03-28T12:35:11Z",
    "updated": "2012-05-11T05:42:42Z",
    "authors": [
      "B. G. Kodge",
      "P. S. Hiremath"
    ],
    "link": "http://arxiv.org/abs/1104.3571v2",
    "pdf_link": "http://arxiv.org/pdf/1104.3571v2"
  },
  {
    "api_id": 92,
    "title": "State-Space Inference for Non-Linear Latent Force Models with\n  Application to Satellite Orbit Prediction",
    "summary": "Latent force models (LFMs) are flexible models that combine mechanistic\nmodelling principles (i.e., physical models) with non-parametric data-driven\ncomponents. Several key applications of LFMs need non-linearities, which\nresults in analytically intractable inference. In this work we show how\nnon-linear LFMs can be represented as non-linear white noise driven state-space\nmodels and present an efficient non-linear Kalman filtering and smoothing based\nmethod for approximate state and parameter inference. We illustrate the\nperformance of the proposed methodology via two simulated examples, and apply\nit to a real-world problem of long-term prediction of GPS satellite orbits.",
    "published": "2012-06-18T15:34:23Z",
    "updated": "2012-06-18T15:34:23Z",
    "authors": [
      "Jouni Hartikainen",
      "Mari Seppanen",
      "Simo Sarkka"
    ],
    "link": "http://arxiv.org/abs/1206.4670v1",
    "pdf_link": "http://arxiv.org/pdf/1206.4670v1"
  },
  {
    "api_id": 93,
    "title": "Discriminative Probabilistic Prototype Learning",
    "summary": "In this paper we propose a simple yet powerful method for learning\nrepresentations in supervised learning scenarios where each original input\ndatapoint is described by a set of vectors and their associated outputs may be\ngiven by soft labels indicating, for example, class probabilities. We represent\nan input datapoint as a mixture of probabilities over the corresponding set of\nfeature vectors where each probability indicates how likely each vector is to\nbelong to an unknown prototype pattern. We propose a probabilistic model that\nparameterizes these prototype patterns in terms of hidden variables and\ntherefore it can be trained with conventional approaches based on likelihood\nmaximization. More importantly, both the model parameters and the prototype\npatterns can be learned from data in a discriminative way. We show that our\nmodel can be seen as a probabilistic generalization of learning vector\nquantization (LVQ). We apply our method to the problems of shape\nclassification, hyperspectral imaging classification and people's work class\ncategorization, showing the superior performance of our method compared to the\nstandard prototype-based classification approach and other competitive\nbenchmark methods.",
    "published": "2012-06-18T15:42:34Z",
    "updated": "2012-06-18T15:42:34Z",
    "authors": [
      "Edwin Bonilla",
      "Antonio Robles-Kelly"
    ],
    "link": "http://arxiv.org/abs/1206.4686v1",
    "pdf_link": "http://arxiv.org/pdf/1206.4686v1"
  },
  {
    "api_id": 94,
    "title": "Plug-in martingales for testing exchangeability on-line",
    "summary": "A standard assumption in machine learning is the exchangeability of data,\nwhich is equivalent to assuming that the examples are generated from the same\nprobability distribution independently. This paper is devoted to testing the\nassumption of exchangeability on-line: the examples arrive one by one, and\nafter receiving each example we would like to have a valid measure of the\ndegree to which the assumption of exchangeability has been falsified. Such\nmeasures are provided by exchangeability martingales. We extend known\ntechniques for constructing exchangeability martingales and show that our new\nmethod is competitive with the martingales introduced before. Finally we\ninvestigate the performance of our testing method on two benchmark datasets,\nUSPS and Statlog Satellite data; for the former, the known techniques give\nsatisfactory results, but for the latter our new more flexible method becomes\nnecessary.",
    "published": "2012-04-15T10:21:57Z",
    "updated": "2012-06-28T09:36:27Z",
    "authors": [
      "Valentina Fedorova",
      "Alex Gammerman",
      "Ilia Nouretdinov",
      "Vladimir Vovk"
    ],
    "link": "http://arxiv.org/abs/1204.3251v2",
    "pdf_link": "http://arxiv.org/pdf/1204.3251v2"
  },
  {
    "api_id": 95,
    "title": "Markov Chains on Orbits of Permutation Groups",
    "summary": "We present a novel approach to detecting and utilizing symmetries in\nprobabilistic graphical models with two main contributions. First, we present a\nscalable approach to computing generating sets of permutation groups\nrepresenting the symmetries of graphical models. Second, we introduce orbital\nMarkov chains, a novel family of Markov chains leveraging model symmetries to\nreduce mixing times. We establish an insightful connection between model\nsymmetries and rapid mixing of orbital Markov chains. Thus, we present the\nfirst lifted MCMC algorithm for probabilistic graphical models. Both analytical\nand empirical results demonstrate the effectiveness and efficiency of the\napproach.",
    "published": "2012-06-23T14:27:39Z",
    "updated": "2012-06-28T14:54:39Z",
    "authors": [
      "Mathias Niepert"
    ],
    "link": "http://arxiv.org/abs/1206.5396v2",
    "pdf_link": "http://arxiv.org/pdf/1206.5396v2"
  },
  {
    "api_id": 96,
    "title": "Alternative Restart Strategies for CMA-ES",
    "summary": "This paper focuses on the restart strategy of CMA-ES on multi-modal\nfunctions. A first alternative strategy proceeds by decreasing the initial\nstep-size of the mutation while doubling the population size at each restart. A\nsecond strategy adaptively allocates the computational budget among the restart\nsettings in the BIPOP scheme. Both restart strategies are validated on the BBOB\nbenchmark; their generality is also demonstrated on an independent real-world\nproblem suite related to spacecraft trajectory optimization.",
    "published": "2012-07-01T13:50:20Z",
    "updated": "2012-07-01T13:50:20Z",
    "authors": [
      "Ilya Loshchilov",
      "Marc Schoenauer",
      "Michèle Sebag"
    ],
    "link": "http://arxiv.org/abs/1207.0206v1",
    "pdf_link": "http://arxiv.org/pdf/1207.0206v1"
  },
  {
    "api_id": 97,
    "title": "Polarimetric SAR Image Smoothing with Stochastic Distances",
    "summary": "Polarimetric Synthetic Aperture Radar (PolSAR) images are establishing as an\nimportant source of information in remote sensing applications. The most\ncomplete format this type of imaging produces consists of complex-valued\nHermitian matrices in every image coordinate and, as such, their visualization\nis challenging. They also suffer from speckle noise which reduces the\nsignal-to-noise ratio. Smoothing techniques have been proposed in the\nliterature aiming at preserving different features and, analogously,\nprojections from the cone of Hermitian positive matrices to different color\nrepresentation spaces are used for enhancing certain characteristics. In this\nwork we propose the use of stochastic distances between models that describe\nthis type of data in a Nagao-Matsuyama-type of smoothing technique. The\nresulting images are shown to present good visualization properties (noise\nreduction with preservation of fine details) in all the considered\nvisualization spaces.",
    "published": "2012-07-03T18:11:46Z",
    "updated": "2012-07-03T18:11:46Z",
    "authors": [
      "Leonardo Torres",
      "Antonio C. Medeiros",
      "Alejandro C. Frery"
    ],
    "link": "http://arxiv.org/abs/1207.0771v1",
    "pdf_link": "http://arxiv.org/pdf/1207.0771v1"
  },
  {
    "api_id": 98,
    "title": "Spatial And Spectral Quality Evaluation Based On Edges Regions Of\n  Satellite Image Fusion",
    "summary": "The Quality of image fusion is an essential determinant of the value of\nprocessing images fusion for many applications. Spatial and spectral qualities\nare the two important indexes that used to evaluate the quality of any fused\nimage. However, the jury is still out of fused image's benefits if it compared\nwith its original images. In addition, there is a lack of measures for\nassessing the objective quality of the spatial resolution for the fusion\nmethods. Therefore, an objective quality of the spatial resolution assessment\nfor fusion images is required. Most important details of the image are in edges\nregions, but most standards of image estimation do not depend upon specifying\nthe edges in the image and measuring their edges. However, they depend upon the\ngeneral estimation or estimating the uniform region, so this study deals with\nnew method proposed to estimate the spatial resolution by Contrast Statistical\nAnalysis (CSA) depending upon calculating the contrast of the edge, non edge\nregions and the rate for the edges regions. Specifying the edges in the image\nis made by using Soble operator with different threshold values. In addition,\nestimating the color distortion added by image fusion based on Histogram\nAnalysis of the edge brightness values of all RGB-color bands and Lcomponent.",
    "published": "2012-07-08T23:06:38Z",
    "updated": "2012-07-08T23:06:38Z",
    "authors": [
      "Firouz Abdullah Al-Wassai",
      "N. V. Kalyankar",
      "Ali A. Al-Zaky"
    ],
    "link": "http://arxiv.org/abs/1207.1922v1",
    "pdf_link": "http://arxiv.org/pdf/1207.1922v1"
  },
  {
    "api_id": 99,
    "title": "Hypothesis Testing in Speckled Data with Stochastic Distances",
    "summary": "Images obtained with coherent illumination, as is the case of sonar,\nultrasound-B, laser and Synthetic Aperture Radar -- SAR, are affected by\nspeckle noise which reduces the ability to extract information from the data.\nSpecialized techniques are required to deal with such imagery, which has been\nmodeled by the G0 distribution and under which regions with different degrees\nof roughness and mean brightness can be characterized by two parameters; a\nthird parameter, the number of looks, is related to the overall signal-to-noise\nratio. Assessing distances between samples is an important step in image\nanalysis; they provide grounds of the separability and, therefore, of the\nperformance of classification procedures. This work derives and compares eight\nstochastic distances and assesses the performance of hypothesis tests that\nemploy them and maximum likelihood estimation. We conclude that tests based on\nthe triangular distance have the closest empirical size to the theoretical one,\nwhile those based on the arithmetic-geometric distances have the best power.\nSince the power of tests based on the triangular distance is close to optimum,\nwe conclude that the safest choice is using this distance for hypothesis\ntesting, even when compared with classical distances as Kullback-Leibler and\nBhattacharyya.",
    "published": "2012-07-12T13:45:41Z",
    "updated": "2012-07-12T13:45:41Z",
    "authors": [
      "Abraão D. C. Nascimento",
      "Renato J. Cintra",
      "Alejandro C. Frery"
    ],
    "link": "http://arxiv.org/abs/1207.2959v1",
    "pdf_link": "http://arxiv.org/pdf/1207.2959v1"
  },
  {
    "api_id": 100,
    "title": "An intelligent approach towards automatic shape modeling and object\n  extraction from satellite images using cellular automata based algorithm",
    "summary": "Automatic feature extraction domain has witnessed the application of many\nintelligent methodologies over past decade; however detection accuracy of these\napproaches were limited as object geometry and contextual knowledge were not\ngiven enough consideration. In this paper, we propose a frame work for accurate\ndetection of features along with automatic interpolation, and interpretation by\nmodeling feature shape as well as contextual knowledge using advanced\ntechniques such as SVRF, Cellular Neural Network, Core set, and MACA. Developed\nmethodology has been compared with contemporary methods using different\nstatistical measures. Investigations over various satellite images revealed\nthat considerable success was achieved with the CNN approach. CNN has been\neffective in modeling different complex features effectively and complexity of\nthe approach has been considerably reduced using corset optimization. The\nsystem has dynamically used spectral and spatial information for representing\ncontextual knowledge using CNN-prolog approach. System has been also proved to\nbe effective in providing intelligent interpolation and interpretation of\nrandom features.",
    "published": "2013-03-27T00:33:52Z",
    "updated": "2013-03-27T00:33:52Z",
    "authors": [
      "P. V. Arun",
      "S. K. Katiyar"
    ],
    "link": "http://arxiv.org/abs/1303.6711v1",
    "pdf_link": "http://arxiv.org/pdf/1303.6711v1"
  },
  {
    "api_id": 101,
    "title": "A Comparative Analysis on the Applicability of Entropy in remote sensing",
    "summary": "Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.\nMethodologies were implemented in Matlab and were enhanced with entropy\nvariations. Evaluation of various implementations was based on different\nstatistical parameters with reference to the study area The popular available\nversions like Tsalli's, Shanon's, and Renyi's entropies were analysed in\ncontext of various remote sensing operations namely thresholding, clustering\nand registration.",
    "published": "2013-03-27T18:57:12Z",
    "updated": "2013-03-27T18:57:12Z",
    "authors": [
      "Dr. S. K. Katiyar",
      "Arun P. V."
    ],
    "link": "http://arxiv.org/abs/1303.6926v1",
    "pdf_link": "http://arxiv.org/pdf/1303.6926v1"
  },
  {
    "api_id": 102,
    "title": "An investigation towards wavelet based optimization of automatic image\n  registration techniques",
    "summary": "Image registration is the process of transforming different sets of data into\none coordinate system and is required for various remote sensing applications\nlike change detection, image fusion, and other related areas. The effect of\nincreased relief displacement, requirement of more control points, and\nincreased data volume are the challenges associated with the registration of\nhigh resolution image data. The objective of this research work is to study the\nmost efficient techniques and to investigate the extent of improvement\nachievable by enhancing them with Wavelet transform. The SIFT feature based\nmethod uses the Eigen value for extracting thousands of key points based on\nscale invariant features and these feature points when further enhanced by the\nwavelet transform yields the best results.",
    "published": "2013-03-27T19:02:02Z",
    "updated": "2013-03-27T19:02:02Z",
    "authors": [
      "Arun P. V.",
      "Dr. S. K. Katiyar"
    ],
    "link": "http://arxiv.org/abs/1303.6927v1",
    "pdf_link": "http://arxiv.org/pdf/1303.6927v1"
  },
  {
    "api_id": 103,
    "title": "Hierarchical Evidence Accumulation in the Pseiki System and Experiments\n  in Model-Driven Mobile Robot Navigation",
    "summary": "In this paper, we will review the process of evidence accumulation in the\nPSEIKI system for expectation-driven interpretation of images of 3-D scenes.\nExpectations are presented to PSEIKI as a geometrical hierarchy of\nabstractions. PSEIKI's job is then to construct abstraction hierarchies in the\nperceived image taking cues from the abstraction hierarchies in the\nexpectations. The Dempster-Shafer formalism is used for associating belief\nvalues with the different possible labels for the constructed abstractions in\nthe perceived image. This system has been used successfully for autonomous\nnavigation of a mobile robot in indoor environments.",
    "published": "2013-03-27T19:38:59Z",
    "updated": "2013-03-27T19:38:59Z",
    "authors": [
      "A. C. Kak",
      "K. M. Andress",
      "C. Lopez-Abadia",
      "M. S. Carroll",
      "J. R. Lewis"
    ],
    "link": "http://arxiv.org/abs/1304.1513v1",
    "pdf_link": "http://arxiv.org/pdf/1304.1513v1"
  },
  {
    "api_id": 104,
    "title": "Evidential Reasoning in Image Understanding",
    "summary": "In this paper, we present some results of evidential reasoning in\nunderstanding multispectral images of remote sensing systems. The\nDempster-Shafer approach of combination of evidences is pursued to yield\ncontextual classification results, which are compared with previous results of\nthe Bayesian context free classification, contextual classifications of dynamic\nprogramming and stochastic relaxation approaches.",
    "published": "2013-03-27T19:49:25Z",
    "updated": "2013-03-27T19:49:25Z",
    "authors": [
      "Minchuan Zhang",
      "Su-shing Chen"
    ],
    "link": "http://arxiv.org/abs/1304.2749v1",
    "pdf_link": "http://arxiv.org/pdf/1304.2749v1"
  },
  {
    "api_id": 105,
    "title": "A planetary nervous system for social mining and collective awareness",
    "summary": "We present a research roadmap of a Planetary Nervous System (PNS), capable of\nsensing and mining the digital breadcrumbs of human activities and unveiling\nthe knowledge hidden in the big data for addressing the big questions about\nsocial complexity. We envision the PNS as a globally distributed,\nself-organizing, techno-social system for answering analytical questions about\nthe status of world-wide society, based on three pillars: social sensing,\nsocial mining, and the idea of trust networks and privacy-aware social mining.\nWe discuss the ingredients of a science and a technology necessary to build the\nPNS upon the three mentioned pillars, beyond the limitations of their\nrespective state-of-art. Social sensing is aimed at developing better methods\nfor harvesting the big data from the techno-social ecosystem and make them\navailable for mining, learning and analysis at a properly high abstraction\nlevel.Social mining is the problem of discovering patterns and models of human\nbehaviour from the sensed data across the various social dimensions by data\nmining, machine learning and social network analysis. Trusted networks and\nprivacy-aware social mining is aimed at creating a new deal around the\nquestions of privacy and data ownership empowering individual persons with full\nawareness and control on own personal data, so that users may allow access and\nuse of their data for their own good and the common good. The PNS will provide\na goal-oriented knowledge discovery framework, made of technology and people,\nable to configure itself to the aim of answering questions about the pulse of\nglobal society. Given an analytical request, the PNS activates a process\ncomposed by a variety of interconnected tasks exploiting the social sensing and\nmining methods within the transparent ecosystem provided by the trusted\nnetwork.",
    "published": "2013-04-02T20:47:34Z",
    "updated": "2013-04-02T20:47:34Z",
    "authors": [
      "Fosca Giannotti",
      "Dino Pedreschi",
      " Alex",
      " Pentland",
      "Paul Lukowicz",
      "Donald Kossmann",
      "James Crowley",
      "Dirk Helbing"
    ],
    "link": "http://arxiv.org/abs/1304.3700v1",
    "pdf_link": "http://arxiv.org/pdf/1304.3700v1"
  },
  {
    "api_id": 106,
    "title": "Merging Satellite Measurements of Rainfall Using Multi-scale Imagery\n  Technique",
    "summary": "Several passive microwave satellites orbit the Earth and measure rainfall.\nThese measurements have the advantage of almost full global coverage when\ncompared to surface rain gauges. However, these satellites have low temporal\nrevisit and missing data over some regions. Image fusion is a useful technique\nto fill in the gaps of one image (one satellite measurement) using another one.\nThe proposed algorithm uses an iterative fusion scheme to integrate information\nfrom two satellite measurements. The algorithm is implemented on two datasets\nfor 7 years of half-hourly data. The results show significant improvements in\nrain detection and rain intensity in the merged measurements.",
    "published": "2013-04-11T19:31:57Z",
    "updated": "2013-04-11T19:31:57Z",
    "authors": [
      "Seyed Hamed Alemohammad",
      "Dara Entekhabi"
    ],
    "link": "http://arxiv.org/abs/1304.3406v1",
    "pdf_link": "http://arxiv.org/pdf/1304.3406v1"
  },
  {
    "api_id": 107,
    "title": "GPU Acclerated Automated Feature Extraction from Satellite Images",
    "summary": "The availability of large volumes of remote sensing data insists on higher\ndegree of automation in feature extraction, making it a need of the hour.The\nhuge quantum of data that needs to be processed entails accelerated processing\nto be enabled.GPUs, which were originally designed to provide efficient\nvisualization, are being massively employed for computation intensive parallel\nprocessing environments. Image processing in general and hence automated\nfeature extraction, is highly computation intensive, where performance\nimprovements have a direct impact on societal needs. In this context, an\nalgorithm has been formulated for automated feature extraction from a\npanchromatic or multispectral image based on image processing techniques. Two\nLaplacian of Guassian (LoG) masks were applied on the image individually\nfollowed by detection of zero crossing points and extracting the pixels based\non their standard deviation with the surrounding pixels. The two extracted\nimages with different LoG masks were combined together which resulted in an\nimage with the extracted features and edges. Finally the user is at liberty to\napply the image smoothing step depending on the noise content in the extracted\nimage. The image is passed through a hybrid median filter to remove the salt\nand pepper noise from the image. This paper discusses the aforesaid algorithm\nfor automated feature extraction, necessity of deployment of GPUs for the same;\nsystem-level challenges and quantifies the benefits of integrating GPUs in such\nenvironment. The results demonstrate that substantial enhancement in\nperformance margin can be achieved with the best utilization of GPU resources\nand an efficient parallelization strategy. Performance results in comparison\nwith the conventional computing scenario have provided a speedup of 20x, on\nrealization of this parallelizing strategy.",
    "published": "2013-04-15T06:03:19Z",
    "updated": "2013-04-15T06:03:19Z",
    "authors": [
      "K. Phani Tejaswi",
      "D. Shanmukha Rao",
      "Thara Nair",
      "A. V. V. Prasad"
    ],
    "link": "http://arxiv.org/abs/1304.3992v1",
    "pdf_link": "http://arxiv.org/pdf/1304.3992v1"
  },
  {
    "api_id": 108,
    "title": "Criticality of the metal-topological insulator transition driven by\n  disorder",
    "summary": "Employing scaling analysis of the localization length, we deduce the critical\nexponent of the metal-topological insulator (TI) transitions induced by\ndisorder. The obtained exponent nu~2.7 shows no conspicuous deviation from the\nvalue established for metal-ordinary insulator transitions in systems of the\nsymplectic class. We investigate the topological phase diagram upon carrier\ndoping to reveal the nature of the so-called topological Anderson insulator\n(TAI) region. The critical exponent of the metal-TAI transition is also first\nestimated, shown to be undistinguishable from the above value within the\nnumerical error. By symmetry considerations we determine the explicit form of\nRashba spin-orbit coupling in systems of C4v point group symmetry.",
    "published": "2012-11-21T13:40:33Z",
    "updated": "2013-04-17T09:04:57Z",
    "authors": [
      "Ai Yamakage",
      "Kentaro Nomura",
      "Ken-Ichiro Imura",
      "Yoshio Kuramoto"
    ],
    "link": "http://arxiv.org/abs/1211.5026v2",
    "pdf_link": "http://arxiv.org/pdf/1211.5026v2"
  },
  {
    "api_id": 109,
    "title": "Analytic Expressions for Stochastic Distances Between Relaxed Complex\n  Wishart Distributions",
    "summary": "The scaled complex Wishart distribution is a widely used model for multilook\nfull polarimetric SAR data whose adequacy has been attested in the literature.\nClassification, segmentation, and image analysis techniques which depend on\nthis model have been devised, and many of them employ some type of\ndissimilarity measure. In this paper we derive analytic expressions for four\nstochastic distances between relaxed scaled complex Wishart distributions in\ntheir most general form and in important particular cases. Using these\ndistances, inequalities are obtained which lead to new ways of deriving the\nBartlett and revised Wishart distances. The expressiveness of the four analytic\ndistances is assessed with respect to the variation of parameters. Such\ndistances are then used for deriving new tests statistics, which are proved to\nhave asymptotic chi-square distribution. Adopting the test size as a comparison\ncriterion, a sensitivity study is performed by means of Monte Carlo experiments\nsuggesting that the Bhattacharyya statistic outperforms all the others. The\npower of the tests is also assessed. Applications to actual data illustrate the\ndiscrimination and homogeneity identification capabilities of these distances.",
    "published": "2013-04-19T13:38:59Z",
    "updated": "2013-04-19T13:38:59Z",
    "authors": [
      "Alejandro C. Frery",
      "Abraão D. C. Nascimento",
      "Renato J. Cintra"
    ],
    "link": "http://arxiv.org/abs/1304.5417v1",
    "pdf_link": "http://arxiv.org/pdf/1304.5417v1"
  },
  {
    "api_id": 110,
    "title": "Cognitive Interpretation of Everyday Activities: Toward Perceptual\n  Narrative Based Visuo-Spatial Scene Interpretation",
    "summary": "We position a narrative-centred computational model for high-level knowledge\nrepresentation and reasoning in the context of a range of assistive\ntechnologies concerned with \"visuo-spatial perception and cognition\" tasks. Our\nproposed narrative model encompasses aspects such as \\emph{space, events,\nactions, change, and interaction} from the viewpoint of commonsense reasoning\nand learning in large-scale cognitive systems. The broad focus of this paper is\non the domain of \"human-activity interpretation\" in smart environments, ambient\nintelligence etc. In the backdrop of a \"smart meeting cinematography\" domain,\nwe position the proposed narrative model, preliminary work on perceptual\nnarrativisation, and the immediate outlook on constructing general-purpose\nopen-source tools for perceptual narrativisation.\n  ACM Classification: I.2 Artificial Intelligence: I.2.0 General -- Cognitive\nSimulation, I.2.4 Knowledge Representation Formalisms and Methods, I.2.10\nVision and Scene Understanding: Architecture and control structures, Motion,\nPerceptual reasoning, Shape, Video analysis\n  General keywords: cognitive systems; human-computer interaction; spatial\ncognition and computation; commonsense reasoning; spatial and temporal\nreasoning; assistive technologies",
    "published": "2013-06-22T10:37:34Z",
    "updated": "2013-06-22T10:37:34Z",
    "authors": [
      "Mehul Bhatt",
      "Jakob Suchan",
      "Carl Schultz"
    ],
    "link": "http://arxiv.org/abs/1306.5308v1",
    "pdf_link": "http://arxiv.org/pdf/1306.5308v1"
  },
  {
    "api_id": 111,
    "title": "Exploiting Data Parallelism in the yConvex Hypergraph Algorithm for\n  Image Representation using GPGPUs",
    "summary": "To define and identify a region-of-interest (ROI) in a digital image, the\nshape descriptor of the ROI has to be described in terms of its boundary\ncharacteristics. To address the generic issues of contour tracking, the yConvex\nHypergraph (yCHG) model was proposed by Kanna et al [1]. In this work, we\npropose a parallel approach to implement the yCHG model by exploiting massively\nparallel cores of NVIDIA's Compute Unified Device Architecture (CUDA). We\nperform our experiments on the MODIS satellite image database by NASA, and\nbased on our analysis we observe that the performance of the serial\nimplementation is better on smaller images, but once the threshold is achieved\nin terms of image resolution, the parallel implementation outperforms its\nsequential counterpart by 2 to 10 times (2x-10x). We also conclude that an\nincrease in the number of hyperedges in the ROI of a given size does not impact\nthe performance of the overall algorithm.",
    "published": "2013-06-23T22:31:49Z",
    "updated": "2013-06-23T22:31:49Z",
    "authors": [
      "Saurabh Jha",
      "Tejaswi Agarwal",
      "B. Rajesh Kanna"
    ],
    "link": "http://arxiv.org/abs/1307.2560v1",
    "pdf_link": "http://arxiv.org/pdf/1307.2560v1"
  },
  {
    "api_id": 112,
    "title": "Hyperspectral Data Unmixing Using GNMF Method and Sparseness Constraint",
    "summary": "Hyperspectral images contain mixed pixels due to low spatial resolution of\nhyperspectral sensors. Mixed pixels are pixels containing more than one\ndistinct material called endmembers. The presence percentages of endmembers in\nmixed pixels are called abundance fractions. Spectral unmixing problem refers\nto decomposing these pixels into a set of endmembers and abundance fractions.\nDue to nonnegativity constraint on abundance fractions, nonnegative matrix\nfactorization methods (NMF) have been widely used for solving spectral unmixing\nproblem. In this paper we have used graph regularized (GNMF) method with\nsparseness constraint to unmix hyperspectral data. This method applied on\nsimulated data using AVIRIS Indian Pines dataset and USGS library and results\nare quantified based on AAD and SAD measures. Results in comparison with other\nmethods show that the proposed method can unmix data more effectively.",
    "published": "2013-06-29T16:57:44Z",
    "updated": "2013-06-29T16:57:44Z",
    "authors": [
      "Roozbeh Rajabi",
      "Hassan Ghassemian"
    ],
    "link": "http://arxiv.org/abs/1307.0129v1",
    "pdf_link": "http://arxiv.org/pdf/1307.0129v1"
  },
  {
    "api_id": 113,
    "title": "Further results on dissimilarity spaces for hyperspectral images RF-CBIR",
    "summary": "Content-Based Image Retrieval (CBIR) systems are powerful search tools in\nimage databases that have been little applied to hyperspectral images.\nRelevance feedback (RF) is an iterative process that uses machine learning\ntechniques and user's feedback to improve the CBIR systems performance. We\npursued to expand previous research in hyperspectral CBIR systems built on\ndissimilarity functions defined either on spectral and spatial features\nextracted by spectral unmixing techniques, or on dictionaries extracted by\ndictionary-based compressors. These dissimilarity functions were not suitable\nfor direct application in common machine learning techniques. We propose to use\na RF general approach based on dissimilarity spaces which is more appropriate\nfor the application of machine learning algorithms to the hyperspectral\nRF-CBIR. We validate the proposed RF method for hyperspectral CBIR systems over\na real hyperspectral dataset.",
    "published": "2013-07-04T11:58:04Z",
    "updated": "2013-07-04T11:58:04Z",
    "authors": [
      "Miguel Angel Veganzones",
      "Mihai Datcu",
      "Manuel Graña"
    ],
    "link": "http://arxiv.org/abs/1307.1289v1",
    "pdf_link": "http://arxiv.org/pdf/1307.1289v1"
  },
  {
    "api_id": 114,
    "title": "Major Limitations of Satellite images",
    "summary": "Remote sensing has proven to be a powerful tool for the monitoring of the\nEarth surface to improve our perception of our surroundings has led to\nunprecedented developments in sensor and information technologies. However,\ntechnologies for effective use of the data and for extracting useful\ninformation from the data of Remote sensing are still very limited since no\nsingle sensor combines the optimal spectral, spatial and temporal resolution.\nThis paper briefly reviews the limitations of satellite remote sensing. Also,\nreviews on the problems of image fusion techniques. The conclusion of this,\nAccording to literature, the remote sensing is still the lack of software tools\nfor effective information extraction from remote sensing data. The trade-off in\nspectral and spatial resolution will remain and new advanced data fusion\napproaches are needed to make optimal use of remote sensors for extract the\nmost useful information.",
    "published": "2013-07-09T13:01:46Z",
    "updated": "2013-07-09T13:01:46Z",
    "authors": [
      "Firouz A. Al-Wassai",
      "N. V. Kalyankar"
    ],
    "link": "http://arxiv.org/abs/1307.2434v1",
    "pdf_link": "http://arxiv.org/pdf/1307.2434v1"
  },
  {
    "api_id": 115,
    "title": "Image Fusion Technologies In Commercial Remote Sensing Packages",
    "summary": "Several remote sensing software packages are used to the explicit purpose of\nanalyzing and visualizing remotely sensed data, with the developing of remote\nsensing sensor technologies from last ten years. Accord-ing to literature, the\nremote sensing is still the lack of software tools for effective information\nextraction from remote sensing data. So, this paper provides a state-of-art of\nmulti-sensor image fusion technologies as well as review on the quality\nevaluation of the single image or fused images in the commercial remote sensing\npack-ages. It also introduces program (ALwassaiProcess) developed for image\nfusion and classification.",
    "published": "2013-07-09T13:14:11Z",
    "updated": "2013-07-09T13:14:11Z",
    "authors": [
      "Firouz Abdullah Al-Wassai",
      "N. V. Kalyankar"
    ],
    "link": "http://arxiv.org/abs/1307.2440v1",
    "pdf_link": "http://arxiv.org/pdf/1307.2440v1"
  },
  {
    "api_id": 116,
    "title": "Completeness of the isomorphism problem for separable C*-algebras",
    "summary": "We prove that the isomorphism problem for separable nuclear C*-algebras is\ncomplete in the class of orbit equivalence relations. In fact, already the\nisomorphism of simple, separable AI C*-algebras is a complete orbit equivalence\nrelation. This means that any isomorphism problem arsing from a continuous\naction of a separable completely metrizable group can be reduced to the\nisomorphism of simple, separable AI C*-algebras. As a consequence, we get that\nthe isomorphism problems for separable nuclear C*-algebras and for separable\nC*-algebras have the same complexity. This answers questions posed by Elliott,\nFarah, Paulsen, Rosendal, Toms and T\\\"ornquist.",
    "published": "2013-06-05T10:35:22Z",
    "updated": "2013-07-13T13:46:41Z",
    "authors": [
      "Marcin Sabok"
    ],
    "link": "http://arxiv.org/abs/1306.1049v2",
    "pdf_link": "http://arxiv.org/pdf/1306.1049v2"
  },
  {
    "api_id": 117,
    "title": "Processing stationary noise: model and parameter selection in\n  variational methods",
    "summary": "Additive or multiplicative stationary noise recently became an important\nissue in applied fields such as microscopy or satellite imaging. Relatively few\nworks address the design of dedicated denoising methods compared to the usual\nwhite noise setting. We recently proposed a variational algorithm to tackle\nthis issue. In this paper, we analyze this problem from a statistical point of\nview and provide deterministic properties of the solutions of the associated\nvariational problems. In the first part of this work, we demonstrate that in\nmany practical problems, the noise can be assimilated to a colored Gaussian\nnoise. We provide a quantitative measure of the distance between a stationary\nprocess and the corresponding Gaussian process. In the second part, we focus on\nthe Gaussian setting and analyze denoising methods which consist of minimizing\nthe sum of a total variation term and an $l^2$ data fidelity term. While the\nconstrained formulation of this problem allows to easily tune the parameters,\nthe Lagrangian formulation can be solved more efficiently since the problem is\nstrongly convex. Our second contribution consists in providing analytical\nvalues of the regularization parameter in order to approximately satisfy\nMorozov's discrepancy principle.",
    "published": "2013-07-17T12:14:52Z",
    "updated": "2013-07-17T12:14:52Z",
    "authors": [
      "Jérôme Fehrenbach",
      "Pierre Weiss"
    ],
    "link": "http://arxiv.org/abs/1307.4592v1",
    "pdf_link": "http://arxiv.org/pdf/1307.4592v1"
  },
  {
    "api_id": 118,
    "title": "Content Based Image Retrieval System using Feature Classification with\n  Modified KNN Algorithm",
    "summary": "Feature means countenance, remote sensing scene objects with similar\ncharacteristics, associated to interesting scene elements in the image\nformation process. They are classified into three types in image processing,\nthat is low, middle and high. Low level features are color, texture and middle\nlevel feature is shape and high level feature is semantic gap of objects. An\nimage retrieval system is a computer system for browsing, searching and\nretrieving images from a large image database. Content Based Image Retrieval is\na technique which uses visual features of image such as color, shape, texture\nto search user required image from large image database according to user\nrequests in the form of a query. MKNN is an enhancing method of KNN. The\nproposed KNN classification is called MKNN. MKNN contains two parts for\nprocessing, they are validity of the train samples and applying weighted KNN.\nThe validity of each point is computed according to its neighbors. In our\nproposal, Modified K-Nearest Neighbor can be considered a kind of weighted KNN\nso that the query label is approximated by weighting the neighbors of the\nquery.",
    "published": "2013-07-17T18:22:24Z",
    "updated": "2013-07-17T18:22:24Z",
    "authors": [
      "T. Dharani",
      "I. Laurence Aroquiaraj"
    ],
    "link": "http://arxiv.org/abs/1307.4717v1",
    "pdf_link": "http://arxiv.org/pdf/1307.4717v1"
  },
  {
    "api_id": 119,
    "title": "Nonlinear unmixing of hyperspectral images: models and algorithms",
    "summary": "When considering the problem of unmixing hyperspectral images, most of the\nliterature in the geoscience and image processing areas relies on the widely\nused linear mixing model (LMM). However, the LMM may be not valid and other\nnonlinear models need to be considered, for instance, when there are\nmulti-scattering effects or intimate interactions. Consequently, over the last\nfew years, several significant contributions have been proposed to overcome the\nlimitations inherent in the LMM. In this paper, we present an overview of\nrecent advances in nonlinear unmixing modeling.",
    "published": "2013-04-06T10:21:56Z",
    "updated": "2013-07-18T14:01:41Z",
    "authors": [
      "Nicolas Dobigeon",
      "Jean-Yves Tourneret",
      "Cédric Richard",
      "José C. M. Bermudez",
      "Stephen McLaughlin",
      "Alfred O. Hero"
    ],
    "link": "http://arxiv.org/abs/1304.1875v2",
    "pdf_link": "http://arxiv.org/pdf/1304.1875v2"
  },
  {
    "api_id": 120,
    "title": "Kernel Multivariate Analysis Framework for Supervised Subspace Learning:\n  A Tutorial on Linear and Kernel Multivariate Methods",
    "summary": "Feature extraction and dimensionality reduction are important tasks in many\nfields of science dealing with signal processing and analysis. The relevance of\nthese techniques is increasing as current sensory devices are developed with\never higher resolution, and problems involving multimodal data sources become\nmore common. A plethora of feature extraction methods are available in the\nliterature collectively grouped under the field of Multivariate Analysis (MVA).\nThis paper provides a uniform treatment of several methods: Principal Component\nAnalysis (PCA), Partial Least Squares (PLS), Canonical Correlation Analysis\n(CCA) and Orthonormalized PLS (OPLS), as well as their non-linear extensions\nderived by means of the theory of reproducing kernel Hilbert spaces. We also\nreview their connections to other methods for classification and statistical\ndependence estimation, and introduce some recent developments to deal with the\nextreme cases of large-scale and low-sized problems. To illustrate the wide\napplicability of these methods in both classification and regression problems,\nwe analyze their performance in a benchmark of publicly available data sets,\nand pay special attention to specific real applications involving audio\nprocessing for music genre prediction and hyperspectral satellite images for\nEarth and climate monitoring.",
    "published": "2013-10-18T16:44:05Z",
    "updated": "2013-10-18T16:44:05Z",
    "authors": [
      "Jerónimo Arenas-García",
      "Kaare Brandt Petersen",
      "Gustavo Camps-Valls",
      "Lars Kai Hansen"
    ],
    "link": "http://arxiv.org/abs/1310.5089v1",
    "pdf_link": "http://arxiv.org/pdf/1310.5089v1"
  },
  {
    "api_id": 121,
    "title": "Advances in Hyperspectral Image Classification: Earth monitoring with\n  statistical learning methods",
    "summary": "Hyperspectral images show similar statistical properties to natural grayscale\nor color photographic images. However, the classification of hyperspectral\nimages is more challenging because of the very high dimensionality of the\npixels and the small number of labeled examples typically available for\nlearning. These peculiarities lead to particular signal processing problems,\nmainly characterized by indetermination and complex manifolds. The framework of\nstatistical learning has gained popularity in the last decade. New methods have\nbeen presented to account for the spatial homogeneity of images, to include\nuser's interaction via active learning, to take advantage of the manifold\nstructure with semisupervised learning, to extract and encode invariances, or\nto adapt classifiers and image representations to unseen yet similar scenes.\nThis tutuorial reviews the main advances for hyperspectral remote sensing image\nclassification through illustrative examples.",
    "published": "2013-10-18T17:49:45Z",
    "updated": "2013-10-18T17:49:45Z",
    "authors": [
      "Gustavo Camps-Valls",
      "Devis Tuia",
      "Lorenzo Bruzzone",
      "Jón Atli Benediktsson"
    ],
    "link": "http://arxiv.org/abs/1310.5107v1",
    "pdf_link": "http://arxiv.org/pdf/1310.5107v1"
  },
  {
    "api_id": 122,
    "title": "Fusion of Hyperspectral and Panchromatic Images using Spectral Uumixing\n  Results",
    "summary": "Hyperspectral imaging, due to providing high spectral resolution images, is\none of the most important tools in the remote sensing field. Because of\ntechnological restrictions hyperspectral sensors has a limited spatial\nresolution. On the other hand panchromatic image has a better spatial\nresolution. Combining this information together can provide a better\nunderstanding of the target scene. Spectral unmixing of mixed pixels in\nhyperspectral images results in spectral signature and abundance fractions of\nendmembers but gives no information about their location in a mixed pixel. In\nthis paper we have used spectral unmixing results of hyperspectral images and\nsegmentation results of panchromatic image for data fusion. The proposed method\nhas been applied on simulated data using AVRIS Indian Pines datasets. Results\nshow that this method can effectively combine information in hyperspectral and\npanchromatic images.",
    "published": "2013-10-22T15:44:51Z",
    "updated": "2013-10-22T15:44:51Z",
    "authors": [
      "Roozbeh Rajabi",
      "Hassan Ghassemian"
    ],
    "link": "http://arxiv.org/abs/1310.5965v1",
    "pdf_link": "http://arxiv.org/pdf/1310.5965v1"
  },
  {
    "api_id": 123,
    "title": "Studying a Chaotic Spiking Neural Model",
    "summary": "Dynamics of a chaotic spiking neuron model are being studied mathematically\nand experimentally. The Nonlinear Dynamic State neuron (NDS) is analysed to\nfurther understand the model and improve it. Chaos has many interesting\nproperties such as sensitivity to initial conditions, space filling, control\nand synchronization. As suggested by biologists, these properties may be\nexploited and play vital role in carrying out computational tasks in human\nbrain. The NDS model has some limitations; in thus paper the model is\ninvestigated to overcome some of these limitations in order to enhance the\nmodel. Therefore, the models parameters are tuned and the resulted dynamics are\nstudied. Also, the discretization method of the model is considered. Moreover,\na mathematical analysis is carried out to reveal the underlying dynamics of the\nmodel after tuning of its parameters. The results of the aforementioned methods\nrevealed some facts regarding the NDS attractor and suggest the stabilization\nof a large number of unstable periodic orbits (UPOs) which might correspond to\nmemories in phase space.",
    "published": "2013-10-26T14:21:10Z",
    "updated": "2013-10-26T14:21:10Z",
    "authors": [
      "Mohammad Alhawarat",
      "Waleed Nazih",
      "Mohammad Eldesouki"
    ],
    "link": "http://arxiv.org/abs/1310.7115v1",
    "pdf_link": "http://arxiv.org/pdf/1310.7115v1"
  },
  {
    "api_id": 124,
    "title": "Nonlinear unmixing of hyperspectral images using a semiparametric model\n  and spatial regularization",
    "summary": "Incorporating spatial information into hyperspectral unmixing procedures has\nbeen shown to have positive effects, due to the inherent spatial-spectral\nduality in hyperspectral scenes. Current research works that consider spatial\ninformation are mainly focused on the linear mixing model. In this paper, we\ninvestigate a variational approach to incorporating spatial correlation into a\nnonlinear unmixing procedure. A nonlinear algorithm operating in reproducing\nkernel Hilbert spaces, associated with an $\\ell_1$ local variation norm as the\nspatial regularizer, is derived. Experimental results, with both synthetic and\nreal data, illustrate the effectiveness of the proposed scheme.",
    "published": "2013-10-31T17:40:20Z",
    "updated": "2013-10-31T17:40:20Z",
    "authors": [
      "Jie Chen",
      "Cédric Richard",
      "Alfred O. Hero III"
    ],
    "link": "http://arxiv.org/abs/1310.8612v1",
    "pdf_link": "http://arxiv.org/pdf/1310.8612v1"
  },
  {
    "api_id": 125,
    "title": "Iterative Bilateral Filtering of Polarimetric SAR Data",
    "summary": "In this paper, we introduce an iterative speckle filtering method for\npolarimetric SAR (PolSAR) images based on the bilateral filter. To locally\nadapt to the spatial structure of images, this filter relies on pixel\nsimilarities in both spatial and radiometric domains. To deal with polarimetric\ndata, we study the use of similarities based on a statistical distance called\nKullback-Leibler divergence as well as two geodesic distances on Riemannian\nmanifolds. To cope with speckle, we propose to progressively refine the result\nthanks to an iterative scheme. Experiments are run over synthetic and\nexperimental data. First, simulations are generated to study the effects of\nfiltering parameters in terms of polarimetric reconstruction error, edge\npreservation and smoothing of homogeneous areas. Comparison with other methods\nshows that our approach compares well to other state of the art methods in the\nextraction of polarimetric information and shows superior performance for edge\nrestoration and noise smoothing. The filter is then applied to experimental\ndata sets from ESAR and FSAR sensors (DLR) at L-band and S-band, respectively.\nThese last experiments show the ability of the filter to restore structures\nsuch as buildings and roads and to preserve boundaries between regions while\nachieving a high amount of smoothing in homogeneous areas.",
    "published": "2013-11-01T12:20:17Z",
    "updated": "2013-11-01T12:20:17Z",
    "authors": [
      "Olivier D'Hondt",
      "Stéphane Guillaso",
      "Olaf Hellwich"
    ],
    "link": "http://arxiv.org/abs/1311.0162v1",
    "pdf_link": "http://arxiv.org/pdf/1311.0162v1"
  },
  {
    "api_id": 126,
    "title": "Quality Assessment of Pixel-Level ImageFusion Using Fuzzy Logic",
    "summary": "Image fusion is to reduce uncertainty and minimize redundancy in the output\nwhile maximizing relevant information from two or more images of a scene into a\nsingle composite image that is more informative and is more suitable for visual\nperception or processing tasks like medical imaging, remote sensing, concealed\nweapon detection, weather forecasting, biometrics etc. Image fusion combines\nregistered images to produce a high quality fused image with spatial and\nspectral information. The fused image with more information will improve the\nperformance of image analysis algorithms used in different applications. In\nthis paper, we proposed a fuzzy logic method to fuse images from different\nsensors, in order to enhance the quality and compared proposed method with two\nother methods i.e. image fusion using wavelet transform and weighted average\ndiscrete wavelet transform based image fusion using genetic algorithm (here\nonwards abbreviated as GA) along with quality evaluation parameters image\nquality index (IQI), mutual information measure (MIM), root mean square error\n(RMSE), peak signal to noise ratio (PSNR), fusion factor (FF), fusion symmetry\n(FS) and fusion index (FI) and entropy. The results obtained from proposed\nfuzzy based image fusion approach improves quality of fused image as compared\nto earlier reported methods, wavelet transform based image fusion and weighted\naverage discrete wavelet transform based image fusion using genetic algorithm.",
    "published": "2013-11-05T21:13:14Z",
    "updated": "2013-11-05T21:13:14Z",
    "authors": [
      "Srinivasa Rao Dammavalam",
      "Seetha Maddala",
      "M. H. M. Krishna Prasad"
    ],
    "link": "http://arxiv.org/abs/1311.1223v1",
    "pdf_link": "http://arxiv.org/pdf/1311.1223v1"
  },
  {
    "api_id": 127,
    "title": "A new bio-inspired method for remote sensing imagery classification",
    "summary": "The problem of supervised classification of the satellite image is considered\nto be the task of grouping pixels into a number of homogeneous regions in space\nintensity. This paper proposes a novel approach that combines a radial basic\nfunction clustering network with a growing neural gas include utility factor\nclassifier to yield improved solutions, obtained with previous networks. The\ndouble objective technique is first used to the development of a method to\nperform the satellite images classification, and finally, the implementation to\naddress the issue of the number of nodes in the hidden layer of the classic\nRadial Basis functions network. Results demonstrating the effectiveness of the\nproposed technique are provided for numeric remote sensing imagery. Moreover,\nthe remotely sensed image of Oran city in Algeria has been classified using the\nproposed technique to establish its utility.",
    "published": "2013-02-11T20:43:47Z",
    "updated": "2013-11-16T14:42:51Z",
    "authors": [
      "Amghar Yasmina Teldja",
      "Fizazi Hadria"
    ],
    "link": "http://arxiv.org/abs/1302.2606v2",
    "pdf_link": "http://arxiv.org/pdf/1302.2606v2"
  },
  {
    "api_id": 128,
    "title": "Supervised learning of a regression model based on latent process.\n  Application to the estimation of fuel cell life time",
    "summary": "This paper describes a pattern recognition approach aiming to estimate fuel\ncell duration time from electrochemical impedance spectroscopy measurements. It\nconsists in first extracting features from both real and imaginary parts of the\nimpedance spectrum. A parametric model is considered in the case of the real\npart, whereas regression model with latent variables is used in the latter\ncase. Then, a linear regression model using different subsets of extracted\nfeatures is used fo r the estimation of fuel cell time duration. The\nperformances of the proposed approach are evaluated on experimental data set to\nshow its feasibility. This could lead to interesting perspectives for\npredictive maintenance policy of fuel cell.",
    "published": "2013-12-25T18:55:59Z",
    "updated": "2013-12-25T18:55:59Z",
    "authors": [
      "Raïssa Onanena",
      "Faicel Chamroukhi",
      "Latifa Oukhellou",
      "Denis Candusso",
      "Patrice Aknin",
      "Daniel Hissel"
    ],
    "link": "http://arxiv.org/abs/1312.7003v1",
    "pdf_link": "http://arxiv.org/pdf/1312.7003v1"
  },
  {
    "api_id": 129,
    "title": "Proceedings 2nd Workshop on GRAPH Inspection and Traversal Engineering",
    "summary": "These are the proceedings of the Second Workshop on GRAPH Inspection and\nTraversal Engineering (GRAPHITE 2013), which took place on March 24, 2013 in\nRome, Italy, as a satellite event of the 16th European Joint Conferences on\nTheory and Practice of Software (ETAPS 2013).\n  The topic of the GRAPHITE workshop is graph analysis in all its forms in\ncomputer science. Graphs are used to represent data in many application areas,\nand they are subjected to various computational algorithms in order to acquire\nthe desired information. These graph algorithms tend to have common\ncharacteristics, such as duplicate detection to guarantee their termination,\nindependent of their application domain. Over the past few years, it has been\nshown that the scalability of such algorithms can be dramatically improved by\nusing, e.g., external memory, by exploiting parallel architectures, such as\nclusters, multi-core CPUs, and graphics processing units, and by using\nheuristics to guide the search. Novel techniques to further scale graph search\nalgorithms, and new applications of graph search are within the scope of this\nworkshop.\n  Another topic of interest of the event is more related to the structural\nproperties of graphs: which kind of graph characteristics are relevant for a\nparticular application area, and how can these be measured? Finally, any novel\nway of using graphs for a particular application area is on topic.\n  The goal of this event is to gather scientists from different communities,\nsuch as model checking, artificial intelligence planning, game playing, and\nalgorithm engineering, who do research on graph search algorithms, such that\nawareness of each others' work is increased.",
    "published": "2013-12-26T07:26:41Z",
    "updated": "2013-12-26T07:26:41Z",
    "authors": [
      "Anton Wijs",
      "Dragan Bošnački",
      "Stefan Edelkamp"
    ],
    "link": "http://arxiv.org/abs/1312.7062v1",
    "pdf_link": "http://arxiv.org/pdf/1312.7062v1"
  },
  {
    "api_id": 130,
    "title": "Satellite image classification and segmentation using non-additive\n  entropy",
    "summary": "Here we compare the Boltzmann-Gibbs-Shannon (standard) with the Tsallis\nentropy on the pattern recognition and segmentation of coloured images obtained\nby satellites, via \"Google Earth\". By segmentation we mean split an image to\nlocate regions of interest. Here, we discriminate and define an image partition\nclasses according to a training basis. This training basis consists of three\npattern classes: aquatic, urban and vegetation regions. Our numerical\nexperiments demonstrate that the Tsallis entropy, used as a feature vector\ncomposed of distinct entropic indexes $q$ outperforms the standard entropy.\nThere are several applications of our proposed methodology, once satellite\nimages can be used to monitor migration form rural to urban regions,\nagricultural activities, oil spreading on the ocean etc.",
    "published": "2014-01-10T17:57:16Z",
    "updated": "2014-01-10T17:57:16Z",
    "authors": [
      "Lucas Assirati",
      "Alexandre Souto Martinez",
      "Odemir Martinez Bruno"
    ],
    "link": "http://arxiv.org/abs/1401.2416v1",
    "pdf_link": "http://arxiv.org/pdf/1401.2416v1"
  },
  {
    "api_id": 131,
    "title": "Tensor Representation and Manifold Learning Methods for Remote Sensing\n  Images",
    "summary": "One of the main purposes of earth observation is to extract interested\ninformation and knowledge from remote sensing (RS) images with high efficiency\nand accuracy. However, with the development of RS technologies, RS system\nprovide images with higher spatial and temporal resolution and more spectral\nchannels than before, and it is inefficient and almost impossible to manually\ninterpret these images. Thus, it is of great interests to explore automatic and\nintelligent algorithms to quickly process such massive RS data with high\naccuracy. This thesis targets to develop some efficient information extraction\nalgorithms for RS images, by relying on the advanced technologies in machine\nlearning. More precisely, we adopt the manifold learning algorithms as the\nmainline and unify the regularization theory, tensor-based method, sparse\nlearning and transfer learning into the same framework. The main contributions\nof this thesis are as follows.",
    "published": "2014-01-13T15:33:57Z",
    "updated": "2014-01-13T15:33:57Z",
    "authors": [
      "Lefei Zhang"
    ],
    "link": "http://arxiv.org/abs/1401.2871v1",
    "pdf_link": "http://arxiv.org/pdf/1401.2871v1"
  },
  {
    "api_id": 132,
    "title": "Survey On The Estimation Of Mutual Information Methods as a Measure of\n  Dependency Versus Correlation Analysis",
    "summary": "In this survey, we present and compare different approaches to estimate\nMutual Information (MI) from data to analyse general dependencies between\nvariables of interest in a system. We demonstrate the performance difference of\nMI versus correlation analysis, which is only optimal in case of linear\ndependencies. First, we use a piece-wise constant Bayesian methodology using a\ngeneral Dirichlet prior. In this estimation method, we use a two-stage approach\nwhere we approximate the probability distribution first and then calculate the\nmarginal and joint entropies. Here, we demonstrate the performance of this\nBayesian approach versus the others for computing the dependency between\ndifferent variables. We also compare these with linear correlation analysis.\nFinally, we apply MI and correlation analysis to the identification of the bias\nin the determination of the aerosol optical depth (AOD) by the satellite based\nModerate Resolution Imaging Spectroradiometer (MODIS) and the ground based\nAErosol RObotic NETwork (AERONET). Here, we observe that the AOD measurements\nby these two instruments might be different for the same location. The reason\nof this bias is explored by quantifying the dependencies between the bias and\n15 other variables including cloud cover, surface reflectivity and others.",
    "published": "2014-01-14T21:17:21Z",
    "updated": "2014-01-14T21:17:21Z",
    "authors": [
      "D. Gencaga",
      "N. K. Malakar",
      "D. J. Lary"
    ],
    "link": "http://arxiv.org/abs/1401.3358v1",
    "pdf_link": "http://arxiv.org/pdf/1401.3358v1"
  },
  {
    "api_id": 133,
    "title": "An adaptive Simulated Annealing-based satellite observation scheduling\n  method combined with a dynamic task clustering strategy",
    "summary": "Efficient scheduling is of great significance to rationally make use of\nscarce satellite resources. Task clustering has been demonstrated to realize an\neffective strategy to improve the efficiency of satellite scheduling. However,\nthe previous task clustering strategy is static. That is, it is integrated into\nthe scheduling in a two-phase manner rather than in a dynamic fashion, without\nexpressing its full potential in improving the satellite scheduling\nperformance. In this study, we present an adaptive Simulated Annealing based\nscheduling algorithm aggregated with a dynamic task clustering strategy (or\nASA-DTC for short) for satellite observation scheduling problems (SOSPs).\nFirst, we develop a formal model for the scheduling of Earth observing\nsatellites. Second, we analyze the related constraints involved in the\nobservation task clustering process. Thirdly, we detail an implementation of\nthe dynamic task clustering strategy and the adaptive Simulated Annealing\nalgorithm. The adaptive Simulated Annealing algorithm is efficient, with the\nendowment of some sophisticated mechanisms, i.e. adaptive temperature control,\ntabu-list based revisiting avoidance mechanism, and intelligent combination of\nneighborhood structures. Finally, we report on experimental simulation studies\nto demonstrate the competitive performance of ASA-DTC. Moreover, we show that\nASA-DTC is especially effective when SOSPs contain a large number of targets or\nthese targets are densely distributed in a certain area.",
    "published": "2014-01-14T22:46:27Z",
    "updated": "2014-01-14T22:46:27Z",
    "authors": [
      "Guohua Wu",
      "Huilin Wang",
      "Haifeng Li",
      "Witold Pedrycz",
      "Dishan Qiu",
      "Manhao Ma",
      "Jin Liu"
    ],
    "link": "http://arxiv.org/abs/1401.6098v1",
    "pdf_link": "http://arxiv.org/pdf/1401.6098v1"
  },
  {
    "api_id": 134,
    "title": "A Heuristic Search Approach to Planning with Continuous Resources in\n  Stochastic Domains",
    "summary": "We consider the problem of optimal planning in stochastic domains with\nresource constraints, where the resources are continuous and the choice of\naction at each step depends on resource availability. We introduce the HAO*\nalgorithm, a generalization of the AO* algorithm that performs search in a\nhybrid state space that is modeled using both discrete and continuous state\nvariables, where the continuous variables represent monotonic resources. Like\nother heuristic search algorithms, HAO* leverages knowledge of the start state\nand an admissible heuristic to focus computational effort on those parts of the\nstate space that could be reached from the start state by following an optimal\npolicy. We show that this approach is especially effective when resource\nconstraints limit how much of the state space is reachable. Experimental\nresults demonstrate its effectiveness in the domain that motivates our\nresearch: automated planning for planetary exploration rovers.",
    "published": "2014-01-15T04:46:00Z",
    "updated": "2014-01-15T04:46:00Z",
    "authors": [
      "Nicolas Meuleau",
      "Emmanuel Benazera",
      "Ronen I. Brafman",
      "Eric A. Hansen",
      " Mausam"
    ],
    "link": "http://arxiv.org/abs/1401.3428v1",
    "pdf_link": "http://arxiv.org/pdf/1401.3428v1"
  },
  {
    "api_id": 135,
    "title": "Structured Priors for Sparse-Representation-Based Hyperspectral Image\n  Classification",
    "summary": "Pixel-wise classification, where each pixel is assigned to a predefined\nclass, is one of the most important procedures in hyperspectral image (HSI)\nanalysis. By representing a test pixel as a linear combination of a small\nsubset of labeled pixels, a sparse representation classifier (SRC) gives rather\nplausible results compared with that of traditional classifiers such as the\nsupport vector machine (SVM). Recently, by incorporating additional structured\nsparsity priors, the second generation SRCs have appeared in the literature and\nare reported to further improve the performance of HSI. These priors are based\non exploiting the spatial dependencies between the neighboring pixels, the\ninherent structure of the dictionary, or both. In this paper, we review and\ncompare several structured priors for sparse-representation-based HSI\nclassification. We also propose a new structured prior called the low rank\ngroup prior, which can be considered as a modification of the low rank prior.\nFurthermore, we will investigate how different structured priors improve the\nresult for the HSI classification.",
    "published": "2014-01-16T03:21:26Z",
    "updated": "2014-01-16T03:21:26Z",
    "authors": [
      "Xiaoxia Sun",
      "Qing Qu",
      "Nasser M. Nasrabadi",
      "Trac D. Tran"
    ],
    "link": "http://arxiv.org/abs/1401.3818v1",
    "pdf_link": "http://arxiv.org/pdf/1401.3818v1"
  },
  {
    "api_id": 136,
    "title": "Effective Features of Remote Sensing Image Classification Using\n  Interactive Adaptive Thresholding Method",
    "summary": "Remote sensing image classification can be performed in many different ways\nto extract meaningful features. One common approach is to perform edge\ndetection. A second approach is to try and detect whole shapes, given the fact\nthat these shapes usually tend to have distinctive properties such as object\nforeground or background. To get optimal results, these two approaches can be\ncombined. This paper adopts a combinatorial optimization method to adaptively\nselect threshold based features to improve remote sensing image. Feature\nselection is an important combinatorial optimization problem in the remote\nsensing image classification. The feature selection method has to achieve three\ncharacteristics: first the performance issues by facilitating data collection\nand reducing storage space and classification time, second to perform semantics\nanalysis helping to understand the problem, and third to improve prediction\naccuracy by avoiding the curse of dimensionality. The goal of this thresholding\nan image is to classify pixels as either dark or light and evaluation of\nclassification results. Interactive adaptive thresholding is a form of\nthresholding that takes into account spatial variations in illumination of\nremote sensing image. We present a technique for remote sensing based adaptive\nthresholding using the interactive satellite image of the input. However, our\nsolution is more robust to illumination changes in the remote sensing image.\nAdditionally, our method is simple and easy to implement but it is effective\nalgorithm to classify the image pixels. This technique is suitable for\npreprocessing the remote sensing image classification, making it a valuable\ntool for interactive remote based applications such as augmented reality of the\nclassification procedure.",
    "published": "2014-01-30T05:33:27Z",
    "updated": "2014-01-30T05:33:27Z",
    "authors": [
      "T. Balaji",
      "Dr. M. Sumathi"
    ],
    "link": "http://arxiv.org/abs/1401.7743v1",
    "pdf_link": "http://arxiv.org/pdf/1401.7743v1"
  },
  {
    "api_id": 137,
    "title": "Probabilistic Planning for Continuous Dynamic Systems under Bounded Risk",
    "summary": "This paper presents a model-based planner called the Probabilistic Sulu\nPlanner or the p-Sulu Planner, which controls stochastic systems in a goal\ndirected manner within user-specified risk bounds. The objective of the p-Sulu\nPlanner is to allow users to command continuous, stochastic systems, such as\nunmanned aerial and space vehicles, in a manner that is both intuitive and\nsafe. To this end, we first develop a new plan representation called a\nchance-constrained qualitative state plan (CCQSP), through which users can\nspecify the desired evolution of the plant state as well as the acceptable\nlevel of risk. An example of a CCQSP statement is go to A through B within 30\nminutes, with less than 0.001% probability of failure.\" We then develop the\np-Sulu Planner, which can tractably solve a CCQSP planning problem. In order to\nenable CCQSP planning, we develop the following two capabilities in this paper:\n1) risk-sensitive planning with risk bounds, and 2) goal-directed planning in a\ncontinuous domain with temporal constraints. The first capability is to ensures\nthat the probability of failure is bounded. The second capability is essential\nfor the planner to solve problems with a continuous state space such as vehicle\npath planning. We demonstrate the capabilities of the p-Sulu Planner by\nsimulations on two real-world scenarios: the path planning and scheduling of a\npersonal aerial vehicle as well as the space rendezvous of an autonomous cargo\nspacecraft.",
    "published": "2014-02-04T01:41:20Z",
    "updated": "2014-02-04T01:41:20Z",
    "authors": [
      "Masahiro Ono",
      "Brian C. Williams",
      "L. Blackmore"
    ],
    "link": "http://arxiv.org/abs/1402.0579v1",
    "pdf_link": "http://arxiv.org/pdf/1402.0579v1"
  },
  {
    "api_id": 138,
    "title": "Comparative analysis of common edge detection techniques in context of\n  object extraction",
    "summary": "Edges characterize boundaries and are therefore a problem of practical\nimportance in remote sensing.In this paper a comparative study of various edge\ndetection techniques and band wise analysis of these algorithms in the context\nof object extraction with regard to remote sensing satellite images from the\nIndian Remote Sensing Satellite (IRS) sensors LISS 3, LISS 4 and Cartosat1 as\nwell as Google Earth is presented.",
    "published": "2014-02-05T00:46:18Z",
    "updated": "2014-02-05T00:46:18Z",
    "authors": [
      "S. K. Katiyar",
      "P. V. Arun"
    ],
    "link": "http://arxiv.org/abs/1405.6132v1",
    "pdf_link": "http://arxiv.org/pdf/1405.6132v1"
  },
  {
    "api_id": 139,
    "title": "A review over the applicability of image entropy in analyses of remote\n  sensing datasets",
    "summary": "Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.",
    "published": "2014-02-05T14:49:36Z",
    "updated": "2014-02-05T14:49:36Z",
    "authors": [
      "S. K. Katiyar",
      "P. V. Arun"
    ],
    "link": "http://arxiv.org/abs/1405.6133v1",
    "pdf_link": "http://arxiv.org/pdf/1405.6133v1"
  },
  {
    "api_id": 140,
    "title": "Bias Correction and Modified Profile Likelihood under the Wishart\n  Complex Distribution",
    "summary": "This paper proposes improved methods for the maximum likelihood (ML)\nestimation of the equivalent number of looks $L$. This parameter has a\nmeaningful interpretation in the context of polarimetric synthetic aperture\nradar (PolSAR) images. Due to the presence of coherent illumination in their\nprocessing, PolSAR systems generate images which present a granular noise\ncalled speckle. As a potential solution for reducing such interference, the\nparameter $L$ controls the signal-noise ratio. Thus, the proposal of efficient\nestimation methodologies for $L$ has been sought. To that end, we consider\nfirstly that a PolSAR image is well described by the scaled complex Wishart\ndistribution. In recent years, Anfinsen et al. derived and analyzed estimation\nmethods based on the ML and on trace statistical moments for obtaining the\nparameter $L$ of the unscaled version of such probability law. This paper\ngeneralizes that approach. We present the second-order bias expression proposed\nby Cox and Snell for the ML estimator of this parameter. Moreover, the formula\nof the profile likelihood modified by Barndorff-Nielsen in terms of $L$ is\ndiscussed. Such derivations yield two new ML estimators for the parameter $L$,\nwhich are compared to the estimators proposed by Anfinsen et al. The\nperformance of these estimators is assessed by means of Monte Carlo\nexperiments, adopting three statistical measures as comparison criterion: the\nmean square error, the bias, and the coefficient of variation. Equivalently to\nthe simulation study, an application to actual PolSAR data concludes that the\nproposed estimators outperform all the others in homogeneous scenarios.",
    "published": "2014-04-18T20:19:02Z",
    "updated": "2014-04-18T20:19:02Z",
    "authors": [
      "Abraão D. C. Nascimento",
      "Alejandro C. Frery",
      "Renato J. Cintra"
    ],
    "link": "http://arxiv.org/abs/1404.4880v1",
    "pdf_link": "http://arxiv.org/pdf/1404.4880v1"
  },
  {
    "api_id": 141,
    "title": "Automated adaptive inference of coarse-grained dynamical models in\n  systems biology",
    "summary": "Cellular regulatory dynamics is driven by large and intricate networks of\ninteractions at the molecular scale, whose sheer size obfuscates understanding.\nIn light of limited experimental data, many parameters of such dynamics are\nunknown, and thus models built on the detailed, mechanistic viewpoint overfit\nand are not predictive. At the other extreme, simple ad hoc models of complex\nprocesses often miss defining features of the underlying systems. Here we\npropose an approach that instead constructs phenomenological, coarse-grained\nmodels of network dynamics that automatically adapt their complexity to the\namount of available data. Such adaptive models lead to accurate predictions\neven when microscopic details of the studied systems are unknown due to\ninsufficient data. The approach is computationally tractable, even for a\nrelatively large number of dynamical variables, allowing its software\nrealization, named Sir Isaac, to make successful predictions even when\nimportant dynamic variables are unobserved. For example, it matches the known\nphase space structure for simulated planetary motion data, avoids overfitting\nin a complex biological signaling system, and produces accurate predictions for\na yeast glycolysis model with only tens of data points and over half of the\ninteracting species unobserved.",
    "published": "2014-04-24T22:35:56Z",
    "updated": "2014-04-24T22:35:56Z",
    "authors": [
      "Bryan C. Daniels",
      "Ilya Nemenman"
    ],
    "link": "http://arxiv.org/abs/1404.6283v1",
    "pdf_link": "http://arxiv.org/pdf/1404.6283v1"
  },
  {
    "api_id": 142,
    "title": "Improving weather radar by fusion and classification",
    "summary": "In air traffic management (ATM) all necessary operations (tactical planing,\nsector configuration, required staffing, runway configuration, routing of\napproaching aircrafts) rely on accurate measurements and predictions of the\ncurrent weather situation. An essential basis of information is delivered by\nweather radar images (WXR), which, unfortunately, exhibit a vast amount of\ndisturbances. Thus, the improvement of these datasets is the key factor for\nmore accurate predictions of weather phenomena and weather conditions. Image\nprocessing methods based on texture analysis and geometric operators allow to\nidentify regions including artefacts as well as zones of missing information.\nCorrection of these zones is implemented by exploiting multi-spectral satellite\ndata (Meteosat Second Generation). Results prove that the proposed system for\nartefact detection and data correction significantly improves the quality of\nWXR data and, thus, enables more reliable weather now- and forecast leading to\nincreased ATM safety.",
    "published": "2014-04-25T08:32:51Z",
    "updated": "2014-04-25T08:32:51Z",
    "authors": [
      "Harald Ganster",
      "Martina Uray",
      "Sylwia Steginska",
      "Gerardus Croonen",
      "Rudolf Kaltenböck",
      "Karin Hennermann"
    ],
    "link": "http://arxiv.org/abs/1404.6351v1",
    "pdf_link": "http://arxiv.org/pdf/1404.6351v1"
  },
  {
    "api_id": 143,
    "title": "Image Resolution and Contrast Enhancement of Satellite Geographical\n  Images with Removal of Noise using Wavelet Transforms",
    "summary": "In this paper the technique for resolution and contrast enhancement of\nsatellite geographical images based on discrete wavelet transform (DWT),\nstationary wavelet transform (SWT) and singular value decomposition (SVD) has\nbeen proposed. In this, the noise is added in the input low resolution and low\ncontrast image. The median filter is used remove noise from the input image.\nThis low resolution, low contrast image without noise is decomposed into four\nsub-bands by using DWT and SWT. The resolution enhancement technique is based\non the interpolation of high frequency components obtained by DWT and input\nimage. SWT is used to enhance input image. DWT is used to decompose an image\ninto four frequency sub bands and these four sub-bands are interpolated using\nbicubic interpolation technique. All these sub-bands are reconstructed as high\nresolution image by using inverse DWT (IDWT). To increase the contrast the\nproposed technique uses DWT and SVD. GHE is used to equalize an image. The\nequalized image is decomposed into four sub-bands using DWT and new LL sub-band\nis reconstructed using SVD. All sub-bands are reconstructed using IDWT to\ngenerate high resolution and contrast image over conventional techniques. The\nexperimental result shows superiority of the proposed technique over\nconventional techniques.\n  Key words: Discrete wavelet transform (DWT), General histogram equalization\n(GHE), Median filter, Singular value decomposition (SVD), Stationary wavelet\ntransform (SWT).",
    "published": "2014-05-08T15:32:00Z",
    "updated": "2014-05-08T15:32:00Z",
    "authors": [
      "Prajakta P. Khairnar",
      "C. A. Manjare"
    ],
    "link": "http://arxiv.org/abs/1405.1967v1",
    "pdf_link": "http://arxiv.org/pdf/1405.1967v1"
  },
  {
    "api_id": 144,
    "title": "Cognitive-mapping and contextual pyramid based Digital Elevation Model\n  Registration and its effective storage using fractal based compression",
    "summary": "Digital Elevation models (DEM) are images having terrain information embedded\ninto them. Using cognitive mapping concepts for DEM registration, has evolved\nfrom this basic idea of using the mapping between the space to objects and\ndefining their relationships to form the basic landmarks that need to be\nmarked, stored and manipulated in and about the environment or other candidate\nenvironments, namely, in our case, the DEMs. The progressive two-level\nencapsulation of methods of geo-spatial cognition includes landmark knowledge\nand layout knowledge and can be useful for DEM registration. Space-based\napproach, that emphasizes on explicit extent of the environment under\nconsideration, and object-based approach, that emphasizes on the relationships\nbetween objects in the local environment being the two paradigms of cognitive\nmapping can be methodically integrated in this three-architecture for DEM\nregistration. Initially, P-model based segmentation is performed followed by\nlandmark formation for contextual mapping that uses contextual pyramid\nformation. Apart from landmarks being used for registration key-point finding,\nEuclidean distance based deformation calculation has been used for\ntransformation and change detection. Landmarks have been categorized to belong\nto either being flat-plain areas without much variation in the land heights;\npeaks that can be found when there is gradual increase in height as compared to\nthe flat areas; valleys, marked with gradual decrease in the height seen in\nDEM; and finally, ripple areas with very shallow crests and nadirs. Fractal\nbased compression was used for storage of co-registered DEMs. This method may\nfurther be extended for DEM-topographic map and DEM-to-remote sensed image\nregistration. Experimental results further cement the fact that DEM\nregistration may be effectively done using the proposed method.",
    "published": "2014-05-09T05:59:01Z",
    "updated": "2014-05-09T05:59:01Z",
    "authors": [
      "Suma Dawn",
      "Vikas Saxena",
      "Bhudev Sharma"
    ],
    "link": "http://arxiv.org/abs/1405.6662v1",
    "pdf_link": "http://arxiv.org/pdf/1405.6662v1"
  },
  {
    "api_id": 145,
    "title": "Hyperspectral pan-sharpening: a variational convex constrained\n  formulation to impose parallel level lines, solved with ADMM",
    "summary": "In this paper, we address the issue of hyperspectral pan-sharpening, which\nconsists in fusing a (low spatial resolution) hyperspectral image HX and a\n(high spatial resolution) panchromatic image P to obtain a high spatial\nresolution hyperspectral image. The problem is addressed under a variational\nconvex constrained formulation. The objective favors high resolution spectral\nbands with level lines parallel to those of the panchromatic image. This term\nis balanced with a total variation term as regularizer. Fit-to-P data and\nfit-to-HX data constraints are effectively considered as mathematical\nconstraints, which depend on the statistics of the data noise measurements. The\ndeveloped Alternating Direction Method of Multipliers (ADMM) optimization\nscheme enables us to solve this problem efficiently despite the non\ndifferentiabilities and the huge number of unknowns.",
    "published": "2014-05-10T07:38:19Z",
    "updated": "2014-05-10T07:38:19Z",
    "authors": [
      "Alexis Huck",
      "François de Vieilleville",
      "Pierre Weiss",
      "Manuel Grizonnet"
    ],
    "link": "http://arxiv.org/abs/1405.2403v1",
    "pdf_link": "http://arxiv.org/pdf/1405.2403v1"
  },
  {
    "api_id": 146,
    "title": "A Review of Image Mosaicing Techniques",
    "summary": "Image Mosaicing is a method of constructing multiple images of the same scene\ninto a larger image. The output of the image mosaic will be the union of two\ninput images. Image-mosaicing algorithms are used to get mosaiced image. Image\nMosaicing processed is basically divided in to 5 phases. Which includes;\nFeature point extraction, Image registration, Homography computation, Warping\nand Blending if Image. Various corner detection algorithm is being used for\nFeature extraction. This corner produces an efficient and informative output\nmosaiced image. Image mosaicing is widely used in creating 3D images, medical\nimaging, computer vision, data from satellites, and military automatic target\nrecognition.",
    "published": "2014-05-11T15:13:56Z",
    "updated": "2014-05-11T15:13:56Z",
    "authors": [
      "Dushyant Vaghela",
      "Prof. Kapildev Naina"
    ],
    "link": "http://arxiv.org/abs/1405.2539v1",
    "pdf_link": "http://arxiv.org/pdf/1405.2539v1"
  },
  {
    "api_id": 147,
    "title": "Effects of Sampling Methods on Prediction Quality. The Case of\n  Classifying Land Cover Using Decision Trees",
    "summary": "Clever sampling methods can be used to improve the handling of big data and\nincrease its usefulness. The subject of this study is remote sensing,\nspecifically airborne laser scanning point clouds representing different\nclasses of ground cover. The aim is to derive a supervised learning model for\nthe classification using CARTs. In order to measure the effect of different\nsampling methods on the classification accuracy, various experiments with\nvarying types of sampling methods, sample sizes, and accuracy metrics have been\ndesigned. Numerical results for a subset of a large surveying project covering\nthe lower Rhine area in Germany are shown. General conclusions regarding\nsampling design are drawn and presented.",
    "published": "2014-05-13T20:07:09Z",
    "updated": "2014-05-13T20:07:09Z",
    "authors": [
      "Ronald Hochreiter",
      "Christoph Waldhauser"
    ],
    "link": "http://arxiv.org/abs/1405.3295v1",
    "pdf_link": "http://arxiv.org/pdf/1405.3295v1"
  },
  {
    "api_id": 148,
    "title": "Hyperspectral image superresolution: An edge-preserving convex\n  formulation",
    "summary": "Hyperspectral remote sensing images (HSIs) are characterized by having a low\nspatial resolution and a high spectral resolution, whereas multispectral images\n(MSIs) are characterized by low spectral and high spatial resolutions. These\ncomplementary characteristics have stimulated active research in the inference\nof images with high spatial and spectral resolutions from HSI-MSI pairs.\n  In this paper, we formulate this data fusion problem as the minimization of a\nconvex objective function containing two data-fitting terms and an\nedge-preserving regularizer. The data-fitting terms are quadratic and account\nfor blur, different spatial resolutions, and additive noise; the regularizer, a\nform of vector Total Variation, promotes aligned discontinuities across the\nreconstructed hyperspectral bands.\n  The optimization described above is rather hard, owing to its\nnon-diagonalizable linear operators, to the non-quadratic and non-smooth nature\nof the regularizer, and to the very large size of the image to be inferred. We\ntackle these difficulties by tailoring the Split Augmented Lagrangian Shrinkage\nAlgorithm (SALSA)---an instance of the Alternating Direction Method of\nMultipliers (ADMM)---to this optimization problem. By using a convenient\nvariable splitting and by exploiting the fact that HSIs generally \"live\" in a\nlow-dimensional subspace, we obtain an effective algorithm that yields\nstate-of-the-art results, as illustrated by experiments.",
    "published": "2014-03-31T17:18:48Z",
    "updated": "2014-06-10T11:58:55Z",
    "authors": [
      "Miguel Simões",
      "José Bioucas-Dias",
      "Luis B. Almeida",
      "Jocelyn Chanussot"
    ],
    "link": "http://arxiv.org/abs/1403.8098v2",
    "pdf_link": "http://arxiv.org/pdf/1403.8098v2"
  },
  {
    "api_id": 149,
    "title": "Learning An Invariant Speech Representation",
    "summary": "Recognition of speech, and in particular the ability to generalize and learn\nfrom small sets of labelled examples like humans do, depends on an appropriate\nrepresentation of the acoustic input. We formulate the problem of finding\nrobust speech features for supervised learning with small sample complexity as\na problem of learning representations of the signal that are maximally\ninvariant to intraclass transformations and deformations. We propose an\nextension of a theory for unsupervised learning of invariant visual\nrepresentations to the auditory domain and empirically evaluate its validity\nfor voiced speech sound classification. Our version of the theory requires the\nmemory-based, unsupervised storage of acoustic templates -- such as specific\nphones or words -- together with all the transformations of each that normally\noccur. A quasi-invariant representation for a speech segment can be obtained by\nprojecting it to each template orbit, i.e., the set of transformed signals, and\ncomputing the associated one-dimensional empirical probability distributions.\nThe computations can be performed by modules of filtering and pooling, and\nextended to hierarchical architectures. In this paper, we apply a single-layer,\nmulticomponent representation for phonemes and demonstrate improved accuracy\nand decreased sample complexity for vowel classification compared to standard\nspectral, cepstral and perceptual features.",
    "published": "2014-06-16T02:03:29Z",
    "updated": "2014-06-16T02:03:29Z",
    "authors": [
      "Georgios Evangelopoulos",
      "Stephen Voinea",
      "Chiyuan Zhang",
      "Lorenzo Rosasco",
      "Tomaso Poggio"
    ],
    "link": "http://arxiv.org/abs/1406.3884v1",
    "pdf_link": "http://arxiv.org/pdf/1406.3884v1"
  },
  {
    "api_id": 150,
    "title": "Automated Real-Time Classification and Decision Making in Massive Data\n  Streams from Synoptic Sky Surveys",
    "summary": "The nature of scientific and technological data collection is evolving\nrapidly: data volumes and rates grow exponentially, with increasing complexity\nand information content, and there has been a transition from static data sets\nto data streams that must be analyzed in real time. Interesting or anomalous\nphenomena must be quickly characterized and followed up with additional\nmeasurements via optimal deployment of limited assets. Modern astronomy\npresents a variety of such phenomena in the form of transient events in digital\nsynoptic sky surveys, including cosmic explosions (supernovae, gamma ray\nbursts), relativistic phenomena (black hole formation, jets), potentially\nhazardous asteroids, etc. We have been developing a set of machine learning\ntools to detect, classify and plan a response to transient events for astronomy\napplications, using the Catalina Real-time Transient Survey (CRTS) as a\nscientific and methodological testbed. The ability to respond rapidly to the\npotentially most interesting events is a key bottleneck that limits the\nscientific returns from the current and anticipated synoptic sky surveys.\nSimilar challenge arise in other contexts, from environmental monitoring using\nsensor networks to autonomous spacecraft systems. Given the exponential growth\nof data rates, and the time-critical response, we need a fully automated and\nrobust approach. We describe the results obtained to date, and the possible\nfuture developments.",
    "published": "2014-07-13T19:09:30Z",
    "updated": "2014-07-13T19:09:30Z",
    "authors": [
      "S. G. Djorgovski",
      "A. A. Mahabal",
      "C. Donalek",
      "M. J. Graham",
      "A. J. Drake",
      "M. Turmon",
      "T. Fuchs"
    ],
    "link": "http://arxiv.org/abs/1407.3502v1",
    "pdf_link": "http://arxiv.org/pdf/1407.3502v1"
  },
  {
    "api_id": 151,
    "title": "An landcover fuzzy logic classification by maximumlikelihood",
    "summary": "In present days remote sensing is most used application in many sectors. This\nremote sensing uses different images like multispectral, hyper spectral or\nultra spectral. The remote sensing image classification is one of the\nsignificant method to classify image. In this state we classify the maximum\nlikelihood classification with fuzzy logic. In this we experimenting fuzzy\nlogic like spatial, spectral texture methods in that different sub methods to\nbe used for image classification.",
    "published": "2014-07-17T17:10:06Z",
    "updated": "2014-07-17T17:10:06Z",
    "authors": [
      "T. Sarath",
      "G. Nagalakshmi"
    ],
    "link": "http://arxiv.org/abs/1407.4739v1",
    "pdf_link": "http://arxiv.org/pdf/1407.4739v1"
  },
  {
    "api_id": 152,
    "title": "Optimizing Auto-correlation for Fast Target Search in Large Search Space",
    "summary": "In remote sensing image-blurring is induced by many sources such as\natmospheric scatter, optical aberration, spatial and temporal sensor\nintegration. The natural blurring can be exploited to speed up target search by\nfast template matching. In this paper, we synthetically induce additional\nnon-uniform blurring to further increase the speed of the matching process. To\navoid loss of accuracy, the amount of synthetic blurring is varied spatially\nover the image according to the underlying content. We extend transitive\nalgorithm for fast template matching by incorporating controlled image blur. To\nthis end we propose an Efficient Group Size (EGS) algorithm which minimizes the\nnumber of similarity computations for a particular search image. A larger\nefficient group size guarantees less computations and more speedup. EGS\nalgorithm is used as a component in our proposed Optimizing auto-correlation\n(OptA) algorithm. In OptA a search image is iteratively non-uniformly blurred\nwhile ensuring no accuracy degradation at any image location. In each iteration\nefficient group size and overall computations are estimated by using the\nproposed EGS algorithm. The OptA algorithm stops when the number of\ncomputations cannot be further decreased without accuracy degradation. The\nproposed algorithm is compared with six existing state of the art exhaustive\naccuracy techniques using correlation coefficient as the similarity measure.\nExperiments on satellite and aerial image datasets demonstrate the\neffectiveness of the proposed algorithm.",
    "published": "2014-07-14T03:57:57Z",
    "updated": "2014-07-25T00:47:47Z",
    "authors": [
      "Arif Mahmood",
      "Ajmal Mian",
      "Robyn Owens"
    ],
    "link": "http://arxiv.org/abs/1407.3535v2",
    "pdf_link": "http://arxiv.org/pdf/1407.3535v2"
  },
  {
    "api_id": 153,
    "title": "Non-parametric Image Registration of Airborne LiDAR, Hyperspectral and\n  Photographic Imagery of Forests",
    "summary": "There is much current interest in using multi-sensor airborne remote sensing\nto monitor the structure and biodiversity of forests. This paper addresses the\napplication of non-parametric image registration techniques to precisely align\nimages obtained from multimodal imaging, which is critical for the successful\nidentification of individual trees using object recognition approaches.\nNon-parametric image registration, in particular the technique of optimizing\none objective function containing data fidelity and regularization terms,\nprovides flexible algorithms for image registration. Using a survey of\nwoodlands in southern Spain as an example, we show that non-parametric image\nregistration can be successful at fusing datasets when there is little prior\nknowledge about how the datasets are interrelated (i.e. in the absence of\nground control points). The validity of non-parametric registration methods in\nairborne remote sensing is demonstrated by a series of experiments. Precise\ndata fusion is a prerequisite to accurate recognition of objects within\nairborne imagery, so non-parametric image registration could make a valuable\ncontribution to the analysis pipeline.",
    "published": "2014-07-28T11:21:57Z",
    "updated": "2014-07-28T11:21:57Z",
    "authors": [
      "Juheon Lee",
      "Xiaohao Cai",
      "Carola-Bibiane Schonlieb",
      "David Coomes"
    ],
    "link": "http://arxiv.org/abs/1410.0226v1",
    "pdf_link": "http://arxiv.org/pdf/1410.0226v1"
  },
  {
    "api_id": 154,
    "title": "Hyperspectral Imaging and Analysis for Sparse Reconstruction and\n  Recognition",
    "summary": "This thesis proposes spatio-spectral techniques for hyperspectral image\nanalysis. Adaptive spatio-spectral support and variable exposure hyperspectral\nimaging is demonstrated to improve spectral reflectance recovery from\nhyperspectral images. Novel spectral dimensionality reduction techniques have\nbeen proposed from the perspective of spectral only and spatio-spectral\ninformation preservation. It was found that the joint sparse and joint group\nsparse hyperspectral image models achieve lower reconstruction error and higher\nrecognition accuracy using only a small subset of bands. Hyperspectral image\ndatabases have been developed and made publicly available for further research\nin compressed hyperspectral imaging, forensic document analysis and spectral\nreflectance recovery.",
    "published": "2014-07-29T10:29:28Z",
    "updated": "2014-07-29T10:29:28Z",
    "authors": [
      "Zohaib Khan"
    ],
    "link": "http://arxiv.org/abs/1407.7686v1",
    "pdf_link": "http://arxiv.org/pdf/1407.7686v1"
  },
  {
    "api_id": 155,
    "title": "Renewal Strings for Cleaning Astronomical Databases",
    "summary": "Large astronomical databases obtained from sky surveys such as the\nSuperCOSMOS Sky Surveys (SSS) invariably suffer from a small number of spurious\nrecords coming from artefactual effects of the telescope, satellites and junk\nobjects in orbit around earth and physical defects on the photographic plate or\nCCD. Though relatively small in number these spurious records present a\nsignificant problem in many situations where they can become a large proportion\nof the records potentially of interest to a given astronomer. In this paper we\nfocus on the four most common causes of unwanted records in the SSS: satellite\nor aeroplane tracks, scratches fibres and other linear phenomena introduced to\nthe plate, circular halos around bright stars due to internal reflections\nwithin the telescope and diffraction spikes near to bright stars. Accurate and\nrobust techniques are needed for locating and flagging such spurious objects.\nWe have developed renewal strings, a probabilistic technique combining the\nHough transform, renewal processes and hidden Markov models which have proven\nhighly effective in this context. The methods are applied to the SSS data to\ndevelop a dataset of spurious object detections, along with confidence\nmeasures, which can allow this unwanted data to be removed from consideration.\nThese methods are general and can be adapted to any future astronomical survey\ndata.",
    "published": "2014-08-07T06:27:12Z",
    "updated": "2014-08-07T06:27:12Z",
    "authors": [
      "Amos J. Storkey",
      "Nigel C. Hambly",
      "Christopher K. I. Williams",
      "Robert G. Mann"
    ],
    "link": "http://arxiv.org/abs/1408.1489v1",
    "pdf_link": "http://arxiv.org/pdf/1408.1489v1"
  },
  {
    "api_id": 156,
    "title": "Markov Chains on Orbits of Permutation Groups",
    "summary": "We present a novel approach to detecting and utilizing symmetries in\nprobabilistic graphical models with two main contributions. First, we present a\nscalable approach to computing generating sets of permutation groups\nrepresenting the symmetries of graphical models. Second, we introduce orbital\nMarkov chains, a novel family of Markov chains leveraging model symmetries to\nreduce mixing times. We establish an insightful connection between model\nsymmetries and rapid mixing of orbital Markov chains. Thus, we present the\nfirst lifted MCMC algorithm for probabilistic graphical models. Both analytical\nand empirical results demonstrate the effectiveness and efficiency of the\napproach.",
    "published": "2014-08-09T05:49:27Z",
    "updated": "2014-08-09T05:49:27Z",
    "authors": [
      "Mathias Niepert"
    ],
    "link": "http://arxiv.org/abs/1408.2052v1",
    "pdf_link": "http://arxiv.org/pdf/1408.2052v1"
  },
  {
    "api_id": 157,
    "title": "Spectral Unmixing of Hyperspectral Imagery using Multilayer NMF",
    "summary": "Hyperspectral images contain mixed pixels due to low spatial resolution of\nhyperspectral sensors. Spectral unmixing problem refers to decomposing mixed\npixels into a set of endmembers and abundance fractions. Due to nonnegativity\nconstraint on abundance fractions, nonnegative matrix factorization (NMF)\nmethods have been widely used for solving spectral unmixing problem. In this\nletter we proposed using multilayer NMF (MLNMF) for the purpose of\nhyperspectral unmixing. In this approach, spectral signature matrix can be\nmodeled as a product of sparse matrices. In fact MLNMF decomposes the\nobservation matrix iteratively in a number of layers. In each layer, we applied\nsparseness constraint on spectral signature matrix as well as on abundance\nfractions matrix. In this way signatures matrix can be sparsely decomposed\ndespite the fact that it is not generally a sparse matrix. The proposed\nalgorithm is applied on synthetic and real datasets. Synthetic data is\ngenerated based on endmembers from USGS spectral library. AVIRIS Cuprite\ndataset has been used as a real dataset for evaluation of proposed method.\nResults of experiments are quantified based on SAD and AAD measures. Results in\ncomparison with previously proposed methods show that the multilayer approach\ncan unmix data more effectively.",
    "published": "2014-08-12T19:07:23Z",
    "updated": "2014-08-12T19:07:23Z",
    "authors": [
      "Roozbeh Rajabi",
      "Hassan Ghassemian"
    ],
    "link": "http://arxiv.org/abs/1408.2810v1",
    "pdf_link": "http://arxiv.org/pdf/1408.2810v1"
  },
  {
    "api_id": 158,
    "title": "Hierarchical Clustering of Hyperspectral Images using Rank-Two\n  Nonnegative Matrix Factorization",
    "summary": "In this paper, we design a hierarchical clustering algorithm for\nhigh-resolution hyperspectral images. At the core of the algorithm, a new\nrank-two nonnegative matrix factorizations (NMF) algorithm is used to split the\nclusters, which is motivated by convex geometry concepts. The method starts\nwith a single cluster containing all pixels, and, at each step, (i) selects a\ncluster in such a way that the error at the next step is minimized, and (ii)\nsplits the selected cluster into two disjoint clusters using rank-two NMF in\nsuch a way that the clusters are well balanced and stable. The proposed method\ncan also be used as an endmember extraction algorithm in the presence of pure\npixels. The effectiveness of this approach is illustrated on several synthetic\nand real-world hyperspectral images, and shown to outperform standard\nclustering techniques such as k-means, spherical k-means and standard NMF.",
    "published": "2013-09-14T09:54:59Z",
    "updated": "2014-08-19T12:49:54Z",
    "authors": [
      "Nicolas Gillis",
      "Da Kuang",
      "Haesun Park"
    ],
    "link": "http://arxiv.org/abs/1310.7441v4",
    "pdf_link": "http://arxiv.org/pdf/1310.7441v4"
  },
  {
    "api_id": 159,
    "title": "Bayesian Fusion of Multi-Band Images",
    "summary": "In this paper, a Bayesian fusion technique for remotely sensed multi-band\nimages is presented. The observed images are related to the high spectral and\nhigh spatial resolution image to be recovered through physical degradations,\ne.g., spatial and spectral blurring and/or subsampling defined by the sensor\ncharacteristics. The fusion problem is formulated within a Bayesian estimation\nframework. An appropriate prior distribution exploiting geometrical\nconsideration is introduced. To compute the Bayesian estimator of the scene of\ninterest from its posterior distribution, a Markov chain Monte Carlo algorithm\nis designed to generate samples asymptotically distributed according to the\ntarget distribution. To efficiently sample from this high-dimension\ndistribution, a Hamiltonian Monte Carlo step is introduced in the Gibbs\nsampling strategy. The efficiency of the proposed fusion method is evaluated\nwith respect to several state-of-the-art fusion techniques. In particular, low\nspatial resolution hyperspectral and multispectral images are fused to produce\na high spatial resolution hyperspectral image.",
    "published": "2013-07-23T09:44:36Z",
    "updated": "2014-08-26T09:34:49Z",
    "authors": [
      "Qi Wei",
      "Nicolas Dobigeon",
      "Jean-Yves Tourneret"
    ],
    "link": "http://arxiv.org/abs/1307.5996v2",
    "pdf_link": "http://arxiv.org/pdf/1307.5996v2"
  },
  {
    "api_id": 160,
    "title": "Sparsity Constrained Graph Regularized NMF for Spectral Unmixing of\n  Hyperspectral Data",
    "summary": "Hyperspectral images contain mixed pixels due to low spatial resolution of\nhyperspectral sensors. Mixed pixels are pixels containing more than one\ndistinct material called endmembers. The presence percentages of endmembers in\nmixed pixels are called abundance fractions. Spectral unmixing problem refers\nto decomposing these pixels into a set of endmembers and abundance fractions.\nDue to nonnegativity constraint on abundance fractions, nonnegative matrix\nfactorization methods (NMF) have been widely used for solving spectral unmixing\nproblem. In this paper we have used graph regularized NMF (GNMF) method\ncombined with sparseness constraint to decompose mixed pixels in hyperspectral\nimagery. This method preserves the geometrical structure of data while\nrepresenting it in low dimensional space. Adaptive regularization parameter\nbased on temperature schedule in simulated annealing method also has been used\nin this paper for the sparseness term. Proposed algorithm is applied on\nsynthetic and real datasets. Synthetic data is generated based on endmembers\nfrom USGS spectral library. AVIRIS Cuprite dataset is used as real dataset for\nevaluation of proposed method. Results are quantified based on spectral angle\ndistance (SAD) and abundance angle distance (AAD) measures. Results in\ncomparison with other methods show that the proposed method can unmix data more\neffectively. Specifically for the Cuprite dataset, performance of the proposed\nmethod is approximately 10% better than the VCA and Sparse NMF in terms of root\nmean square of SAD.",
    "published": "2014-11-03T08:41:32Z",
    "updated": "2014-11-03T08:41:32Z",
    "authors": [
      "Roozbeh Rajabi",
      "Hassan Ghassemian"
    ],
    "link": "http://arxiv.org/abs/1411.0392v1",
    "pdf_link": "http://arxiv.org/pdf/1411.0392v1"
  },
  {
    "api_id": 161,
    "title": "A convex formulation for hyperspectral image superresolution via\n  subspace-based regularization",
    "summary": "Hyperspectral remote sensing images (HSIs) usually have high spectral\nresolution and low spatial resolution. Conversely, multispectral images (MSIs)\nusually have low spectral and high spatial resolutions. The problem of\ninferring images which combine the high spectral and high spatial resolutions\nof HSIs and MSIs, respectively, is a data fusion problem that has been the\nfocus of recent active research due to the increasing availability of HSIs and\nMSIs retrieved from the same geographical area.\n  We formulate this problem as the minimization of a convex objective function\ncontaining two quadratic data-fitting terms and an edge-preserving regularizer.\nThe data-fitting terms account for blur, different resolutions, and additive\nnoise. The regularizer, a form of vector Total Variation, promotes\npiecewise-smooth solutions with discontinuities aligned across the\nhyperspectral bands.\n  The downsampling operator accounting for the different spatial resolutions,\nthe non-quadratic and non-smooth nature of the regularizer, and the very large\nsize of the HSI to be estimated lead to a hard optimization problem. We deal\nwith these difficulties by exploiting the fact that HSIs generally \"live\" in a\nlow-dimensional subspace and by tailoring the Split Augmented Lagrangian\nShrinkage Algorithm (SALSA), which is an instance of the Alternating Direction\nMethod of Multipliers (ADMM), to this optimization problem, by means of a\nconvenient variable splitting. The spatial blur and the spectral linear\noperators linked, respectively, with the HSI and MSI acquisition processes are\nalso estimated, and we obtain an effective algorithm that outperforms the\nstate-of-the-art, as illustrated in a series of experiments with simulated and\nreal-life data.",
    "published": "2014-11-14T18:36:31Z",
    "updated": "2014-11-14T18:36:31Z",
    "authors": [
      "Miguel Simões",
      "José Bioucas-Dias",
      "Luis B. Almeida",
      "Jocelyn Chanussot"
    ],
    "link": "http://arxiv.org/abs/1411.4005v1",
    "pdf_link": "http://arxiv.org/pdf/1411.4005v1"
  },
  {
    "api_id": 162,
    "title": "Approximate evaluation of marginal association probabilities with belief\n  propagation",
    "summary": "Data association, the problem of reasoning over correspondence between\ntargets and measurements, is a fundamental problem in tracking. This paper\npresents a graphical model formulation of data association and applies an\napproximate inference method, belief propagation (BP), to obtain estimates of\nmarginal association probabilities. We prove that BP is guaranteed to converge,\nand bound the number of iterations necessary. Experiments reveal a favourable\ncomparison to prior methods in terms of accuracy and computational complexity.",
    "published": "2012-09-12T06:45:25Z",
    "updated": "2014-11-20T00:47:06Z",
    "authors": [
      "Jason L. Williams",
      "Roslyn A. Lau"
    ],
    "link": "http://arxiv.org/abs/1209.6299v2",
    "pdf_link": "http://arxiv.org/pdf/1209.6299v2"
  },
  {
    "api_id": 163,
    "title": "Detecting fraudulent activity in a cloud using privacy-friendly data\n  aggregates",
    "summary": "More users and companies make use of cloud services every day. They all\nexpect a perfect performance and any issue to remain transparent to them. This\nlast statement is very challenging to perform. A user's activities in our cloud\ncan affect the overall performance of our servers, having an impact on other\nresources. We can consider these kind of activities as fraudulent. They can be\neither illegal activities, such as launching a DDoS attack or just activities\nwhich are undesired by the cloud provider, such as Bitcoin mining, which uses\nsubstantial power, reduces the life of the hardware and can possibly slow down\nother user's activities. This article discusses a method to detect such\nactivities by using non-intrusive, privacy-friendly data: billing data. We use\nOpenStack as an example with data provided by Telemetry, the component in\ncharge of measuring resource usage for billing purposes. Results will be shown\nproving the efficiency of this method and ways to improve it will be provided\nas well as its advantages and disadvantages.",
    "published": "2014-11-25T03:56:43Z",
    "updated": "2014-11-25T03:56:43Z",
    "authors": [
      "Marc Solanas",
      "Julio Hernandez-Castro",
      "Debojyoti Dutta"
    ],
    "link": "http://arxiv.org/abs/1411.6721v1",
    "pdf_link": "http://arxiv.org/pdf/1411.6721v1"
  },
  {
    "api_id": 164,
    "title": "A GALEX based search for the sparse young stellar population in the\n  Taurus-Aurigae star forming region",
    "summary": "In this work, we identify 63 bona fide new candidates to T Tauri stars (TTSs)\nin the Taurus-Auriga region using as baseline its ultraviolet excess. The\ninitial data set has been defined from the GALEX all sky survey (AIS). The\nGALEX satellite obtained images in the near ultraviolet (NUV) and far\nultraviolet (FUV) bands where the TTSs show a prominent excess, compared with\nmain sequence or giants stars. GALEX AIS surveyed the Taurus-Auriga molecular\ncomplex, as well as, a fraction of the California Nebula and the Perseus\ncomplex; bright sources and the dark clouds themselves are avoided.\n  The properties of the TTSs in the ultraviolet (GALEX), optical (UCAC4) and\ninfrared (2MASS) have been defined using as qualification sample the TTSs\nobserved with the International Ultraviolet Explorer. The candidates have been\nidentified by means of a mixed ultraviolet-optical-infrared excess set of\ncolors; it is found that the color-color diagram FUV-NUV versus J-K is ideally\nsuited for this purpose. From an initial sample of 163,313 bona-fide NUV\nsources, a final list with 63 new candidates to TTSs in the region has been\nproduced. The search procedure has been validated by its ability to detect all\nknown TTSs in the area surveyed: 31 TTSs.\n  Also, it is shown that the weak-lined TTSs are located in a well defined\nstripe in the FUV-NUV versus J-K diagram. Moreover, we provide in this work a\nlist of TTSs photometric standards for future GALEX-based studies of the young\nstellar population in star forming regions.",
    "published": "2014-12-09T15:41:56Z",
    "updated": "2014-12-09T15:41:56Z",
    "authors": [
      "Ana I. Gomez de Castro",
      "Javier López-Santiago",
      "Fátima López-Martínez",
      "Néstor Sánchez",
      "Paola Sestito",
      "Elisa de Castro",
      "Manuel Cornide",
      "Javier Yañez Gestoso"
    ],
    "link": "http://arxiv.org/abs/1412.3002v1",
    "pdf_link": "http://arxiv.org/pdf/1412.3002v1"
  },
  {
    "api_id": 165,
    "title": "Information-Theoretic Methods for Identifying Relationships among\n  Climate Variables",
    "summary": "Information-theoretic quantities, such as entropy, are used to quantify the\namount of information a given variable provides. Entropies can be used together\nto compute the mutual information, which quantifies the amount of information\ntwo variables share. However, accurately estimating these quantities from data\nis extremely challenging. We have developed a set of computational techniques\nthat allow one to accurately compute marginal and joint entropies. These\nalgorithms are probabilistic in nature and thus provide information on the\nuncertainty in our estimates, which enable us to establish statistical\nsignificance of our findings. We demonstrate these methods by identifying\nrelations between cloud data from the International Satellite Cloud Climatology\nProject (ISCCP) and data from other sources, such as equatorial pacific sea\nsurface temperatures (SST).",
    "published": "2014-12-19T05:22:07Z",
    "updated": "2014-12-19T05:22:07Z",
    "authors": [
      "Kevin H. Knuth",
      "Deniz Gençağa",
      "William B. Rossow"
    ],
    "link": "http://arxiv.org/abs/1412.6219v1",
    "pdf_link": "http://arxiv.org/pdf/1412.6219v1"
  },
  {
    "api_id": 166,
    "title": "Context-Aware Analytics in MOM Applications",
    "summary": "Manufacturing Operations Management (MOM) systems are complex in the sense\nthat they integrate data from heterogeneous systems inside the automation\npyramid. The need for context-aware analytics arises from the dynamics of these\nsystems that influence data generation and hamper comparability of analytics,\nespecially predictive models (e.g. predictive maintenance), where concept drift\naffects application of these models in the future. Recently, an increasing\namount of research has been directed towards data integration using semantic\ncontext models. Manual construction of such context models is an elaborate and\nerror-prone task. Therefore, we pose the challenge to apply combinations of\nknowledge extraction techniques in the domain of analytics in MOM, which\ncomprises the scope of data integration within Product Life-cycle Management\n(PLM), Enterprise Resource Planning (ERP), and Manufacturing Execution Systems\n(MES). We describe motivations, technological challenges and show benefits of\ncontext-aware analytics, which leverage from and regard the interconnectedness\nof semantic context data. Our example scenario shows the need for distribution\nand effective change tracking of context information.",
    "published": "2014-12-26T18:32:58Z",
    "updated": "2014-12-26T18:32:58Z",
    "authors": [
      "Martin Ringsquandl",
      "Steffen Lamparter",
      "Raffaello Lepratti"
    ],
    "link": "http://arxiv.org/abs/1412.7968v1",
    "pdf_link": "http://arxiv.org/pdf/1412.7968v1"
  },
  {
    "api_id": 167,
    "title": "Accurate Localization in Dense Urban Area Using Google Street View Image",
    "summary": "Accurate information about the location and orientation of a camera in mobile\ndevices is central to the utilization of location-based services (LBS). Most of\nsuch mobile devices rely on GPS data but this data is subject to inaccuracy due\nto imperfections in the quality of the signal provided by satellites. This\nshortcoming has spurred the research into improving the accuracy of\nlocalization. Since mobile devices have camera, a major thrust of this research\nhas been seeks to acquire the local scene and apply image retrieval techniques\nby querying a GPS-tagged image database to find the best match for the acquired\nscene.. The techniques are however computationally demanding and unsuitable for\nreal-time applications such as assistive technology for navigation by the blind\nand visually impaired which motivated out work. To overcome the high complexity\nof those techniques, we investigated the use of inertial sensors as an aid in\nimage-retrieval-based approach. Armed with information of media other than\nimages, such as data from the GPS module along with orientation sensors such as\naccelerometer and gyro, we sought to limit the size of the image set to c\nsearch for the best match. Specifically, data from the orientation sensors\nalong with Dilution of precision (DOP) from GPS are used to find the angle of\nview and estimation of position. We present analysis of the reduction in the\nimage set size for the search as well as simulations to demonstrate the\neffectiveness in a fast implementation with 98% Estimated Position Error.",
    "published": "2014-12-29T22:09:41Z",
    "updated": "2014-12-29T22:09:41Z",
    "authors": [
      "Mahdi Salarian"
    ],
    "link": "http://arxiv.org/abs/1412.8496v1",
    "pdf_link": "http://arxiv.org/pdf/1412.8496v1"
  },
  {
    "api_id": 168,
    "title": "SIRF: Simultaneous Image Registration and Fusion in A Unified Framework",
    "summary": "In this paper, we propose a novel method for image fusion with a\nhigh-resolution panchromatic image and a low-resolution multispectral image at\nthe same geographical location. The fusion is formulated as a convex\noptimization problem which minimizes a linear combination of a least-squares\nfitting term and a dynamic gradient sparsity regularizer. The former is to\npreserve accurate spectral information of the multispectral image, while the\nlatter is to keep sharp edges of the high-resolution panchromatic image. We\nfurther propose to simultaneously register the two images during the fusing\nprocess, which is naturally achieved by virtue of the dynamic gradient sparsity\nproperty. An efficient algorithm is then devised to solve the optimization\nproblem, accomplishing a linear computational complexity in the size of the\noutput image in each iteration. We compare our method against seven\nstate-of-the-art image fusion methods on multispectral image datasets from four\nsatellites. Extensive experimental results demonstrate that the proposed method\nsubstantially outperforms the others in terms of both spatial and spectral\nqualities. We also show that our method can provide high-quality products from\ncoarsely registered real-world datasets. Finally, a MATLAB implementation is\nprovided to facilitate future research.",
    "published": "2014-11-18T23:26:37Z",
    "updated": "2015-01-01T22:00:10Z",
    "authors": [
      "Chen Chen",
      "Yeqing Li",
      "Wei Liu",
      "Junzhou Huang"
    ],
    "link": "http://arxiv.org/abs/1411.5065v2",
    "pdf_link": "http://arxiv.org/pdf/1411.5065v2"
  },
  {
    "api_id": 169,
    "title": "Fast forward feature selection for the nonlinear classification of\n  hyperspectral images",
    "summary": "A fast forward feature selection algorithm is presented in this paper. It is\nbased on a Gaussian mixture model (GMM) classifier. GMM are used for\nclassifying hyperspectral images. The algorithm selects iteratively spectral\nfeatures that maximizes an estimation of the classification rate. The\nestimation is done using the k-fold cross validation. In order to perform fast\nin terms of computing time, an efficient implementation is proposed. First, the\nGMM can be updated when the estimation of the classification rate is computed,\nrather than re-estimate the full model. Secondly, using marginalization of the\nGMM, sub models can be directly obtained from the full model learned with all\nthe spectral features. Experimental results for two real hyperspectral data\nsets show that the method performs very well in terms of classification\naccuracy and processing time. Furthermore, the extracted model contains very\nfew spectral channels.",
    "published": "2015-01-05T13:37:37Z",
    "updated": "2015-01-05T13:37:37Z",
    "authors": [
      "Mathieu Fauvel",
      "Clement Dechesne",
      "Anthony Zullo",
      "Frédéric Ferraty"
    ],
    "link": "http://arxiv.org/abs/1501.00857v1",
    "pdf_link": "http://arxiv.org/pdf/1501.00857v1"
  },
  {
    "api_id": 170,
    "title": "OGLE-III Microlensing Events and the Structure of the Galactic Bulge",
    "summary": "We present and study the largest and the most comprehensive catalog of\nmicrolensing events ever constructed. The sample of standard microlensing\nevents comprises 3718 unique events from years 2001--2009, with 1409 not\ndetected before in real-time by the Early Warning System of the Optical\nGravitational Lensing Experiment (OGLE). The search pipeline makes use of\nMachine Learning algorithms in order to help find rare phenomena among 150\nmillion objects and derive the detection efficiency. Applications of the\ncatalog can be numerous, from analyzing individual events to large statistical\nstudies for the Galactic mass and kinematics distributions and planetary\nabundances.\n  We derive the maps of the mean Einstein ring crossing time of events spanning\n31 sq. deg. toward of the Galactic Center and compare the observed\ndistributions with the most recent models. We find good agreement within the\nobserved region and we see the signature of the tilt of the bar in the\nmicrolensing data. However, the asymmetry of the mean time-scales seems to rise\nmore steeply than predictions, indicating either a somewhat different\norientation of the bar or a larger bar width. The map for the events with\nsources in the Galactic bulge shows a dependence of the mean time-scale on the\nGalactic latitude, signaling an increasing contribution from disk lenses closer\nto the plane, related with the height of the disk. Our data present a perfect\nset for comparing and enhancing new models of the central parts of the Milky\nWay and creating the 3D picture of the Galaxy.",
    "published": "2014-05-13T12:56:05Z",
    "updated": "2015-01-07T14:44:40Z",
    "authors": [
      "Lukasz Wyrzykowski",
      "Alicja E. Rynkiewicz",
      "Jan Skowron",
      "Szymon Kozlowski",
      "Andrzej Udalski",
      "Michal K. Szymanski",
      "Marcin Kubiak",
      "Igor Soszynski",
      "Grzegorz Pietrzynski",
      "Radoslaw Poleski",
      "Pawel Pietrukowicz",
      "Michal Pawlak"
    ],
    "link": "http://arxiv.org/abs/1405.3134v4",
    "pdf_link": "http://arxiv.org/pdf/1405.3134v4"
  },
  {
    "api_id": 171,
    "title": "An Effective Image Feature Classiffication using an improved SOM",
    "summary": "Image feature classification is a challenging problem in many computer vision\napplications, specifically, in the fields of remote sensing, image analysis and\npattern recognition. In this paper, a novel Self Organizing Map, termed\nimproved SOM (iSOM), is proposed with the aim of effectively classifying\nMammographic images based on their texture feature representation. The main\ncontribution of the iSOM is to introduce a new node structure for the map\nrepresentation and adopting a learning technique based on Kohonen SOM\naccordingly. The main idea is to control, in an unsupervised fashion, the\nweight updating procedure depending on the class reliability of the node,\nduring the weight update time. Experiments held on a real Mammographic images.\nResults showed high accuracy compared to classical SOM and other state-of-art\nclassifiers.",
    "published": "2015-01-08T04:05:39Z",
    "updated": "2015-01-08T04:05:39Z",
    "authors": [
      "M. Abdelsamea",
      "Marghny H. Mohamed",
      "Mohamed Bamatraf"
    ],
    "link": "http://arxiv.org/abs/1501.01723v1",
    "pdf_link": "http://arxiv.org/pdf/1501.01723v1"
  },
  {
    "api_id": 172,
    "title": "Investigation of a chaotic spiking neuron model",
    "summary": "Chaos provides many interesting properties that can be used to achieve\ncomputational tasks. Such properties are sensitivity to initial conditions,\nspace filling, control and synchronization. Chaotic neural models have been\ndevised to exploit such properties. In this paper, a chaotic spiking neuron\nmodel is investigated experimentally. This investigation is performed to\nunderstand the dynamic behaviours of the model.\n  The aim of this research is to investigate the dynamics of the nonlinear\ndynamic state neuron (NDS) experimentally. The experimental approach has\nrevealed some quantitative and qualitative properties of the NDS model such as\nthe control mechanism, the reset mechanism, and the way the model may exhibit\ndynamic behaviours in phase space. It is shown experimentally in this paper\nthat both the reset mechanism and the self-feed back control mechanism are\nimportant for the NDS model to work and to stabilise to one of the large number\nof available unstable periodic orbits (UPOs) that are embedded in its\nattractor. The experimental investigation suggests that the internal dynamics\nof the NDS neuron provide a rich set of dynamic behaviours that can be\ncontrolled and stabilised. These wide range of dynamic behaviours may be\nexploited to carry out information processing tasks.",
    "published": "2015-01-09T16:20:42Z",
    "updated": "2015-01-09T16:20:42Z",
    "authors": [
      "M. Alhawarat",
      "T. Olde Scheper",
      "N. T. Crook"
    ],
    "link": "http://arxiv.org/abs/1501.02192v1",
    "pdf_link": "http://arxiv.org/pdf/1501.02192v1"
  },
  {
    "api_id": 173,
    "title": "Visual Analytics of Image-Centric Cohort Studies in Epidemiology",
    "summary": "Epidemiology characterizes the influence of causes to disease and health\nconditions of defined populations. Cohort studies are population-based studies\ninvolving usually large numbers of randomly selected individuals and comprising\nnumerous attributes, ranging from self-reported interview data to results from\nvarious medical examinations, e.g., blood and urine samples. Since recently,\nmedical imaging has been used as an additional instrument to assess risk\nfactors and potential prognostic information. In this chapter, we discuss such\nstudies and how the evaluation may benefit from visual analytics. Cluster\nanalysis to define groups, reliable image analysis of organs in medical imaging\ndata and shape space exploration to characterize anatomical shapes are among\nthe visual analytics tools that may enable epidemiologists to fully exploit the\npotential of their huge and complex data. To gain acceptance, visual analytics\ntools need to complement more classical epidemiologic tools, primarily\nhypothesis-driven statistical analysis.",
    "published": "2015-01-15T16:51:20Z",
    "updated": "2015-01-15T16:51:20Z",
    "authors": [
      "Bernhard Preim",
      "Paul Klemm",
      "Helwig Hauser",
      "Katrin Hegenscheid",
      "Steffen Oeltze",
      "Klaus Toennies",
      "Henry Völzke"
    ],
    "link": "http://arxiv.org/abs/1501.04009v1",
    "pdf_link": "http://arxiv.org/pdf/1501.04009v1"
  },
  {
    "api_id": 174,
    "title": "Meaningful Objects Segmentation from SAR Images via A Multi-Scale\n  Non-Local Active Contour Model",
    "summary": "The segmentation of synthetic aperture radar (SAR) images is a longstanding\nyet challenging task, not only because of the presence of speckle, but also due\nto the variations of surface backscattering properties in the images.\nTremendous investigations have been made to eliminate the speckle effects for\nthe segmentation of SAR images, while few work devotes to dealing with the\nvariations of backscattering coefficients in the images. In order to overcome\nboth the two difficulties, this paper presents a novel SAR image segmentation\nmethod by exploiting a multi-scale active contour model based on the non-local\nprocessing principle. More precisely, we first formulize the SAR segmentation\nproblem with an active contour model by integrating the non-local interactions\nbetween pairs of patches inside and outside the segmented regions. Secondly, a\nmulti-scale strategy is proposed to speed up the non-local active contour\nsegmentation procedure and to avoid falling into local minimum for achieving\nmore accurate segmentation results. Experimental results on simulated and real\nSAR images demonstrate the efficiency and feasibility of the proposed method:\nit can not only achieve precise segmentations for images with heavy speckles\nand non-local intensity variations, but also can be used for SAR images from\ndifferent types of sensors.",
    "published": "2015-01-17T06:03:28Z",
    "updated": "2015-01-17T06:03:28Z",
    "authors": [
      "Gui-Song Xia",
      "Gang Liu",
      "Wen Yang"
    ],
    "link": "http://arxiv.org/abs/1501.04163v1",
    "pdf_link": "http://arxiv.org/pdf/1501.04163v1"
  },
  {
    "api_id": 175,
    "title": "Big Data: How Geo-information Helped Shape the Future of Data\n  Engineering",
    "summary": "Very large data sets are the common rule in automated mapping, GIS, remote\nsensing, and what we can name geo-information. Indeed, in 1983 Landsat was\nalready delivering gigabytes of data, and other sensors were in orbit or ready\nfor launch, and a tantamount of cartographic data was being digitized. The\nretrospective paper revisits several issues that geo-information sciences had\nto face from the early stages on, including: structure ( to bring some\nstructure to the data registered from a sampled signal, metadata); processing\n(huge amounts of data for big computers and fast algorithms); uncertainty (the\nkinds of errors, their quantification); consistency (when merging different\nsources of data is logically allowed, and meaningful); ontologies (clear and\nagreed shared definitions, if any kind of decision should be based upon them).\nAll these issues are the background of Internet queries, and the underlying\ntechnology has been shaped during those years when geo-information engineering\nemerged.",
    "published": "2015-01-20T14:57:11Z",
    "updated": "2015-01-20T14:57:11Z",
    "authors": [
      "Robert Jeansoulin"
    ],
    "link": "http://arxiv.org/abs/1501.04832v1",
    "pdf_link": "http://arxiv.org/pdf/1501.04832v1"
  },
  {
    "api_id": 176,
    "title": "Tracking an Object with Unknown Accelerations using a Shadowing Filter",
    "summary": "A commonly encountered problem is the tracking of a physical object, like a\nmaneuvering ship, aircraft, land vehicle, spacecraft or animate creature\ncarrying a wireless device. The sensor data is often limited and inaccurate\nobservations of range or bearing. This problem is more difficult than tracking\na ballistic trajectory, because an operative affects unknown and arbitrarily\nchanging accelerations. Although stochastic methods of filtering or state\nestimation (Kalman filters and particle filters) are widely used, out of vogue\nvariational methods are more appropriate in this tracking context, because the\nobjects do not typically display any significant random motions at the length\nand time scales of interest. This leads us to propose a rather elegant approach\nbased on a \\emph{shadowing filter}. The resulting filter is efficient (reduces\nto the solution of linear equations) and robust (uneffected by missing data and\nsingular correlations that would cause catastrophic failure of Bayesian\nfilters.) The tracking is so robust, that in some common situations it actually\nperforms better by ignoring error correlations that are so vital to Kalman\nfilters.",
    "published": "2015-01-21T06:30:51Z",
    "updated": "2015-01-21T06:30:51Z",
    "authors": [
      "Kevin Judd"
    ],
    "link": "http://arxiv.org/abs/1502.07743v1",
    "pdf_link": "http://arxiv.org/pdf/1502.07743v1"
  },
  {
    "api_id": 177,
    "title": "Estimating the Intrinsic Dimension of Hyperspectral Images Using an\n  Eigen-Gap Approach",
    "summary": "Linear mixture models are commonly used to represent hyperspectral datacube\nas a linear combinations of endmember spectra. However, determining of the\nnumber of endmembers for images embedded in noise is a crucial task. This paper\nproposes a fully automatic approach for estimating the number of endmembers in\nhyperspectral images. The estimation is based on recent results of random\nmatrix theory related to the so-called spiked population model. More precisely,\nwe study the gap between successive eigenvalues of the sample covariance matrix\nconstructed from high dimensional noisy samples. The resulting estimation\nstrategy is unsupervised and robust to correlated noise. This strategy is\nvalidated on both synthetic and real images. The experimental results are very\npromising and show the accuracy of this algorithm with respect to\nstate-of-the-art algorithms.",
    "published": "2015-01-22T16:18:35Z",
    "updated": "2015-01-22T16:18:35Z",
    "authors": [
      "A. Halimi",
      "P. Honeine",
      "M. Kharouf",
      "C. Richard",
      "J. -Y. Tourneret"
    ],
    "link": "http://arxiv.org/abs/1501.05552v1",
    "pdf_link": "http://arxiv.org/pdf/1501.05552v1"
  },
  {
    "api_id": 178,
    "title": "Bi-Objective Nonnegative Matrix Factorization: Linear Versus\n  Kernel-Based Models",
    "summary": "Nonnegative matrix factorization (NMF) is a powerful class of feature\nextraction techniques that has been successfully applied in many fields, namely\nin signal and image processing. Current NMF techniques have been limited to a\nsingle-objective problem in either its linear or nonlinear kernel-based\nformulation. In this paper, we propose to revisit the NMF as a multi-objective\nproblem, in particular a bi-objective one, where the objective functions\ndefined in both input and feature spaces are taken into account. By taking the\nadvantage of the sum-weighted method from the literature of multi-objective\noptimization, the proposed bi-objective NMF determines a set of nondominated,\nPareto optimal, solutions instead of a single optimal decomposition. Moreover,\nthe corresponding Pareto front is studied and approximated. Experimental\nresults on unmixing real hyperspectral images confirm the efficiency of the\nproposed bi-objective NMF compared with the state-of-the-art methods.",
    "published": "2015-01-22T22:59:47Z",
    "updated": "2015-01-22T22:59:47Z",
    "authors": [
      "Paul Honeine",
      "Fei Zhu"
    ],
    "link": "http://arxiv.org/abs/1501.05684v1",
    "pdf_link": "http://arxiv.org/pdf/1501.05684v1"
  },
  {
    "api_id": 179,
    "title": "Unsupervised Segmentation of Multispectral Images with Cellular Automata",
    "summary": "Multispectral images acquired by satellites are used to study phenomena on\nthe Earth's surface. Unsupervised classification techniques analyze\nmultispectral image content without considering prior knowledge of the observed\nterrain; this is done using techniques which group pixels that have similar\nstatistics of digital level distribution in the various image channels. In this\npaper, we propose a methodology for unsupervised classification based on a\ndeterministic cellular automaton. The automaton is initialized in an\nunsupervised manner by setting seed cells, selected according to two criteria:\nto be representative of the spatial distribution of the dominant elements in\nthe image, and to take into account the diversity of spectral signatures in the\nimage. The automaton's evolution is based on an attack rule that is applied\nsimultaneously to all its cells. Among the noteworthy advantages of\ndeterministic cellular automata for multispectral processing of satellite\nimagery is the consideration of topological information in the image via seed\npositioning, and the ability to modify the scale of the study.",
    "published": "2015-01-23T16:11:23Z",
    "updated": "2015-01-23T16:11:23Z",
    "authors": [
      "Wuilian Torres",
      "Antonio Rueda-Toicen"
    ],
    "link": "http://arxiv.org/abs/1501.05854v1",
    "pdf_link": "http://arxiv.org/pdf/1501.05854v1"
  },
  {
    "api_id": 180,
    "title": "Eclipsing Binaries From the CSTAR Project at Dome A, Antarctica",
    "summary": "The Chinese Small Telescope ARray (CSTAR) has observed an area around the\nCelestial South Pole at Dome A since 2008. About $20,000$ light curves in the i\nband were obtained lasting from March to July, 2008. The photometric precision\nachieves about 4 mmag at i = 7.5 and 20 mmag at i = 12 within a 30 s exposure\ntime. These light curves are analyzed using Lomb--Scargle, Phase Dispersion\nMinimization, and Box Least Squares methods to search for periodic signals.\nFalse positives may appear as a variable signature caused by contaminating\nstars and the observation mode of CSTAR. Therefore the period and position of\neach variable candidate are checked to eliminate false positives. Eclipsing\nbinaries are removed by visual inspection, frequency spectrum analysis and\nlocally linear embedding technique. We identify 53 eclipsing binaries in the\nfield of view of CSTAR, containing 24 detached binaries, 8 semi-detached\nbinaries, 18 contact binaries, and 3 ellipsoidal variables. To derive the\nparameters of these binaries, we use the Eclipsing Binaries via Artificial\nIntelligence (EBAI) method. The primary and the secondary eclipse timing\nvariations (ETVs) for semi-detached and contact systems are analyzed.\nCorrelated primary and secondary ETVs confirmed by false alarm tests may\nindicate an unseen perturbing companion. Through ETV analysis, we identify two\ntriple systems (CSTAR J084612.64-883342.9 and CSTAR J220502.55-895206.7). The\norbital parameters of the third body in CSTAR J220502.55-895206.7 are derived\nusing a simple dynamical model.",
    "published": "2015-04-21T02:29:10Z",
    "updated": "2015-04-21T02:29:10Z",
    "authors": [
      "Ming Yang",
      "Hui Zhang",
      "Songhu Wang",
      "Ji-Lin Zhou",
      "Xu Zhou",
      "Lingzhi Wang",
      "Lifan Wang",
      "R. A. Wittenmyer",
      "Hui-Gen Liu",
      "Zeyang Meng",
      "M. C. B. Ashley",
      "J. W. V. Storey",
      "D. Bayliss",
      "Chris Tinney",
      "Ying Wang",
      "Donghong Wu",
      "Ensi Liang",
      "Zhouyi Yu",
      "Zhou Fan",
      "Long-Long Feng",
      "Xuefei Gong",
      "J. S. Lawrence",
      "Qiang Liu",
      "D. M. Luong-Van",
      "Jun Ma",
      "Zhenyu Wu",
      "Jun Yan",
      "Huigen Yang",
      "Ji Yang",
      "Xiangyan Yuan",
      "Tianmeng Zhang",
      "Zhenxi Zhu",
      "Hu Zou"
    ],
    "link": "http://arxiv.org/abs/1504.05281v1",
    "pdf_link": "http://arxiv.org/pdf/1504.05281v1"
  },
  {
    "api_id": 181,
    "title": "A Group Theoretic Perspective on Unsupervised Deep Learning",
    "summary": "Why does Deep Learning work? What representations does it capture? How do\nhigher-order representations emerge? We study these questions from the\nperspective of group theory, thereby opening a new approach towards a theory of\nDeep learning.\n  One factor behind the recent resurgence of the subject is a key algorithmic\nstep called {\\em pretraining}: first search for a good generative model for the\ninput samples, and repeat the process one layer at a time. We show deeper\nimplications of this simple principle, by establishing a connection with the\ninterplay of orbits and stabilizers of group actions. Although the neural\nnetworks themselves may not form groups, we show the existence of {\\em shadow}\ngroups whose elements serve as close approximations.\n  Over the shadow groups, the pre-training step, originally introduced as a\nmechanism to better initialize a network, becomes equivalent to a search for\nfeatures with minimal orbits. Intuitively, these features are in a way the {\\em\nsimplest}. Which explains why a deep learning network learns simple features\nfirst. Next, we show how the same principle, when repeated in the deeper\nlayers, can capture higher order representations, and why representation\ncomplexity increases as the layers get deeper.",
    "published": "2015-04-08T22:39:05Z",
    "updated": "2015-04-21T06:05:52Z",
    "authors": [
      "Arnab Paul",
      "Suresh Venkatasubramanian"
    ],
    "link": "http://arxiv.org/abs/1504.02462v3",
    "pdf_link": "http://arxiv.org/pdf/1504.02462v3"
  },
  {
    "api_id": 182,
    "title": "SegSALSA-STR: A convex formulation to supervised hyperspectral image\n  segmentation using hidden fields and structure tensor regularization",
    "summary": "We present a supervised hyperspectral image segmentation algorithm based on a\nconvex formulation of a marginal maximum a posteriori segmentation with hidden\nfields and structure tensor regularization: Segmentation via the Constraint\nSplit Augmented Lagrangian Shrinkage by Structure Tensor Regularization\n(SegSALSA-STR). This formulation avoids the generally discrete nature of\nsegmentation problems and the inherent NP-hardness of the integer optimization\nassociated.\n  We extend the Segmentation via the Constraint Split Augmented Lagrangian\nShrinkage (SegSALSA) algorithm by generalizing the vectorial total variation\nprior using a structure tensor prior constructed from a patch-based Jacobian.\nThe resulting algorithm is convex, time-efficient and highly parallelizable.\nThis shows the potential of combining hidden fields with convex optimization\nthrough the inclusion of different regularizers. The SegSALSA-STR algorithm is\nvalidated in the segmentation of real hyperspectral images.",
    "published": "2015-04-27T11:08:53Z",
    "updated": "2015-04-27T11:08:53Z",
    "authors": [
      "Filipe Condessa",
      "Jose Bioucas-Dias",
      "Jelena Kovacevic"
    ],
    "link": "http://arxiv.org/abs/1504.07028v1",
    "pdf_link": "http://arxiv.org/pdf/1504.07028v1"
  },
  {
    "api_id": 183,
    "title": "Dynamic Body VSLAM with Semantic Constraints",
    "summary": "Image based reconstruction of urban environments is a challenging problem\nthat deals with optimization of large number of variables, and has several\nsources of errors like the presence of dynamic objects. Since most large scale\napproaches make the assumption of observing static scenes, dynamic objects are\nrelegated to the noise modeling section of such systems. This is an approach of\nconvenience since the RANSAC based framework used to compute most multiview\ngeometric quantities for static scenes naturally confine dynamic objects to the\nclass of outlier measurements. However, reconstructing dynamic objects along\nwith the static environment helps us get a complete picture of an urban\nenvironment. Such understanding can then be used for important robotic tasks\nlike path planning for autonomous navigation, obstacle tracking and avoidance,\nand other areas. In this paper, we propose a system for robust SLAM that works\nin both static and dynamic environments. To overcome the challenge of dynamic\nobjects in the scene, we propose a new model to incorporate semantic\nconstraints into the reconstruction algorithm. While some of these constraints\nare based on multi-layered dense CRFs trained over appearance as well as motion\ncues, other proposed constraints can be expressed as additional terms in the\nbundle adjustment optimization process that does iterative refinement of 3D\nstructure and camera / object motion trajectories. We show results on the\nchallenging KITTI urban dataset for accuracy of motion segmentation and\nreconstruction of the trajectory and shape of moving objects relative to ground\ntruth. We are able to show average relative error reduction by a significant\namount for moving object trajectory reconstruction relative to state-of-the-art\nmethods like VISO 2, as well as standard bundle adjustment algorithms.",
    "published": "2015-04-27T20:30:04Z",
    "updated": "2015-04-27T20:30:04Z",
    "authors": [
      "N. Dinesh Reddy",
      "Prateek Singhal",
      "Visesh Chari",
      "K. Madhava Krishna"
    ],
    "link": "http://arxiv.org/abs/1504.07269v1",
    "pdf_link": "http://arxiv.org/pdf/1504.07269v1"
  },
  {
    "api_id": 184,
    "title": "ASTROMLSKIT: A New Statistical Machine Learning Toolkit: A Platform for\n  Data Analytics in Astronomy",
    "summary": "Astroinformatics is a new impact area in the world of astronomy, occasionally\ncalled the final frontier, where several astrophysicists, statisticians and\ncomputer scientists work together to tackle various data intensive astronomical\nproblems. Exponential growth in the data volume and increased complexity of the\ndata augments difficult questions to the existing challenges. Classical\nproblems in Astronomy are compounded by accumulation of astronomical volume of\ncomplex data, rendering the task of classification and interpretation\nincredibly laborious. The presence of noise in the data makes analysis and\ninterpretation even more arduous. Machine learning algorithms and data analytic\ntechniques provide the right platform for the challenges posed by these\nproblems. A diverse range of open problem like star-galaxy separation,\ndetection and classification of exoplanets, classification of supernovae is\ndiscussed. The focus of the paper is the applicability and efficacy of various\nmachine learning algorithms like K Nearest Neighbor (KNN), random forest (RF),\ndecision tree (DT), Support Vector Machine (SVM), Na\\\"ive Bayes and Linear\nDiscriminant Analysis (LDA) in analysis and inference of the decision theoretic\nproblems in Astronomy. The machine learning algorithms, integrated into\nASTROMLSKIT, a toolkit developed in the course of the work, have been used to\nanalyze HabCat data and supernovae data. Accuracy has been found to be\nappreciably good.",
    "published": "2015-04-29T14:06:18Z",
    "updated": "2015-04-29T14:06:18Z",
    "authors": [
      "Snehanshu Saha",
      "Surbhi Agrawal",
      "Manikandan. R",
      "Kakoli Bora",
      "Swati Routh",
      "Anand Narasimhamurthy"
    ],
    "link": "http://arxiv.org/abs/1504.07865v1",
    "pdf_link": "http://arxiv.org/pdf/1504.07865v1"
  },
  {
    "api_id": 185,
    "title": "Robust hyperspectral image classification with rejection fields",
    "summary": "In this paper we present a novel method for robust hyperspectral image\nclassification using context and rejection. Hyperspectral image classification\nis generally an ill-posed image problem where pixels may belong to unknown\nclasses, and obtaining representative and complete training sets is costly.\nFurthermore, the need for high classification accuracies is frequently greater\nthan the need to classify the entire image.\n  We approach this problem with a robust classification method that combines\nclassification with context with classification with rejection. A rejection\nfield that will guide the rejection is derived from the classification with\ncontextual information obtained by using the SegSALSA algorithm. We validate\nour method in real hyperspectral data and show that the performance gains\nobtained from the rejection fields are equivalent to an increase the dimension\nof the training sets.",
    "published": "2015-04-29T16:30:45Z",
    "updated": "2015-04-29T16:30:45Z",
    "authors": [
      "Filipe Condessa",
      "Jose Bioucas-Dias",
      "Jelena Kovacevic"
    ],
    "link": "http://arxiv.org/abs/1504.07918v1",
    "pdf_link": "http://arxiv.org/pdf/1504.07918v1"
  },
  {
    "api_id": 186,
    "title": "Quantum thermal Hall effect of Majorana fermions on the surface of\n  superconducting topoloigcal insulators",
    "summary": "We study the quantum anomalous thermal Hall effect in a topological\nsuperconductor which possesses an integer bulk topological number, and supports\nMajorana excitations on the surface. To realize the quantum thermal Hall\neffect, a finite gap at the surface is induced by applying an external magnetic\nfield or by the proximity effects with magnetic materials or $s$-wave\nsuperconductors with complex pair-potentials. Basing on the lattice model\nHamiltonian for superconducting states in Cu-doped Bi$_2$Se$_3$, we compute the\nthermal Hall conductivity as a function of various parameters such as the\nchemical potential, the pair-potential, and the spin-orbit coupling induced\nband gap. It is argued that the bulk topological invariant corresponds to the\nquantization rule of the thermal Hall conductivity induced by complex $s$-wave\npair-potentials.",
    "published": "2014-03-05T07:18:47Z",
    "updated": "2015-05-01T05:04:27Z",
    "authors": [
      "Yosuke Shimizu",
      "Ai Yamakage",
      "Kentaro Nomura"
    ],
    "link": "http://arxiv.org/abs/1403.1021v2",
    "pdf_link": "http://arxiv.org/pdf/1403.1021v2"
  },
  {
    "api_id": 187,
    "title": "Towards Formal Fault Tree Analysis using Theorem Proving",
    "summary": "Fault Tree Analysis (FTA) is a dependability analysis technique that has been\nwidely used to predict reliability, availability and safety of many complex\nengineering systems. Traditionally, these FTA-based analyses are done using\npaper-and-pencil proof methods or computer simulations, which cannot ascertain\nabsolute correctness due to their inherent limitations. As a complementary\napproach, we propose to use the higher-order-logic theorem prover HOL4 to\nconduct the FTA-based analysis of safety-critical systems where accuracy of\nfailure analysis is a dire need. In particular, the paper presents a\nhigher-order-logic formalization of generic Fault Tree gates, i.e., AND, OR,\nNAND, NOR, XOR and NOT and the formal verification of their failure probability\nexpressions. Moreover, we have formally verified the generic probabilistic\ninclusion-exclusion principle, which is one of the foremost requirements for\nconducting the FTA-based failure analysis of any given system. For illustration\npurposes, we conduct the FTA-based failure analysis of a solar array that is\nused as the main source of power for the Dong Fang Hong-3 (DFH-3) satellite.",
    "published": "2015-05-08T05:14:08Z",
    "updated": "2015-05-08T05:14:08Z",
    "authors": [
      "Waqar Ahmed",
      "Osman Hasan"
    ],
    "link": "http://arxiv.org/abs/1505.02648v1",
    "pdf_link": "http://arxiv.org/pdf/1505.02648v1"
  },
  {
    "api_id": 188,
    "title": "Removing systematic errors for exoplanet search via latent causes",
    "summary": "We describe a method for removing the effect of confounders in order to\nreconstruct a latent quantity of interest. The method, referred to as\nhalf-sibling regression, is inspired by recent work in causal inference using\nadditive noise models. We provide a theoretical justification and illustrate\nthe potential of the method in a challenging astronomy application.",
    "published": "2015-05-12T14:49:08Z",
    "updated": "2015-05-12T14:49:08Z",
    "authors": [
      "Bernhard Schölkopf",
      "David W. Hogg",
      "Dun Wang",
      "Daniel Foreman-Mackey",
      "Dominik Janzing",
      "Carl-Johann Simon-Gabriel",
      "Jonas Peters"
    ],
    "link": "http://arxiv.org/abs/1505.03036v1",
    "pdf_link": "http://arxiv.org/pdf/1505.03036v1"
  },
  {
    "api_id": 189,
    "title": "Theoretical and Numerical Analysis of Approximate Dynamic Programming\n  with Approximation Errors",
    "summary": "This study is aimed at answering the famous question of how the approximation\nerrors at each iteration of Approximate Dynamic Programming (ADP) affect the\nquality of the final results considering the fact that errors at each iteration\naffect the next iteration. To this goal, convergence of Value Iteration scheme\nof ADP for deterministic nonlinear optimal control problems with undiscounted\ncost functions is investigated while considering the errors existing in\napproximating respective functions. The boundedness of the results around the\noptimal solution is obtained based on quantities which are known in a general\noptimal control problem and assumptions which are verifiable. Moreover, since\nthe presence of the approximation errors leads to the deviation of the results\nfrom optimality, sufficient conditions for stability of the system operated by\nthe result obtained after a finite number of value iterations, along with an\nestimation of its region of attraction, are derived in terms of a calculable\nupper bound of the control approximation error. Finally, the process of\nimplementation of the method on an orbital maneuver problem is investigated\nthrough which the assumptions made in the theoretical developments are verified\nand the sufficient conditions are applied for guaranteeing stability and near\noptimality.",
    "published": "2014-12-18T16:38:10Z",
    "updated": "2015-05-15T18:41:08Z",
    "authors": [
      "Ali Heydari"
    ],
    "link": "http://arxiv.org/abs/1412.6095v3",
    "pdf_link": "http://arxiv.org/pdf/1412.6095v3"
  },
  {
    "api_id": 190,
    "title": "Algorithmic Analysis of Edge Ranking and Profiling for MTF Determination\n  of an Imaging System",
    "summary": "Edge detection is one of the most principal techniques for detecting\ndiscontinuities in the gray levels of image pixels. The Modulation Transfer\nFunction (MTF) is one of the main criteria for assessing imaging quality and is\na parameter frequently used for measuring the sharpness of an imaging system.\nIn order to determine the MTF, it is essential to determine the best edge from\nthe target image so that an edge profile can be developed and then the line\nspread function and hence the MTF, can be computed accordingly. For regular\nimage sizes, the human visual system is adept enough to identify suitable edges\nfrom the image. But considering huge image datasets, such as those obtained\nfrom satellites, the image size may range in few gigabytes and in such a case,\nmanual inspection of images for determination of the best suitable edge is not\nplausible and hence, edge profiling tasks have to be automated. This paper\npresents a novel, yet simple, algorithm for edge ranking and detection from\nimage data-sets for MTF computation, which is ideal for automation on\nvectorised graphical processing units.",
    "published": "2015-05-20T12:12:48Z",
    "updated": "2015-05-20T12:12:48Z",
    "authors": [
      "Poorna Banerjee Dasgupta"
    ],
    "link": "http://arxiv.org/abs/1505.05338v1",
    "pdf_link": "http://arxiv.org/pdf/1505.05338v1"
  },
  {
    "api_id": 191,
    "title": "A Pareto Front-Based Multiobjective Path Planning Algorithm",
    "summary": "Path planning is one of the most vital elements of mobile robotics. With a\npriori knowledge of the environment, global path planning provides a\ncollision-free route through the workspace. The global path plan can be\ncalculated with a variety of informed search algorithms, most notably the A*\nsearch method, guaranteed to deliver a complete and optimal solution that\nminimizes the path cost. Path planning optimization typically looks to minimize\nthe distance traversed from start to goal, yet many mobile robot applications\ncall for additional path planning objectives, presenting a multiobjective\noptimization (MOO) problem. Past studies have applied genetic algorithms to MOO\npath planning problems, but these may have the disadvantages of computational\ncomplexity and suboptimal solutions. Alternatively, the algorithm in this paper\napproaches MOO path planning with the use of Pareto fronts, or finding\nnon-dominated solutions. The algorithm presented incorporates Pareto optimality\ninto every step of A* search, thus it is named A*-PO. Results of simulations\nshow A*-PO outperformed several variations of the standard A* algorithm for MOO\npath planning. A planetary exploration rover case study was added to\ndemonstrate the viability of A*-PO in a real-world application.",
    "published": "2015-05-22T04:35:12Z",
    "updated": "2015-05-22T04:35:12Z",
    "authors": [
      "Alexander Lavin"
    ],
    "link": "http://arxiv.org/abs/1505.05947v1",
    "pdf_link": "http://arxiv.org/pdf/1505.05947v1"
  },
  {
    "api_id": 192,
    "title": "Geometry of Graph Edit Distance Spaces",
    "summary": "In this paper we study the geometry of graph spaces endowed with a special\nclass of graph edit distances. The focus is on geometrical results useful for\nstatistical pattern recognition. The main result is the Graph Representation\nTheorem. It states that a graph is a point in some geometrical space, called\norbit space. Orbit spaces are well investigated and easier to explore than the\noriginal graph space. We derive a number of geometrical results from the orbit\nspace representation, translate them to the graph space, and indicate their\nsignificance and usefulness in statistical pattern recognition.",
    "published": "2015-05-29T14:51:23Z",
    "updated": "2015-05-29T14:51:23Z",
    "authors": [
      "Brijnesh J. Jain"
    ],
    "link": "http://arxiv.org/abs/1505.08071v1",
    "pdf_link": "http://arxiv.org/pdf/1505.08071v1"
  },
  {
    "api_id": 193,
    "title": "Hyperspectral Image Classification and Clutter Detection via Multiple\n  Structural Embeddings and Dimension Reductions",
    "summary": "We present a new and effective approach for Hyperspectral Image (HSI)\nclassification and clutter detection, overcoming a few long-standing challenges\npresented by HSI data characteristics. Residing in a high-dimensional spectral\nattribute space, HSI data samples are known to be strongly correlated in their\nspectral signatures, exhibit nonlinear structure due to several physical laws,\nand contain uncertainty and noise from multiple sources. In the presented\napproach, we generate an adaptive, structurally enriched representation\nenvironment, and employ the locally linear embedding (LLE) in it. There are two\nstructure layers external to LLE. One is feature space embedding: the HSI data\nattributes are embedded into a discriminatory feature space where\nspatio-spectral coherence and distinctive structures are distilled and\nexploited to mitigate various difficulties encountered in the native\nhyperspectral attribute space. The other structure layer encloses the ranges of\nalgorithmic parameters for LLE and feature embedding, and supports a\nmultiplexing and integrating scheme for contending with multi-source\nuncertainty. Experiments on two commonly used HSI datasets with a small number\nof learning samples have rendered remarkably high-accuracy classification\nresults, as well as distinctive maps of detected clutter regions.",
    "published": "2015-06-03T04:04:43Z",
    "updated": "2015-06-03T04:04:43Z",
    "authors": [
      "Alexandros-Stavros Iliopoulos",
      "Tiancheng Liu",
      "Xiaobai Sun"
    ],
    "link": "http://arxiv.org/abs/1506.01115v1",
    "pdf_link": "http://arxiv.org/pdf/1506.01115v1"
  },
  {
    "api_id": 194,
    "title": "Multilayer Structured NMF for Spectral Unmixing of Hyperspectral Images",
    "summary": "One of the challenges in hyperspectral data analysis is the presence of mixed\npixels. Mixed pixels are the result of low spatial resolution of hyperspectral\nsensors. Spectral unmixing methods decompose a mixed pixel into a set of\nendmembers and abundance fractions. Due to nonnegativity constraint on\nabundance fraction values, NMF based methods are well suited to this problem.\nIn this paper multilayer NMF has been used to improve the results of NMF\nmethods for spectral unmixing of hyperspectral data under the linear mixing\nframework. Sparseness constraint on both spectral signatures and abundance\nfractions matrices are used in this paper. Evaluation of the proposed algorithm\nis done using synthetic and real datasets in terms of spectral angle and\nabundance angle distances. Results show that the proposed algorithm outperforms\nother previously proposed methods.",
    "published": "2015-06-04T13:53:33Z",
    "updated": "2015-06-04T13:53:33Z",
    "authors": [
      "Roozbeh Rajabi",
      "Hassan Ghassemian"
    ],
    "link": "http://arxiv.org/abs/1506.01596v1",
    "pdf_link": "http://arxiv.org/pdf/1506.01596v1"
  },
  {
    "api_id": 195,
    "title": "Automatic Classification of Kepler Planetary Transit Candidates",
    "summary": "In the first three years of operation the Kepler mission found 3,697 planet\ncandidates from a set of 18,406 transit-like features detected on over 200,000\ndistinct stars. Vetting candidate signals manually by inspecting light curves\nand other diagnostic information is a labor intensive effort. Additionally,\nthis classification methodology does not yield any information about the\nquality of planet candidates; all candidates are as credible as any other\ncandidate. The torrent of exoplanet discoveries will continue after Kepler as\nthere will be a number of exoplanet surveys that have an even broader search\narea. This paper presents the application of machine-learning techniques to the\nclassification of exoplanet transit-like signals present in the \\Kepler light\ncurve data. Transit-like detections are transformed into a uniform set of\nreal-numbered attributes, the most important of which are described in this\npaper. Each of the known transit-like detections is assigned a class of planet\ncandidate; astrophysical false positive; or systematic, instrumental noise. We\nuse a random forest algorithm to learn the mapping from attributes to classes\non this training set. The random forest algorithm has been used previously to\nclassify variable stars; this is the first time it has been used for exoplanet\nclassification. We are able to achieve an overall error rate of 5.85% and an\nerror rate for classifying exoplanets candidates of 2.81%.",
    "published": "2014-08-07T06:53:57Z",
    "updated": "2015-06-05T00:02:54Z",
    "authors": [
      "Sean D. McCauliff",
      "Jon M. Jenkins",
      "Joseph Catanzarite",
      "Christopher J. Burke",
      "Jeffrey L. Coughlin",
      "Joseph D. Twicken",
      "Peter Tenenbaum",
      "Shawn Seader",
      "Jie Li",
      "Miles Cote"
    ],
    "link": "http://arxiv.org/abs/1408.1496v2",
    "pdf_link": "http://arxiv.org/pdf/1408.1496v2"
  },
  {
    "api_id": 196,
    "title": "Optimal Sparse Kernel Learning for Hyperspectral Anomaly Detection",
    "summary": "In this paper, a novel framework of sparse kernel learning for Support Vector\nData Description (SVDD) based anomaly detection is presented. In this work,\noptimal sparse feature selection for anomaly detection is first modeled as a\nMixed Integer Programming (MIP) problem. Due to the prohibitively high\ncomputational complexity of the MIP, it is relaxed into a Quadratically\nConstrained Linear Programming (QCLP) problem. The QCLP problem can then be\npractically solved by using an iterative optimization method, in which multiple\nsubsets of features are iteratively found as opposed to a single subset. The\nQCLP-based iterative optimization problem is solved in a finite space called\nthe \\emph{Empirical Kernel Feature Space} (EKFS) instead of in the input space\nor \\emph{Reproducing Kernel Hilbert Space} (RKHS). This is possible because of\nthe fact that the geometrical properties of the EKFS and the corresponding RKHS\nremain the same. Now, an explicit nonlinear exploitation of the data in a\nfinite EKFS is achievable, which results in optimal feature ranking.\nExperimental results based on a hyperspectral image show that the proposed\nmethod can provide improved performance over the current state-of-the-art\ntechniques.",
    "published": "2015-06-08T16:51:40Z",
    "updated": "2015-06-08T16:51:40Z",
    "authors": [
      "Zhimin Peng",
      "Prudhvi Gurram",
      "Heesung Kwon",
      "Wotao Yin"
    ],
    "link": "http://arxiv.org/abs/1506.02585v1",
    "pdf_link": "http://arxiv.org/pdf/1506.02585v1"
  },
  {
    "api_id": 197,
    "title": "Investigating the Kinematics of Coronal Mass Ejections with the\n  Automated CORIMP Catalog",
    "summary": "Studying coronal mass ejections (CMEs) in coronagraph data can be challenging\ndue to their diffuse structure and transient nature, compounded by the\nvariations in their dynamics, morphology, and frequency of occurrence. The\nlarge amounts of data available from missions like the Solar and Heliospheric\nObservatory (SOHO) make manual cataloging of CMEs tedious and prone to human\nerror, and so a robust method of detection and analysis is required and often\npreferred. A new coronal image processing catalog called CORIMP has been\ndeveloped in an effort to achieve this, through the implementation of a dynamic\nbackground separation technique and multiscale edge detection. These algorithms\ntogether isolate and characterise CME structure in the field-of-view of the\nLarge Angle Spectrometric Coronagraph (LASCO) onboard SOHO. CORIMP also applies\na Savitzky-Golay filter, along with quadratic and linear fits, to the\nheight-time measurements for better revealing the true CME speed and\nacceleration profiles across the plane-of-sky. Here we present a sample of new\nresults from the CORIMP CME catalog, and directly compare them with the other\nautomated catalogs of Computer Aided CME Tracking (CACTus) and Solar Eruptive\nEvents Detection System (SEEDS), as well as the manual CME catalog at the\nCoordinated Data Analysis Workshop (CDAW) Data Center and a previously\npublished study of the sample events. We further investigate a form of\nunsupervised machine learning by using a k-means clustering algorithm to\ndistinguish detections of multiple CMEs that occur close together in space and\ntime. While challenges still exist, this investigation and comparison of\nresults demonstrates the reliability and robustness of the CORIMP catalog,\nproving its effectiveness at detecting and tracking CMEs throughout the LASCO\ndataset.",
    "published": "2015-06-12T15:39:27Z",
    "updated": "2015-06-12T15:39:27Z",
    "authors": [
      "Jason P. Byrne"
    ],
    "link": "http://arxiv.org/abs/1506.04046v1",
    "pdf_link": "http://arxiv.org/pdf/1506.04046v1"
  },
  {
    "api_id": 198,
    "title": "Automatic Channel Network Extraction from Remotely Sensed Images by\n  Singularity Analysis",
    "summary": "Quantitative analysis of channel networks plays an important role in river\nstudies. To provide a quantitative representation of channel networks, we\npropose a new method that extracts channels from remotely sensed images and\nestimates their widths. Our fully automated method is based on a recently\nproposed Multiscale Singularity Index that responds strongly to curvilinear\nstructures but weakly to edges. The algorithm produces a channel map, using a\nsingle image where water and non-water pixels have contrast, such as a Landsat\nnear-infrared band image or a water index defined on multiple bands. The\nproposed method provides a robust alternative to the procedures that are used\nin remote sensing of fluvial geomorphology and makes classification and\nanalysis of channel networks easier. The source code of the algorithm is\navailable at: http://live.ece.utexas.edu/research/cne/.",
    "published": "2015-06-29T15:03:04Z",
    "updated": "2015-06-29T15:03:04Z",
    "authors": [
      "F. Isikdogan",
      "A. C. Bovik",
      "P. Passalacqua"
    ],
    "link": "http://arxiv.org/abs/1506.08670v1",
    "pdf_link": "http://arxiv.org/pdf/1506.08670v1"
  },
  {
    "api_id": 199,
    "title": "Semiblind Hyperspectral Unmixing in the Presence of Spectral Library\n  Mismatches",
    "summary": "The dictionary-aided sparse regression (SR) approach has recently emerged as\na promising alternative to hyperspectral unmixing (HU) in remote sensing. By\nusing an available spectral library as a dictionary, the SR approach identifies\nthe underlying materials in a given hyperspectral image by selecting a small\nsubset of spectral samples in the dictionary to represent the whole image. A\ndrawback with the current SR developments is that an actual spectral signature\nin the scene is often assumed to have zero mismatch with its corresponding\ndictionary sample, and such an assumption is considered too ideal in practice.\nIn this paper, we tackle the spectral signature mismatch problem by proposing a\ndictionary-adjusted nonconvex sparsity-encouraging regression (DANSER)\nframework. The main idea is to incorporate dictionary correcting variables in\nan SR formulation. A simple and low per-iteration complexity algorithm is\ntailor-designed for practical realization of DANSER. Using the same dictionary\ncorrecting idea, we also propose a robust subspace solution for dictionary\npruning. Extensive simulations and real-data experiments show that the proposed\nmethod is effective in mitigating the undesirable spectral signature mismatch\neffects.",
    "published": "2015-07-07T03:00:17Z",
    "updated": "2015-07-07T03:00:17Z",
    "authors": [
      "Xiao Fu",
      "Wing-Kin Ma",
      "José Bioucas-Dias",
      "Tsung-Han Chan"
    ],
    "link": "http://arxiv.org/abs/1507.01661v1",
    "pdf_link": "http://arxiv.org/pdf/1507.01661v1"
  },
  {
    "api_id": 200,
    "title": "A genetic algorithm for autonomous navigation in partially observable\n  domain",
    "summary": "The problem of autonomous navigation is one of the basic problems for\nrobotics. Although, in general, it may be challenging when an autonomous\nvehicle is placed into partially observable domain. In this paper we consider\nsimplistic environment model and introduce a navigation algorithm based on\nLearning Classifier System.",
    "published": "2015-07-27T11:50:44Z",
    "updated": "2015-07-27T11:50:44Z",
    "authors": [
      "Maxim Borisyak",
      "Andrey Ustyuzhanin"
    ],
    "link": "http://arxiv.org/abs/1507.07374v1",
    "pdf_link": "http://arxiv.org/pdf/1507.07374v1"
  },
  {
    "api_id": 201,
    "title": "Dense v.s. Sparse: A Comparative Study of Sampling Analysis in Scene\n  Classification of High-Resolution Remote Sensing Imagery",
    "summary": "Scene classification is a key problem in the interpretation of\nhigh-resolution remote sensing imagery. Many state-of-the-art methods, e.g.\nbag-of-visual-words model and its variants, the topic models as well as deep\nlearning-based approaches, share similar procedures: patch sampling, feature\ndescription/learning and classification. Patch sampling is the first and a key\nprocedure which has a great influence on the results. In the literature, many\ndifferent sampling strategies have been used, {e.g. dense sampling, random\nsampling, keypoint-based sampling and saliency-based sampling, etc. However, it\nis still not clear which sampling strategy is suitable for the scene\nclassification of high-resolution remote sensing images. In this paper, we\ncomparatively study the effects of different sampling strategies under the\nscenario of scene classification of high-resolution remote sensing images. We\ndivide the existing sampling methods into two types: dense sampling and sparse\nsampling, the later of which includes random sampling, keypoint-based sampling\nand various saliency-based sampling proposed recently. In order to compare\ntheir performances, we rely on a standard bag-of-visual-words model to\nconstruct our testing scheme, owing to their simplicity, robustness and\nefficiency. The experimental results on two commonly used datasets show that\ndense sampling has the best performance among all the strategies but with high\nspatial and computational complexity, random sampling gives better or\ncomparable results than other sparse sampling methods, like the sophisticated\nmulti-scale key-point operators and the saliency-based methods which are\nintensively studied and commonly used recently.",
    "published": "2015-02-04T05:34:31Z",
    "updated": "2015-07-31T07:02:30Z",
    "authors": [
      "Jingwen Hu",
      "Gui-Song Xia",
      "Fan Hu",
      "Liangpei Zhang"
    ],
    "link": "http://arxiv.org/abs/1502.01097v2",
    "pdf_link": "http://arxiv.org/pdf/1502.01097v2"
  },
  {
    "api_id": 202,
    "title": "Land Use Classification in Remote Sensing Images by Convolutional Neural\n  Networks",
    "summary": "We explore the use of convolutional neural networks for the semantic\nclassification of remote sensing scenes. Two recently proposed architectures,\nCaffeNet and GoogLeNet, are adopted, with three different learning modalities.\nBesides conventional training from scratch, we resort to pre-trained networks\nthat are only fine-tuned on the target data, so as to avoid overfitting\nproblems and reduce design time. Experiments on two remote sensing datasets,\nwith markedly different characteristics, testify on the effectiveness and wide\napplicability of the proposed solution, which guarantees a significant\nperformance improvement over all state-of-the-art references.",
    "published": "2015-08-01T07:15:19Z",
    "updated": "2015-08-01T07:15:19Z",
    "authors": [
      "Marco Castelluccio",
      "Giovanni Poggi",
      "Carlo Sansone",
      "Luisa Verdoliva"
    ],
    "link": "http://arxiv.org/abs/1508.00092v1",
    "pdf_link": "http://arxiv.org/pdf/1508.00092v1"
  },
  {
    "api_id": 203,
    "title": "On Hyperspectral Classification in the Compressed Domain",
    "summary": "In this paper, we study the problem of hyperspectral pixel classification\nbased on the recently proposed architectures for compressive whisk-broom\nhyperspectral imagers without the need to reconstruct the complete data cube. A\nclear advantage of classification in the compressed domain is its suitability\nfor real-time on-site processing of the sensed data. Moreover, it is assumed\nthat the training process also takes place in the compressed domain, thus,\nisolating the classification unit from the recovery unit at the receiver's\nside. We show that, perhaps surprisingly, using distinct measurement matrices\nfor different pixels results in more accuracy of the learned classifier and\nconsistent classification performance, supporting the role of information\ndiversity in learning.",
    "published": "2015-08-02T20:40:21Z",
    "updated": "2015-08-02T20:40:21Z",
    "authors": [
      "Mohammad Aghagolzadeh",
      "Hayder Radha"
    ],
    "link": "http://arxiv.org/abs/1508.00282v1",
    "pdf_link": "http://arxiv.org/pdf/1508.00282v1"
  },
  {
    "api_id": 204,
    "title": "Estimating snow cover from publicly available images",
    "summary": "In this paper we study the problem of estimating snow cover in mountainous\nregions, that is, the spatial extent of the earth surface covered by snow. We\nargue that publicly available visual content, in the form of user generated\nphotographs and image feeds from outdoor webcams, can both be leveraged as\nadditional measurement sources, complementing existing ground, satellite and\nairborne sensor data. To this end, we describe two content acquisition and\nprocessing pipelines that are tailored to such sources, addressing the specific\nchallenges posed by each of them, e.g., identifying the mountain peaks,\nfiltering out images taken in bad weather conditions, handling varying\nillumination conditions. The final outcome is summarized in a snow cover index,\nwhich indicates for a specific mountain and day of the year, the fraction of\nvisible area covered by snow, possibly at different elevations. We created a\nmanually labelled dataset to assess the accuracy of the image snow covered area\nestimation, achieving 90.0% precision at 91.1% recall. In addition, we show\nthat seasonal trends related to air temperature are captured by the snow cover\nindex.",
    "published": "2015-08-05T12:46:26Z",
    "updated": "2015-08-05T12:46:26Z",
    "authors": [
      "Roman Fedorov",
      "Alessandro Camerada",
      "Piero Fraternali",
      "Marco Tagliasacchi"
    ],
    "link": "http://arxiv.org/abs/1508.01055v1",
    "pdf_link": "http://arxiv.org/pdf/1508.01055v1"
  },
  {
    "api_id": 205,
    "title": "A Machine Learning Technique to Identify Transit Shaped Signals",
    "summary": "We describe a new metric that uses machine learning to determine if a\nperiodic signal found in a photometric time series appears to be shaped like\nthe signature of a transiting exoplanet. This metric uses dimensionality\nreduction and k-nearest neighbors to determine whether a given signal is\nsufficiently similar to known transits in the same data set. This metric is\nbeing used by the Kepler Robovetter to determine which signals should be part\nof the Q1-Q17 DR24 catalog of planetary candidates. The Kepler Mission reports\nroughly 20,000 potential transiting signals with each run of its pipeline, yet\nonly a few thousand appear sufficiently transit shaped to be part of the\ncatalog. The other signals tend to be variable stars and instrumental noise.\nWith this metric we are able to remove more than 90% of the non-transiting\nsignals while retaining more than 99% of the known planet candidates. When\ntested with injected transits, less than 1% are lost. This metric will enable\nthe Kepler mission and future missions looking for transiting planets to\nrapidly and consistently find the best planetary candidates for follow-up and\ncataloging.",
    "published": "2015-08-31T20:23:47Z",
    "updated": "2015-08-31T20:23:47Z",
    "authors": [
      "Susan E. Thompson",
      "Fergal Mullally",
      "Jeff Coughlin",
      "Jessie L. Christiansen",
      "Christopher E. Henze",
      "Michael R. Haas",
      "Christopher J. Burke"
    ],
    "link": "http://arxiv.org/abs/1509.00041v1",
    "pdf_link": "http://arxiv.org/pdf/1509.00041v1"
  },
  {
    "api_id": 206,
    "title": "Remote sensing image classification exploiting multiple kernel learning",
    "summary": "We propose a strategy for land use classification which exploits Multiple\nKernel Learning (MKL) to automatically determine a suitable combination of a\nset of features without requiring any heuristic knowledge about the\nclassification task. We present a novel procedure that allows MKL to achieve\ngood performance in the case of small training sets. Experimental results on\npublicly available datasets demonstrate the feasibility of the proposed\napproach.",
    "published": "2014-10-20T17:15:50Z",
    "updated": "2015-09-01T09:25:50Z",
    "authors": [
      "Claudio Cusano",
      "Paolo Napoletano",
      "Raimondo Schettini"
    ],
    "link": "http://arxiv.org/abs/1410.5358v3",
    "pdf_link": "http://arxiv.org/pdf/1410.5358v3"
  },
  {
    "api_id": 207,
    "title": "Vision-Based Road Detection using Contextual Blocks",
    "summary": "Road detection is a fundamental task in autonomous navigation systems. In\nthis paper, we consider the case of monocular road detection, where images are\nsegmented into road and non-road regions. Our starting point is the well-known\nmachine learning approach, in which a classifier is trained to distinguish road\nand non-road regions based on hand-labeled images. We proceed by introducing\nthe use of \"contextual blocks\" as an efficient way of providing contextual\ninformation to the classifier. Overall, the proposed methodology, including its\nimage feature selection and classifier, was conceived with computational cost\nin mind, leaving room for optimized implementations. Regarding experiments, we\nperform a sensible evaluation of each phase and feature subset that composes\nour system. The results show a great benefit from using contextual blocks and\ndemonstrate their computational efficiency. Finally, we submit our results to\nthe KITTI road detection benchmark achieving scores comparable with state of\nthe art methods.",
    "published": "2015-09-03T15:24:06Z",
    "updated": "2015-09-03T15:24:06Z",
    "authors": [
      "Caio César Teodoro Mendes",
      "Vincent Frémont",
      "Denis Fernando Wolf"
    ],
    "link": "http://arxiv.org/abs/1509.01122v1",
    "pdf_link": "http://arxiv.org/pdf/1509.01122v1"
  },
  {
    "api_id": 208,
    "title": "Discovering governing equations from data: Sparse identification of\n  nonlinear dynamical systems",
    "summary": "The ability to discover physical laws and governing equations from data is\none of humankind's greatest intellectual achievements. A quantitative\nunderstanding of dynamic constraints and balances in nature has facilitated\nrapid development of knowledge and enabled advanced technological achievements,\nincluding aircraft, combustion engines, satellites, and electrical power. In\nthis work, we combine sparsity-promoting techniques and machine learning with\nnonlinear dynamical systems to discover governing physical equations from\nmeasurement data. The only assumption about the structure of the model is that\nthere are only a few important terms that govern the dynamics, so that the\nequations are sparse in the space of possible functions; this assumption holds\nfor many physical systems. In particular, we use sparse regression to determine\nthe fewest terms in the dynamic governing equations required to accurately\nrepresent the data. The resulting models are parsimonious, balancing model\ncomplexity with descriptive ability while avoiding overfitting. We demonstrate\nthe algorithm on a wide range of problems, from simple canonical systems,\nincluding linear and nonlinear oscillators and the chaotic Lorenz system, to\nthe fluid vortex shedding behind an obstacle. The fluid example illustrates the\nability of this method to discover the underlying dynamics of a system that\ntook experts in the community nearly 30 years to resolve. We also show that\nthis method generalizes to parameterized, time-varying, or externally forced\nsystems.",
    "published": "2015-09-11T16:43:06Z",
    "updated": "2015-09-11T16:43:06Z",
    "authors": [
      "Steven L. Brunton",
      "Joshua L. Proctor",
      "J. Nathan Kutz"
    ],
    "link": "http://arxiv.org/abs/1509.03580v1",
    "pdf_link": "http://arxiv.org/pdf/1509.03580v1"
  },
  {
    "api_id": 209,
    "title": "DeepSat - A Learning framework for Satellite Imagery",
    "summary": "Satellite image classification is a challenging problem that lies at the\ncrossroads of remote sensing, computer vision, and machine learning. Due to the\nhigh variability inherent in satellite data, most of the current object\nclassification approaches are not suitable for handling satellite datasets. The\nprogress of satellite image analytics has also been inhibited by the lack of a\nsingle labeled high-resolution dataset with multiple class labels. The\ncontributions of this paper are twofold - (1) first, we present two new\nsatellite datasets called SAT-4 and SAT-6, and (2) then, we propose a\nclassification framework that extracts features from an input image, normalizes\nthem and feeds the normalized feature vectors to a Deep Belief Network for\nclassification. On the SAT-4 dataset, our best network produces a\nclassification accuracy of 97.95% and outperforms three state-of-the-art object\nrecognition algorithms, namely - Deep Belief Networks, Convolutional Neural\nNetworks and Stacked Denoising Autoencoders by ~11%. On SAT-6, it produces a\nclassification accuracy of 93.9% and outperforms the other algorithms by ~15%.\nComparative studies with a Random Forest classifier show the advantage of an\nunsupervised learning approach over traditional supervised learning techniques.\nA statistical analysis based on Distribution Separability Criterion and\nIntrinsic Dimensionality Estimation substantiates the effectiveness of our\napproach in learning better representations for satellite imagery.",
    "published": "2015-09-11T18:32:51Z",
    "updated": "2015-09-11T18:32:51Z",
    "authors": [
      "Saikat Basu",
      "Sangram Ganguly",
      "Supratik Mukhopadhyay",
      "Robert DiBiano",
      "Manohar Karki",
      "Ramakrishna Nemani"
    ],
    "link": "http://arxiv.org/abs/1509.03602v1",
    "pdf_link": "http://arxiv.org/pdf/1509.03602v1"
  },
  {
    "api_id": 210,
    "title": "A Novel Pre-processing Scheme to Improve the Prediction of Sand Fraction\n  from Seismic Attributes using Neural Networks",
    "summary": "This paper presents a novel pre-processing scheme to improve the prediction\nof sand fraction from multiple seismic attributes such as seismic impedance,\namplitude and frequency using machine learning and information filtering. The\navailable well logs along with the 3-D seismic data have been used to benchmark\nthe proposed pre-processing stage using a methodology which primarily consists\nof three steps: pre-processing, training and post-processing. An Artificial\nNeural Network (ANN) with conjugate-gradient learning algorithm has been used\nto model the sand fraction. The available sand fraction data from the high\nresolution well logs has far more information content than the low resolution\nseismic attributes. Therefore, regularization schemes based on Fourier\nTransform (FT), Wavelet Decomposition (WD) and Empirical Mode Decomposition\n(EMD) have been proposed to shape the high resolution sand fraction data for\neffective machine learning. The input data sets have been segregated into\ntraining, testing and validation sets. The test results are primarily used to\ncheck different network structures and activation function performances. Once\nthe network passes the testing phase with an acceptable performance in terms of\nthe selected evaluators, the validation phase follows. In the validation stage,\nthe prediction model is tested against unseen data. The network yielding\nsatisfactory performance in the validation stage is used to predict\nlithological properties from seismic attributes throughout a given volume.\nFinally, a post-processing scheme using 3-D spatial filtering is implemented\nfor smoothing the sand fraction in the volume. Prediction of lithological\nproperties using this framework is helpful for Reservoir Characterization.",
    "published": "2015-09-23T17:15:21Z",
    "updated": "2015-09-23T17:15:21Z",
    "authors": [
      "Soumi Chaki",
      "Aurobinda Routray",
      "William K. Mohanty"
    ],
    "link": "http://arxiv.org/abs/1509.07065v1",
    "pdf_link": "http://arxiv.org/pdf/1509.07065v1"
  },
  {
    "api_id": 211,
    "title": "3D Scan Registration using Curvelet Features in Planetary Environments",
    "summary": "Topographic mapping in planetary environments relies on accurate 3D scan\nregistration methods. However, most global registration algorithms relying on\nfeatures such as FPFH and Harris-3D show poor alignment accuracy in these\nsettings due to the poor structure of the Mars-like terrain and variable\nresolution, occluded, sparse range data that is hard to register without some\na-priori knowledge of the environment. In this paper, we propose an alternative\napproach to 3D scan registration using the curvelet transform that performs\nmulti-resolution geometric analysis to obtain a set of coefficients indexed by\nscale (coarsest to finest), angle and spatial position. Features are detected\nin the curvelet domain to take advantage of the directional selectivity of the\ntransform. A descriptor is computed for each feature by calculating the 3D\nspatial histogram of the image gradients, and nearest neighbor based matching\nis used to calculate the feature correspondences. Correspondence rejection\nusing Random Sample Consensus identifies inliers, and a locally optimal\nSingular Value Decomposition-based estimation of the rigid-body transformation\naligns the laser scans given the re-projected correspondences in the metric\nspace. Experimental results on a publicly available data-set of planetary\nanalogue indoor facility, as well as simulated and real-world scans from Neptec\nDesign Group's IVIGMS 3D laser rangefinder at the outdoor CSA Mars yard\ndemonstrates improved performance over existing methods in the challenging\nsparse Mars-like terrain.",
    "published": "2015-09-23T17:51:03Z",
    "updated": "2015-09-23T17:51:03Z",
    "authors": [
      "Siddhant Ahuja",
      "Peter Iles",
      "Steven L. Waslander"
    ],
    "link": "http://arxiv.org/abs/1509.07075v1",
    "pdf_link": "http://arxiv.org/pdf/1509.07075v1"
  },
  {
    "api_id": 212,
    "title": "Discriminative Map Retrieval Using View-Dependent Map Descriptor",
    "summary": "Map retrieval, the problem of similarity search over a large collection of 2D\npointset maps previously built by mobile robots, is crucial for autonomous\nnavigation in indoor and outdoor environments. Bag-of-words (BoW) methods\nconstitute a popular approach to map retrieval; however, these methods have\nextremely limited descriptive ability because they ignore the spatial layout\ninformation of the local features. The main contribution of this paper is an\nextension of the bag-of-words map retrieval method to enable the use of spatial\ninformation from local features. Our strategy is to explicitly model a unique\nviewpoint of an input local map; the pose of the local feature is defined with\nrespect to this unique viewpoint, and can be viewed as an additional invariant\nfeature for discriminative map retrieval. Specifically, we wish to determine a\nunique viewpoint that is invariant to moving objects, clutter, occlusions, and\nactual viewpoints. Hence, we perform scene parsing to analyze the scene\nstructure, and consider the \"center\" of the scene structure to be the unique\nviewpoint. Our scene parsing is based on a Manhattan world grammar that imposes\na quasi-Manhattan world constraint to enable the robust detection of a scene\nstructure that is invariant to clutter and moving objects. Experimental results\nusing the publicly available radish dataset validate the efficacy of the\nproposed approach.",
    "published": "2015-09-25T08:02:19Z",
    "updated": "2015-09-25T08:02:19Z",
    "authors": [
      "Enfu Liu",
      "Kanji Tanaka"
    ],
    "link": "http://arxiv.org/abs/1509.07615v1",
    "pdf_link": "http://arxiv.org/pdf/1509.07615v1"
  },
  {
    "api_id": 213,
    "title": "Computational Intelligence Challenges and Applications on Large-Scale\n  Astronomical Time Series Databases",
    "summary": "Time-domain astronomy (TDA) is facing a paradigm shift caused by the\nexponential growth of the sample size, data complexity and data generation\nrates of new astronomical sky surveys. For example, the Large Synoptic Survey\nTelescope (LSST), which will begin operations in northern Chile in 2022, will\ngenerate a nearly 150 Petabyte imaging dataset of the southern hemisphere sky.\nThe LSST will stream data at rates of 2 Terabytes per hour, effectively\ncapturing an unprecedented movie of the sky. The LSST is expected not only to\nimprove our understanding of time-varying astrophysical objects, but also to\nreveal a plethora of yet unknown faint and fast-varying phenomena. To cope with\na change of paradigm to data-driven astronomy, the fields of astroinformatics\nand astrostatistics have been created recently. The new data-oriented paradigms\nfor astronomy combine statistics, data mining, knowledge discovery, machine\nlearning and computational intelligence, in order to provide the automated and\nrobust methods needed for the rapid detection and classification of known\nastrophysical objects as well as the unsupervised characterization of novel\nphenomena. In this article we present an overview of machine learning and\ncomputational intelligence applications to TDA. Future big data challenges and\nnew lines of research in TDA, focusing on the LSST, are identified and\ndiscussed from the viewpoint of computational intelligence/machine learning.\nInterdisciplinary collaboration will be required to cope with the challenges\nposed by the deluge of astronomical data coming from the LSST.",
    "published": "2015-09-25T18:24:48Z",
    "updated": "2015-09-25T18:24:48Z",
    "authors": [
      "Pablo Huijse",
      "Pablo A. Estevez",
      "Pavlos Protopapas",
      "Jose C. Principe",
      "Pablo Zegers"
    ],
    "link": "http://arxiv.org/abs/1509.07823v1",
    "pdf_link": "http://arxiv.org/pdf/1509.07823v1"
  },
  {
    "api_id": 214,
    "title": "Feature Selection for classification of hyperspectral data by minimizing\n  a tight bound on the VC dimension",
    "summary": "Hyperspectral data consists of large number of features which require\nsophisticated analysis to be extracted. A popular approach to reduce\ncomputational cost, facilitate information representation and accelerate\nknowledge discovery is to eliminate bands that do not improve the\nclassification and analysis methods being applied. In particular, algorithms\nthat perform band elimination should be designed to take advantage of the\nspecifics of the classification method being used. This paper employs a\nrecently proposed filter-feature-selection algorithm based on minimizing a\ntight bound on the VC dimension. We have successfully applied this algorithm to\ndetermine a reasonable subset of bands without any user-defined stopping\ncriteria on widely used hyperspectral images and demonstrate that this method\noutperforms state-of-the-art methods in terms of both sparsity of feature set\nas well as accuracy of classification.\\end{abstract}",
    "published": "2015-09-27T17:36:18Z",
    "updated": "2015-09-27T17:36:18Z",
    "authors": [
      "Phool Preet",
      "Sanjit Singh Batra",
      " Jayadeva"
    ],
    "link": "http://arxiv.org/abs/1509.08112v1",
    "pdf_link": "http://arxiv.org/pdf/1509.08112v1"
  },
  {
    "api_id": 215,
    "title": "Reasoning in complex environments with the SelectScript declarative\n  language",
    "summary": "SelectScript is an extendable, adaptable, and declarative domain-specific\nlanguage aimed at information retrieval from simulation environments and\nrobotic world models in an SQL-like manner. In this work we have extended the\nlanguage in two directions. First, we have implemented hierarchical queries;\nsecond, we improve efficiency enabling manual design space exploration on\ndifferent \"search\" strategies. We demonstrate the applicability of such\nextensions in two application problems; the basic language concepts are\nexplained by solving the classical problem of the Towers of Hanoi and then a\ncommon path planning problem in a complex 3D environment is implemented.",
    "published": "2015-08-17T21:26:39Z",
    "updated": "2015-10-04T15:53:29Z",
    "authors": [
      "André Dietrich",
      "Sebastian Zug",
      "Luigi Nardi",
      "Jörg Kaiser"
    ],
    "link": "http://arxiv.org/abs/1508.04159v2",
    "pdf_link": "http://arxiv.org/pdf/1508.04159v2"
  },
  {
    "api_id": 216,
    "title": "Simultaneously sparse and low-rank abundance matrix estimation for\n  hyperspectral image unmixing",
    "summary": "In a plethora of applications dealing with inverse problems, e.g. in image\nprocessing, social networks, compressive sensing, biological data processing\netc., the signal of interest is known to be structured in several ways at the\nsame time. This premise has recently guided the research to the innovative and\nmeaningful idea of imposing multiple constraints on the parameters involved in\nthe problem under study. For instance, when dealing with problems whose\nparameters form sparse and low-rank matrices, the adoption of suitably combined\nconstraints imposing sparsity and low-rankness, is expected to yield\nsubstantially enhanced estimation results. In this paper, we address the\nspectral unmixing problem in hyperspectral images. Specifically, two novel\nunmixing algorithms are introduced, in an attempt to exploit both spatial\ncorrelation and sparse representation of pixels lying in homogeneous regions of\nhyperspectral images. To this end, a novel convex mixed penalty term is first\ndefined consisting of the sum of the weighted $\\ell_1$ and the weighted nuclear\nnorm of the abundance matrix corresponding to a small area of the image\ndetermined by a sliding square window. This penalty term is then used to\nregularize a conventional quadratic cost function and impose simultaneously\nsparsity and row-rankness on the abundance matrix. The resulting regularized\ncost function is minimized by a) an incremental proximal sparse and low-rank\nunmixing algorithm and b) an algorithm based on the alternating minimization\nmethod of multipliers (ADMM). The effectiveness of the proposed algorithms is\nillustrated in experiments conducted both on simulated and real data.",
    "published": "2015-04-07T08:23:45Z",
    "updated": "2015-10-14T16:53:41Z",
    "authors": [
      "Paris Giampouras",
      "Konstantinos Themelis",
      "Athanasios Rontogiannis",
      "Konstantinos Koutroumbas"
    ],
    "link": "http://arxiv.org/abs/1504.01515v2",
    "pdf_link": "http://arxiv.org/pdf/1504.01515v2"
  },
  {
    "api_id": 217,
    "title": "Dynamical spectral unmixing of multitemporal hyperspectral images",
    "summary": "In this paper, we consider the problem of unmixing a time series of\nhyperspectral images. We propose a dynamical model based on linear mixing\nprocesses at each time instant. The spectral signatures and fractional\nabundances of the pure materials in the scene are seen as latent variables, and\nassumed to follow a general dynamical structure. Based on a simplified version\nof this model, we derive an efficient spectral unmixing algorithm to estimate\nthe latent variables by performing alternating minimizations. The performance\nof the proposed approach is demonstrated on synthetic and real multitemporal\nhyperspectral images.",
    "published": "2015-10-14T18:51:51Z",
    "updated": "2015-10-14T18:51:51Z",
    "authors": [
      "Simon Henrot",
      "Jocelyn Chanussot",
      "Christian Jutten"
    ],
    "link": "http://arxiv.org/abs/1510.04238v1",
    "pdf_link": "http://arxiv.org/pdf/1510.04238v1"
  },
  {
    "api_id": 218,
    "title": "Accurate Vision-based Vehicle Localization using Satellite Imagery",
    "summary": "We propose a method for accurately localizing ground vehicles with the aid of\nsatellite imagery. Our approach takes a ground image as input, and outputs the\nlocation from which it was taken on a georeferenced satellite image. We perform\nvisual localization by estimating the co-occurrence probabilities between the\nground and satellite images based on a ground-satellite feature dictionary. The\nmethod is able to estimate likelihoods over arbitrary locations without the\nneed for a dense ground image database. We present a ranking-loss based\nalgorithm that learns location-discriminative feature projection matrices that\nresult in further improvements in accuracy. We evaluate our method on the\nMalaga and KITTI public datasets and demonstrate significant improvements over\na baseline that performs exhaustive search.",
    "published": "2015-10-30T17:35:23Z",
    "updated": "2015-10-30T17:35:23Z",
    "authors": [
      "Hang Chu",
      "Hongyuan Mei",
      "Mohit Bansal",
      "Matthew R. Walter"
    ],
    "link": "http://arxiv.org/abs/1510.09171v1",
    "pdf_link": "http://arxiv.org/pdf/1510.09171v1"
  },
  {
    "api_id": 219,
    "title": "Estimating Target Signatures with Diverse Density",
    "summary": "Hyperspectral target detection algorithms rely on knowing the desired target\nsignature in advance. However, obtaining an effective target signature can be\ndifficult; signatures obtained from laboratory measurements or\nhand-spectrometers in the field may not transfer to airborne imagery\neffectively. One approach to dealing with this difficulty is to learn an\neffective target signature from training data. An approach for learning target\nsignatures from training data is presented. The proposed approach addresses\nuncertainty and imprecision in groundtruth in the training data using a\nmultiple instance learning, diverse density (DD) based objective function.\nAfter learning the target signature given data with uncertain and imprecise\ngroundtruth, target detection can be applied on test data. Results are shown on\nsimulated and real data.",
    "published": "2015-10-30T18:26:51Z",
    "updated": "2015-10-30T18:26:51Z",
    "authors": [
      "Taylor Glenn",
      "Alina Zare"
    ],
    "link": "http://arxiv.org/abs/1510.09184v1",
    "pdf_link": "http://arxiv.org/pdf/1510.09184v1"
  },
  {
    "api_id": 220,
    "title": "Optimized Mission Planning for Planetary Exploration Rovers",
    "summary": "The exploration of planetary surfaces is predominately unmanned, calling for\na landing vehicle and an autonomous and/or teleoperated rover. Artificial\nintelligence and machine learning techniques can be leveraged for better\nmission planning. This paper describes the coordinated use of both global\nnavigation and metaheuristic optimization algorithms to plan the safe,\nefficient missions. The aim is to determine the least-cost combination of a\nsafe landing zone (LZ) and global path plan, where avoiding terrain hazards for\nthe lander and rover minimizes cost. Computer vision methods were used to\nidentify surface craters, mounds, and rocks as obstacles. Multiple search\nmethods were investigated for the rover global path plan. Several combinatorial\noptimization algorithms were implemented to select the shortest distance path\nas the preferred mission plan. Simulations were run for a sample Google Lunar X\nPrize mission. The result of this study is an optimization scheme that path\nplans with the A* search method, and uses simulated annealing to select ideal\nLZ-path- goal combination for the mission. Simulation results show the methods\nare effective in minimizing the risk of hazards and increasing efficiency. This\npaper is specific to a lunar mission, but the resulting architecture may be\napplied to a large variety of planetary missions and rovers.",
    "published": "2015-11-01T01:11:30Z",
    "updated": "2015-11-01T01:11:30Z",
    "authors": [
      "Alexander Lavin"
    ],
    "link": "http://arxiv.org/abs/1511.00195v1",
    "pdf_link": "http://arxiv.org/pdf/1511.00195v1"
  },
  {
    "api_id": 221,
    "title": "A Pareto Optimal D* Search Algorithm for Multiobjective Path Planning",
    "summary": "Path planning is one of the most vital elements of mobile robotics, providing\nthe agent with a collision-free route through the workspace. The global path\nplan can be calculated with a variety of informed search algorithms, most\nnotably the A* search method, guaranteed to deliver a complete and optimal\nsolution that minimizes the path cost. D* is widely used for its dynamic\nreplanning capabilities. Path planning optimization typically looks to minimize\nthe distance traversed from start to goal, but many mobile robot applications\ncall for additional path planning objectives, presenting a multiobjective\noptimization (MOO) problem. Common search algorithms, e.g. A* and D*, are not\nwell suited for MOO problems, yielding suboptimal results. The search algorithm\npresented in this paper is designed for optimal MOO path planning. The\nalgorithm incorporates Pareto optimality into D*, and is thus named D*-PO.\nNon-dominated solution paths are guaranteed by calculating the Pareto front at\neach search step. Simulations were run to model a planetary exploration rover\nin a Mars environment, with five path costs. The results show the new, Pareto\noptimal D*-PO outperforms the traditional A* and D* algorithms for MOO path\nplanning.",
    "published": "2015-11-03T05:48:26Z",
    "updated": "2015-11-03T05:48:26Z",
    "authors": [
      "Alexander Lavin"
    ],
    "link": "http://arxiv.org/abs/1511.00787v1",
    "pdf_link": "http://arxiv.org/pdf/1511.00787v1"
  },
  {
    "api_id": 222,
    "title": "Spectral-Spatial Classification of Hyperspectral Image Using\n  Autoencoders",
    "summary": "Hyperspectral image (HSI) classification is a hot topic in the remote sensing\ncommunity. This paper proposes a new framework of spectral-spatial feature\nextraction for HSI classification, in which for the first time the concept of\ndeep learning is introduced. Specifically, the model of autoencoder is\nexploited in our framework to extract various kinds of features. First we\nverify the eligibility of autoencoder by following classical spectral\ninformation based classification and use autoencoders with different depth to\nclassify hyperspectral image. Further in the proposed framework, we combine PCA\non spectral dimension and autoencoder on the other two spatial dimensions to\nextract spectral-spatial information for classification. The experimental\nresults show that this framework achieves the highest classification accuracy\namong all methods, and outperforms classical classifiers such as SVM and\nPCA-based SVM.",
    "published": "2015-11-09T22:29:13Z",
    "updated": "2015-11-09T22:29:13Z",
    "authors": [
      "Zhouhan Lin",
      "Yushi Chen",
      "Xing Zhao",
      "Gang Wang"
    ],
    "link": "http://arxiv.org/abs/1511.02916v1",
    "pdf_link": "http://arxiv.org/pdf/1511.02916v1"
  },
  {
    "api_id": 223,
    "title": "SIDRA: a blind algorithm for signal detection in photometric surveys",
    "summary": "We present the Signal Detection using Random-Forest Algorithm (SIDRA). SIDRA\nis a detection and classification algorithm based on the Machine Learning\ntechnique (Random Forest). The goal of this paper is to show the power of SIDRA\nfor quick and accurate signal detection and classification. We first diagnose\nthe power of the method with simulated light curves and try it on a subset of\nthe Kepler space mission catalogue. We use five classes of simulated light\ncurves (CONSTANT, TRANSIT, VARIABLE, MLENS and EB for constant light curves,\ntransiting exoplanet, variable, microlensing events and eclipsing binaries,\nrespectively) to analyse the power of the method. The algorithm uses four\nfeatures in order to classify the light curves. The training sample contains\n5000 light curves (1000 from each class) and 50000 random light curves for\ntesting. The total SIDRA success ratio is $\\geq 90\\%$. Furthermore, the success\nratio reaches 95 - 100$\\%$ for the CONSTANT, VARIABLE, EB, and MLENS classes\nand 92$\\%$ for the TRANSIT class with a decision probability of 60$\\%$. Because\nthe TRANSIT class is the one which fails the most, we run a simultaneous fit\nusing SIDRA and a Box Least Square (BLS) based algorithm for searching for\ntransiting exoplanets. As a result, our algorithm detects 7.5$\\%$ more planets\nthan a classic BLS algorithm, with better results for lower signal-to-noise\nlight curves. SIDRA succeeds to catch 98$\\%$ of the planet candidates in the\nKepler sample and fails for 7$\\%$ of the false alarms subset. SIDRA promises to\nbe useful for developing a detection algorithm and/or classifier for large\nphotometric surveys such as TESS and PLATO exoplanet future space missions.",
    "published": "2015-11-11T11:14:53Z",
    "updated": "2015-11-11T11:14:53Z",
    "authors": [
      "D. Mislis",
      "E. Bachelet",
      "K. A. Alsubai",
      "D. M. Bramich",
      "N. Parley"
    ],
    "link": "http://arxiv.org/abs/1511.03456v1",
    "pdf_link": "http://arxiv.org/pdf/1511.03456v1"
  },
  {
    "api_id": 224,
    "title": "Implementation and comparative quantitative assessment of different\n  multispectral image pansharpening approches",
    "summary": "In remote sensing, images acquired by various earth observation satellites\ntend to have either a high spatial and low spectral resolution or vice versa.\nPansharpening is a technique which aims to improve spatial resolution of\nmultispectral image. The challenges involve in the pansharpening are not only\nto improve the spatial resolution but also to preserve spectral quality of the\nmultispectral image. In this paper, various pansharpening algorithms are\ndiscussed and classified based on approaches they have adopted. Using MATLAB\nimage processing toolbox, several state-of-art pan-sharpening algorithms are\nimplemented. Quality of pansharpened images are assessed visually and\nquantitatively. Correlation coefficient (CC), Root mean square error (RMSE),\nRelative average spectral error (RASE) and Universal quality index (Q) indices\nare used to easure spectral quality while to spatial-CC (SCC) quantitative\nparameter is used for spatial quality measurement. Finally, the paper is\nconcluded with useful remarks.",
    "published": "2015-11-15T04:48:17Z",
    "updated": "2015-11-15T04:48:17Z",
    "authors": [
      "Shailesh Panchal",
      "Rajesh Thakker"
    ],
    "link": "http://arxiv.org/abs/1511.04659v1",
    "pdf_link": "http://arxiv.org/pdf/1511.04659v1"
  },
  {
    "api_id": 225,
    "title": "Line-Node Dirac Semimetal and Topological Insulating Phase in\n  Noncentrosymmetric Pnictides CaAgX (X = P, As)",
    "summary": "Two noncentrosymmetric ternary pnictides, CaAgP and CaAgAs, are reported as\ntopological line-node semimetals protected solely by mirror-reflection\nsymmetry. The band gap vanishes on a circle in momentum space, and surface\nstates emerge within the circle. Extending this study to spin-orbit coupled\nsystems reveals that, compared with CaAgP, a substantial band gap is induced in\nCaAgAs by large spin-orbit interaction. The resulting states are a topological\ninsulator, in which the Z2 topological invariant is given by 1; 000. To clarify\nthe Z2 topological invariants for time-reversal-invariant systems without\nspatial-inversion symmetry, we introduce an alternative way to calculate the\ninvariants characterizing a line node and topological insulator for\nmirror-reflection-invariant systems.",
    "published": "2015-10-01T12:37:58Z",
    "updated": "2015-11-19T14:49:24Z",
    "authors": [
      "Ai Yamakage",
      "Youichi Yamakawa",
      "Yukio Tanaka",
      "Yoshihiko Okamoto"
    ],
    "link": "http://arxiv.org/abs/1510.00202v3",
    "pdf_link": "http://arxiv.org/pdf/1510.00202v3"
  },
  {
    "api_id": 226,
    "title": "Identifying the Absorption Bump with Deep Learning",
    "summary": "The pervasive interstellar dust grains provide significant insights to\nunderstand the formation and evolution of the stars, planetary systems, and the\ngalaxies, and may harbor the building blocks of life. One of the most effective\nway to analyze the dust is via their interaction with the light from background\nsources. The observed extinction curves and spectral features carry the size\nand composition information of dust. The broad absorption bump at 2175 Angstrom\nis the most prominent feature in the extinction curves. Traditionally,\nstatistical methods are applied to detect the existence of the absorption bump.\nThese methods require heavy preprocessing and the co-existence of other\nreference features to alleviate the influence from the noises. In this paper,\nwe apply Deep Learning techniques to detect the broad absorption bump. We\ndemonstrate the key steps for training the selected models and their results.\nThe success of Deep Learning based method inspires us to generalize a common\nmethodology for broader science discovery problems. We present our on-going\nwork to build the DeepDis system for such kind of applications.",
    "published": "2015-11-17T22:27:05Z",
    "updated": "2015-11-20T14:20:46Z",
    "authors": [
      "Min Li",
      "Sudeep Gaddam",
      "Xiaolin Li",
      "Yinan Zhao",
      "Jingzhe Ma",
      "Jian Ge"
    ],
    "link": "http://arxiv.org/abs/1511.05607v2",
    "pdf_link": "http://arxiv.org/pdf/1511.05607v2"
  },
  {
    "api_id": 227,
    "title": "Unsupervised Deep Feature Extraction for Remote Sensing Image\n  Classification",
    "summary": "This paper introduces the use of single layer and deep convolutional networks\nfor remote sensing data analysis. Direct application to multi- and\nhyper-spectral imagery of supervised (shallow or deep) convolutional networks\nis very challenging given the high input data dimensionality and the relatively\nsmall amount of available labeled data. Therefore, we propose the use of greedy\nlayer-wise unsupervised pre-training coupled with a highly efficient algorithm\nfor unsupervised learning of sparse features. The algorithm is rooted on sparse\nrepresentations and enforces both population and lifetime sparsity of the\nextracted features, simultaneously. We successfully illustrate the expressive\npower of the extracted representations in several scenarios: classification of\naerial scenes, as well as land-use classification in very high resolution\n(VHR), or land-cover classification from multi- and hyper-spectral images. The\nproposed algorithm clearly outperforms standard Principal Component Analysis\n(PCA) and its kernel counterpart (kPCA), as well as current state-of-the-art\nalgorithms of aerial classification, while being extremely computationally\nefficient at learning representations of data. Results show that single layer\nconvolutional networks can extract powerful discriminative features only when\nthe receptive field accounts for neighboring pixels, and are preferred when the\nclassification requires high resolution and detailed results. However, deep\narchitectures significantly outperform single layers variants, capturing\nincreasing levels of abstraction and complexity throughout the feature\nhierarchy.",
    "published": "2015-11-25T17:36:28Z",
    "updated": "2015-11-25T17:36:28Z",
    "authors": [
      "Adriana Romero",
      "Carlo Gatta",
      "Gustau Camps-Valls"
    ],
    "link": "http://arxiv.org/abs/1511.08131v1",
    "pdf_link": "http://arxiv.org/pdf/1511.08131v1"
  },
  {
    "api_id": 228,
    "title": "Deep Neural Network for Real-Time Autonomous Indoor Navigation",
    "summary": "Autonomous indoor navigation of Micro Aerial Vehicles (MAVs) possesses many\nchallenges. One main reason is that GPS has limited precision in indoor\nenvironments. The additional fact that MAVs are not able to carry heavy weight\nor power consuming sensors, such as range finders, makes indoor autonomous\nnavigation a challenging task. In this paper, we propose a practical system in\nwhich a quadcopter autonomously navigates indoors and finds a specific target,\ni.e., a book bag, by using a single camera. A deep learning model,\nConvolutional Neural Network (ConvNet), is used to learn a controller strategy\nthat mimics an expert pilot's choice of action. We show our system's\nperformance through real-time experiments in diverse indoor locations. To\nunderstand more about our trained network, we use several visualization\ntechniques.",
    "published": "2015-11-15T07:35:10Z",
    "updated": "2015-11-26T07:52:46Z",
    "authors": [
      "Dong Ki Kim",
      "Tsuhan Chen"
    ],
    "link": "http://arxiv.org/abs/1511.04668v2",
    "pdf_link": "http://arxiv.org/pdf/1511.04668v2"
  },
  {
    "api_id": 229,
    "title": "Compressive hyperspectral imaging via adaptive sampling and dictionary\n  learning",
    "summary": "In this paper, we propose a new sampling strategy for hyperspectral signals\nthat is based on dictionary learning and singular value decomposition (SVD).\nSpecifically, we first learn a sparsifying dictionary from training spectral\ndata using dictionary learning. We then perform an SVD on the dictionary and\nuse the first few left singular vectors as the rows of the measurement matrix\nto obtain the compressive measurements for reconstruction. The proposed method\nprovides significant improvement over the conventional compressive sensing\napproaches. The reconstruction performance is further improved by\nreconditioning the sensing matrix using matrix balancing. We also demonstrate\nthat the combination of dictionary learning and SVD is robust by applying them\nto different datasets.",
    "published": "2015-12-02T23:13:04Z",
    "updated": "2015-12-02T23:13:04Z",
    "authors": [
      "Mingrui Yang",
      "Frank de Hoog",
      "Yuqi Fan",
      "Wen Hu"
    ],
    "link": "http://arxiv.org/abs/1512.00901v1",
    "pdf_link": "http://arxiv.org/pdf/1512.00901v1"
  },
  {
    "api_id": 230,
    "title": "Image segmentation of cross-country scenes captured in IR spectrum",
    "summary": "Computer vision has become a major source of information for autonomous\nnavigation of robots of various types, self-driving cars, military robots and\nmars/lunar rovers are some examples. Nevertheless, the majority of methods\nfocus on analysing images captured in visible spectrum. In this manuscript we\nelaborate on the problem of segmenting cross-country scenes captured in IR\nspectrum. For this purpose we proposed employing salient features. Salient\nfeatures are robust to variations in scale, brightness and view angle. We\nsuggest the Speeded-Up Robust Features as a basis for our salient features for\na number of reasons discussed in the paper. We also provide a comparison of two\nSURF implementations. The SURF features are extracted from images of different\nterrain types. For every feature we estimate a terrain class membership\nfunction. The membership values are obtained by means of either the multi-layer\nperceptron or nearest neighbours. The features' class membership values and\ntheir spatial positions are then applied to estimate class membership values\nfor all pixels in the image. To decrease the effect of segmentation blinking\nthat is caused by rapid switching between different terrain types and to speed\nup segmentation, we are tracking camera position and predict features'\npositions. The comparison of the multi-layer perception and the nearest\nneighbour classifiers is presented in the paper. The error rate of the terrain\nsegmentation using the nearest neighbours obtained on the testing set is\n16.6+-9.17%.",
    "published": "2016-04-08T20:14:46Z",
    "updated": "2016-04-08T20:14:46Z",
    "authors": [
      "Artem Lenskiy"
    ],
    "link": "http://arxiv.org/abs/1604.02469v1",
    "pdf_link": "http://arxiv.org/pdf/1604.02469v1"
  },
  {
    "api_id": 231,
    "title": "Application of Multifractal Analysis to Segmentation of Water Bodies in\n  Optical and Synthetic Aperture Radar Satellite Images",
    "summary": "A method for segmenting water bodies in optical and synthetic aperture radar\n(SAR) satellite images is proposed. It makes use of the textural features of\nthe different regions in the image for segmentation. The method consists in a\nmultiscale analysis of the images, which allows us to study the images\nregularity both, locally and globally. As results of the analysis, coarse\nmultifractal spectra of studied images and a group of images that associates\neach position (pixel) with its corresponding value of local regularity (or\nsingularity) spectrum are obtained. Thresholds are then applied to the\nmultifractal spectra of the images for the classification. These thresholds are\nselected after studying the characteristics of the spectra under the assumption\nthat water bodies have larger local regularity than other soil types.\nClassifications obtained by the multifractal method are compared quantitatively\nwith those obtained by neural networks trained to classify the pixels of the\nimages in covered against uncovered by water. In optical images, the\nclassifications are also compared with those derived using the so-called\nNormalized Differential Water Index (NDWI).",
    "published": "2016-04-08T21:24:15Z",
    "updated": "2016-04-08T21:24:15Z",
    "authors": [
      "Victor Manuel San Martin",
      "Alejandra Figliola"
    ],
    "link": "http://arxiv.org/abs/1604.02488v1",
    "pdf_link": "http://arxiv.org/pdf/1604.02488v1"
  },
  {
    "api_id": 232,
    "title": "Analysis of a Planetary Scale Scientific Collaboration Dataset Reveals\n  Novel Patterns",
    "summary": "Scientific collaboration networks are an important component of scientific\noutput and contribute significantly to expanding our knowledge and to the\neconomy and gross domestic product of nations. Here we examine a dataset from\nthe Mendeley scientific collaboration network. We analyze this data using a\ncombination of machine learning techniques and dynamical models. We find\ninteresting clusters of countries with different characteristics of\ncollaboration. Some of these clusters are dominated by developed countries that\nhave higher number of self connections compared with connections to other\ncountries. Another cluster is dominated by impoverished nations that have\nmostly connections and collaborations with other countries but fewer self\nconnections. We also propose a complex systems dynamical model that explains\nthese characteristics. Our model explains how the scientific collaboration\nnetworks of impoverished and developing nations change over time. We also find\ninteresting patterns in the behaviour of countries that may reflect past\nforeign policies and contemporary geopolitics. Our model and analysis gives\ninsights and guidelines into how scientific development of developing countries\ncan be guided. This is intimately related to fostering economic development of\nimpoverished nations and creating a richer and more prosperous society.",
    "published": "2015-09-24T11:10:01Z",
    "updated": "2016-04-09T13:45:48Z",
    "authors": [
      "Soumya Banerjee"
    ],
    "link": "http://arxiv.org/abs/1509.07313v2",
    "pdf_link": "http://arxiv.org/pdf/1509.07313v2"
  },
  {
    "api_id": 233,
    "title": "Application of the Second-Order Statistics for Estimation of the Pure\n  Spectra of Individual Components from the Visible Hyperspectral Images of\n  Their Mixture",
    "summary": "The second-order statistics (SOS) can be applied in estimation of the pure\nspectra of chemical components from the spectrum of their mixture, when SOS\nseems to be good at estimation of spectral patterns, but their peak directions\nare opposite in some cases. In this paper, one method for judgment of the peak\ndirection of the pure spectra was proposed, where the base line of the pure\nspectra was drawn by using their histograms and the peak directions were chosen\nso as to make all of the pure spectra located upwards over the base line.\nResults of the SOS analysis on the visible hyperspectral images of the mixture\ncomposed of two or three chemical components showed that the present method\noffered the reasonable shape and direction of the pure spectra of its\ncomponents.",
    "published": "2016-04-12T01:23:40Z",
    "updated": "2016-04-12T01:23:40Z",
    "authors": [
      "Sung-Ho Jong",
      "Yong-U Ri",
      "Kye-Ryong Sin"
    ],
    "link": "http://arxiv.org/abs/1604.03193v1",
    "pdf_link": "http://arxiv.org/pdf/1604.03193v1"
  },
  {
    "api_id": 234,
    "title": "Removing Clouds and Recovering Ground Observations in Satellite Image\n  Sequences via Temporally Contiguous Robust Matrix Completion",
    "summary": "We consider the problem of removing and replacing clouds in satellite image\nsequences, which has a wide range of applications in remote sensing. Our\napproach first detects and removes the cloud-contaminated part of the image\nsequences. It then recovers the missing scenes from the clean parts using the\nproposed \"TECROMAC\" (TEmporally Contiguous RObust MAtrix Completion) objective.\nThe objective function balances temporal smoothness with a low rank solution\nwhile staying close to the original observations. The matrix whose the rows are\npixels and columnsare days corresponding to the image, has low-rank because the\npixels reflect land-types such as vegetation, roads and lakes and there are\nrelatively few variations as a result. We provide efficient optimization\nalgorithms for TECROMAC, so we can exploit images containing millions of\npixels. Empirical results on real satellite image sequences, as well as\nsimulated data, demonstrate that our approach is able to recover underlying\nimages from heavily cloud-contaminated observations.",
    "published": "2016-04-13T19:13:17Z",
    "updated": "2016-04-13T19:13:17Z",
    "authors": [
      "Jialei Wang",
      "Peder A. Olsen",
      "Andrew R. Conn",
      "Aurelie C. Lozano"
    ],
    "link": "http://arxiv.org/abs/1604.03915v1",
    "pdf_link": "http://arxiv.org/pdf/1604.03915v1"
  },
  {
    "api_id": 235,
    "title": "Unsupervised Nonlinear Spectral Unmixing based on a Multilinear Mixing\n  Model",
    "summary": "In the community of remote sensing, nonlinear mixing models have recently\nreceived particular attention in hyperspectral image processing. In this paper,\nwe present a novel nonlinear spectral unmixing method following the recent\nmultilinear mixing model of [1], which includes an infinite number of terms\nrelated to interactions between different endmembers. The proposed unmixing\nmethod is unsupervised in the sense that the endmembers are estimated jointly\nwith the abundances and other parameters of interest, i.e., the transition\nprobability of undergoing further interactions. Non-negativity and sum-to one\nconstraints are imposed on abundances while only nonnegativity is considered\nfor endmembers. The resulting unmixing problem is formulated as a constrained\nnonlinear optimization problem, which is solved by a block coordinate descent\nstrategy, consisting of updating the endmembers, abundances and transition\nprobability iteratively. The proposed method is evaluated and compared with\nlinear unmixing methods for synthetic and real hyperspectral datasets acquired\nby the AVIRIS sensor. The advantage of using non-linear unmixing as opposed to\nlinear unmixing is clearly shown in these examples.",
    "published": "2016-04-14T20:09:22Z",
    "updated": "2016-04-14T20:09:22Z",
    "authors": [
      "Qi Wei",
      "Marcus Chen",
      "Jean-Yves Tourneret",
      "Simon Godsill"
    ],
    "link": "http://arxiv.org/abs/1604.04293v1",
    "pdf_link": "http://arxiv.org/pdf/1604.04293v1"
  },
  {
    "api_id": 236,
    "title": "Correlation and variable importance in random forests",
    "summary": "This paper is about variable selection with the random forests algorithm in\npresence of correlated predictors. In high-dimensional regression or\nclassification frameworks, variable selection is a difficult task, that becomes\neven more challenging in the presence of highly correlated predictors. Firstly\nwe provide a theoretical study of the permutation importance measure for an\nadditive regression model. This allows us to describe how the correlation\nbetween predictors impacts the permutation importance. Our results motivate the\nuse of the Recursive Feature Elimination (RFE) algorithm for variable selection\nin this context. This algorithm recursively eliminates the variables using\npermutation importance measure as a ranking criterion. Next various simulation\nexperiments illustrate the efficiency of the RFE algorithm for selecting a\nsmall number of variables together with a good prediction error. Finally, this\nselection algorithm is tested on the Landsat Satellite data from the UCI\nMachine Learning Repository.",
    "published": "2013-10-21T20:47:05Z",
    "updated": "2016-04-18T16:38:48Z",
    "authors": [
      "Baptiste Gregorutti",
      "Bertrand Michel",
      "Philippe Saint-Pierre"
    ],
    "link": "http://arxiv.org/abs/1310.5726v5",
    "pdf_link": "http://arxiv.org/pdf/1310.5726v5"
  },
  {
    "api_id": 237,
    "title": "VLSI Extreme Learning Machine: A Design Space Exploration",
    "summary": "In this paper, we describe a compact low-power, high performance hardware\nimplementation of the extreme learning machine (ELM) for machine learning\napplications. Mismatch in current mirrors are used to perform the vector-matrix\nmultiplication that forms the first stage of this classifier and is the most\ncomputationally intensive. Both regression and classification (on UCI data\nsets) are demonstrated and a design space trade-off between speed, power and\naccuracy is explored. Our results indicate that for a wide set of problems,\n$\\sigma V_T$ in the range of $15-25$mV gives optimal results. An input weight\nmatrix rotation method to extend the input dimension and hidden layer size\nbeyond the physical limits imposed by the chip is also described. This allows\nus to overcome a major limit imposed on most hardware machine learners. The\nchip is implemented in a $0.35 \\mu$m CMOS process and occupies a die area of\naround 5 mm $\\times$ 5 mm. Operating from a $1$ V power supply, it achieves an\nenergy efficiency of $0.47$ pJ/MAC at a classification rate of $31.6$ kHz.",
    "published": "2016-05-03T02:52:51Z",
    "updated": "2016-05-03T02:52:51Z",
    "authors": [
      "Enyi Yao",
      "Arindam Basu"
    ],
    "link": "http://arxiv.org/abs/1605.00740v1",
    "pdf_link": "http://arxiv.org/pdf/1605.00740v1"
  },
  {
    "api_id": 238,
    "title": "Hierarchical Modeling of Multidimensional Data in Regularly Decomposed\n  Spaces: Applications in Image Analysis",
    "summary": "This last document is showing the gradual introduction of hierarchical\nmodeling techniques in image analysis. The first chapter is dealing with the\nfirst works carried out in the field of industrial applications of pattern\nrecognition. The second chapter is focusing on the usage of these techniques in\nsatellite imagery and on the development of a satellite data archiving system\nin the aim of using it in digital geography. The third chapter is about face\nrecognition based on planar image analysis and about the recognition of\npartially hidden patterns. The present publication is ending with the\ndescription of a future system of self-descriptive coding of still or moving\npictures in relation with the current video coding standards. As in the\nprevious documents, it will be found in annex algorithms targeted on image\nanalysis according two complementary approaches: - boundary-based approach for\nthe industrial applications of artificial vision; - region-based approach for\nsatellite image analysis.",
    "published": "2016-05-04T12:15:45Z",
    "updated": "2016-05-04T12:15:45Z",
    "authors": [
      "Olivier Guye"
    ],
    "link": "http://arxiv.org/abs/1605.01242v1",
    "pdf_link": "http://arxiv.org/pdf/1605.01242v1"
  },
  {
    "api_id": 239,
    "title": "Image-level Classification in Hyperspectral Images using Feature\n  Descriptors, with Application to Face Recognition",
    "summary": "In this paper, we proposed a novel pipeline for image-level classification in\nthe hyperspectral images. By doing this, we show that the discriminative\nspectral information at image-level features lead to significantly improved\nperformance in a face recognition task. We also explored the potential of\ntraditional feature descriptors in the hyperspectral images. From our\nevaluations, we observe that SIFT features outperform the state-of-the-art\nhyperspectral face recognition methods, and also the other descriptors. With\nthe increasing deployment of hyperspectral sensors in a multitude of\napplications, we believe that our approach can effectively exploit the spectral\ninformation in hyperspectral images, thus beneficial to more accurate\nclassification.",
    "published": "2016-05-11T13:18:22Z",
    "updated": "2016-05-11T13:18:22Z",
    "authors": [
      "Vivek Sharma",
      "Luc Van Gool"
    ],
    "link": "http://arxiv.org/abs/1605.03428v1",
    "pdf_link": "http://arxiv.org/pdf/1605.03428v1"
  },
  {
    "api_id": 240,
    "title": "A data base of synthetic photometry in the GALEX ultraviolet bands for\n  the stellar sources observed with the International Ultraviolet Explorer",
    "summary": "The Galaxy Evolution Explorer (GALEX) has produced the largest photometric\ncatalogue of ultraviolet (UV) sources. As such, it has defined the new standard\nbands for UV photometry: the near UV band (NUV) and the far UV band (FUV).\nHowever, due to brightness limits, the GALEX mission has avoided the Galactic\nplane which is crucial for astrophysical research and future space missions.\nThe International Ultraviolet Explorer (IUE) satellite obtained 63,755 spectra\nin the low dispersion mode during its 18 years lifetime. We have derived the\nphotometry in the GALEX bands for the stellar sources in the IUE Archive to\nextend the GALEX data base with observations including the Galactic plane.Good\nquality spectra have been selected for all IUE classes of stellar sources. The\nGALEX FUV and NUV magnitudes have been computed using the GALEX transmission\ncurves, as well as the conversion equations between flux and magnitudes\nprovided by the mission (galexgi.gsfc.nasa.gov). Consistency between GALEX and\nIUE synthetic photometries has been tested using White Dwarfs (WD) contained in\nboth samples. The non-linear response performance of GALEX inferred from this\ndata agrees with the results from GALEX calibration. The photometric data base\nis made available to the community through the services of the Centre de\nDonn\\'ees Stellaires at Strasbourg (CDS). The catalogue contains FUV magnitudes\nfor 1,631 sources, ranging from FUV=1.81 to FUV=18.65 mag. In the NUV band, the\ncatalogue includes observations for 1,005 stars ranging from NUV = 3.08 to NUV=\n17.74 mag . UV photometry for 1,493 not included in the GALEX AIS GR5 catalogue\nis provided; most of them are hot (O-A spectral type) stars. The sources in the\ncatalogue are distributed over the full sky, including the Galactic plane.",
    "published": "2016-05-13T10:29:33Z",
    "updated": "2016-05-13T10:29:33Z",
    "authors": [
      "Leire Beitia-Antero",
      "Ana I. Gomez de Castro"
    ],
    "link": "http://arxiv.org/abs/1605.04112v1",
    "pdf_link": "http://arxiv.org/pdf/1605.04112v1"
  },
  {
    "api_id": 241,
    "title": "Detecting Burnscar from Hyperspectral Imagery via Sparse Representation\n  with Low-Rank Interference",
    "summary": "In this paper, we propose a burnscar detection model for hyperspectral\nimaging (HSI) data. The proposed model contains two-processing steps in which\nthe first step separate and then suppress the cloud information presenting in\nthe data set using an RPCA algorithm and the second step detect the burnscar\narea in the low-rank component output of the first step. Experiments are\nconducted on the public MODIS dataset available at NASA official website.",
    "published": "2016-05-01T18:18:45Z",
    "updated": "2016-05-17T23:25:22Z",
    "authors": [
      "Minh Dao",
      "Xiang Xiang",
      "Bulent Ayhan",
      "Chiman Kwan",
      "Trac D. Tran"
    ],
    "link": "http://arxiv.org/abs/1605.00287v2",
    "pdf_link": "http://arxiv.org/pdf/1605.00287v2"
  },
  {
    "api_id": 242,
    "title": "On the Sampling Strategy for Evaluation of Spectral-spatial Methods in\n  Hyperspectral Image Classification",
    "summary": "Spectral-spatial processing has been increasingly explored in remote sensing\nhyperspectral image classification. While extensive studies have focused on\ndeveloping methods to improve the classification accuracy, experimental setting\nand design for method evaluation have drawn little attention. In the scope of\nsupervised classification, we find that traditional experimental designs for\nspectral processing are often improperly used in the spectral-spatial\nprocessing context, leading to unfair or biased performance evaluation. This is\nespecially the case when training and testing samples are randomly drawn from\nthe same image - a practice that has been commonly adopted in the experiments.\nUnder such setting, the dependence caused by overlap between the training and\ntesting samples may be artificially enhanced by some spatial information\nprocessing methods such as spatial filtering and morphological operation. Such\ninteraction between training and testing sets has violated data independence\nassumption that is abided by supervised learning theory and performance\nevaluation mechanism. Therefore, the widely adopted pixel-based random sampling\nstrategy is not always suitable to evaluate spectral-spatial classification\nalgorithms because it is difficult to determine whether the improvement of\nclassification accuracy is caused by incorporating spatial information into\nclassifier or by increasing the overlap between training and testing samples.\nTo partially solve this problem, we propose a novel controlled random sampling\nstrategy for spectral-spatial methods. It can greatly reduce the overlap\nbetween training and testing samples and provides more objective and accurate\nevaluation.",
    "published": "2016-05-19T06:59:03Z",
    "updated": "2016-05-19T06:59:03Z",
    "authors": [
      "Jie Liang",
      "Jun Zhou",
      "Yuntao Qian",
      "Lian Wen",
      "Xiao Bai",
      "Yongsheng Gao"
    ],
    "link": "http://arxiv.org/abs/1605.05829v1",
    "pdf_link": "http://arxiv.org/pdf/1605.05829v1"
  },
  {
    "api_id": 243,
    "title": "Fine-to-coarse Knowledge Transfer For Low-Res Image Classification",
    "summary": "We address the difficult problem of distinguishing fine-grained object\ncategories in low resolution images. Wepropose a simple an effective deep\nlearning approach that transfers fine-grained knowledge gained from high\nresolution training data to the coarse low-resolution test scenario. Such\nfine-to-coarse knowledge transfer has many real world applications, such as\nidentifying objects in surveillance photos or satellite images where the image\nresolution at the test time is very low but plenty of high resolution photos of\nsimilar objects are available. Our extensive experiments on two standard\nbenchmark datasets containing fine-grained car models and bird species\ndemonstrate that our approach can effectively transfer fine-detail knowledge to\ncoarse-detail imagery.",
    "published": "2016-05-21T20:08:53Z",
    "updated": "2016-05-21T20:08:53Z",
    "authors": [
      "Xingchao Peng",
      "Judy Hoffman",
      "Stella X. Yu",
      "Kate Saenko"
    ],
    "link": "http://arxiv.org/abs/1605.06695v1",
    "pdf_link": "http://arxiv.org/pdf/1605.06695v1"
  },
  {
    "api_id": 244,
    "title": "Absolute parameters for AI Phoenicis using WASP photometry",
    "summary": "AI Phe is a double-lined, detached binary, in which a K-type sub-giant star\ntotally eclipses its main-sequence companion every 24.6 days. This\nconfiguration makes AI Phe ideal for testing stellar evolutionary models.\nDifficulties in obtaining a complete lightcurve mean the precision of existing\nradii measurements could be improved. Our aim is to improve the precision of\nthe radius measurements for the stars in AI Phe using high-precision photometry\nfrom WASP, and use these improved radius measurements together with estimates\nof the masses, temperatures and composition of the stars to place constraints\non the mixing length, helium abundance and age of the system. A best-fit ebop\nmodel is used to obtain lightcurve parameters, with their standard errors\ncalculated using a prayer-bead algorithm. These were combined with previously\npublished spectroscopic orbit results, to obtain masses and radii. A Bayesian\nmethod is used to estimate the age of the system for model grids with different\nmixing lengths and helium abundances. The radii are found to be\n$R_1=1.835\\pm0.014$ R$_{\\odot}$, $R_2=2.912\\pm0.014$ R$_{\\odot}$ and the masses\n$M_1=1.1973\\pm0.0037$ M$_{\\odot}$, $M_2=1.2473\\pm0.0039$ M$_{\\odot}$. From the\nbest-fit stellar models we infer a mixing length of 1.78, a helium abundance of\n$Y_{AI}=0.26^{+0.02}_{-0.01}$ and an age of $4.39\\pm0.32$ Gyr. Times of primary\nminimum show the period of AI Phe is not constant. Currently, there are\ninsufficient data to determine the cause of this variation. Improved precision\nin the masses and radii have improved the age estimate, and allowed the mixing\nlength and helium abundance to be constrained. The eccentricity is now the\nlargest source of uncertainty in calculating the masses. More binaries with\nparameters measured to a similar level of precision would allow us to test for\nrelationships between helium abundance and mixing length.",
    "published": "2016-05-23T15:20:31Z",
    "updated": "2016-05-23T15:20:31Z",
    "authors": [
      "J. A. Kirkby-Kent",
      "P. F. L. Maxted",
      "A. M. Serenelli",
      "O. D. Turner",
      "D. F. Evans",
      "D. R. Anderson",
      "C. Hellier",
      "R. G. West"
    ],
    "link": "http://arxiv.org/abs/1605.07059v1",
    "pdf_link": "http://arxiv.org/pdf/1605.07059v1"
  },
  {
    "api_id": 245,
    "title": "Multimodal Remote Sensing Image Registration with Accuracy Estimation at\n  Local and Global Scales",
    "summary": "This paper focuses on potential accuracy of remote sensing images\nregistration. We investigate how this accuracy can be estimated without ground\ntruth available and used to improve registration quality of mono- and\nmulti-modal pair of images. At the local scale of image fragments, the\nCramer-Rao lower bound (CRLB) on registration error is estimated for each local\ncorrespondence between coarsely registered pair of images. This CRLB is defined\nby local image texture and noise properties. Opposite to the standard approach,\nwhere registration accuracy is only evaluated at the output of the registration\nprocess, such valuable information is used by us as an additional input\nknowledge. It greatly helps detecting and discarding outliers and refining the\nestimation of geometrical transformation model parameters. Based on these\nideas, a new area-based registration method called RAE (Registration with\nAccuracy Estimation) is proposed. In addition to its ability to automatically\nregister very complex multimodal image pairs with high accuracy, the RAE method\nprovides registration accuracy at the global scale as covariance matrix of\nestimation error of geometrical transformation model parameters or as\npoint-wise registration Standard Deviation. This accuracy does not depend on\nany ground truth availability and characterizes each pair of registered images\nindividually. Thus, the RAE method can identify image areas for which a\npredefined registration accuracy is guaranteed. The RAE method is proved\nsuccessful with reaching subpixel accuracy while registering eight complex\nmono/multimodal and multitemporal image pairs including optical to optical,\noptical to radar, optical to Digital Elevation Model (DEM) images and DEM to\nradar cases. Other methods employed in comparisons fail to provide in a stable\nmanner accurate results on the same test cases.",
    "published": "2016-02-08T20:05:42Z",
    "updated": "2016-05-25T20:16:54Z",
    "authors": [
      "M. L. Uss",
      "B. Vozel",
      "V. V. Lukin",
      "K. Chehdi"
    ],
    "link": "http://arxiv.org/abs/1602.02720v2",
    "pdf_link": "http://arxiv.org/pdf/1602.02720v2"
  },
  {
    "api_id": 246,
    "title": "Aerial image geolocalization from recognition and matching of roads and\n  intersections",
    "summary": "Aerial image analysis at a semantic level is important in many applications\nwith strong potential impact in industry and consumer use, such as automated\nmapping, urban planning, real estate and environment monitoring, or disaster\nrelief. The problem is enjoying a great interest in computer vision and remote\nsensing, due to increased computer power and improvement in automated image\nunderstanding algorithms. In this paper we address the task of automatic\ngeolocalization of aerial images from recognition and matching of roads and\nintersections. Our proposed method is a novel contribution in the literature\nthat could enable many applications of aerial image analysis when GPS data is\nnot available. We offer a complete pipeline for geolocalization, from the\ndetection of roads and intersections, to the identification of the enclosing\ngeographic region by matching detected intersections to previously learned\nmanually labeled ones, followed by accurate geometric alignment between the\ndetected roads and the manually labeled maps. We test on a novel dataset with\naerial images of two European cities and use the publicly available\nOpenStreetMap project for collecting ground truth roads annotations. We show in\nextensive experiments that our approach produces highly accurate localizations\nin the challenging case when we train on images from one city and test on the\nother and the quality of the aerial images is relatively poor. We also show\nthat the the alignment between detected roads and pre-stored manual annotations\ncan be effectively used for improving the quality of the road detection\nresults.",
    "published": "2016-05-26T15:11:09Z",
    "updated": "2016-05-26T15:11:09Z",
    "authors": [
      "Dragos Costea",
      "Marius Leordeanu"
    ],
    "link": "http://arxiv.org/abs/1605.08323v1",
    "pdf_link": "http://arxiv.org/pdf/1605.08323v1"
  },
  {
    "api_id": 247,
    "title": "Hyperspectral Image Classification with Support Vector Machines on\n  Kernel Distribution Embeddings",
    "summary": "We propose a novel approach for pixel classification in hyperspectral images,\nleveraging on both the spatial and spectral information in the data. The\nintroduced method relies on a recently proposed framework for learning on\ndistributions -- by representing them with mean elements in reproducing kernel\nHilbert spaces (RKHS) and formulating a classification algorithm therein. In\nparticular, we associate each pixel to an empirical distribution of its\nneighbouring pixels, a judicious representation of which in an RKHS, in\nconjunction with the spectral information contained in the pixel itself, give a\nnew explicit set of features that can be fed into a suite of standard\nclassification techniques -- we opt for a well-established framework of support\nvector machines (SVM). Furthermore, the computational complexity is reduced via\nrandom Fourier features formalism. We study the consistency and the convergence\nrates of the proposed method and the experiments demonstrate strong performance\non hyperspectral data with gains in comparison to the state-of-the-art results.",
    "published": "2016-05-30T08:26:28Z",
    "updated": "2016-05-30T08:26:28Z",
    "authors": [
      "Gianni Franchi",
      "Jesus Angulo",
      "Dino Sejdinovic"
    ],
    "link": "http://arxiv.org/abs/1605.09136v1",
    "pdf_link": "http://arxiv.org/pdf/1605.09136v1"
  },
  {
    "api_id": 248,
    "title": "Hyperspectral Subspace Identification Using SURE",
    "summary": "Remote sensing hyperspectral sensors collect large volumes of high\ndimensional spectral and spatial data. However, due to spectral and spatial\nredundancy the true hyperspectral signal lies on a subspace of much lower\ndimension than the original data. The identification of the signal subspace is\na very important first step for most hyperspectral algorithms. In this paper we\ninvestigate the important problem of identifying the hyperspectral signal\nsubspace by minimizing the mean squared error (MSE) between the true signal and\nan estimate of the signal. Since the MSE is uncomputable in practice, due to\nits dependency on the true signal, we propose a method based on the Stein's\nunbiased risk estimator (SURE) that provides an unbiased estimate of the MSE.\nThe resulting method is simple and fully automatic and we evaluate it using\nboth simulated and real hyperspectral data sets. Experimental results shows\nthat our proposed method compares well to recent state-of-the-art subspace\nidentification methods.",
    "published": "2016-06-01T11:01:54Z",
    "updated": "2016-06-01T11:01:54Z",
    "authors": [
      "Behnood Rasti",
      "Magnus O. Ulfarsson",
      "Johannes R. Sveinsson"
    ],
    "link": "http://arxiv.org/abs/1606.00219v1",
    "pdf_link": "http://arxiv.org/pdf/1606.00219v1"
  },
  {
    "api_id": 249,
    "title": "Exploiting AIS Data for Intelligent Maritime Navigation: A Comprehensive\n  Survey",
    "summary": "The Automatic Identification System (AIS) tracks vessel movement by means of\nelectronic exchange of navigation data between vessels, with onboard\ntransceiver, terrestrial and/or satellite base stations. The gathered data\ncontains a wealth of information useful for maritime safety, security and\nefficiency. This paper surveys AIS data sources and relevant aspects of\nnavigation in which such data is or could be exploited for safety of seafaring,\nnamely traffic anomaly detection, route estimation, collision prediction and\npath planning.",
    "published": "2016-06-03T06:46:31Z",
    "updated": "2016-06-03T06:46:31Z",
    "authors": [
      "Enmei Tu",
      "Guanghao Zhang",
      "Lily Rachmawati",
      "Eshan Rajabally",
      "Guang-Bin Huang"
    ],
    "link": "http://arxiv.org/abs/1606.00981v1",
    "pdf_link": "http://arxiv.org/pdf/1606.00981v1"
  },
  {
    "api_id": 250,
    "title": "Online Unmixing of Multitemporal Hyperspectral Images accounting for\n  Spectral Variability",
    "summary": "Hyperspectral unmixing is aimed at identifying the reference spectral\nsignatures composing an hyperspectral image and their relative abundance\nfractions in each pixel. In practice, the identified signatures may vary\nspectrally from an image to another due to varying acquisition conditions, thus\ninducing possibly significant estimation errors. Against this background,\nhyperspectral unmixing of several images acquired over the same area is of\nconsiderable interest. Indeed, such an analysis enables the endmembers of the\nscene to be tracked and the corresponding endmember variability to be\ncharacterized. Sequential endmember estimation from a set of hyperspectral\nimages is expected to provide improved performance when compared to methods\nanalyzing the images independently. However, the significant size of\nhyperspectral data precludes the use of batch procedures to jointly estimate\nthe mixture parameters of a sequence of hyperspectral images. Provided that\neach elementary component is present in at least one image of the sequence, we\npropose to perform an online hyperspectral unmixing accounting for temporal\nendmember variability. The online hyperspectral unmixing is formulated as a\ntwo-stage stochastic program, which can be solved using a stochastic\napproximation. The performance of the proposed method is evaluated on synthetic\nand real data. A comparison with independent unmixing algorithms finally\nillustrates the interest of the proposed strategy.",
    "published": "2015-10-20T13:47:24Z",
    "updated": "2016-06-06T16:05:14Z",
    "authors": [
      "Pierre-Antoine Thouvenin",
      "Nicolas Dobigeon",
      "Jean-Yves Tourneret"
    ],
    "link": "http://arxiv.org/abs/1510.05893v3",
    "pdf_link": "http://arxiv.org/pdf/1510.05893v3"
  },
  {
    "api_id": 251,
    "title": "Fully Convolutional Networks for Dense Semantic Labelling of\n  High-Resolution Aerial Imagery",
    "summary": "The trend towards higher resolution remote sensing imagery facilitates a\ntransition from land-use classification to object-level scene understanding.\nRather than relying purely on spectral content, appearance-based image features\ncome into play. In this work, deep convolutional neural networks (CNNs) are\napplied to semantic labelling of high-resolution remote sensing data. Recent\nadvances in fully convolutional networks (FCNs) are adapted to overhead data\nand shown to be as effective as in other domains. A full-resolution labelling\nis inferred using a deep FCN with no downsampling, obviating the need for\ndeconvolution or interpolation. To make better use of image features, a\npre-trained CNN is fine-tuned on remote sensing data in a hybrid network\ncontext, resulting in superior results compared to a network trained from\nscratch. The proposed approach is applied to the problem of labelling\nhigh-resolution aerial imagery, where fine boundary detail is important. The\ndense labelling yields state-of-the-art accuracy for the ISPRS Vaihingen and\nPotsdam benchmark data sets.",
    "published": "2016-06-08T14:52:04Z",
    "updated": "2016-06-08T14:52:04Z",
    "authors": [
      "Jamie Sherrah"
    ],
    "link": "http://arxiv.org/abs/1606.02585v1",
    "pdf_link": "http://arxiv.org/pdf/1606.02585v1"
  },
  {
    "api_id": 252,
    "title": "Machine Learning Techniques and Applications For Ground-based Image\n  Analysis",
    "summary": "Ground-based whole sky cameras have opened up new opportunities for\nmonitoring the earth's atmosphere. These cameras are an important complement to\nsatellite images by providing geoscientists with cheaper, faster, and more\nlocalized data. The images captured by whole sky imagers can have high spatial\nand temporal resolution, which is an important pre-requisite for applications\nsuch as solar energy modeling, cloud attenuation analysis, local weather\nprediction, etc.\n  Extracting valuable information from the huge amount of image data by\ndetecting and analyzing the various entities in these images is challenging.\nHowever, powerful machine learning techniques have become available to aid with\nthe image analysis. This article provides a detailed walk-through of recent\ndevelopments in these techniques and their applications in ground-based\nimaging. We aim to bridge the gap between computer vision and remote sensing\nwith the help of illustrative examples. We demonstrate the advantages of using\nmachine learning techniques in ground-based image analysis via three primary\napplications -- segmentation, classification, and denoising.",
    "published": "2016-06-09T03:33:11Z",
    "updated": "2016-06-09T03:33:11Z",
    "authors": [
      "Soumyabrata Dev",
      "Bihan Wen",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "link": "http://arxiv.org/abs/1606.02811v1",
    "pdf_link": "http://arxiv.org/pdf/1606.02811v1"
  },
  {
    "api_id": 253,
    "title": "Color-based Segmentation of Sky/Cloud Images From Ground-based Cameras",
    "summary": "Sky/cloud images captured by ground-based cameras (a.k.a. whole sky imagers)\nare increasingly used nowadays because of their applications in a number of\nfields, including climate modeling, weather prediction, renewable energy\ngeneration, and satellite communications. Due to the wide variety of cloud\ntypes and lighting conditions in such images, accurate and robust segmentation\nof clouds is challenging. In this paper, we present a supervised segmentation\nframework for ground-based sky/cloud images based on a systematic analysis of\ndifferent color spaces and components, using partial least squares (PLS)\nregression. Unlike other state-of-the-art methods, our proposed approach is\nentirely learning-based and does not require any manually-defined parameters.\nIn addition, we release the Singapore Whole Sky IMaging SEGmentation Database\n(SWIMSEG), a large database of annotated sky/cloud images, to the research\ncommunity.",
    "published": "2016-06-12T06:17:10Z",
    "updated": "2016-06-12T06:17:10Z",
    "authors": [
      "Soumyabrata Dev",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "link": "http://arxiv.org/abs/1606.03669v1",
    "pdf_link": "http://arxiv.org/pdf/1606.03669v1"
  },
  {
    "api_id": 254,
    "title": "Probe-based Rapid Hybrid Hyperspectral and Tissue Surface Imaging Aided\n  by Fully Convolutional Networks",
    "summary": "Tissue surface shape and reflectance spectra provide rich intra-operative\ninformation useful in surgical guidance. We propose a hybrid system which\ndisplays an endoscopic image with a fast joint inspection of tissue surface\nshape using structured light (SL) and hyperspectral imaging (HSI). For SL a\nminiature fibre probe is used to project a coloured spot pattern onto the\ntissue surface. In HSI mode standard endoscopic illumination is used, with the\nfibre probe collecting reflected light and encoding the spatial information\ninto a linear format that can be imaged onto the slit of a spectrograph.\nCorrespondence between the arrangement of fibres at the distal and proximal\nends of the bundle was found using spectral encoding. Then during pattern\ndecoding, a fully convolutional network (FCN) was used for spot detection,\nfollowed by a matching propagation algorithm for spot identification. This\nmethod enabled fast reconstruction (12 frames per second) using a GPU. The\nhyperspectral image was combined with the white light image and the\nreconstructed surface, showing the spectral information of different areas.\nValidation of this system using phantom and ex vivo experiments has been\ndemonstrated.",
    "published": "2016-06-15T14:00:07Z",
    "updated": "2016-06-15T14:00:07Z",
    "authors": [
      "Jianyu Lin",
      "Neil T. Clancy",
      "Xueqing Sun",
      "Ji Qi",
      "Mirek Janatka",
      "Danail Stoyanov",
      "Daniel S. Elson"
    ],
    "link": "http://arxiv.org/abs/1606.04766v1",
    "pdf_link": "http://arxiv.org/pdf/1606.04766v1"
  },
  {
    "api_id": 255,
    "title": "Combining multiscale features for classification of hyperspectral\n  images: a sequence based kernel approach",
    "summary": "Nowadays, hyperspectral image classification widely copes with spatial\ninformation to improve accuracy. One of the most popular way to integrate such\ninformation is to extract hierarchical features from a multiscale segmentation.\nIn the classification context, the extracted features are commonly concatenated\ninto a long vector (also called stacked vector), on which is applied a\nconventional vector-based machine learning technique (e.g. SVM with Gaussian\nkernel). In this paper, we rather propose to use a sequence structured kernel:\nthe spectrum kernel. We show that the conventional stacked vector-based kernel\nis actually a special case of this kernel. Experiments conducted on various\npublicly available hyperspectral datasets illustrate the improvement of the\nproposed kernel w.r.t. conventional ones using the same hierarchical spatial\nfeatures.",
    "published": "2016-06-15T21:19:54Z",
    "updated": "2016-06-15T21:19:54Z",
    "authors": [
      "Yanwei Cui",
      "Laetitia Chapel",
      "Sébastien Lefèvre"
    ],
    "link": "http://arxiv.org/abs/1606.04985v1",
    "pdf_link": "http://arxiv.org/pdf/1606.04985v1"
  },
  {
    "api_id": 256,
    "title": "Robust Active Perception via Data-association aware Belief Space\n  planning",
    "summary": "We develop a belief space planning (BSP) approach that advances the state of\nthe art by incorporating reasoning about data association (DA) within planning,\nwhile considering additional sources of uncertainty. Existing BSP approaches\ntypically assume data association is given and perfect, an assumption that can\nbe harder to justify while operating, in the presence of localization\nuncertainty, in ambiguous and perceptually aliased environments. In contrast,\nour data association aware belief space planning (DA-BSP) approach explicitly\nreasons about DA within belief evolution, and as such can better accommodate\nthese challenging real world scenarios. In particular, we show that due to\nperceptual aliasing, the posterior belief becomes a mixture of probability\ndistribution functions, and design cost functions that measure the expected\nlevel of ambiguity and posterior uncertainty. Using these and standard costs\n(e.g.~control penalty, distance to goal) within the objective function, yields\na general framework that reliably represents action impact, and in particular,\ncapable of active disambiguation. Our approach is thus applicable to robust\nactive perception and autonomous navigation in perceptually aliased\nenvironments. We demonstrate key aspects in basic and realistic simulations.",
    "published": "2016-06-16T10:22:04Z",
    "updated": "2016-06-16T10:22:04Z",
    "authors": [
      "Shashank Pathak",
      "Antony Thomas",
      "Asaf Feniger",
      "Vadim Indelman"
    ],
    "link": "http://arxiv.org/abs/1606.05124v1",
    "pdf_link": "http://arxiv.org/pdf/1606.05124v1"
  },
  {
    "api_id": 257,
    "title": "3D zigzag for multislicing, multiband and video processing",
    "summary": "We present a 3D zigzag rafter (first in literature) which allows us to obtain\nthe exact sequence of spectral components after application of Discrete Cosine\nTransform 3D (DCT-2D) over a cube. Such cube represents part of a video or\neventually a group of images such as multislicing (e.g., Magnetic Resonance or\nComputed Tomography imaging) and multi or hyperspectral imagery (optical\nsatellites). Besides, we present a new version of the traditional 2D zigzag,\nincluding the case of rectangular blocks. Finally, all the attached code is\ndone in MATLAB, and that code serves both blocks of pixels or blocks of blocks.",
    "published": "2016-06-16T16:45:39Z",
    "updated": "2016-06-16T16:45:39Z",
    "authors": [
      "Mario Mastriani"
    ],
    "link": "http://arxiv.org/abs/1606.05255v1",
    "pdf_link": "http://arxiv.org/pdf/1606.05255v1"
  },
  {
    "api_id": 258,
    "title": "A Survey of Pansharpening Methods with A New Band-Decoupled Variational\n  Model",
    "summary": "Most satellites decouple the acquisition of a panchromatic image at high\nspatial resolution from the acquisition of a multispectral image at lower\nspatial resolution. Pansharpening is a fusion technique used to increase the\nspatial resolution of the multispectral data while simultaneously preserving\nits spectral information. In this paper, we consider pansharpening as an\noptimization problem minimizing a cost function with a nonlocal regularization\nterm. The energy functional which is to be minimized decouples for each band,\nthus permitting the application to misregistered spectral components. This\nrequirement is achieved by dropping the, commonly used, assumption that relates\nthe spectral and panchromatic modalities by a linear transformation. Instead, a\nnew constraint that preserves the radiometric ratio between the panchromatic\nand each spectral component is introduced. An exhaustive performance comparison\nof the proposed fusion method with several classical and state-of-the-art\npansharpening techniques illustrates its superiority in preserving spatial\ndetails, reducing color distortions, and avoiding the creation of aliasing\nartifacts.",
    "published": "2016-06-17T23:12:32Z",
    "updated": "2016-06-17T23:12:32Z",
    "authors": [
      "Joan Duran",
      "Antoni Buades",
      "Bartomeu Coll",
      "Catalina Sbert",
      "Gwendoline Blanchet"
    ],
    "link": "http://arxiv.org/abs/1606.05703v1",
    "pdf_link": "http://arxiv.org/pdf/1606.05703v1"
  },
  {
    "api_id": 259,
    "title": "Preliminaries of a Space Situational Awareness Ontology",
    "summary": "Space situational awareness (SSA) is vital for international safety and\nsecurity, and the future of space travel. By improving SSA data-sharing we\nimprove global SSA. Computational ontology may provide one means toward that\ngoal. This paper develops the ontology of the SSA domain and takes steps in the\ncreation of the space situational awareness ontology. Ontology objectives,\nrequirements and desiderata are outlined; and both the SSA domain and the\ndiscipline of ontology are described. The purposes of the ontology include:\nexploring the potential for ontology development and engineering to (i)\nrepresent SSA data, general domain knowledge, objects and relationships (ii)\nannotate and express the meaning of that data, and (iii) foster SSA\ndata-exchange and integration among SSA actors, orbital debris databases, space\nobject catalogs and other SSA data repositories. By improving SSA via data- and\nknowledge-sharing, we can (iv) expand our scientific knowledge of the space\nenvironment, (v) advance our capacity for planetary defense from near-Earth\nobjects, and (vi) ensure the future of safe space flight for generations to\ncome.",
    "published": "2016-06-02T19:37:14Z",
    "updated": "2016-06-23T00:38:21Z",
    "authors": [
      "Robert John Rovetto",
      "T. S. Kelso"
    ],
    "link": "http://arxiv.org/abs/1606.01924v2",
    "pdf_link": "http://arxiv.org/pdf/1606.01924v2"
  },
  {
    "api_id": 260,
    "title": "Multiclass feature learning for hyperspectral image classification:\n  sparse and hierarchical solutions",
    "summary": "In this paper, we tackle the question of discovering an effective set of\nspatial filters to solve hyperspectral classification problems. Instead of\nfixing a priori the filters and their parameters using expert knowledge, we let\nthe model find them within random draws in the (possibly infinite) space of\npossible filters. We define an active set feature learner that includes in the\nmodel only features that improve the classifier. To this end, we consider a\nfast and linear classifier, multiclass logistic classification, and show that\nwith a good representation (the filters discovered), such a simple classifier\ncan reach at least state of the art performances. We apply the proposed active\nset learner in four hyperspectral image classification problems, including\nagricultural and urban classification at different resolutions, as well as\nmultimodal data. We also propose a hierarchical setting, which allows to\ngenerate more complex banks of features that can better describe the\nnonlinearities present in the data.",
    "published": "2016-06-23T12:05:23Z",
    "updated": "2016-06-23T12:05:23Z",
    "authors": [
      "Devis Tuia",
      "Rémi Flamary",
      "Nicolas Courty"
    ],
    "link": "http://arxiv.org/abs/1606.07279v1",
    "pdf_link": "http://arxiv.org/pdf/1606.07279v1"
  },
  {
    "api_id": 261,
    "title": "Non-convex regularization in remote sensing",
    "summary": "In this paper, we study the effect of different regularizers and their\nimplications in high dimensional image classification and sparse linear\nunmixing. Although kernelization or sparse methods are globally accepted\nsolutions for processing data in high dimensions, we present here a study on\nthe impact of the form of regularization used and its parametrization. We\nconsider regularization via traditional squared (2) and sparsity-promoting (1)\nnorms, as well as more unconventional nonconvex regularizers (p and Log Sum\nPenalty). We compare their properties and advantages on several classification\nand linear unmixing tasks and provide advices on the choice of the best\nregularizer for the problem at hand. Finally, we also provide a fully\nfunctional toolbox for the community.",
    "published": "2016-06-23T12:36:01Z",
    "updated": "2016-06-23T12:36:01Z",
    "authors": [
      "Devis Tuia",
      "Remi Flamary",
      "Michel Barlaud"
    ],
    "link": "http://arxiv.org/abs/1606.07289v1",
    "pdf_link": "http://arxiv.org/pdf/1606.07289v1"
  },
  {
    "api_id": 262,
    "title": "An On-line Variational Bayesian Model for Multi-Person Tracking from\n  Cluttered Scenes",
    "summary": "Object tracking is an ubiquitous problem that appears in many applications\nsuch as remote sensing, audio processing, computer vision, human-machine\ninterfaces, human-robot interaction, etc. Although thoroughly investigated in\ncomputer vision, tracking a time-varying number of persons remains a\nchallenging open problem. In this paper, we propose an on-line variational\nBayesian model for multi-person tracking from cluttered visual observations\nprovided by person detectors. The contributions of this paper are the\nfollowings. First, we propose a variational Bayesian framework for tracking an\nunknown and varying number of persons. Second, our model results in a\nvariational expectation-maximization (VEM) algorithm with closed-form\nexpressions for the posterior distributions of the latent variables and for the\nestimation of the model parameters. Third, the proposed model exploits\nobservations from multiple detectors, and it is therefore multimodal by nature.\nFinally, we propose to embed both object-birth and object-visibility processes\nin an effort to robustly handle person appearances and disappearances over\ntime. Evaluated on classical multiple person tracking datasets, our method\nshows competitive results with respect to state-of-the-art multiple-object\ntracking models, such as the probability hypothesis density (PHD) filter among\nothers.",
    "published": "2015-09-04T16:16:42Z",
    "updated": "2016-06-30T08:50:42Z",
    "authors": [
      "Sileye Ba",
      "Xavier Alameda-Pineda",
      "Alessio Xompero",
      "Radu Horaud"
    ],
    "link": "http://arxiv.org/abs/1509.01520v3",
    "pdf_link": "http://arxiv.org/pdf/1509.01520v3"
  },
  {
    "api_id": 263,
    "title": "Sequential Dimensionality Reduction for Extracting Localized Features",
    "summary": "Linear dimensionality reduction techniques are powerful tools for image\nanalysis as they allow the identification of important features in a data set.\nIn particular, nonnegative matrix factorization (NMF) has become very popular\nas it is able to extract sparse, localized and easily interpretable features by\nimposing an additive combination of nonnegative basis elements. Nonnegative\nmatrix underapproximation (NMU) is a closely related technique that has the\nadvantage to identify features sequentially. In this paper, we propose a\nvariant of NMU that is particularly well suited for image analysis as it\nincorporates the spatial information, that is, it takes into account the fact\nthat neighboring pixels are more likely to be contained in the same features,\nand favors the extraction of localized features by looking for sparse basis\nelements. We show that our new approach competes favorably with comparable\nstate-of-the-art techniques on synthetic, facial and hyperspectral image data\nsets.",
    "published": "2015-05-26T14:06:16Z",
    "updated": "2016-07-05T06:44:58Z",
    "authors": [
      "Gabriella Casalino",
      "Nicolas Gillis"
    ],
    "link": "http://arxiv.org/abs/1505.06957v2",
    "pdf_link": "http://arxiv.org/pdf/1505.06957v2"
  },
  {
    "api_id": 264,
    "title": "Fundamental Parameters of Main-Sequence Stars in an Instant with Machine\n  Learning",
    "summary": "Owing to the remarkable photometric precision of space observatories like\nKepler, stellar and planetary systems beyond our own are now being\ncharacterized en masse for the first time. These characterizations are pivotal\nfor endeavors such as searching for Earth-like planets and solar twins,\nunderstanding the mechanisms that govern stellar evolution, and tracing the\ndynamics of our Galaxy. The volume of data that is becoming available, however,\nbrings with it the need to process this information accurately and rapidly.\nWhile existing methods can constrain fundamental stellar parameters such as\nages, masses, and radii from these observations, they require substantial\ncomputational efforts to do so.\n  We develop a method based on machine learning for rapidly estimating\nfundamental parameters of main-sequence solar-like stars from classical and\nasteroseismic observations. We first demonstrate this method on a\nhare-and-hound exercise and then apply it to the Sun, 16 Cyg A & B, and 34\nplanet-hosting candidates that have been observed by the Kepler spacecraft. We\nfind that our estimates and their associated uncertainties are comparable to\nthe results of other methods, but with the additional benefit of being able to\nexplore many more stellar parameters while using much less computation time. We\nfurthermore use this method to present evidence for an empirical diffusion-mass\nrelation. Our method is open source and freely available for the community to\nuse.\n  The source code for all analyses and for all figures appearing in this\nmanuscript can be found electronically at\nhttps://github.com/earlbellinger/asteroseismology",
    "published": "2016-07-06T20:41:25Z",
    "updated": "2016-07-06T20:41:25Z",
    "authors": [
      "Earl P. Bellinger",
      "George C. Angelou",
      "Saskia Hekker",
      "Sarbani Basu",
      "Warrick Ball",
      "Elisabeth Guggenberger"
    ],
    "link": "http://arxiv.org/abs/1607.02137v1",
    "pdf_link": "http://arxiv.org/pdf/1607.02137v1"
  },
  {
    "api_id": 265,
    "title": "Spatial Context based Angular Information Preserving Projection for\n  Hyperspectral Image Classification",
    "summary": "Dimensionality reduction is a crucial preprocessing for hyperspectral data\nanalysis - finding an appropriate subspace is often required for subsequent\nimage classification. In recent work, we proposed supervised angular\ninformation based dimensionality reduction methods to find effective subspaces.\nSince unlabeled data are often more readily available compared to labeled data,\nwe propose an unsupervised projection that finds a lower dimensional subspace\nwhere local angular information is preserved. To exploit spatial information\nfrom the hyperspectral images, we further extend our unsupervised projection to\nincorporate spatial contextual information around each pixel in the image.\nAdditionally, we also propose a sparse representation based classifier which is\noptimized to exploit spatial information during classification - we hence\nassert that our proposed projection is particularly suitable for classifiers\nwhere local similarity and spatial context are both important. Experimental\nresults with two real-world hyperspectral datasets demonstrate that our\nproposed methods provide a robust classification performance.",
    "published": "2016-07-15T17:38:34Z",
    "updated": "2016-07-15T17:38:34Z",
    "authors": [
      "Minshan Cui",
      "Saurabh Prasad"
    ],
    "link": "http://arxiv.org/abs/1607.04593v1",
    "pdf_link": "http://arxiv.org/pdf/1607.04593v1"
  },
  {
    "api_id": 266,
    "title": "Person Re-identification with Hyperspectral Multi-Camera Systems --- A\n  Pilot Study",
    "summary": "Person re-identification in a multi-camera environment is an important part\nof modern surveillance systems. Person re-identification from color images has\nbeen the focus of much active research, due to the numerous challenges posed\nwith such analysis tasks, such as variations in illumination, pose and\nviewpoints. In this paper, we suggest that hyperspectral imagery has the\npotential to provide unique information that is expected to be beneficial for\nthe re-identification task. Specifically, we assert that by accurately\ncharacterizing the unique spectral signature for each person's skin,\nhyperspectral imagery can provide very useful descriptors (e.g. spectral\nsignatures from skin pixels) for re-identification. Towards this end, we\nacquired proof-of-concept hyperspectral re-identification data under\nchallenging (practical) conditions from 15 people. Our results indicate that\nhyperspectral data result in a substantially enhanced re-identification\nperformance compared to color (RGB) images, when using spectral signatures over\nskin as the feature descriptor.",
    "published": "2016-07-15T18:38:38Z",
    "updated": "2016-07-15T18:38:38Z",
    "authors": [
      "Saurabh Prasad",
      "Tanu Priya",
      "Minshan Cui",
      "Shishir Shah"
    ],
    "link": "http://arxiv.org/abs/1607.04609v1",
    "pdf_link": "http://arxiv.org/pdf/1607.04609v1"
  },
  {
    "api_id": 267,
    "title": "Sparse Representation-Based Classification: Orthogonal Least Squares or\n  Orthogonal Matching Pursuit?",
    "summary": "Spare representation of signals has received significant attention in recent\nyears. Based on these developments, a sparse representation-based\nclassification (SRC) has been proposed for a variety of classification and\nrelated tasks, including face recognition. Recently, a class dependent variant\nof SRC was proposed to overcome the limitations of SRC for remote sensing image\nclassification. Traditionally, greedy pursuit based method such as orthogonal\nmatching pursuit (OMP) are used for sparse coefficient recovery due to their\nsimplicity as well as low time-complexity. However, orthogonal least square\n(OLS) has not yet been widely used in classifiers that exploit the sparse\nrepresentation properties of data. Since OLS produces lower signal\nreconstruction error than OMP under similar conditions, we hypothesize that\nmore accurate signal estimation will further improve the classification\nperformance of classifiers that exploiting the sparsity of data. In this paper,\nwe present a classification method based on OLS, which implements OLS in a\nclasswise manner to perform the classification. We also develop and present its\nkernelized variant to handle nonlinearly separable data. Based on two\nreal-world benchmarking hyperspectral datasets, we demonstrate that class\ndependent OLS based methods outperform several baseline methods including\ntraditional SRC and the support vector machine classifier.",
    "published": "2016-07-18T03:05:07Z",
    "updated": "2016-07-18T03:05:07Z",
    "authors": [
      "Minshan Cui",
      "Saurabh Prasad"
    ],
    "link": "http://arxiv.org/abs/1607.04942v1",
    "pdf_link": "http://arxiv.org/pdf/1607.04942v1"
  },
  {
    "api_id": 268,
    "title": "On the estimation of stellar parameters with uncertainty prediction from\n  Generative Artificial Neural Networks: application to Gaia RVS simulated\n  spectra",
    "summary": "Aims. We present an innovative artificial neural network (ANN) architecture,\ncalled Generative ANN (GANN), that computes the forward model, that is it\nlearns the function that relates the unknown outputs (stellar atmospheric\nparameters, in this case) to the given inputs (spectra). Such a model can be\nintegrated in a Bayesian framework to estimate the posterior distribution of\nthe outputs. Methods. The architecture of the GANN follows the same scheme as a\nnormal ANN, but with the inputs and outputs inverted. We train the network with\nthe set of atmospheric parameters (Teff, logg, [Fe/H] and [alpha/Fe]),\nobtaining the stellar spectra for such inputs. The residuals between the\nspectra in the grid and the estimated spectra are minimized using a validation\ndataset to keep solutions as general as possible. Results. The performance of\nboth conventional ANNs and GANNs to estimate the stellar parameters as a\nfunction of the star brightness is presented and compared for different\nGalactic populations. GANNs provide significantly improved parameterizations\nfor early and intermediate spectral types with rich and intermediate\nmetallicities. The behaviour of both algorithms is very similar for our sample\nof late-type stars, obtaining residuals in the derivation of [Fe/H] and\n[alpha/Fe] below 0.1dex for stars with Gaia magnitude Grvs<12, which accounts\nfor a number in the order of four million stars to be observed by the Radial\nVelocity Spectrograph of the Gaia satellite. Conclusions. Uncertainty\nestimation of computed astrophysical parameters is crucial for the validation\nof the parameterization itself and for the subsequent exploitation by the\nastronomical community. GANNs produce not only the parameters for a given\nspectrum, but a goodness-of-fit between the observed spectrum and the predicted\none for a given set of parameters. Moreover, they allow us to obtain the full\nposterior distribution...",
    "published": "2016-07-19T15:16:56Z",
    "updated": "2016-07-19T15:16:56Z",
    "authors": [
      "C. Dafonte",
      "D. Fustes",
      "M. Manteiga",
      "D. Garabato",
      "M. A. Alvarez",
      "A. Ulla",
      "C. Allende Prieto"
    ],
    "link": "http://arxiv.org/abs/1607.05954v1",
    "pdf_link": "http://arxiv.org/pdf/1607.05954v1"
  },
  {
    "api_id": 269,
    "title": "Automatic Detection of Solar Photovoltaic Arrays in High Resolution\n  Aerial Imagery",
    "summary": "The quantity of small scale solar photovoltaic (PV) arrays in the United\nStates has grown rapidly in recent years. As a result, there is substantial\ninterest in high quality information about the quantity, power capacity, and\nenergy generated by such arrays, including at a high spatial resolution (e.g.,\ncounties, cities, or even smaller regions). Unfortunately, existing methods for\nobtaining this information, such as surveys and utility interconnection\nfilings, are limited in their completeness and spatial resolution. This work\npresents a computer algorithm that automatically detects PV panels using very\nhigh resolution color satellite imagery. The approach potentially offers a\nfast, scalable method for obtaining accurate information on PV array location\nand size, and at much higher spatial resolutions than are currently available.\nThe method is validated using a very large (135 km^2) collection of publicly\navailable [1] aerial imagery, with over 2,700 human annotated PV array\nlocations. The results demonstrate the algorithm is highly effective on a\nper-pixel basis. It is likewise effective at object-level PV array detection,\nbut with significant potential for improvement in estimating the precise\nshape/size of the PV arrays. These results are the first of their kind for the\ndetection of solar PV in aerial imagery, demonstrating the feasibility of the\napproach and establishing a baseline performance for future investigations.",
    "published": "2016-07-20T17:07:53Z",
    "updated": "2016-07-20T17:07:53Z",
    "authors": [
      "Jordan M. Malof",
      "Kyle Bradbury",
      "Leslie M. Collins",
      "Richard G. Newell"
    ],
    "link": "http://arxiv.org/abs/1607.06029v1",
    "pdf_link": "http://arxiv.org/pdf/1607.06029v1"
  },
  {
    "api_id": 270,
    "title": "Density Matching Reward Learning",
    "summary": "In this paper, we focus on the problem of inferring the underlying reward\nfunction of an expert given demonstrations, which is often referred to as\ninverse reinforcement learning (IRL). In particular, we propose a model-free\ndensity-based IRL algorithm, named density matching reward learning (DMRL),\nwhich does not require model dynamics. The performance of DMRL is analyzed\ntheoretically and the sample complexity is derived. Furthermore, the proposed\nDMRL is extended to handle nonlinear IRL problems by assuming that the reward\nfunction is in the reproducing kernel Hilbert space (RKHS) and kernel DMRL\n(KDMRL) is proposed. The parameters for KDMRL can be computed analytically,\nwhich greatly reduces the computation time. The performance of KDMRL is\nextensively evaluated in two sets of experiments: grid world and track driving\nexperiments. In grid world experiments, the proposed KDMRL method is compared\nwith both model-based and model-free IRL methods and shows superior performance\non a nonlinear reward setting and competitive performance on a linear reward\nsetting in terms of expected value differences. Then we move on to more\nrealistic experiments of learning different driving styles for autonomous\nnavigation in complex and dynamic tracks using KDMRL and receding horizon\ncontrol.",
    "published": "2016-08-12T07:26:59Z",
    "updated": "2016-08-12T07:26:59Z",
    "authors": [
      "Sungjoon Choi",
      "Kyungjae Lee",
      "Andy Park",
      "Songhwai Oh"
    ],
    "link": "http://arxiv.org/abs/1608.03694v1",
    "pdf_link": "http://arxiv.org/pdf/1608.03694v1"
  },
  {
    "api_id": 271,
    "title": "Fully DNN-based Multi-label regression for audio tagging",
    "summary": "Acoustic event detection for content analysis in most cases relies on lots of\nlabeled data. However, manually annotating data is a time-consuming task, which\nthus makes few annotated resources available so far. Unlike audio event\ndetection, automatic audio tagging, a multi-label acoustic event classification\ntask, only relies on weakly labeled data. This is highly desirable to some\npractical applications using audio analysis. In this paper we propose to use a\nfully deep neural network (DNN) framework to handle the multi-label\nclassification task in a regression way. Considering that only chunk-level\nrather than frame-level labels are available, the whole or almost whole frames\nof the chunk were fed into the DNN to perform a multi-label regression for the\nexpected tags. The fully DNN, which is regarded as an encoding function, can\nwell map the audio features sequence to a multi-tag vector. A deep pyramid\nstructure was also designed to extract more robust high-level features related\nto the target tags. Further improved methods were adopted, such as the Dropout\nand background noise aware training, to enhance its generalization capability\nfor new audio recordings in mismatched environments. Compared with the\nconventional Gaussian Mixture Model (GMM) and support vector machine (SVM)\nmethods, the proposed fully DNN-based method could well utilize the long-term\ntemporal information with the whole chunk as the input. The results show that\nour approach obtained a 15% relative improvement compared with the official\nGMM-based method of DCASE 2016 challenge.",
    "published": "2016-06-24T14:17:34Z",
    "updated": "2016-08-13T10:39:29Z",
    "authors": [
      "Yong Xu",
      "Qiang Huang",
      "Wenwu Wang",
      "Philip J. B. Jackson",
      "Mark D. Plumbley"
    ],
    "link": "http://arxiv.org/abs/1606.07695v2",
    "pdf_link": "http://arxiv.org/pdf/1606.07695v2"
  },
  {
    "api_id": 272,
    "title": "Robust Volume Minimization-Based Matrix Factorization for Remote Sensing\n  and Document Clustering",
    "summary": "This paper considers \\emph{volume minimization} (VolMin)-based structured\nmatrix factorization (SMF). VolMin is a factorization criterion that decomposes\na given data matrix into a basis matrix times a structured coefficient matrix\nvia finding the minimum-volume simplex that encloses all the columns of the\ndata matrix. Recent work showed that VolMin guarantees the identifiability of\nthe factor matrices under mild conditions that are realistic in a wide variety\nof applications. This paper focuses on both theoretical and practical aspects\nof VolMin. On the theory side, exact equivalence of two independently developed\nsufficient conditions for VolMin identifiability is proven here, thereby\nproviding a more comprehensive understanding of this aspect of VolMin. On the\nalgorithm side, computational complexity and sensitivity to outliers are two\nkey challenges associated with real-world applications of VolMin. These are\naddressed here via a new VolMin algorithm that handles volume regularization in\na computationally simple way, and automatically detects and {iteratively\ndownweights} outliers, simultaneously. Simulations and real-data experiments\nusing a remotely sensed hyperspectral image and the Reuters document corpus are\nemployed to showcase the effectiveness of the proposed algorithm.",
    "published": "2016-08-15T14:51:10Z",
    "updated": "2016-08-15T14:51:10Z",
    "authors": [
      "Xiao Fu",
      "Kejun Huang",
      "Bo Yang",
      "Wing-Kin Ma",
      "Nicholas D. Sidiropoulos"
    ],
    "link": "http://arxiv.org/abs/1608.04290v1",
    "pdf_link": "http://arxiv.org/pdf/1608.04290v1"
  },
  {
    "api_id": 273,
    "title": "AID: A Benchmark Dataset for Performance Evaluation of Aerial Scene\n  Classification",
    "summary": "Aerial scene classification, which aims to automatically label an aerial\nimage with a specific semantic category, is a fundamental problem for\nunderstanding high-resolution remote sensing imagery. In recent years, it has\nbecome an active task in remote sensing area and numerous algorithms have been\nproposed for this task, including many machine learning and data-driven\napproaches. However, the existing datasets for aerial scene classification like\nUC-Merced dataset and WHU-RS19 are with relatively small sizes, and the results\non them are already saturated. This largely limits the development of scene\nclassification algorithms. This paper describes the Aerial Image Dataset (AID):\na large-scale dataset for aerial scene classification. The goal of AID is to\nadvance the state-of-the-arts in scene classification of remote sensing images.\nFor creating AID, we collect and annotate more than ten thousands aerial scene\nimages. In addition, a comprehensive review of the existing aerial scene\nclassification techniques as well as recent widely-used deep learning methods\nis given. Finally, we provide a performance analysis of typical aerial scene\nclassification and deep learning approaches on AID, which can be served as the\nbaseline results on this benchmark.",
    "published": "2016-08-18T04:20:45Z",
    "updated": "2016-08-18T04:20:45Z",
    "authors": [
      "Gui-Song Xia",
      "Jingwen Hu",
      "Fan Hu",
      "Baoguang Shi",
      "Xiang Bai",
      "Yanfei Zhong",
      "Liangpei Zhang"
    ],
    "link": "http://arxiv.org/abs/1608.05167v1",
    "pdf_link": "http://arxiv.org/pdf/1608.05167v1"
  },
  {
    "api_id": 274,
    "title": "Probabilistic Data Analysis with Probabilistic Programming",
    "summary": "Probabilistic techniques are central to data analysis, but different\napproaches can be difficult to apply, combine, and compare. This paper\nintroduces composable generative population models (CGPMs), a computational\nabstraction that extends directed graphical models and can be used to describe\nand compose a broad class of probabilistic data analysis techniques. Examples\ninclude hierarchical Bayesian models, multivariate kernel methods,\ndiscriminative machine learning, clustering algorithms, dimensionality\nreduction, and arbitrary probabilistic programs. We also demonstrate the\nintegration of CGPMs into BayesDB, a probabilistic programming platform that\ncan express data analysis tasks using a modeling language and a structured\nquery language. The practical value is illustrated in two ways. First, CGPMs\nare used in an analysis that identifies satellite data records which probably\nviolate Kepler's Third Law, by composing causal probabilistic programs with\nnon-parametric Bayes in under 50 lines of probabilistic code. Second, for\nseveral representative data analysis tasks, we report on lines of code and\naccuracy measurements of various CGPMs, plus comparisons with standard baseline\nsolutions from Python and MATLAB libraries.",
    "published": "2016-08-18T17:47:53Z",
    "updated": "2016-08-18T17:47:53Z",
    "authors": [
      "Feras Saad",
      "Vikash Mansinghka"
    ],
    "link": "http://arxiv.org/abs/1608.05347v1",
    "pdf_link": "http://arxiv.org/pdf/1608.05347v1"
  },
  {
    "api_id": 275,
    "title": "On Simulated Annealing Dedicated to Maximin Latin Hypercube Designs",
    "summary": "The goal of our research was to enhance local search heuristics used to\nconstruct Latin Hypercube Designs. First, we introduce the \\textit{1D-move}\nperturbation to improve the space exploration performed by these algorithms.\nSecond, we propose a new evaluation function $\\psi_{p,\\sigma}$ specifically\ntargeting the Maximin criterion.\n  Exhaustive series of experiments with Simulated Annealing, which we used as a\ntypically well-behaving local search heuristics, confirm that our goal was\nreached as the result we obtained surpasses the best scores reported in the\nliterature. Furthermore, the $\\psi_{p,\\sigma}$ function seems very promising\nfor a wide spectrum of optimization problems through the Maximin criterion.",
    "published": "2016-08-23T14:55:43Z",
    "updated": "2016-08-23T14:55:43Z",
    "authors": [
      "Pierre Bergé",
      "Kaourintin Le Guiban",
      "Arpad Rimmel",
      "Joanna Tomasik"
    ],
    "link": "http://arxiv.org/abs/1608.07225v1",
    "pdf_link": "http://arxiv.org/pdf/1608.07225v1"
  },
  {
    "api_id": 276,
    "title": "Marginal multi-Bernoulli filters: RFS derivation of MHT, JIPDA and\n  association-based MeMBer",
    "summary": "Recent developments in random finite sets (RFSs) have yielded a variety of\ntracking methods that avoid data association. This paper derives a form of the\nfull Bayes RFS filter and observes that data association is implicitly present,\nin a data structure similar to MHT. Subsequently, algorithms are obtained by\napproximating the distribution of associations. Two algorithms result: one\nnearly identical to JIPDA, and another related to the MeMBer filter. Both\nimprove performance in challenging environments.",
    "published": "2012-03-14T02:57:54Z",
    "updated": "2016-08-24T08:11:59Z",
    "authors": [
      "Jason L. Williams"
    ],
    "link": "http://arxiv.org/abs/1203.2995v6",
    "pdf_link": "http://arxiv.org/pdf/1203.2995v6"
  },
  {
    "api_id": 277,
    "title": "Design-Space Exploration and Optimization of an Energy-Efficient and\n  Reliable 3D Small-world Network-on-Chip",
    "summary": "A three-dimensional (3D) Network-on-Chip (NoC) enables the design of high\nperformance and low power many-core chips. Existing 3D NoCs are inadequate for\nmeeting the ever-increasing performance requirements of many-core processors\nsince they are simple extensions of regular 2D architectures and they do not\nfully exploit the advantages provided by 3D integration. Moreover, the\nanticipated performance gain of a 3D NoC-enabled many-core chip may be\ncompromised due to the potential failures of through-silicon-vias (TSVs) that\nare predominantly used as vertical interconnects in a 3D IC. To address these\nproblems, we propose a machine-learning-inspired predictive design methodology\nfor energy-efficient and reliable many-core architectures enabled by 3D\nintegration. We demonstrate that a small-world network-based 3D NoC (3D SWNoC)\nperforms significantly better than its 3D MESH-based counterparts. On average,\nthe 3D SWNoC shows 35% energy-delay-product (EDP) improvement over 3D MESH for\nthe PARSEC and SPLASH2 benchmarks considered in this work. To improve the\nreliability of 3D NoC, we propose a computationally efficient spare-vertical\nlink (sVL) allocation algorithm based on a state-space search formulation. Our\nresults show that the proposed sVL allocation algorithm can significantly\nimprove the reliability as well as the lifetime of 3D SWNoC.",
    "published": "2016-08-24T21:24:02Z",
    "updated": "2016-08-24T21:24:02Z",
    "authors": [
      "Sourav Das",
      "Janardhan Rao Doppa",
      "Partha Pratim Pande",
      "Krishnendu Chakrabarty"
    ],
    "link": "http://arxiv.org/abs/1608.06972v1",
    "pdf_link": "http://arxiv.org/pdf/1608.06972v1"
  },
  {
    "api_id": 278,
    "title": "Design and Autonomous Control of the Active Adaptive Suspension System\n  Rudra Mars Rover",
    "summary": "Semi or completely autonomous unmanned vehicles, remotely driven or\ncontrolled through artificial intelligence, are instrumental to foster space\nexploration. One of the most essential tasks of a rover is terrain traversing\nwhich requires the need of efficient suspension systems. This communication\npresents a suspension system giving degrees of freedom to every wheel with the\nhelp of linear actuators connected through bell crank levers. The actuation of\nlinear actuators directly varies the height of every wheel from the chassis\nhence offering articulation to the rover. A control system is developed\noffering an algorithm for its autonomous actuation. This system proves\ninstrumental for leveling of the chassis where any kind of slope, roll or\npitch, may impute abstaining of payloads from efficient working. This was tried\nand tested successfully as a part of the rover developed by Team RUDRA from SRM\nUniversity, INDIA (first Team from Asia and finishing at the fifth position) at\nUniversity Rover Challenge 2013, held at UTAH, USA in May-June.",
    "published": "2014-07-19T15:04:44Z",
    "updated": "2016-08-25T16:24:26Z",
    "authors": [
      "Karan Vaish",
      "Shah Mihir Rajesh",
      "K. Pasupatheeswaran",
      "Anubha Parashar",
      "Jyoti Chaturvedi"
    ],
    "link": "http://arxiv.org/abs/1407.5197v2",
    "pdf_link": "http://arxiv.org/pdf/1407.5197v2"
  },
  {
    "api_id": 279,
    "title": "Hyperspectral Image Recovery via Hybrid Regularization",
    "summary": "Natural images tend to mostly consist of smooth regions with individual\npixels having highly correlated spectra. This information can be exploited to\nrecover hyperspectral images of natural scenes from their incomplete and noisy\nmeasurements. To perform the recovery while taking full advantage of the prior\nknowledge, we formulate a composite cost function containing a square-error\ndata-fitting term and two distinct regularization terms pertaining to spatial\nand spectral domains. The regularization for the spatial domain is the sum of\ntotal-variation of the image frames corresponding to all spectral bands. The\nregularization for the spectral domain is the l1-norm of the coefficient matrix\nobtained by applying a suitable sparsifying transform to the spectra of the\npixels. We use an accelerated proximal-subgradient method to minimize the\nformulated cost function. We analyze the performance of the proposed algorithm\nand prove its convergence. Numerical simulations using real hyperspectral\nimages exhibit that the proposed algorithm offers an excellent recovery\nperformance with a number of measurements that is only a small fraction of the\nhyperspectral image data size. Simulation results also show that the proposed\nalgorithm significantly outperforms an accelerated proximal-gradient algorithm\nthat solves the classical basis-pursuit denoising problem to recover the\nhyperspectral image.",
    "published": "2015-11-09T23:31:31Z",
    "updated": "2016-08-26T02:27:31Z",
    "authors": [
      "Reza Arablouei",
      "Frank de Hoog"
    ],
    "link": "http://arxiv.org/abs/1511.02928v2",
    "pdf_link": "http://arxiv.org/pdf/1511.02928v2"
  },
  {
    "api_id": 280,
    "title": "Hyperspectral Unmixing with Endmember Variability using Partial\n  Membership Latent Dirichlet Allocation",
    "summary": "The application of Partial Membership Latent Dirichlet Allocation(PM-LDA) for\nhyperspectral endmember estimation and spectral unmixing is presented. PM-LDA\nprovides a model for a hyperspectral image analysis that accounts for spectral\nvariability and incorporates spatial information through the use of\nsuperpixel-based 'documents.' In our application of PM-LDA, we employ the\nNormal Compositional Model in which endmembers are represented as Normal\ndistributions to account for spectral variability and proportion vectors are\nmodeled as random variables governed by a Dirichlet distribution. The use of\nthe Dirichlet distribution enforces positivity and sum-to-one constraints on\nthe proportion values. Algorithm results on real hyperspectral data indicate\nthat PM-LDA produces endmember distributions that represent the ground truth\nclasses and their associated variability.",
    "published": "2016-09-12T17:32:41Z",
    "updated": "2016-09-12T17:32:41Z",
    "authors": [
      "Sheng Zou",
      "Alina Zare"
    ],
    "link": "http://arxiv.org/abs/1609.03500v1",
    "pdf_link": "http://arxiv.org/pdf/1609.03500v1"
  },
  {
    "api_id": 281,
    "title": "Pure density functional for strong correlations and the thermodynamic\n  limit from machine learning",
    "summary": "We use density-matrix renormalization group, applied to a one-dimensional\nmodel of continuum Hamiltonians, to accurately solve chains of hydrogen atoms\nof various separations and numbers of atoms. We train and test a\nmachine-learned approximation to $F[n]$, the universal part of the electronic\ndensity functional, to within quantum chemical accuracy. Our calculation (a)\nbypasses the standard Kohn-Sham approach, avoiding the need to find orbitals,\n(b) includes the strong correlation of highly-stretched bonds without any\nspecific difficulty (unlike all standard DFT approximations) and (c) is so\naccurate that it can be used to find the energy in the thermodynamic limit to\nquantum chemical accuracy.",
    "published": "2016-09-13T07:10:38Z",
    "updated": "2016-09-13T07:10:38Z",
    "authors": [
      "Li Li",
      "Thomas E. Baker",
      "Steven R. White",
      "Kieron Burke"
    ],
    "link": "http://arxiv.org/abs/1609.03705v1",
    "pdf_link": "http://arxiv.org/pdf/1609.03705v1"
  },
  {
    "api_id": 282,
    "title": "Technical Report: Band selection for nonlinear unmixing of hyperspectral\n  images as a maximal clique problem",
    "summary": "Kernel-based nonlinear mixing models have been applied to unmix spectral\ninformation of hyperspectral images when the type of mixing occurring in the\nscene is too complex or unknown. Such methods, however, usually require the\ninversion of matrices of sizes equal to the number of spectral bands. Reducing\nthe computational load of these methods remains a challenge in large scale\napplications. This paper proposes a centralized method for band selection (BS)\nin the reproducing kernel Hilbert space (RKHS). It is based upon the coherence\ncriterion, which sets the largest value allowed for correlations between the\nbasis kernel functions characterizing the unmixing model. We show that the\nproposed BS approach is equivalent to solving a maximum clique problem (MCP),\nthat is, searching for the biggest complete subgraph in a graph. Furthermore,\nwe devise a strategy for selecting the coherence threshold and the Gaussian\nkernel bandwidth using coherence bounds for linearly independent bases.\nSimulation results illustrate the efficiency of the proposed method.",
    "published": "2016-03-01T20:08:51Z",
    "updated": "2016-09-19T22:53:26Z",
    "authors": [
      "Tales Imbiriba",
      "José Carlos Moreira Bermudez",
      "Cédric Richard"
    ],
    "link": "http://arxiv.org/abs/1603.00437v2",
    "pdf_link": "http://arxiv.org/pdf/1603.00437v2"
  },
  {
    "api_id": 283,
    "title": "Detecting Changes Between Optical Images of Different Spatial and\n  Spectral Resolutions: a Fusion-Based Approach",
    "summary": "Change detection is one of the most challenging issues when analyzing\nremotely sensed images. Comparing several multi-date images acquired through\nthe same kind of sensor is the most common scenario. Conversely, designing\nrobust, flexible and scalable algorithms for change detection becomes even more\nchallenging when the images have been acquired by two different kinds of\nsensors. This situation arises in case of emergency under critical constraints.\nThis paper presents, to the best of authors' knowledge, the first strategy to\ndeal with optical images characterized by dissimilar spatial and spectral\nresolutions. Typical considered scenarios include change detection between\npanchromatic or multispectral and hyperspectral images. The proposed strategy\nconsists of a 3-step procedure: i) inferring a high spatial and spectral\nresolution image by fusion of the two observed images characterized one by a\nlow spatial resolution and the other by a low spectral resolution, ii)\npredicting two images with respectively the same spatial and spectral\nresolutions as the observed images by degradation of the fused one and iii)\nimplementing a decision rule to each pair of observed and predicted images\ncharacterized by the same spatial and spectral resolutions to identify changes.\nThe performance of the proposed framework is evaluated on real images with\nsimulated realistic changes.",
    "published": "2016-09-20T09:58:35Z",
    "updated": "2016-09-20T09:58:35Z",
    "authors": [
      "Vinicius Ferraris",
      "Nicolas Dobigeon",
      "Qi Wei",
      "Marie Chabert"
    ],
    "link": "http://arxiv.org/abs/1609.06074v1",
    "pdf_link": "http://arxiv.org/pdf/1609.06074v1"
  },
  {
    "api_id": 284,
    "title": "Robust Fusion of Multi-Band Images with Different Spatial and Spectral\n  Resolutions for Change Detection",
    "summary": "Archetypal scenarios for change detection generally consider two images\nacquired through sensors of the same modality. However, in some specific cases\nsuch as emergency situations, the only images available may be those acquired\nthrough different kinds of sensors. More precisely, this paper addresses the\nproblem of detecting changes between two multi-band optical images\ncharacterized by different spatial and spectral resolutions. This sensor\ndissimilarity introduces additional issues in the context of operational change\ndetection. To alleviate these issues, classical change detection methods are\napplied after independent preprocessing steps (e.g., resampling) used to get\nthe same spatial and spectral resolutions for the pair of observed images.\nNevertheless, these preprocessing steps tend to throw away relevant\ninformation. Conversely, in this paper, we propose a method that more\neffectively uses the available information by modeling the two observed images\nas spatial and spectral versions of two (unobserved) latent images\ncharacterized by the same high spatial and high spectral resolutions. As they\ncover the same scene, these latent images are expected to be globally similar\nexcept for possible changes in sparse spatial locations. Thus, the change\ndetection task is envisioned through a robust multi-band image fusion method\nwhich enforces the differences between the estimated latent images to be\nspatially sparse. This robust fusion problem is formulated as an inverse\nproblem which is iteratively solved using an efficient block-coordinate descent\nalgorithm. The proposed method is applied to real panchormatic/multispectral\nand hyperspectral images with simulated realistic changes. A comparison with\nstate-of-the-art change detection methods evidences the accuracy of the\nproposed strategy.",
    "published": "2016-09-20T10:04:04Z",
    "updated": "2016-09-20T10:04:04Z",
    "authors": [
      "Vinicius Ferraris",
      "Nicolas Dobigeon",
      "Qi Wei",
      "Marie Chabert"
    ],
    "link": "http://arxiv.org/abs/1609.06076v1",
    "pdf_link": "http://arxiv.org/pdf/1609.06076v1"
  },
  {
    "api_id": 285,
    "title": "On the usability of deep networks for object-based image analysis",
    "summary": "As computer vision before, remote sensing has been radically changed by the\nintroduction of Convolution Neural Networks. Land cover use, object detection\nand scene understanding in aerial images rely more and more on deep learning to\nachieve new state-of-the-art results. Recent architectures such as Fully\nConvolutional Networks (Long et al., 2015) can even produce pixel level\nannotations for semantic mapping. In this work, we show how to use such deep\nnetworks to detect, segment and classify different varieties of wheeled\nvehicles in aerial images from the ISPRS Potsdam dataset. This allows us to\ntackle object detection and classification on a complex dataset made up of\nvisually similar classes, and to demonstrate the relevance of such a subclass\nmodeling approach. Especially, we want to show that deep learning is also\nsuitable for object-oriented analysis of Earth Observation data. First, we\ntrain a FCN variant on the ISPRS Potsdam dataset and show how the learnt\nsemantic maps can be used to extract precise segmentation of vehicles, which\nallow us studying the repartition of vehicles in the city. Second, we train a\nCNN to perform vehicle classification on the VEDAI (Razakarivony and Jurie,\n2016) dataset, and transfer its knowledge to classify candidate segmented\nvehicles on the Potsdam dataset.",
    "published": "2016-09-22T07:39:37Z",
    "updated": "2016-09-22T07:39:37Z",
    "authors": [
      "Nicolas Audebert",
      "Bertrand Le Saux",
      "Sébastien Lefèvre"
    ],
    "link": "http://arxiv.org/abs/1609.06845v1",
    "pdf_link": "http://arxiv.org/pdf/1609.06845v1"
  },
  {
    "api_id": 286,
    "title": "Semantic Segmentation of Earth Observation Data Using Multimodal and\n  Multi-scale Deep Networks",
    "summary": "This work investigates the use of deep fully convolutional neural networks\n(DFCNN) for pixel-wise scene labeling of Earth Observation images. Especially,\nwe train a variant of the SegNet architecture on remote sensing data over an\nurban area and study different strategies for performing accurate semantic\nsegmentation. Our contributions are the following: 1) we transfer efficiently a\nDFCNN from generic everyday images to remote sensing images; 2) we introduce a\nmulti-kernel convolutional layer for fast aggregation of predictions at\nmultiple scales; 3) we perform data fusion from heterogeneous sensors (optical\nand laser) using residual correction. Our framework improves state-of-the-art\naccuracy on the ISPRS Vaihingen 2D Semantic Labeling dataset.",
    "published": "2016-09-22T07:42:06Z",
    "updated": "2016-09-22T07:42:06Z",
    "authors": [
      "Nicolas Audebert",
      "Bertrand Le Saux",
      "Sébastien Lefèvre"
    ],
    "link": "http://arxiv.org/abs/1609.06846v1",
    "pdf_link": "http://arxiv.org/pdf/1609.06846v1"
  },
  {
    "api_id": 287,
    "title": "How Useful is Region-based Classification of Remote Sensing Images in a\n  Deep Learning Framework?",
    "summary": "In this paper, we investigate the impact of segmentation algorithms as a\npreprocessing step for classification of remote sensing images in a deep\nlearning framework. Especially, we address the issue of segmenting the image\ninto regions to be classified using pre-trained deep neural networks as feature\nextractors for an SVM-based classifier. An efficient segmentation as a\npreprocessing step helps learning by adding a spatially-coherent structure to\nthe data. Therefore, we compare algorithms producing superpixels with more\ntraditional remote sensing segmentation algorithms and measure the variation in\nterms of classification accuracy. We establish that superpixel algorithms allow\nfor a better classification accuracy as a homogenous and compact segmentation\nfavors better generalization of the training samples.",
    "published": "2016-09-22T08:21:20Z",
    "updated": "2016-09-22T08:21:20Z",
    "authors": [
      "Nicolas Audebert",
      "Bertrand Le Saux",
      "Sébastien Lefèvre"
    ],
    "link": "http://arxiv.org/abs/1609.06861v1",
    "pdf_link": "http://arxiv.org/pdf/1609.06861v1"
  },
  {
    "api_id": 288,
    "title": "Small near-Earth asteroids in the Palomar Transient Factory survey: A\n  real-time streak-detection system",
    "summary": "Near-Earth asteroids (NEAs) in the 1-100 meter size range are estimated to be\n$\\sim$1,000 times more numerous than the $\\sim$15,000 currently-catalogued\nNEAs, most of which are in the 0.5-10 kilometer size range. Impacts from 10-100\nmeter size NEAs are not statistically life-threatening but may cause\nsignificant regional damage, while 1-10 meter size NEAs with low velocities\nrelative to Earth are compelling targets for space missions. We describe the\nimplementation and initial results of a real-time NEA-discovery system\nspecialized for the detection of small, high angular rate (visually-streaked)\nNEAs in Palomar Transient Factory (PTF) images. PTF is a 1.2-m aperture,\n7.3-deg$^2$ field-of-view optical survey designed primarily for the discovery\nof extragalactic transients (e.g., supernovae) in 60-second exposures reaching\n$\\sim$20.5 visual magnitude. Our real-time NEA discovery pipeline uses a\nmachine-learned classifier to filter a large number of false-positive streak\ndetections, permitting a human scanner to efficiently and remotely identify\nreal asteroid streaks during the night. Upon recognition of a streaked NEA\ndetection (typically within an hour of the discovery exposure), the scanner\ntriggers follow-up with the same telescope and posts the observations to the\nMinor Planet Center for worldwide confirmation. We describe our ten initial\nconfirmed discoveries, all small NEAs that passed 0.3-15 lunar distances from\nEarth. Lastly, we derive useful scaling laws for comparing\nstreaked-NEA-detection capabilities of different surveys as a function of their\nhardware and survey-pattern characteristics. This work most directly informs\nestimates of the streak-detection capabilities of the Zwicky Transient Facility\n(ZTF, planned to succeed PTF in 2017), which will apply PTF's current\nresolution and sensitivity over a 47-deg$^2$ field-of-view.",
    "published": "2016-09-26T15:15:09Z",
    "updated": "2016-09-26T15:15:09Z",
    "authors": [
      "Adam Waszczak",
      "Thomas A. Prince",
      "Russ Laher",
      "Frank Masci",
      "Brian Bue",
      "Umaa Rebbapragada",
      "Tom Barlow",
      "Jason Surace",
      "George Helou",
      "Shrinivas Kulkarni"
    ],
    "link": "http://arxiv.org/abs/1609.08018v1",
    "pdf_link": "http://arxiv.org/pdf/1609.08018v1"
  },
  {
    "api_id": 289,
    "title": "Mobility Map Computations for Autonomous Navigation using an RGBD Sensor",
    "summary": "In recent years, the numbers of life-size humanoids as well as their mobile\ncapabilities have steadily grown. Stable walking motion and control for\nhumanoid robots are active fields of research. In this scenario an open\nquestion is how to model and analyse the scene so that a motion planning\nalgorithm can generate an appropriate walking pattern. This paper presents the\ncurrent work towards scene modelling and understanding, using an RGBD sensor.\nThe main objective is to provide the humanoid robot iCub with capabilities to\nnavigate safely and interact with various parts of the environment. In this\nsense we address the problem of traversability analysis of the scene, focusing\non classification of point clouds as a function of mobility, and hence walking\nsafety.",
    "published": "2016-10-05T09:22:32Z",
    "updated": "2016-10-05T09:22:32Z",
    "authors": [
      "Nicolò Genesio",
      "Tariq Abuhashim",
      "Fabio Solari",
      "Manuela Chessa",
      "Lorenzo Natale"
    ],
    "link": "http://arxiv.org/abs/1610.01326v1",
    "pdf_link": "http://arxiv.org/pdf/1610.01326v1"
  },
  {
    "api_id": 290,
    "title": "Transit Shapes and Self Organising Maps as a Tool for Ranking Planetary\n  Candidates: Application to Kepler and K2",
    "summary": "A crucial step in planet hunting surveys is to select the best candidates for\nfollow up observations, given limited telescope resources. This is often\nperformed by human `eyeballing', a time consuming and statistically awkward\nprocess. Here we present a new, fast machine learning technique to separate\ntrue planet signals from astrophysical false positives. We use Self Organising\nMaps (SOMs) to study the transit shapes of \\emph{Kepler} and \\emph{K2} known\nand candidate planets. We find that SOMs are capable of distinguishing known\nplanets from known false positives with a success rate of 87.0\\%, using the\ntransit shape alone. Furthermore, they do not require any candidates to be\ndispositioned prior to use, meaning that they can be used early in a mission's\nlifetime. A method for classifying candidates using a SOM is developed, and\napplied to previously unclassified members of the \\emph{Kepler} KOI list as\nwell as candidates from the \\emph{K2} mission. The method is extremely fast,\ntaking minutes to run the entire KOI list on a typical laptop. We make\n\\texttt{Python} code for performing classifications publicly available, using\neither new SOMs or those created in this work. The SOM technique represents a\nnovel method for ranking planetary candidate lists, and can be used both alone\nor as part of a larger autovetting code.",
    "published": "2016-11-07T10:19:37Z",
    "updated": "2016-11-07T10:19:37Z",
    "authors": [
      "David J. Armstrong",
      "Don Pollacco",
      "Alexandre Santerne"
    ],
    "link": "http://arxiv.org/abs/1611.01968v1",
    "pdf_link": "http://arxiv.org/pdf/1611.01968v1"
  },
  {
    "api_id": 291,
    "title": "Neural Networks Designing Neural Networks: Multi-Objective\n  Hyper-Parameter Optimization",
    "summary": "Artificial neural networks have gone through a recent rise in popularity,\nachieving state-of-the-art results in various fields, including image\nclassification, speech recognition, and automated control. Both the performance\nand computational complexity of such models are heavily dependant on the design\nof characteristic hyper-parameters (e.g., number of hidden layers, nodes per\nlayer, or choice of activation functions), which have traditionally been\noptimized manually. With machine learning penetrating low-power mobile and\nembedded areas, the need to optimize not only for performance (accuracy), but\nalso for implementation complexity, becomes paramount. In this work, we present\na multi-objective design space exploration method that reduces the number of\nsolution networks trained and evaluated through response surface modelling.\nGiven spaces which can easily exceed 1020 solutions, manually designing a\nnear-optimal architecture is unlikely as opportunities to reduce network\ncomplexity, while maintaining performance, may be overlooked. This problem is\nexacerbated by the fact that hyper-parameters which perform well on specific\ndatasets may yield sub-par results on others, and must therefore be designed on\na per-application basis. In our work, machine learning is leveraged by training\nan artificial neural network to predict the performance of future candidate\nnetworks. The method is evaluated on the MNIST and CIFAR-10 image datasets,\noptimizing for both recognition accuracy and computational complexity.\nExperimental results demonstrate that the proposed method can closely\napproximate the Pareto-optimal front, while only exploring a small fraction of\nthe design space.",
    "published": "2016-11-07T15:38:39Z",
    "updated": "2016-11-07T15:38:39Z",
    "authors": [
      "Sean C. Smithson",
      "Guang Yang",
      "Warren J. Gross",
      "Brett H. Meyer"
    ],
    "link": "http://arxiv.org/abs/1611.02120v1",
    "pdf_link": "http://arxiv.org/pdf/1611.02120v1"
  },
  {
    "api_id": 292,
    "title": "Space Development and Space Science Together, an Historic Opportunity",
    "summary": "The national space programs have an historic opportunity to help solve the\nglobal-scale economic and environmental problems of Earth while becoming more\neffective at science through the use of space resources. Space programs will be\nmore cost-effective when they work to establish a supply chain in space, mining\nand manufacturing then replicating the assets of the supply chain so it grows\nto larger capacity. This has become achievable because of advances in robotics\nand artificial intelligence. It is roughly estimated that developing a lunar\noutpost that relies upon and also develops the supply chain will cost about 1/3\nor less of the existing annual budgets of the national space programs. It will\nrequire a sustained commitment of several decades to complete, during which\ntime science and exploration become increasingly effective. At the end, this\nspace industry will capable of addressing global-scale challenges including\nlimited resources, clean energy, economic development, and preservation of the\nenvironment. Other potential solutions, including nuclear fusion and\nterrestrial renewable energy sources, do not address the root problem of our\nlimited globe and there are real questions whether they will be inadequate or\ntoo late. While industry in space likewise cannot provide perfect assurance, it\nis uniquely able to solve the root problem, and it gives us an important chance\nthat we should grasp. What makes this such an historic opportunity is that the\nspace-based solution is obtainable as a side-benefit of doing space science and\nexploration within their existing budgets. Thinking pragmatically, it may take\nsome time for policymakers to agree that setting up a complete supply chain is\nan achievable goal, so this paper describes a strategy of incremental progress.",
    "published": "2016-09-02T20:09:24Z",
    "updated": "2016-11-07T23:12:28Z",
    "authors": [
      "Philip Metzger"
    ],
    "link": "http://arxiv.org/abs/1609.00737v3",
    "pdf_link": "http://arxiv.org/pdf/1609.00737v3"
  },
  {
    "api_id": 293,
    "title": "Evaluating Urbanization from Satellite and Aerial Images by means of a\n  statistical approach to the texture analysis",
    "summary": "Statistical methods are usually applied in the processing of digital images\nfor the analysis of the textures displayed by them. Aiming to evaluate the\nurbanization of a given location from satellite or aerial images, here we\nconsider a simple processing to distinguish in them the 'urban' from the\n'rural' texture. The method is based on the mean values and the standard\ndeviations of the colour tones of image pixels. The processing of the input\nimages allows to obtain some maps from which a quantitative evaluation of the\ntextures can be obtained.",
    "published": "2016-11-10T20:16:57Z",
    "updated": "2016-11-10T20:16:57Z",
    "authors": [
      "Amelia Carolina Sparavigna"
    ],
    "link": "http://arxiv.org/abs/1611.03469v1",
    "pdf_link": "http://arxiv.org/pdf/1611.03469v1"
  },
  {
    "api_id": 294,
    "title": "Adaptive Deep Pyramid Matching for Remote Sensing Scene Classification",
    "summary": "Convolutional neural networks (CNNs) have attracted increasing attention in\nthe remote sensing community. Most CNNs only take the last fully-connected\nlayers as features for the classification of remotely sensed images, discarding\nthe other convolutional layer features which may also be helpful for\nclassification purposes. In this paper, we propose a new adaptive deep pyramid\nmatching (ADPM) model that takes advantage of the features from all of the\nconvolutional layers for remote sensing image classification. To this end, the\noptimal fusing weights for different convolutional layers are learned from the\ndata itself. In remotely sensed scenes, the objects of interest exhibit\ndifferent scales in distinct scenes, and even a single scene may contain\nobjects with different sizes. To address this issue, we select the CNN with\nspatial pyramid pooling (SPP-net) as the basic deep network, and further\nconstruct a multi-scale ADPM model to learn complementary information from\nmulti-scale images. Our experiments have been conducted using two widely used\nremote sensing image databases, and the results show that the proposed method\nsignificantly improves the performance when compared to other state-of-the-art\nmethods.",
    "published": "2016-11-11T05:17:56Z",
    "updated": "2016-11-11T05:17:56Z",
    "authors": [
      "Qingshan Liu",
      "Renlong Hang",
      "Huihui Song",
      "Fuping Zhu",
      "Javier Plaza",
      "Antonio Plaza"
    ],
    "link": "http://arxiv.org/abs/1611.03589v1",
    "pdf_link": "http://arxiv.org/pdf/1611.03589v1"
  },
  {
    "api_id": 295,
    "title": "Learning Multi-Scale Deep Features for High-Resolution Satellite Image\n  Classification",
    "summary": "In this paper, we propose a multi-scale deep feature learning method for\nhigh-resolution satellite image classification. Specifically, we firstly warp\nthe original satellite image into multiple different scales. The images in each\nscale are employed to train a deep convolutional neural network (DCNN).\nHowever, simultaneously training multiple DCNNs is time-consuming. To address\nthis issue, we explore DCNN with spatial pyramid pooling (SPP-net). Since\ndifferent SPP-nets have the same number of parameters, which share the\nidentical initial values, and only fine-tuning the parameters in\nfully-connected layers ensures the effectiveness of each network, thereby\ngreatly accelerating the training process. Then, the multi-scale satellite\nimages are fed into their corresponding SPP-nets respectively to extract\nmulti-scale deep features. Finally, a multiple kernel learning method is\ndeveloped to automatically learn the optimal combination of such features.\nExperiments on two difficult datasets show that the proposed method achieves\nfavorable performance compared to other state-of-the-art methods.",
    "published": "2016-11-11T05:31:42Z",
    "updated": "2016-11-11T05:31:42Z",
    "authors": [
      "Qingshan Liu",
      "Renlong Hang",
      "Huihui Song",
      "Zhi Li"
    ],
    "link": "http://arxiv.org/abs/1611.03591v1",
    "pdf_link": "http://arxiv.org/pdf/1611.03591v1"
  },
  {
    "api_id": 296,
    "title": "Feature Extraction and Soft Computing Methods for Aerospace Structure\n  Defect Classification",
    "summary": "This study concerns the effectiveness of several techniques and methods of\nsignals processing and data interpretation for the diagnosis of aerospace\nstructure defects. This is done by applying different known feature extraction\nmethods, in addition to a new CBIR-based one; and some soft computing\ntechniques including a recent HPC parallel implementation of the U-BRAIN\nlearning algorithm on Non Destructive Testing data. The performance of the\nresulting detection systems are measured in terms of Accuracy, Sensitivity,\nSpecificity, and Precision. Their effectiveness is evaluated by the Matthews\ncorrelation, the Area Under Curve (AUC), and the F-Measure. Several experiments\nare performed on a standard dataset of eddy current signal samples for aircraft\nstructures. Our experimental results evidence that the key to a successful\ndefect classifier is the feature extraction method - namely the novel\nCBIR-based one outperforms all the competitors - and they illustrate the\ngreater effectiveness of the U-BRAIN algorithm and the MLP neural network among\nthe soft computing methods in this kind of application.\n  Keywords- Non-destructive testing (NDT); Soft Computing; Feature Extraction;\nClassification Algorithms; Content-Based Image Retrieval (CBIR); Eddy Currents\n(EC).",
    "published": "2016-11-15T10:47:12Z",
    "updated": "2016-11-15T10:47:12Z",
    "authors": [
      "Gianni D'Angelo",
      "Salvatore Rampone"
    ],
    "link": "http://arxiv.org/abs/1611.04782v1",
    "pdf_link": "http://arxiv.org/pdf/1611.04782v1"
  },
  {
    "api_id": 297,
    "title": "Atmospheric tides in Earth-like planets",
    "summary": "Atmospheric tides can strongly affect the rotational dynamics of planets. In\nthe family of Earth-like planets, such as Venus, this physical mechanism\ncoupled with solid tides makes the angular velocity evolve over long timescales\nand determines the equilibrium configurations of their spin. Contrary to the\nsolid core, the atmosphere is submitted to both tidal gravitational potential\nand insolation flux coming from the star. The complex response of the gas is\nintrinsically linked to its physical properties. This dependence has to be\ncharacterized and quantified to study the large variety of extrasolar planetary\nsystems. We develop a theoretical global model where radiative losses, which\nare predominant in slowly rotating atmospheres, are taken into account. We\nanalytically compute the tidal perturbation of pressure, density, temperature\nand velocity field from which we deduce the expressions of atmospheric Love\nnumbers and tidal torque exerted by the star. The dynamics of atmospheric tides\ndepends on the frequency regime of the tidal perturbation: the thermal regime\nnear synchronization and the dynamical regime characterizing fast-rotating\nplanets. The dependence of the torque on the tidal frequency is quantified for\nEarth-like and Venus-like exoplanets and is in good agreement with the results\ngiven by Global Climate Models (GCM) simulations. Introducing dissipative\nprocesses such as radiation regularizes the tidal response of the atmosphere,\notherwise it is singular at synchronization. We demonstrate the important role\nplayed by the physical and dynamical properties of a super-Earth atmosphere\n(e.g. Coriolis, stratification, background pressure, density, temperature,\nradiative emission) and point out the key parameters defining tidal regimes\n(e.g. inertia, Brunt-V\\\"ais\\\"al\\\"a, radiative frequencies, tidal frequency) and\ncharacterize the behaviour of the fluid shell with dissipation.",
    "published": "2016-11-15T12:34:36Z",
    "updated": "2016-11-15T12:34:36Z",
    "authors": [
      "Pierre Auclair-Desrotour",
      "Jacques Laskar",
      "Stéphane Mathis"
    ],
    "link": "http://arxiv.org/abs/1611.04806v1",
    "pdf_link": "http://arxiv.org/pdf/1611.04806v1"
  },
  {
    "api_id": 298,
    "title": "Multilinear Low-Rank Tensors on Graphs & Applications",
    "summary": "We propose a new framework for the analysis of low-rank tensors which lies at\nthe intersection of spectral graph theory and signal processing. As a first\nstep, we present a new graph based low-rank decomposition which approximates\nthe classical low-rank SVD for matrices and multi-linear SVD for tensors. Then,\nbuilding on this novel decomposition we construct a general class of convex\noptimization problems for approximately solving low-rank tensor inverse\nproblems, such as tensor Robust PCA. The whole framework is named as\n'Multilinear Low-rank tensors on Graphs (MLRTG)'. Our theoretical analysis\nshows: 1) MLRTG stands on the notion of approximate stationarity of\nmulti-dimensional signals on graphs and 2) the approximation error depends on\nthe eigen gaps of the graphs. We demonstrate applications for a wide variety of\n4 artificial and 12 real tensor datasets, such as EEG, FMRI, BCI, surveillance\nvideos and hyperspectral images. Generalization of the tensor concepts to\nnon-euclidean domain, orders of magnitude speed-up, low-memory requirement and\nsignificantly enhanced performance at low SNR are the key aspects of our\nframework.",
    "published": "2016-11-15T14:05:43Z",
    "updated": "2016-11-15T14:05:43Z",
    "authors": [
      "Nauman Shahid",
      "Francesco Grassi",
      "Pierre Vandergheynst"
    ],
    "link": "http://arxiv.org/abs/1611.04835v1",
    "pdf_link": "http://arxiv.org/pdf/1611.04835v1"
  },
  {
    "api_id": 299,
    "title": "Correcting biased observation model error in data assimilation",
    "summary": "While the formulation of most data assimilation schemes assumes an unbiased\nobservation model error, in real applications, model error with nontrivial\nbiases is unavoidable. A practical example is the error in the radiative\ntransfer model (which is used to assimilate satellite measurements) in the\npresence of clouds. As a consequence, many (in fact 99\\%) of the cloudy\nobserved measurements are not being used although they may contain useful\ninformation. This paper presents a novel nonparametric Bayesian scheme which is\nable to learn the observation model error distribution and correct the bias in\nincoming observations. This scheme can be used in tandem with any data\nassimilation forecasting system. The proposed model error estimator uses\nnonparametric likelihood functions constructed with data-driven basis functions\nbased on the theory of kernel embeddings of conditional distributions developed\nin the machine learning community. Numerically, we show positive results with\ntwo examples. The first example is designed to produce a bimodality in the\nobservation model error (typical of \"cloudy\" observations) by introducing\nobstructions to the observations which occur randomly in space and time. The\nsecond example, which is physically more realistic, is to assimilate cloudy\nsatellite brightness temperature-like quantities, generated from a stochastic\ncloud model for tropical convection and a simple radiative transfer model.",
    "published": "2016-11-16T18:48:18Z",
    "updated": "2016-11-16T18:48:18Z",
    "authors": [
      "John Harlim",
      "Tyrus Berry"
    ],
    "link": "http://arxiv.org/abs/1611.05405v1",
    "pdf_link": "http://arxiv.org/pdf/1611.05405v1"
  },
  {
    "api_id": 300,
    "title": "The Geodesic Distance between $\\mathcal{G}_I^0$ Models and its\n  Application to Region Discrimination",
    "summary": "The $\\mathcal{G}_I^0$ distribution is able to characterize different regions\nin monopolarized SAR imagery. It is indexed by three parameters: the number of\nlooks (which can be estimated in the whole image), a scale parameter and a\ntexture parameter. This paper presents a new proposal for feature extraction\nand region discrimination in SAR imagery, using the geodesic distance as a\nmeasure of dissimilarity between $\\mathcal{G}_I^0$ models. We derive geodesic\ndistances between models that describe several practical situations, assuming\nthe number of looks known, for same and different texture and for same and\ndifferent scale. We then apply this new tool to the problems of (i)~identifying\nedges between regions with different texture, and (ii)~quantify the\ndissimilarity between pairs of samples in actual SAR data. We analyze the\nadvantages of using the geodesic distance when compared to stochastic\ndistances.",
    "published": "2017-01-01T22:37:13Z",
    "updated": "2017-01-01T22:37:13Z",
    "authors": [
      "José Naranjo-Torres",
      "Juliana Gambini",
      "Alejandro C. Frery"
    ],
    "link": "http://arxiv.org/abs/1701.00294v1",
    "pdf_link": "http://arxiv.org/pdf/1701.00294v1"
  },
  {
    "api_id": 301,
    "title": "Early Science with the Large Millimetre Telescope: Molecules in the\n  Extreme Outflow of a proto-Planetary Nebula",
    "summary": "Extremely high velocity emission likely related to jets is known to occur in\nsome proto-Planetary Nebulae. However, the molecular complexity of this\nkinematic component is largely unknown. We observed the known extreme outflow\nfrom the proto-Planetary Nebula IRAS 16342-3814, a prototype water fountain, in\nthe full frequency range from 73 to 111 GHz with the RSR receiver on the Large\nMillimetre Telescope. We detected the molecules SiO, HCN, SO, and $^{13}$CO.\nAll molecular transitions, with the exception of the latter are detected for\nthe first time in this source, and all present emission with velocities up to a\nfew hundred km s$^{-1}$. IRAS 16342-3814 is therefore the only source of this\nkind presenting extreme outflow activity simultaneously in all these molecules,\nwith SO and SiO emission showing the highest velocities found of these species\nin proto-Planetary Nebulae. To be confirmed is a tentative weak SO component\nwith a FWHM $\\sim$ 700 km s$^{-1}$. The extreme outflow gas consists of dense\ngas (n$_{\\rm H_2} >$ 10$^{4.8}$--10$^{5.7}$ cm$^{-3}$), with a mass larger than\n$\\sim$ 0.02--0.15 M$_{\\odot}$. The relatively high abundances of SiO and SO may\nbe an indication of an oxygen-rich extreme high velocity gas.",
    "published": "2017-01-04T23:32:02Z",
    "updated": "2017-01-04T23:32:02Z",
    "authors": [
      "A. I. Gómez-Ruiz",
      "L. Guzman-Ramirez",
      "E. O. Serrano",
      "D. Sanchez-Arguelles",
      "A. Luna",
      "F. P. Schloerb",
      "G. Narayanan",
      "M. S. Yun",
      "R. Sahai",
      "A. A. Zijlstra",
      "M. Chavez-Dagostino",
      "A. Montaña",
      "D. H. Hughes",
      "M. Rodríguez"
    ],
    "link": "http://arxiv.org/abs/1701.01179v1",
    "pdf_link": "http://arxiv.org/pdf/1701.01179v1"
  },
  {
    "api_id": 302,
    "title": "Adapting astronomical source detection software to help detect animals\n  in thermal images obtained by unmanned aerial systems",
    "summary": "In this paper we describe an unmanned aerial system equipped with a\nthermal-infrared camera and software pipeline that we have developed to monitor\nanimal populations for conservation purposes. Taking a multi-disciplinary\napproach to tackle this problem, we use freely available astronomical source\ndetection software and the associated expertise of astronomers, to efficiently\nand reliably detect humans and animals in aerial thermal-infrared footage.\nCombining this astronomical detection software with existing machine learning\nalgorithms into a single, automated, end-to-end pipeline, we test the software\nusing aerial video footage taken in a controlled, field-like environment. We\ndemonstrate that the pipeline works reliably and describe how it can be used to\nestimate the completeness of different observational datasets to objects of a\ngiven type as a function of height, observing conditions etc. -- a crucial step\nin converting video footage to scientifically useful information such as the\nspatial distribution and density of different animal species. Finally, having\ndemonstrated the potential utility of the system, we describe the steps we are\ntaking to adapt the system for work in the field, in particular systematic\nmonitoring of endangered species at National Parks around the world.",
    "published": "2017-01-06T12:15:05Z",
    "updated": "2017-01-06T12:15:05Z",
    "authors": [
      "S. N. Longmore",
      "R. P. Collins",
      "S. Pfeifer",
      "S. E. Fox",
      "M. Mulero-Pazmany",
      "F. Bezombes",
      "A. Goodwind",
      "M. de Juan Ovelar",
      "J. H. Knapen",
      "S. A. Wich"
    ],
    "link": "http://arxiv.org/abs/1701.01611v1",
    "pdf_link": "http://arxiv.org/pdf/1701.01611v1"
  },
  {
    "api_id": 303,
    "title": "Automated Design of CubeSats and Small Spacecrafts",
    "summary": "The miniaturization of electronics, sensors and actuators has enabled the\ngrowing use of CubeSats and sub-20 kg spacecraft. Their reduced mass and volume\nhas the potential to translate into significant reductions in required\npropellant and launch mass for interplanetary missions, earth observation and\nfor astrophysics applications. There is an important need to optimize the\ndesign of these spacecraft to better ascertain their maximal capabilities by\nfinding optimized solution, where mass, volume and power is a premium. Current\nspacecraft design methods require a team of experts, who use their engineering\nexperience and judgement to develop a spacecraft design. Such an approach can\nmiss innovative designs not thought of by a human design team. In this work we\npresent a compelling alternative approach that extends the capabilities of a\nspacecraft engineering design team to search for and identify near-optimal\nsolutions using machine learning. The approach enables automated design of a\nspacecraft that requires specifying quantitative goals, requiring reaching a\ntarget location or operating at a predetermined orbit for a required time. Next\na virtual warehouse of components is specified that be selected to produce a\ncandidate design. Candidate designs are produced using an artificial Darwinian\napproach, where fittest design survives and reproduce, while unfit individuals\nare culled off. Our past work in space robotic has produced systems designs and\ncontrollers that are human competitive. Finding a near-optimal solution\npresents vast improvements over a solution obtained through engineering\njudgment and point design alone. The approach shows a credible pathway to\nidentify and evaluate many more candidate designs than it would be otherwise\npossible with a human design team alone.",
    "published": "2017-01-06T19:42:44Z",
    "updated": "2017-01-06T19:42:44Z",
    "authors": [
      "Himangshu Kalita",
      "Jekan Thangavelautham"
    ],
    "link": "http://arxiv.org/abs/1701.01742v1",
    "pdf_link": "http://arxiv.org/pdf/1701.01742v1"
  },
  {
    "api_id": 304,
    "title": "Map-guided Hyperspectral Image Superpixel Segmentation Using Proportion\n  Maps",
    "summary": "A map-guided superpixel segmentation method for hyperspectral imagery is\ndeveloped and introduced. The proposed approach develops a\nhyperspectral-appropriate version of the SLIC superpixel segmentation\nalgorithm, leverages map information to guide segmentation, and incorporates\nthe semi-supervised Partial Membership Latent Dirichlet Allocation (sPM-LDA) to\nobtain a final superpixel segmentation. The proposed method is applied to two\nreal hyperspectral data sets and quantitative cluster validity metrics indicate\nthat the proposed approach outperforms existing hyperspectral superpixel\nsegmentation methods.",
    "published": "2017-01-06T19:52:10Z",
    "updated": "2017-01-06T19:52:10Z",
    "authors": [
      "Hao Sun",
      "Alina Zare"
    ],
    "link": "http://arxiv.org/abs/1701.01745v1",
    "pdf_link": "http://arxiv.org/pdf/1701.01745v1"
  },
  {
    "api_id": 305,
    "title": "Stage 4 validation of the Satellite Image Automatic Mapper lightweight\n  computer program for Earth observation Level 2 product generation, Part 1\n  Theory",
    "summary": "The European Space Agency (ESA) defines an Earth Observation (EO) Level 2\nproduct as a multispectral (MS) image corrected for geometric, atmospheric,\nadjacency and topographic effects, stacked with its scene classification map\n(SCM), whose legend includes quality layers such as cloud and cloud-shadow. No\nESA EO Level 2 product has ever been systematically generated at the ground\nsegment. To contribute toward filling an information gap from EO big data to\nthe ESA EO Level 2 product, an original Stage 4 validation (Val) of the\nSatellite Image Automatic Mapper (SIAM) lightweight computer program was\nconducted by independent means on an annual Web-Enabled Landsat Data (WELD)\nimage composite time-series of the conterminous U.S. The core of SIAM is a one\npass prior knowledge based decision tree for MS reflectance space\nhyperpolyhedralization into static color names presented in literature in\nrecent years. For the sake of readability this paper is split into two. The\npresent Part 1 Theory provides the multidisciplinary background of a priori\ncolor naming in cognitive science, from linguistics to computer vision. To cope\nwith dictionaries of MS color names and land cover class names that do not\ncoincide and must be harmonized, an original hybrid guideline is proposed to\nidentify a categorical variable pair relationship. An original quantitative\nmeasure of categorical variable pair association is also proposed. The\nsubsequent Part 2 Validation discusses Stage 4 Val results collected by an\noriginal protocol for wall-to-wall thematic map quality assessment without\nsampling where the test and reference map legends can differ. Conclusions are\nthat the SIAM-WELD maps instantiate a Level 2 SCM product whose legend is the 4\nclass taxonomy of the FAO Land Cover Classification System at the Dichotomous\nPhase Level 1 vegetation/nonvegetation and Level 2 terrestrial/aquatic.",
    "published": "2017-01-08T09:26:49Z",
    "updated": "2017-01-08T09:26:49Z",
    "authors": [
      "Andrea Baraldi",
      "Michael Laurence Humber",
      "Dirk Tiede",
      "Stefan Lang"
    ],
    "link": "http://arxiv.org/abs/1701.01930v1",
    "pdf_link": "http://arxiv.org/pdf/1701.01930v1"
  },
  {
    "api_id": 306,
    "title": "Stage 4 validation of the Satellite Image Automatic Mapper lightweight\n  computer program for Earth observation Level 2 product generation, Part 2\n  Validation",
    "summary": "The European Space Agency (ESA) defines an Earth Observation (EO) Level 2\nproduct as a multispectral (MS) image corrected for geometric, atmospheric,\nadjacency and topographic effects, stacked with its scene classification map\n(SCM) whose legend includes quality layers such as cloud and cloud-shadow. No\nESA EO Level 2 product has ever been systematically generated at the ground\nsegment. To contribute toward filling an information gap from EO big sensory\ndata to the ESA EO Level 2 product, a Stage 4 validation (Val) of an off the\nshelf Satellite Image Automatic Mapper (SIAM) lightweight computer program for\nprior knowledge based MS color naming was conducted by independent means. A\ntime-series of annual Web Enabled Landsat Data (WELD) image composites of the\nconterminous U.S. (CONUS) was selected as input dataset. The annual SIAM WELD\nmaps of the CONUS were validated in comparison with the U.S. National Land\nCover Data (NLCD) 2006 map. These test and reference maps share the same\nspatial resolution and spatial extent, but their map legends are not the same\nand must be harmonized. For the sake of readability this paper is split into\ntwo. The previous Part 1 Theory provided the multidisciplinary background of a\npriori color naming. The present Part 2 Validation presents and discusses Stage\n4 Val results collected from the test SIAM WELD map time series and the\nreference NLCD map by an original protocol for wall to wall thematic map\nquality assessment without sampling, where the test and reference map legends\ncan differ in agreement with the Part 1. Conclusions are that the SIAM-WELD\nmaps instantiate a Level 2 SCM product whose legend is the FAO Land Cover\nClassification System (LCCS) taxonomy at the Dichotomous Phase (DP) Level 1\nvegetation/nonvegetation, Level 2 terrestrial/aquatic or superior LCCS level.",
    "published": "2017-01-08T09:35:30Z",
    "updated": "2017-01-08T09:35:30Z",
    "authors": [
      "Andrea Baraldi",
      "Michael Laurence Humber",
      "Dirk Tiede",
      "Stefan Lang"
    ],
    "link": "http://arxiv.org/abs/1701.01932v1",
    "pdf_link": "http://arxiv.org/pdf/1701.01932v1"
  },
  {
    "api_id": 307,
    "title": "Automated Linear-Time Detection and Quality Assessment of Superpixels in\n  Uncalibrated True- or False-Color RGB Images",
    "summary": "Capable of automated near real time superpixel detection and quality\nassessment in an uncalibrated monitor typical red green blue (RGB) image,\ndepicted in either true or false colors, an original low level computer vision\n(CV) lightweight computer program, called RGB Image Automatic Mapper (RGBIAM),\nis designed and implemented. Constrained by the Calibration Validation (CalVal)\nrequirements of the Quality Assurance Framework for Earth Observation (QA4EO)\nguidelines, RGBIAM requires as mandatory an uncalibrated RGB image pre\nprocessing first stage, consisting of an automated statistical model based\ncolor constancy algorithm. The RGBIAM hybrid inference pipeline comprises: (I)\na direct quantitative to nominal (QN) RGB variable transform, where RGB pixel\nvalues are mapped onto a prior dictionary of color names, equivalent to a\nstatic polyhedralization of the RGB cube. Prior color naming is the deductive\ncounterpart of inductive vector quantization (VQ), whose typical VQ error\nfunction to minimize is a root mean square error (RMSE). In the output multi\nlevel color map domain, superpixels are automatically detected in linear time\nas connected sets of pixels featuring the same color label. (II) An inverse\nnominal to quantitative (NQ) RGB variable transform, where a superpixelwise\nconstant RGB image approximation is generated in linear time to assess a VQ\nerror image. The hybrid direct and inverse RGBIAM QNQ transform is: (i) general\npurpose, data and application independent. (ii) Automated, i.e., it requires no\nuser machine interaction. (iii) Near real time, with a computational complexity\nincreasing linearly with the image size. (iv) Implemented in tile streaming\nmode, to cope with massive images. Collected outcome and process quality\nindicators, including degree of automation, computational efficiency, VQ rate\nand VQ error, are consistent with theoretical expectations.",
    "published": "2017-01-08T11:09:59Z",
    "updated": "2017-01-08T11:09:59Z",
    "authors": [
      "Andrea Baraldi",
      "Dirk Tiede",
      "Stefan Lang"
    ],
    "link": "http://arxiv.org/abs/1701.01940v1",
    "pdf_link": "http://arxiv.org/pdf/1701.01940v1"
  },
  {
    "api_id": 308,
    "title": "Multi-spectral Image Panchromatic Sharpening, Outcome and Process\n  Quality Assessment Protocol",
    "summary": "Multispectral (MS) image panchromatic (PAN) sharpening algorithms proposed to\nthe remote sensing community are ever increasing in number and variety. Their\naim is to sharpen a coarse spatial resolution MS image with a fine spatial\nresolution PAN image acquired simultaneously by a spaceborne or airborne Earth\nobservation (EO) optical imaging sensor pair. Unfortunately, to date, no\nstandard evaluation procedure for MS image PAN sharpening outcome and process\nis community agreed upon, in contrast with the Quality Assurance Framework for\nEarth Observation (QA4EO) guidelines proposed by the intergovernmental Group on\nEarth Observations (GEO). In general, process is easier to measure, outcome is\nmore important. The original contribution of the present study is fourfold.\nFirst, existing procedures for quantitative quality assessment (Q2A) of the\n(sole) PAN sharpened MS product are critically reviewed. Their conceptual and\nimplementation drawbacks are highlighted to be overcome for quality\nimprovement. Second, a novel (to the best of these authors' knowledge, the\nfirst) protocol for Q2A of MS image PAN sharpening product and process is\ndesigned, implemented and validated by independent means. Third, within this\nprotocol, an innovative categorization of spectral and spatial image quality\nindicators and metrics is presented. Fourth, according to this new taxonomy, an\noriginal third order isotropic multi scale gray level co occurrence matrix\n(TIMS GLCM) calculator and a TIMS GLCM texture feature extractor are proposed\nto replace popular second order GLCMs.",
    "published": "2017-01-08T11:22:59Z",
    "updated": "2017-01-08T11:22:59Z",
    "authors": [
      "Andrea Baraldi",
      "Francesca Despini",
      "Sergio Teggi"
    ],
    "link": "http://arxiv.org/abs/1701.01942v1",
    "pdf_link": "http://arxiv.org/pdf/1701.01942v1"
  },
  {
    "api_id": 309,
    "title": "A dissimilarity-based approach to predictive maintenance with\n  application to HVAC systems",
    "summary": "The goal of predictive maintenance is to forecast the occurrence of faults of\nan appliance, in order to proactively take the necessary actions to ensure its\navailability. In many application scenarios, predictive maintenance is applied\nto a set of homogeneous appliances. In this paper, we firstly review taxonomies\nand main methodologies currently used for condition-based maintenance;\nsecondly, we argue that the mutual dissimilarities of the behaviours of all\nappliances of this set (the \"cohort\") can be exploited to detect upcoming\nfaults. Specifically, inspired by dissimilarity-based representations, we\npropose a novel machine learning approach based on the analysis of concurrent\nmutual differences of the measurements coming from the cohort. We evaluate our\nmethod over one year of historical data from a cohort of 17 HVAC (Heating,\nVentilation and Air Conditioning) systems installed in an Italian hospital. We\nshow that certain kinds of faults can be foreseen with an accuracy, measured in\nterms of area under the ROC curve, as high as 0.96.",
    "published": "2017-01-13T11:31:35Z",
    "updated": "2017-01-13T11:31:35Z",
    "authors": [
      "Riccardo Satta",
      "Stefano Cavallari",
      "Eraldo Pomponi",
      "Daniele Grasselli",
      "Davide Picheo",
      "Carlo Annis"
    ],
    "link": "http://arxiv.org/abs/1701.03633v1",
    "pdf_link": "http://arxiv.org/pdf/1701.03633v1"
  },
  {
    "api_id": 310,
    "title": "Multi-Objective Software Suite of Two-Dimensional Shape Descriptors for\n  Object-Based Image Analysis",
    "summary": "In recent years two sets of planar (2D) shape attributes, provided with an\nintuitive physical meaning, were proposed to the remote sensing community by,\nrespectively, Nagao & Matsuyama and Shackelford & Davis in their seminal works\non the increasingly popular geographic object based image analysis (GEOBIA)\nparadigm. These two published sets of intuitive geometric features were\nselected as initial conditions by the present R&D software project, whose\nmulti-objective goal was to accomplish: (i) a minimally dependent and maximally\ninformative design (knowledge/information representation) of a general purpose,\nuser and application independent dictionary of 2D shape terms provided with a\nphysical meaning intuitive to understand by human end users and (ii) an\neffective (accurate, scale invariant, easy to use) and efficient implementation\nof 2D shape descriptors. To comply with the Quality Assurance Framework for\nEarth Observation guidelines, the proposed suite of geometric functions is\nvalidated by means of a novel quantitative quality assurance policy, centered\non inter feature dependence (causality) assessment. This innovative\nmultivariate feature validation strategy is alternative to traditional feature\nselection procedures based on either inductive data learning classification\naccuracy estimation, which is inherently case specific, or cross correlation\nestimation, because statistical cross correlation does not imply causation. The\nproject deliverable is an original general purpose software suite of seven\nvalidated off the shelf 2D shape descriptors intuitive to use. Alternative to\nexisting commercial or open source software libraries of tens of planar shape\nfunctions whose informativeness remains unknown, it is eligible for use in\n(GE)OBIA systems in operating mode, expected to mimic human reasoning based on\na convergence of evidence approach.",
    "published": "2017-01-08T11:16:43Z",
    "updated": "2017-02-02T08:12:20Z",
    "authors": [
      "Andrea Baraldi",
      "João V. B. Soares"
    ],
    "link": "http://arxiv.org/abs/1701.01941v2",
    "pdf_link": "http://arxiv.org/pdf/1701.01941v2"
  },
  {
    "api_id": 311,
    "title": "Multi-feature combined cloud and cloud shadow detection in GaoFen-1 wide\n  field of view imagery",
    "summary": "The wide field of view (WFV) imaging system onboard the Chinese GaoFen-1\n(GF-1) optical satellite has a 16-m resolution and four-day revisit cycle for\nlarge-scale Earth observation. The advantages of the high temporal-spatial\nresolution and the wide field of view make the GF-1 WFV imagery very popular.\nHowever, cloud cover is an inevitable problem in GF-1 WFV imagery, which\ninfluences its precise application. Accurate cloud and cloud shadow detection\nin GF-1 WFV imagery is quite difficult due to the fact that there are only\nthree visible bands and one near-infrared band. In this paper, an automatic\nmulti-feature combined (MFC) method is proposed for cloud and cloud shadow\ndetection in GF-1 WFV imagery. The MFC algorithm first implements threshold\nsegmentation based on the spectral features and mask refinement based on guided\nfiltering to generate a preliminary cloud mask. The geometric features are then\nused in combination with the texture features to improve the cloud detection\nresults and produce the final cloud mask. Finally, the cloud shadow mask can be\nacquired by means of the cloud and shadow matching and follow-up correction\nprocess. The method was validated using 108 globally distributed scenes. The\nresults indicate that MFC performs well under most conditions, and the average\noverall accuracy of MFC cloud detection is as high as 96.8%. In the contrastive\nanalysis with the official provided cloud fractions, MFC shows a significant\nimprovement in cloud fraction estimation, and achieves a high accuracy for the\ncloud and cloud shadow detection in the GF-1 WFV imagery with fewer spectral\nbands. The proposed method could be used as a preprocessing step in the future\nto monitor land-cover change, and it could also be easily extended to other\noptical satellite imagery which has a similar spectral setting.",
    "published": "2016-06-17T03:26:54Z",
    "updated": "2017-02-05T04:59:29Z",
    "authors": [
      "Zhiwei Li",
      "Huanfeng Shen",
      "Huifang Li",
      "Guisong Xia",
      "Paolo Gamba",
      "Liangpei Zhang"
    ],
    "link": "http://arxiv.org/abs/1606.05415v4",
    "pdf_link": "http://arxiv.org/pdf/1606.05415v4"
  },
  {
    "api_id": 312,
    "title": "A large comparison of feature-based approaches for buried target\n  classification in forward-looking ground-penetrating radar",
    "summary": "Forward-looking ground-penetrating radar (FLGPR) has recently been\ninvestigated as a remote sensing modality for buried target detection (e.g.,\nlandmines). In this context, raw FLGPR data is beamformed into images and then\ncomputerized algorithms are applied to automatically detect subsurface buried\ntargets. Most existing algorithms are supervised, meaning they are trained to\ndiscriminate between labeled target and non-target imagery, usually based on\nfeatures extracted from the imagery. A large number of features have been\nproposed for this purpose, however thus far it is unclear which are the most\neffective. The first goal of this work is to provide a comprehensive comparison\nof detection performance using existing features on a large collection of FLGPR\ndata. Fusion of the decisions resulting from processing each feature is also\nconsidered. The second goal of this work is to investigate two modern feature\nlearning approaches from the object recognition literature: the\nbag-of-visual-words and the Fisher vector for FLGPR processing. The results\nindicate that the new feature learning approaches outperform existing methods.\nResults also show that fusion between existing features and new features yields\nlittle additional performance improvements.",
    "published": "2017-02-09T22:06:04Z",
    "updated": "2017-02-09T22:06:04Z",
    "authors": [
      "Joseph A. Camilo",
      "Leslie M. Collins",
      "Jordan M. Malof"
    ],
    "link": "http://arxiv.org/abs/1702.03000v1",
    "pdf_link": "http://arxiv.org/pdf/1702.03000v1"
  },
  {
    "api_id": 313,
    "title": "A clustering approach to heterogeneous change detection",
    "summary": "Change detection in heterogeneous multitemporal satellite images is a\nchallenging and still not much studied topic in remote sensing and earth\nobservation. This paper focuses on comparison of image pairs covering the same\ngeographical area and acquired by two different sensors, one optical radiometer\nand one synthetic aperture radar, at two different times. We propose a\nclustering-based technique to detect changes, identified as clusters that split\nor merge in the different images. To evaluate potentials and limitations of our\nmethod, we perform experiments on real data. Preliminary results confirm the\nrelationship between splits and merges of clusters and the occurrence of\nchanges. However, it becomes evident that it is necessary to incorporate prior,\nancillary, or application-specific information to improve the interpretation of\nclustering results and to identify unambiguously the areas of change.",
    "published": "2017-02-10T14:12:14Z",
    "updated": "2017-02-10T14:12:14Z",
    "authors": [
      "Luigi Tommaso Luppino",
      "Stian Normann Anfinsen",
      "Gabriele Moser",
      "Robert Jenssen",
      "Filippo Maria Bianchi",
      "Sebastiano Serpico",
      "Gregoire Mercier"
    ],
    "link": "http://arxiv.org/abs/1702.03176v1",
    "pdf_link": "http://arxiv.org/pdf/1702.03176v1"
  },
  {
    "api_id": 314,
    "title": "Data-Intensive Supercomputing in the Cloud: Global Analytics for\n  Satellite Imagery",
    "summary": "We present our experiences using cloud computing to support data-intensive\nanalytics on satellite imagery for commercial applications. Drawing from our\nbackground in high-performance computing, we draw parallels between the early\ndays of clustered computing systems and the current state of cloud computing\nand its potential to disrupt the HPC market. Using our own virtual file system\nlayer on top of cloud remote object storage, we demonstrate aggregate read\nbandwidth of 230 gigabytes per second using 512 Google Compute Engine (GCE)\nnodes accessing a USA multi-region standard storage bucket. This figure is\ncomparable to the best HPC storage systems in existence. We also present\nseveral of our application results, including the identification of field\nboundaries in Ukraine, and the generation of a global cloud-free base layer\nfrom Landsat imagery.",
    "published": "2017-02-13T19:00:04Z",
    "updated": "2017-02-13T19:00:04Z",
    "authors": [
      "Michael S. Warren",
      "Samuel W. Skillman",
      "Rick Chartrand",
      "Tim Kelton",
      "Ryan Keisler",
      "David Raleigh",
      "Matthew Turk"
    ],
    "link": "http://arxiv.org/abs/1702.03935v1",
    "pdf_link": "http://arxiv.org/pdf/1702.03935v1"
  },
  {
    "api_id": 315,
    "title": "Unsupervised Classification in Hyperspectral Imagery with Nonlocal Total\n  Variation and Primal-Dual Hybrid Gradient Algorithm",
    "summary": "In this paper, a graph-based nonlocal total variation method (NLTV) is\nproposed for unsupervised classification of hyperspectral images (HSI). The\nvariational problem is solved by the primal-dual hybrid gradient (PDHG)\nalgorithm. By squaring the labeling function and using a stable simplex\nclustering routine, an unsupervised clustering method with random\ninitialization can be implemented. The effectiveness of this proposed algorithm\nis illustrated on both synthetic and real-world HSI, and numerical results show\nthat the proposed algorithm outperforms other standard unsupervised clustering\nmethods such as spherical K-means, nonnegative matrix factorization (NMF), and\nthe graph-based Merriman-Bence-Osher (MBO) scheme.",
    "published": "2016-04-27T19:11:10Z",
    "updated": "2017-02-13T21:45:19Z",
    "authors": [
      "Wei Zhu",
      "Victoria Chayes",
      "Alexandre Tiard",
      "Stephanie Sanchez",
      "Devin Dahlberg",
      "Andrea L. Bertozzi",
      "Stanley Osher",
      "Dominique Zosso",
      "Da Kuang"
    ],
    "link": "http://arxiv.org/abs/1604.08182v2",
    "pdf_link": "http://arxiv.org/pdf/1604.08182v2"
  },
  {
    "api_id": 316,
    "title": "Inertia-Constrained Pixel-by-Pixel Nonnegative Matrix Factorisation: a\n  Hyperspectral Unmixing Method Dealing with Intra-class Variability",
    "summary": "Blind source separation is a common processing tool to analyse the\nconstitution of pixels of hyperspectral images. Such methods usually suppose\nthat pure pixel spectra (endmembers) are the same in all the image for each\nclass of materials. In the framework of remote sensing, such an assumption is\nno more valid in the presence of intra-class variabilities due to illumination\nconditions, weathering, slight variations of the pure materials, etc... In this\npaper, we first describe the results of investigations highlighting intra-class\nvariability measured in real images. Considering these results, a new\nformulation of the linear mixing model is presented leading to two new methods.\nUnconstrained Pixel-by-pixel NMF (UP-NMF) is a new blind source separation\nmethod based on the assumption of a linear mixing model, which can deal with\nintra-class variability. To overcome UP-NMF limitations an extended method is\nproposed, named Inertia-constrained Pixel-by-pixel NMF (IP-NMF). For each\nsensed spectrum, these extended versions of NMF extract a corresponding set of\nsource spectra. A constraint is set to limit the spreading of each source's\nestimates in IP-NMF. The methods are tested on a semi-synthetic data set built\nwith spectra extracted from a real hyperspectral image and then numerically\nmixed. We thus demonstrate the interest of our methods for realistic source\nvariabilities. Finally, IP-NMF is tested on a real data set and it is shown to\nyield better performance than state of the art methods.",
    "published": "2017-02-24T15:43:10Z",
    "updated": "2017-02-24T15:43:10Z",
    "authors": [
      "Charlotte Revel",
      "Yannick Deville",
      "Véronique Achard",
      "Xavier Briottet"
    ],
    "link": "http://arxiv.org/abs/1702.07630v1",
    "pdf_link": "http://arxiv.org/pdf/1702.07630v1"
  },
  {
    "api_id": 317,
    "title": "A multi-task convolutional neural network for mega-city analysis using\n  very high resolution satellite imagery and geospatial data",
    "summary": "Mega-city analysis with very high resolution (VHR) satellite images has been\ndrawing increasing interest in the fields of city planning and social\ninvestigation. It is known that accurate land-use, urban density, and\npopulation distribution information is the key to mega-city monitoring and\nenvironmental studies. Therefore, how to generate land-use, urban density, and\npopulation distribution maps at a fine scale using VHR satellite images has\nbecome a hot topic. Previous studies have focused solely on individual tasks\nwith elaborate hand-crafted features and have ignored the relationship between\ndifferent tasks. In this study, we aim to propose a universal framework which\ncan: 1) automatically learn the internal feature representation from the raw\nimage data; and 2) simultaneously produce fine-scale land-use, urban density,\nand population distribution maps. For the first target, a deep convolutional\nneural network (CNN) is applied to learn the hierarchical feature\nrepresentation from the raw image data. For the second target, a novel\nCNN-based universal framework is proposed to process the VHR satellite images\nand generate the land-use, urban density, and population distribution maps. To\nthe best of our knowledge, this is the first CNN-based mega-city analysis\nmethod which can process a VHR remote sensing image with such a large data\nvolume. A VHR satellite image (1.2 m spatial resolution) of the center of Wuhan\ncovering an area of 2606 km2 was used to evaluate the proposed method. The\nexperimental results confirm that the proposed method can achieve a promising\naccuracy for land-use, urban density, and population distribution maps.",
    "published": "2017-02-26T04:23:36Z",
    "updated": "2017-02-26T04:23:36Z",
    "authors": [
      "Fan Zhang",
      "Bo Du",
      "Liangpei Zhang"
    ],
    "link": "http://arxiv.org/abs/1702.07985v1",
    "pdf_link": "http://arxiv.org/pdf/1702.07985v1"
  },
  {
    "api_id": 318,
    "title": "Bayesian Nonparametric Unmixing of Hyperspectral Images",
    "summary": "Hyperspectral imaging is an important tool in remote sensing, allowing for\naccurate analysis of vast areas. Due to a low spatial resolution, a pixel of a\nhyperspectral image rarely represents a single material, but rather a mixture\nof different spectra. HSU aims at estimating the pure spectra present in the\nscene of interest, referred to as endmembers, and their fractions in each\npixel, referred to as abundances. Today, many HSU algorithms have been\nproposed, based either on a geometrical or statistical model. While most\nmethods assume that the number of endmembers present in the scene is known,\nthere is only little work about estimating this number from the observed data.\nIn this work, we propose a Bayesian nonparametric framework that jointly\nestimates the number of endmembers, the endmembers itself, and their\nabundances, by making use of the Indian Buffet Process as a prior for the\nendmembers. Simulation results and experiments on real data demonstrate the\neffectiveness of the proposed algorithm, yielding results comparable with\nstate-of-the-art methods while being able to reliably infer the number of\nendmembers. In scenarios with strong noise, where other algorithms provide only\npoor results, the proposed approach tends to overestimate the number of\nendmembers slightly. The additional endmembers, however, often simply represent\nnoisy replicas of present endmembers and could easily be merged in a\npost-processing step.",
    "published": "2017-02-26T09:10:45Z",
    "updated": "2017-02-26T09:10:45Z",
    "authors": [
      "Jürgen Hahn",
      "Abdelhak M. Zoubir"
    ],
    "link": "http://arxiv.org/abs/1702.08007v1",
    "pdf_link": "http://arxiv.org/pdf/1702.08007v1"
  },
  {
    "api_id": 319,
    "title": "Remote Sensing Image Scene Classification: Benchmark and State of the\n  Art",
    "summary": "Remote sensing image scene classification plays an important role in a wide\nrange of applications and hence has been receiving remarkable attention. During\nthe past years, significant efforts have been made to develop various datasets\nor present a variety of approaches for scene classification from remote sensing\nimages. However, a systematic review of the literature concerning datasets and\nmethods for scene classification is still lacking. In addition, almost all\nexisting datasets have a number of limitations, including the small scale of\nscene classes and the image numbers, the lack of image variations and\ndiversity, and the saturation of accuracy. These limitations severely limit the\ndevelopment of new approaches especially deep learning-based methods. This\npaper first provides a comprehensive review of the recent progress. Then, we\npropose a large-scale dataset, termed \"NWPU-RESISC45\", which is a publicly\navailable benchmark for REmote Sensing Image Scene Classification (RESISC),\ncreated by Northwestern Polytechnical University (NWPU). This dataset contains\n31,500 images, covering 45 scene classes with 700 images in each class. The\nproposed NWPU-RESISC45 (i) is large-scale on the scene classes and the total\nimage number, (ii) holds big variations in translation, spatial resolution,\nviewpoint, object pose, illumination, background, and occlusion, and (iii) has\nhigh within-class diversity and between-class similarity. The creation of this\ndataset will enable the community to develop and evaluate various data-driven\nalgorithms. Finally, several representative methods are evaluated using the\nproposed dataset and the results are reported as a useful baseline for future\nresearch.",
    "published": "2017-03-01T03:38:13Z",
    "updated": "2017-03-01T03:38:13Z",
    "authors": [
      "Gong Cheng",
      "Junwei Han",
      "Xiaoqiang Lu"
    ],
    "link": "http://arxiv.org/abs/1703.00121v1",
    "pdf_link": "http://arxiv.org/pdf/1703.00121v1"
  },
  {
    "api_id": 320,
    "title": "Introduction to Nonnegative Matrix Factorization",
    "summary": "In this paper, we introduce and provide a short overview of nonnegative\nmatrix factorization (NMF). Several aspects of NMF are discussed, namely, the\napplication in hyperspectral imaging, geometry and uniqueness of NMF solutions,\ncomplexity, algorithms, and its link with extended formulations of polyhedra.\nIn order to put NMF into perspective, the more general problem class of\nconstrained low-rank matrix approximation problems is first briefly introduced.",
    "published": "2017-03-02T08:23:04Z",
    "updated": "2017-03-02T08:23:04Z",
    "authors": [
      "Nicolas Gillis"
    ],
    "link": "http://arxiv.org/abs/1703.00663v1",
    "pdf_link": "http://arxiv.org/pdf/1703.00663v1"
  },
  {
    "api_id": 321,
    "title": "Non-line-of-sight tracking of people at long range",
    "summary": "A remote-sensing system that can determine the position of hidden objects has\napplications in many critical real-life scenarios, such as search and rescue\nmissions and safe autonomous driving. Previous work has shown the ability to\nrange and image objects hidden from the direct line of sight, employing\nadvanced optical imaging technologies aimed at small objects at short range. In\nthis work we demonstrate a long-range tracking system based on single laser\nillumination and single-pixel single-photon detection. This enables us to track\none or more people hidden from view at a stand-off distance of over 50~m. These\nresults pave the way towards next generation LiDAR systems that will\nreconstruct not only the direct-view scene but also the main elements hidden\nbehind walls or corners.",
    "published": "2017-03-02T16:57:04Z",
    "updated": "2017-03-02T16:57:04Z",
    "authors": [
      "Susan Chan",
      "Ryan E. Warburton",
      "Genevieve Gariepy",
      "Jonathan Leach",
      "Daniele Faccio"
    ],
    "link": "http://arxiv.org/abs/1703.02124v1",
    "pdf_link": "http://arxiv.org/pdf/1703.02124v1"
  },
  {
    "api_id": 322,
    "title": "High-Resolution Multispectral Dataset for Semantic Segmentation",
    "summary": "Unmanned aircraft have decreased the cost required to collect remote sensing\nimagery, which has enabled researchers to collect high-spatial resolution data\nfrom multiple sensor modalities more frequently and easily. The increase in\ndata will push the need for semantic segmentation frameworks that are able to\nclassify non-RGB imagery, but this type of algorithmic development requires an\nincrease in publicly available benchmark datasets with class labels. In this\npaper, we introduce a high-resolution multispectral dataset with image labels.\nThis new benchmark dataset has been pre-split into training/testing folds in\norder to standardize evaluation and continue to push state-of-the-art\nclassification frameworks for non-RGB imagery.",
    "published": "2017-03-06T15:16:56Z",
    "updated": "2017-03-06T15:16:56Z",
    "authors": [
      "Ronald Kemker",
      "Carl Salvaggio",
      "Christopher Kanan"
    ],
    "link": "http://arxiv.org/abs/1703.01918v1",
    "pdf_link": "http://arxiv.org/pdf/1703.01918v1"
  },
  {
    "api_id": 323,
    "title": "Uncertain Photometric Redshifts with Deep Learning Methods",
    "summary": "The need for accurate photometric redshifts estimation is a topic that has\nfundamental importance in Astronomy, due to the necessity of efficiently\nobtaining redshift information without the need of spectroscopic analysis. We\npropose a method for determining accurate multimodal photo-z probability\ndensity functions (PDFs) using Mixture Density Networks (MDN) and Deep\nConvolutional Networks (DCN). A comparison with a Random Forest (RF) is\nperformed.",
    "published": "2017-03-06T17:07:13Z",
    "updated": "2017-03-06T17:07:13Z",
    "authors": [
      "Antonio D'Isanto"
    ],
    "link": "http://arxiv.org/abs/1703.01979v1",
    "pdf_link": "http://arxiv.org/pdf/1703.01979v1"
  },
  {
    "api_id": 324,
    "title": "Discriminative models for multi-instance problems with tree-structure",
    "summary": "Modeling network traffic is gaining importance in order to counter modern\nthreats of ever increasing sophistication. It is though surprisingly difficult\nand costly to construct reliable classifiers on top of telemetry data due to\nthe variety and complexity of signals that no human can manage to interpret in\nfull. Obtaining training data with sufficiently large and variable body of\nlabels can thus be seen as prohibitive problem. The goal of this work is to\ndetect infected computers by observing their HTTP(S) traffic collected from\nnetwork sensors, which are typically proxy servers or network firewalls, while\nrelying on only minimal human input in model training phase. We propose a\ndiscriminative model that makes decisions based on all computer's traffic\nobserved during predefined time window (5 minutes in our case). The model is\ntrained on collected traffic samples over equally sized time window per large\nnumber of computers, where the only labels needed are human verdicts about the\ncomputer as a whole (presumed infected vs. presumed clean). As part of training\nthe model itself recognizes discriminative patterns in traffic targeted to\nindividual servers and constructs the final high-level classifier on top of\nthem. We show the classifier to perform with very high precision, while the\nlearned traffic patterns can be interpreted as Indicators of Compromise. In the\nfollowing we implement the discriminative model as a neural network with\nspecial structure reflecting two stacked multi-instance problems. The main\nadvantages of the proposed configuration include not only improved accuracy and\nability to learn from gross labels, but also automatic learning of server types\n(together with their detectors) which are typically visited by infected\ncomputers.",
    "published": "2017-03-07T06:53:34Z",
    "updated": "2017-03-07T06:53:34Z",
    "authors": [
      "Tomas Pevny",
      "Petr Somol"
    ],
    "link": "http://arxiv.org/abs/1703.02868v1",
    "pdf_link": "http://arxiv.org/pdf/1703.02868v1"
  },
  {
    "api_id": 325,
    "title": "Deep Reinforcement Learning for Tensegrity Robot Locomotion",
    "summary": "Tensegrity robots, composed of rigid rods connected by elastic cables, have a\nnumber of unique properties that make them appealing for use as planetary\nexploration rovers. However, control of tensegrity robots remains a difficult\nproblem due to their unusual structures and complex dynamics. In this work, we\nshow how locomotion gaits can be learned automatically using a novel extension\nof mirror descent guided policy search (MDGPS) applied to periodic locomotion\nmovements, and we demonstrate the effectiveness of our approach on tensegrity\nrobot locomotion. We evaluate our method with real-world and simulated\nexperiments on the SUPERball tensegrity robot, showing that the learned\npolicies generalize to changes in system parameters, unreliable sensor\nmeasurements, and variation in environmental conditions, including varied\nterrains and a range of different gravities. Our experiments demonstrate that\nour method not only learns fast, power-efficient feedback policies for rolling\ngaits, but that these policies can succeed with only the limited onboard\nsensing provided by SUPERball's accelerometers. We compare the learned feedback\npolicies to learned open-loop policies and hand-engineered controllers, and\ndemonstrate that the learned policy enables the first continuous, reliable\nlocomotion gait for the real SUPERball robot. Our code and other supplementary\nmaterials are available from http://rll.berkeley.edu/drl_tensegrity",
    "published": "2016-09-28T19:38:03Z",
    "updated": "2017-03-08T01:52:36Z",
    "authors": [
      "Marvin Zhang",
      "Xinyang Geng",
      "Jonathan Bruce",
      "Ken Caluwaerts",
      "Massimo Vespignani",
      "Vytas SunSpiral",
      "Pieter Abbeel",
      "Sergey Levine"
    ],
    "link": "http://arxiv.org/abs/1609.09049v3",
    "pdf_link": "http://arxiv.org/pdf/1609.09049v3"
  },
  {
    "api_id": 326,
    "title": "Crossing-Line-Node Semimetals: General Theory and Application to\n  Rare-Earth Trihydrides",
    "summary": "Multiple line nodes in energy-band gaps are found in semimetals preserving\nmirror-reflection symmetry. We classify possible configurations of multiple\nline nodes with crossing points (crossing line nodes) under point-group\nsymmetry. Taking the spin-orbit interaction (SOI) into account, we also\nclassify topological phase transitions from crossing-line-node Dirac semimetals\nto other topological phases, e.g., topological insulators and point-node\nsemimetals. This study enables one to find crossing-line-node semimetal\nmaterials and their behavior in the presence of SOI from the band structure in\nthe absence of SOI without detailed calculations. As an example, the theory\napplies to hexagonal rare-earth trihydrides with the HoD3 structure and\nclarifies that it is a crossing-line-node Dirac semimetal hosting three line\nnodes.",
    "published": "2017-03-10T09:15:43Z",
    "updated": "2017-03-10T09:15:43Z",
    "authors": [
      "Shingo Kobayashi",
      "Youichi Yamakawa",
      "Ai Yamakage",
      "Takumi Inohara",
      "Yoshihiko Okamoto",
      "Yukio Tanaka"
    ],
    "link": "http://arxiv.org/abs/1703.03587v1",
    "pdf_link": "http://arxiv.org/pdf/1703.03587v1"
  },
  {
    "api_id": 327,
    "title": "Efficient Optical flow and Stereo Vision for Velocity Estimation and\n  Obstacle Avoidance on an Autonomous Pocket Drone",
    "summary": "Miniature Micro Aerial Vehicles (MAV) are very suitable for flying in indoor\nenvironments, but autonomous navigation is challenging due to their strict\nhardware limitations. This paper presents a highly efficient computer vision\nalgorithm called Edge-FS for the determination of velocity and depth. It runs\nat 20 Hz on a 4 g stereo camera with an embedded STM32F4 microprocessor (168\nMHz, 192 kB) and uses feature histograms to calculate optical flow and stereo\ndisparity. The stereo-based distance estimates are used to scale the optical\nflow in order to retrieve the drone's velocity. The velocity and depth\nmeasurements are used for fully autonomous flight of a 40 g pocket drone only\nrelying on on-board sensors. The method allows the MAV to control its velocity\nand avoid obstacles.",
    "published": "2016-12-20T15:11:27Z",
    "updated": "2017-03-14T17:43:04Z",
    "authors": [
      "Kimberly McGuire",
      "Guido de Croon",
      "Christophe De Wagter",
      "Karl Tuyls",
      "Hilbert Kappen"
    ],
    "link": "http://arxiv.org/abs/1612.06702v2",
    "pdf_link": "http://arxiv.org/pdf/1612.06702v2"
  },
  {
    "api_id": 328,
    "title": "Discriminate-and-Rectify Encoders: Learning from Image Transformation\n  Sets",
    "summary": "The complexity of a learning task is increased by transformations in the\ninput space that preserve class identity. Visual object recognition for example\nis affected by changes in viewpoint, scale, illumination or planar\ntransformations. While drastically altering the visual appearance, these\nchanges are orthogonal to recognition and should not be reflected in the\nrepresentation or feature encoding used for learning. We introduce a framework\nfor weakly supervised learning of image embeddings that are robust to\ntransformations and selective to the class distribution, using sets of\ntransforming examples (orbit sets), deep parametrizations and a novel\norbit-based loss. The proposed loss combines a discriminative, contrastive part\nfor orbits with a reconstruction error that learns to rectify orbit\ntransformations. The learned embeddings are evaluated in distance metric-based\ntasks, such as one-shot classification under geometric transformations, as well\nas face verification and retrieval under more realistic visual variability. Our\nresults suggest that orbit sets, suitably computed or observed, can be used for\nefficient, weakly-supervised learning of semantically relevant image\nembeddings.",
    "published": "2017-03-14T22:21:48Z",
    "updated": "2017-03-14T22:21:48Z",
    "authors": [
      "Andrea Tacchetti",
      "Stephen Voinea",
      "Georgios Evangelopoulos"
    ],
    "link": "http://arxiv.org/abs/1703.04775v1",
    "pdf_link": "http://arxiv.org/pdf/1703.04775v1"
  },
  {
    "api_id": 329,
    "title": "Astrophysics and Big Data: Challenges, Methods, and Tools",
    "summary": "Nowadays there is no field research which is not flooded with data. Among the\nsciences, Astrophysics has always been driven by the analysis of massive\namounts of data. The development of new and more sophisticated observation\nfacilities, both ground-based and spaceborne, has led data more and more\ncomplex (Variety), an exponential growth of both data Volume (i.e., in the\norder of petabytes), and Velocity in terms of production and transmission.\nTherefore, new and advanced processing solutions will be needed to process this\nhuge amount of data. We investigate some of these solutions, based on machine\nlearning models as well as tools and architectures for Big Data analysis that\ncan be exploited in the astrophysical context.",
    "published": "2017-03-15T11:23:40Z",
    "updated": "2017-03-15T11:23:40Z",
    "authors": [
      "Mauro Garofalo",
      "Alessio Botta",
      "Giorgio Ventre"
    ],
    "link": "http://arxiv.org/abs/1703.05084v1",
    "pdf_link": "http://arxiv.org/pdf/1703.05084v1"
  },
  {
    "api_id": 330,
    "title": "Reweighted Infrared Patch-Tensor Model With Both Non-Local and Local\n  Priors for Single-Frame Small Target Detection",
    "summary": "Many state-of-the-art methods have been proposed for infrared small target\ndetection. They work well on the images with homogeneous backgrounds and\nhigh-contrast targets. However, when facing highly heterogeneous backgrounds,\nthey would not perform very well, mainly due to: 1) the existence of strong\nedges and other interfering components, 2) not utilizing the priors fully.\nInspired by this, we propose a novel method to exploit both local and non-local\npriors simultaneously. Firstly, we employ a new infrared patch-tensor (IPT)\nmodel to represent the image and preserve its spatial correlations. Exploiting\nthe target sparse prior and background non-local self-correlation prior, the\ntarget-background separation is modeled as a robust low-rank tensor recovery\nproblem. Moreover, with the help of the structure tensor and reweighted idea,\nwe design an entry-wise local-structure-adaptive and sparsity enhancing weight\nto replace the globally constant weighting parameter. The decomposition could\nbe achieved via the element-wise reweighted higher-order robust principal\ncomponent analysis with an additional convergence condition according to the\npractical situation of target detection. Extensive experiments demonstrate that\nour model outperforms the other state-of-the-arts, in particular for the images\nwith very dim targets and heavy clutters.",
    "published": "2017-03-27T15:57:27Z",
    "updated": "2017-03-27T15:57:27Z",
    "authors": [
      "Yimian Dai",
      "Yiquan Wu"
    ],
    "link": "http://arxiv.org/abs/1703.09157v1",
    "pdf_link": "http://arxiv.org/pdf/1703.09157v1"
  },
  {
    "api_id": 331,
    "title": "Learned Spectral Super-Resolution",
    "summary": "We describe a novel method for blind, single-image spectral super-resolution.\nWhile conventional super-resolution aims to increase the spatial resolution of\nan input image, our goal is to spectrally enhance the input, i.e., generate an\nimage with the same spatial resolution, but a greatly increased number of\nnarrow (hyper-spectral) wave-length bands. Just like the spatial statistics of\nnatural images has rich structure, which one can exploit as prior to predict\nhigh-frequency content from a low resolution image, the same is also true in\nthe spectral domain: the materials and lighting conditions of the observed\nworld induce structure in the spectrum of wavelengths observed at a given\npixel. Surprisingly, very little work exists that attempts to use this\ndiagnosis and achieve blind spectral super-resolution from single images. We\nstart from the conjecture that, just like in the spatial domain, we can learn\nthe statistics of natural image spectra, and with its help generate finely\nresolved hyper-spectral images from RGB input. Technically, we follow the\ncurrent best practice and implement a convolutional neural network (CNN), which\nis trained to carry out the end-to-end mapping from an entire RGB image to the\ncorresponding hyperspectral image of equal size. We demonstrate spectral\nsuper-resolution both for conventional RGB images and for multi-spectral\nsatellite data, outperforming the state-of-the-art.",
    "published": "2017-03-28T09:17:38Z",
    "updated": "2017-03-28T09:17:38Z",
    "authors": [
      "Silvano Galliani",
      "Charis Lanaras",
      "Dimitrios Marmanis",
      "Emmanuel Baltsavias",
      "Konrad Schindler"
    ],
    "link": "http://arxiv.org/abs/1703.09470v1",
    "pdf_link": "http://arxiv.org/pdf/1703.09470v1"
  },
  {
    "api_id": 332,
    "title": "On The Statistical Properties of the Lower Main Sequence",
    "summary": "Astronomy is in an era where all-sky surveys are mapping the Galaxy. The\nplethora of photometric, spectroscopic, asteroseismic and astrometric data\nallows us to characterise the comprising stars in detail. Here we quantify to\nwhat extent precise stellar observations reveal information about the\nproperties of a star, including properties that are unobserved, or even\nunobservable. We analyse the diagnostic potential of classical and\nasteroseismic observations for inferring stellar parameters such as age, mass\nand radius from evolutionary tracks of solar-like oscillators on the lower main\nsequence. We perform rank correlation tests in order to determine the capacity\nof each observable quantity to probe structural components of stars and infer\ntheir evolutionary histories. We also analyse the principal components of\nclassic and asteroseismic observables to highlight the degree of redundancy\npresent in the measured quantities and demonstrate the extent to which\ninformation of the model parameters can be extracted. We perform multiple\nregression using combinations of observable quantities in a grid of\nevolutionary simulations and appraise the predictive utility of each\ncombination in determining the properties of stars. We identify the\ncombinations that are useful and provide limits to where each type of\nobservable quantity can reveal information about a star. We investigate the\naccuracy with which targets in the upcoming TESS and PLATO missions can be\ncharacterized. We demonstrate that the combination of observations from GAIA\nand PLATO will allow us to tightly constrain stellar masses, ages and radii\nwith machine learning for the purposes of Galactic and planetary studies.",
    "published": "2017-03-29T18:00:01Z",
    "updated": "2017-03-29T18:00:01Z",
    "authors": [
      "George C. Angelou",
      "Earl P. Bellinger",
      "Saskia Hekker",
      "Sarbani Basu"
    ],
    "link": "http://arxiv.org/abs/1703.10165v1",
    "pdf_link": "http://arxiv.org/pdf/1703.10165v1"
  },
  {
    "api_id": 333,
    "title": "Detecting Human Interventions on the Landscape: KAZE Features, Poisson\n  Point Processes, and a Construction Dataset",
    "summary": "We present an algorithm capable of identifying a wide variety of\nhuman-induced change on the surface of the planet by analyzing matches between\nlocal features in time-sequenced remote sensing imagery. We evaluate feature\nsets, match protocols, and the statistical modeling of feature matches. With\napplication of KAZE features, k-nearest-neighbor descriptor matching, and\ngeometric proximity and bi-directional match consistency checks, average match\nrates increase more than two-fold over the previous standard. In testing our\nplatform, we developed a small, labeled benchmark dataset expressing\nlarge-scale residential, industrial, and civic construction, along with null\ninstances, in California between the years 2010 and 2012. On the benchmark set,\nour algorithm makes precise, accurate change proposals on two-thirds of scenes.\nFurther, the detection threshold can be tuned so that all or almost all\nproposed detections are true positives.",
    "published": "2017-03-29T18:56:32Z",
    "updated": "2017-03-29T18:56:32Z",
    "authors": [
      "Edward Boyda",
      "Colin McCormick",
      "Dan Hammer"
    ],
    "link": "http://arxiv.org/abs/1703.10196v1",
    "pdf_link": "http://arxiv.org/pdf/1703.10196v1"
  },
  {
    "api_id": 334,
    "title": "Lensless Imaging with Compressive Ultrafast Sensing",
    "summary": "Lensless imaging is an important and challenging problem. One notable\nsolution to lensless imaging is a single pixel camera which benefits from ideas\ncentral to compressive sampling. However, traditional single pixel cameras\nrequire many illumination patterns which result in a long acquisition process.\nHere we present a method for lensless imaging based on compressive ultrafast\nsensing. Each sensor acquisition is encoded with a different illumination\npattern and produces a time series where time is a function of the photon's\norigin in the scene. Currently available hardware with picosecond time\nresolution enables time tagging photons as they arrive to an omnidirectional\nsensor. This allows lensless imaging with significantly fewer patterns compared\nto regular single pixel imaging. To that end, we develop a framework for\ndesigning lensless imaging systems that use ultrafast detectors. We provide an\nalgorithm for ideal sensor placement and an algorithm for optimized active\nillumination patterns. We show that efficient lensless imaging is possible with\nultrafast measurement and compressive sensing. This paves the way for novel\nimaging architectures and remote sensing in extreme situations where imaging\nwith a lens is not possible.",
    "published": "2016-10-19T01:08:55Z",
    "updated": "2017-03-30T02:04:49Z",
    "authors": [
      "Guy Satat",
      "Matthew Tancik",
      "Ramesh Raskar"
    ],
    "link": "http://arxiv.org/abs/1610.05834v2",
    "pdf_link": "http://arxiv.org/pdf/1610.05834v2"
  },
  {
    "api_id": 335,
    "title": "Online deforestation detection",
    "summary": "Deforestation detection using satellite images can make an important\ncontribution to forest management. Current approaches can be broadly divided\ninto those that compare two images taken at similar periods of the year and\nthose that monitor changes by using multiple images taken during the growing\nseason. The CMFDA algorithm described in Zhu et al. (2012) is an algorithm that\nbuilds on the latter category by implementing a year-long, continuous,\ntime-series based approach to monitoring images. This algorithm was developed\nfor 30m resolution, 16-day frequency reflectance data from the Landsat\nsatellite. In this work we adapt the algorithm to 1km, 16-day frequency\nreflectance data from the modis sensor aboard the Terra satellite. The CMFDA\nalgorithm is composed of two submodels which are fitted on a pixel-by-pixel\nbasis. The first estimates the amount of surface reflectance as a function of\nthe day of the year. The second estimates the occurrence of a deforestation\nevent by comparing the last few predicted and real reflectance values. For this\ncomparison, the reflectance observations for six different bands are first\ncombined into a forest index. Real and predicted values of the forest index are\nthen compared and high absolute differences for consecutive observation dates\nare flagged as deforestation events. Our adapted algorithm also uses the two\nmodel framework. However, since the modis 13A2 dataset used, includes\nreflectance data for different spectral bands than those included in the\nLandsat dataset, we cannot construct the forest index. Instead we propose two\ncontrasting approaches: a multivariate and an index approach similar to that of\nCMFDA.",
    "published": "2017-04-03T22:40:48Z",
    "updated": "2017-04-03T22:40:48Z",
    "authors": [
      "Emiliano Diaz"
    ],
    "link": "http://arxiv.org/abs/1704.00829v1",
    "pdf_link": "http://arxiv.org/pdf/1704.00829v1"
  },
  {
    "api_id": 336,
    "title": "Super-resolving multiresolution images with band-independant geometry of\n  multispectral pixels",
    "summary": "A new resolution enhancement method is presented for multispectral and\nmulti-resolution images, such as these provided by the Sentinel-2 satellites.\nStarting from the highest resolution bands, band-dependent information\n(reflectance) is separated from information that is common to all bands\n(geometry of scene elements). This model is then applied to unmix\nlow-resolution bands, preserving their reflectance, while propagating\nband-independent information to preserve the sub-pixel details. A reference\nimplementation is provided, with an application example for super-resolving\nSentinel-2 data.",
    "published": "2016-09-26T14:28:49Z",
    "updated": "2017-04-04T10:29:55Z",
    "authors": [
      "Nicolas Brodu"
    ],
    "link": "http://arxiv.org/abs/1609.07986v3",
    "pdf_link": "http://arxiv.org/pdf/1609.07986v3"
  },
  {
    "api_id": 337,
    "title": "Agent-Based Model Calibration using Machine Learning Surrogates",
    "summary": "Taking agent-based models (ABM) closer to the data is an open challenge. This\npaper explicitly tackles parameter space exploration and calibration of ABMs\ncombining supervised machine-learning and intelligent sampling to build a\nsurrogate meta-model. The proposed approach provides a fast and accurate\napproximation of model behaviour, dramatically reducing computation time. In\nthat, our machine-learning surrogate facilitates large scale explorations of\nthe parameter-space, while providing a powerful filter to gain insights into\nthe complex functioning of agent-based models. The algorithm introduced in this\npaper merges model simulation and output analysis into a surrogate meta-model,\nwhich substantially ease ABM calibration. We successfully apply our approach to\nthe Brock and Hommes (1998) asset pricing model and to the \"Island\" endogenous\ngrowth model (Fagiolo and Dosi, 2003). Performance is evaluated against a\nrelatively large out-of-sample set of parameter combinations, while employing\ndifferent user-defined statistical tests for output analysis. The results\ndemonstrate the capacity of machine learning surrogates to facilitate fast and\nprecise exploration of agent-based models' behaviour over their often rugged\nparameter spaces.",
    "published": "2017-03-30T18:57:56Z",
    "updated": "2017-04-06T07:30:13Z",
    "authors": [
      "Francesco Lamperti",
      "Andrea Roventini",
      "Amir Sani"
    ],
    "link": "http://arxiv.org/abs/1703.10639v2",
    "pdf_link": "http://arxiv.org/pdf/1703.10639v2"
  },
  {
    "api_id": 338,
    "title": "Estimation of solar irradiance using ground-based whole sky imagers",
    "summary": "Ground-based whole sky imagers (WSIs) can provide localized images of the sky\nof high temporal and spatial resolution, which permits fine-grained cloud\nobservation. In this paper, we show how images taken by WSIs can be used to\nestimate solar radiation. Sky cameras are useful here because they provide\nadditional information about cloud movement and coverage, which are otherwise\nnot available from weather station data. Our setup includes ground-based\nweather stations at the same location as the imagers. We use their measurements\nto validate our methods.",
    "published": "2016-06-08T13:21:30Z",
    "updated": "2017-04-06T09:38:37Z",
    "authors": [
      "Soumyabrata Dev",
      "Florian M. Savoy",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "link": "http://arxiv.org/abs/1606.02546v2",
    "pdf_link": "http://arxiv.org/pdf/1606.02546v2"
  },
  {
    "api_id": 339,
    "title": "Automatic tuning of Free Electron Lasers",
    "summary": "Existing FEL facilities often suffer from stability issues: so electron\norbit, transverse electron optics, electron bunch compression and other\nparameters have to be readjusted often to account for drifts in performance of\nvarious components. The tuning procedures typically employed in operation are\noften manual and lengthy. We have been developing a combination of model-free\nand model-based automatic tuning methods to meet the needs of present and\nupcoming XFEL facilities. Our approach has been implemented at FLASH\n\\cite{flash} to achieve automatic SASE tuning using empirical control of orbit,\nelectron optics and bunch compression. In this paper we describe our approach\nto empirical tuning, the software which implements it, and the results of using\nit at FLASH. We also discuss the potential of using machine learning and\nmodel-based techniques in tuning methods.",
    "published": "2017-04-07T18:18:08Z",
    "updated": "2017-04-07T18:18:08Z",
    "authors": [
      "I. Agapov",
      "G. Geloni",
      "S. Tomin",
      "I. Zagorodnov"
    ],
    "link": "http://arxiv.org/abs/1704.02335v1",
    "pdf_link": "http://arxiv.org/pdf/1704.02335v1"
  },
  {
    "api_id": 340,
    "title": "Sub-Pixel Registration of Wavelet-Encoded Images",
    "summary": "Sub-pixel registration is a crucial step for applications such as\nsuper-resolution in remote sensing, motion compensation in magnetic resonance\nimaging, and non-destructive testing in manufacturing, to name a few. Recently,\nthese technologies have been trending towards wavelet encoded imaging and\nsparse/compressive sensing. The former plays a crucial role in reducing imaging\nartifacts, while the latter significantly increases the acquisition speed. In\nview of these new emerging needs for applications of wavelet encoded imaging,\nwe propose a sub-pixel registration method that can achieve direct wavelet\ndomain registration from a sparse set of coefficients. We make the following\ncontributions: (i) We devise a method of decoupling scale, rotation, and\ntranslation parameters in the Haar wavelet domain, (ii) We derive explicit\nmathematical expressions that define in-band sub-pixel registration in terms of\nwavelet coefficients, (iii) Using the derived expressions, we propose an\napproach to achieve in-band subpixel registration, avoiding back and forth\ntransformations. (iv) Our solution remains highly accurate even when a sparse\nset of coefficients are used, which is due to localization of signals in a\nsparse set of wavelet coefficients. We demonstrate the accuracy of our method,\nand show that it outperforms the state-of-the-art on simulated and real data,\neven when the data is sparse.",
    "published": "2017-05-01T07:27:04Z",
    "updated": "2017-05-01T07:27:04Z",
    "authors": [
      "Vildan Atalay Aydin",
      "Hassan Foroosh"
    ],
    "link": "http://arxiv.org/abs/1705.00430v1",
    "pdf_link": "http://arxiv.org/pdf/1705.00430v1"
  },
  {
    "api_id": 341,
    "title": "SAR image despeckling through convolutional neural networks",
    "summary": "In this paper we investigate the use of discriminative model learning through\nConvolutional Neural Networks (CNNs) for SAR image despeckling. The network\nuses a residual learning strategy, hence it does not recover the filtered\nimage, but the speckle component, which is then subtracted from the noisy one.\nTraining is carried out by considering a large multitemporal SAR image and its\nmultilook version, in order to approximate a clean image. Experimental results,\nboth on synthetic and real SAR data, show the method to achieve better\nperformance with respect to state-of-the-art techniques.",
    "published": "2017-04-02T09:44:05Z",
    "updated": "2017-05-03T15:53:02Z",
    "authors": [
      "G. Chierchia",
      "D. Cozzolino",
      "G. Poggi",
      "L. Verdoliva"
    ],
    "link": "http://arxiv.org/abs/1704.00275v2",
    "pdf_link": "http://arxiv.org/pdf/1704.00275v2"
  },
  {
    "api_id": 342,
    "title": "Machine learning reveals orbital interaction in crystalline materials",
    "summary": "We propose a novel representation of crystalline materials named\norbital-field matrix (OFM) based on the distribution of valence shell\nelectrons. We demonstrate that this new representation can be highly useful in\nmining material data. Our experiment shows that the formation energies of\ncrystalline materials, the atomization energies of molecular materials, and the\nlocal magnetic moments of the constituent atoms in transition metal--rare-earth\nmetal bimetal alloys can be predicted with high accuracy using the OFM.\nKnowledge regarding the role of coordination numbers of transition-metal and\nrare-earth metal elements in determining the local magnetic moment of\ntransition metal sites can be acquired directly from decision tree regression\nanalyses using the OFM.",
    "published": "2017-05-02T16:06:10Z",
    "updated": "2017-05-03T17:07:21Z",
    "authors": [
      "Tien Lam Pham",
      "Hiori Kino",
      "Kiyoyuki Terakura",
      "Takashi Miyake",
      "Ichigaku Takigawa",
      "Koji Tsuda",
      "Hieu Chi Dam"
    ],
    "link": "http://arxiv.org/abs/1705.01043v2",
    "pdf_link": "http://arxiv.org/pdf/1705.01043v2"
  },
  {
    "api_id": 343,
    "title": "Searching for Moving Objects in HSC-SSP: Pipeline and Preliminary\n  Results",
    "summary": "The Hyper Suprime-Cam Subaru Strategic Program (HSC-SSP) is currently the\ndeepest wide- field survey in progress. The 8.2 m aperture of Subaru telescope\nis very powerful in detect- ing faint/small moving objects, including\nnear-Earth objects, asteroids, centaurs and Tran- Neptunian objects (TNOs).\nHowever, the cadence and dithering pattern of the HSC-SSP are not designed for\ndetecting moving objects, making it difficult to do so systematically. In this\npaper, we introduce a new pipeline for detecting moving objects (specifically\nTNOs) in a non-dedicated survey. The HSC-SSP catalogs are re-arranged into the\nHEALPix architecture. Then, the stationary detections and false positive are\nremoved with a machine learning al- gorithm to produce a list of moving object\ncandidates. An orbit linking algorithm and visual inspections are executed to\ngenerate the final list of detected TNOs. The preliminary results of a search\nfor TNOs using this new pipeline on data from the first HSC-SSP data release\n(Mar 2014 to Nov 2015) are also presented.",
    "published": "2017-05-04T07:15:40Z",
    "updated": "2017-05-04T07:15:40Z",
    "authors": [
      "Ying-Tung Chen",
      "Hsing-Wen Lin",
      "Mike Alexandersen",
      "Matthew J. Lehner",
      "Shiang-Yu Wang",
      "Jen-Hung Wang",
      "Fumi Yoshida",
      "Yutaka Komiyama",
      "Satoshi Miyazaki"
    ],
    "link": "http://arxiv.org/abs/1705.01722v1",
    "pdf_link": "http://arxiv.org/pdf/1705.01722v1"
  },
  {
    "api_id": 344,
    "title": "A Design Methodology for Efficient Implementation of Deconvolutional\n  Neural Networks on an FPGA",
    "summary": "In recent years deep learning algorithms have shown extremely high\nperformance on machine learning tasks such as image classification and speech\nrecognition. In support of such applications, various FPGA accelerator\narchitectures have been proposed for convolutional neural networks (CNNs) that\nenable high performance for classification tasks at lower power than CPU and\nGPU processors. However, to date, there has been little research on the use of\nFPGA implementations of deconvolutional neural networks (DCNNs). DCNNs, also\nknown as generative CNNs, encode high-dimensional probability distributions and\nhave been widely used for computer vision applications such as scene\ncompletion, scene segmentation, image creation, image denoising, and\nsuper-resolution imaging. We propose an FPGA architecture for deconvolutional\nnetworks built around an accelerator which effectively handles the complex\nmemory access patterns needed to perform strided deconvolutions, and that\nsupports convolution as well. We also develop a three-step design optimization\nmethod that systematically exploits statistical analysis, design space\nexploration and VLSI optimization. To verify our FPGA deconvolutional\naccelerator design methodology we train DCNNs offline on two representative\ndatasets using the generative adversarial network method (GAN) run on\nTensorflow, and then map these DCNNs to an FPGA DCNN-plus-accelerator\nimplementation to perform generative inference on a Xilinx Zynq-7000 FPGA. Our\nDCNN implementation achieves a peak performance density of 0.012 GOPs/DSP.",
    "published": "2017-05-07T09:18:44Z",
    "updated": "2017-05-07T09:18:44Z",
    "authors": [
      "Xinyu Zhang",
      "Srinjoy Das",
      "Ojash Neopane",
      "Ken Kreutz-Delgado"
    ],
    "link": "http://arxiv.org/abs/1705.02583v1",
    "pdf_link": "http://arxiv.org/pdf/1705.02583v1"
  },
  {
    "api_id": 345,
    "title": "Going Deeper with Contextual CNN for Hyperspectral Image Classification",
    "summary": "In this paper, we describe a novel deep convolutional neural network (CNN)\nthat is deeper and wider than other existing deep networks for hyperspectral\nimage classification. Unlike current state-of-the-art approaches in CNN-based\nhyperspectral image classification, the proposed network, called contextual\ndeep CNN, can optimally explore local contextual interactions by jointly\nexploiting local spatio-spectral relationships of neighboring individual pixel\nvectors. The joint exploitation of the spatio-spectral information is achieved\nby a multi-scale convolutional filter bank used as an initial component of the\nproposed CNN pipeline. The initial spatial and spectral feature maps obtained\nfrom the multi-scale filter bank are then combined together to form a joint\nspatio-spectral feature map. The joint feature map representing rich spectral\nand spatial properties of the hyperspectral image is then fed through a fully\nconvolutional network that eventually predicts the corresponding label of each\npixel vector. The proposed approach is tested on three benchmark datasets: the\nIndian Pines dataset, the Salinas dataset and the University of Pavia dataset.\nPerformance comparison shows enhanced classification performance of the\nproposed approach over the current state-of-the-art on the three datasets.",
    "published": "2016-04-12T18:44:34Z",
    "updated": "2017-05-09T14:21:21Z",
    "authors": [
      "Hyungtae Lee",
      "Heesung Kwon"
    ],
    "link": "http://arxiv.org/abs/1604.03519v3",
    "pdf_link": "http://arxiv.org/pdf/1604.03519v3"
  },
  {
    "api_id": 346,
    "title": "Using Satellite Imagery for Good: Detecting Communities in Desert and\n  Mapping Vaccination Activities",
    "summary": "Deep convolutional neural networks (CNNs) have outperformed existing object\nrecognition and detection algorithms. On the other hand satellite imagery\ncaptures scenes that are diverse. This paper describes a deep learning approach\nthat analyzes a geo referenced satellite image and efficiently detects built\nstructures in it. A Fully Convolution Network (FCN) is trained on low\nresolution Google earth satellite imagery in order to achieve end result. The\ndetected built communities are then correlated with the vaccination activity\nthat has furnished some useful statistics.",
    "published": "2017-05-12T07:23:06Z",
    "updated": "2017-05-12T07:23:06Z",
    "authors": [
      "Anza Shakeel",
      "Mohsen Ali"
    ],
    "link": "http://arxiv.org/abs/1705.04451v1",
    "pdf_link": "http://arxiv.org/pdf/1705.04451v1"
  },
  {
    "api_id": 347,
    "title": "Variance Based Moving K-Means Algorithm",
    "summary": "Clustering is a useful data exploratory method with its wide applicability in\nmultiple fields. However, data clustering greatly relies on initialization of\ncluster centers that can result in large intra-cluster variance and dead\ncenters, therefore leading to sub-optimal solutions. This paper proposes a\nnovel variance based version of the conventional Moving K-Means (MKM) algorithm\ncalled Variance Based Moving K-Means (VMKM) that can partition data into\noptimal homogeneous clusters, irrespective of cluster initialization. The\nalgorithm utilizes a novel distance metric and a unique data element selection\ncriteria to transfer the selected elements between clusters to achieve low\nintra-cluster variance and subsequently avoid dead centers. Quantitative and\nqualitative comparison with various clustering techniques is performed on four\ndatasets selected from image processing, bioinformatics, remote sensing and the\nstock market respectively. An extensive analysis highlights the superior\nperformance of the proposed method over other techniques.",
    "published": "2017-04-07T12:10:39Z",
    "updated": "2017-05-12T13:03:54Z",
    "authors": [
      "Vibin Vijay",
      "Raghunath Vp",
      "Amarjot Singh",
      "SN Omar"
    ],
    "link": "http://arxiv.org/abs/1704.02197v2",
    "pdf_link": "http://arxiv.org/pdf/1704.02197v2"
  },
  {
    "api_id": 348,
    "title": "Extracting urban impervious surface from GF-1 imagery using one-class\n  classifiers",
    "summary": "Impervious surface area is a direct consequence of the urbanization, which\nalso plays an important role in urban planning and environmental management.\nWith the rapidly technical development of remote sensing, monitoring urban\nimpervious surface via high spatial resolution (HSR) images has attracted\nunprecedented attention recently. Traditional multi-classes models are\ninefficient for impervious surface extraction because it requires labeling all\nneeded and unneeded classes that occur in the image exhaustively. Therefore, we\nneed to find a reliable one-class model to classify one specific land cover\ntype without labeling other classes. In this study, we investigate several\none-class classifiers, such as Presence and Background Learning (PBL), Positive\nUnlabeled Learning (PUL), OCSVM, BSVM and MAXENT, to extract urban impervious\nsurface area using high spatial resolution imagery of GF-1, China's new\ngeneration of high spatial remote sensing satellite, and evaluate the\nclassification accuracy based on artificial interpretation results. Compared to\ntraditional multi-classes classifiers (ANN and SVM), the experimental results\nindicate that PBL and PUL provide higher classification accuracy, which is\nsimilar to the accuracy provided by ANN model. Meanwhile, PBL and PUL\noutperforms OCSVM, BSVM, MAXENT and SVM models. Hence, the one-class\nclassifiers only need a small set of specific samples to train models without\nlosing predictive accuracy, which is supposed to gain more attention on urban\nimpervious surface extraction or other one specific land cover type.",
    "published": "2017-05-13T13:39:42Z",
    "updated": "2017-05-13T13:39:42Z",
    "authors": [
      "Yao Yao",
      "Jialv He",
      "Jinbao Zhang",
      "Yatao Zhang"
    ],
    "link": "http://arxiv.org/abs/1705.04824v1",
    "pdf_link": "http://arxiv.org/pdf/1705.04824v1"
  },
  {
    "api_id": 349,
    "title": "Joint Learning from Earth Observation and OpenStreetMap Data to Get\n  Faster Better Semantic Maps",
    "summary": "In this work, we investigate the use of OpenStreetMap data for semantic\nlabeling of Earth Observation images. Deep neural networks have been used in\nthe past for remote sensing data classification from various sensors, including\nmultispectral, hyperspectral, SAR and LiDAR data. While OpenStreetMap has\nalready been used as ground truth data for training such networks, this\nabundant data source remains rarely exploited as an input information layer. In\nthis paper, we study different use cases and deep network architectures to\nleverage OpenStreetMap data for semantic labeling of aerial and satellite\nimages. Especially , we look into fusion based architectures and coarse-to-fine\nsegmentation to include the OpenStreetMap layer into multispectral-based deep\nfully convolutional networks. We illustrate how these methods can be\nsuccessfully used on two public datasets: ISPRS Potsdam and DFC2017. We show\nthat OpenStreetMap data can efficiently be integrated into the vision-based\ndeep learning models and that it significantly improves both the accuracy\nperformance and the convergence speed of the networks.",
    "published": "2017-05-17T09:07:08Z",
    "updated": "2017-05-17T09:07:08Z",
    "authors": [
      "Nicolas Audebert",
      "Bertrand Le Saux",
      "Sébastien Lefèvre"
    ],
    "link": "http://arxiv.org/abs/1705.06057v1",
    "pdf_link": "http://arxiv.org/pdf/1705.06057v1"
  },
  {
    "api_id": 350,
    "title": "Locally-adapted convolution-based super-resolution of\n  irregularly-sampled ocean remote sensing data",
    "summary": "Super-resolution is a classical problem in image processing, with numerous\napplications to remote sensing image enhancement. Here, we address the\nsuper-resolution of irregularly-sampled remote sensing images. Using an optimal\ninterpolation as the low-resolution reconstruction, we explore locally-adapted\nmultimodal convolutional models and investigate different dictionary-based\ndecompositions, namely based on principal component analysis (PCA), sparse\npriors and non-negativity constraints. We consider an application to the\nreconstruction of sea surface height (SSH) fields from two information sources,\nalong-track altimeter data and sea surface temperature (SST) data. The reported\nexperiments demonstrate the relevance of the proposed model, especially\nlocally-adapted parametrizations with non-negativity constraints, to outperform\noptimally-interpolated reconstructions.",
    "published": "2017-04-07T09:51:23Z",
    "updated": "2017-09-27T15:24:51Z",
    "authors": [
      "Manuel López-Radcenco",
      "Ronan Fablet",
      "Abdeldjalil Aïssa-El-Bey",
      "Pierre Ailliot"
    ],
    "link": "http://arxiv.org/abs/1704.02162v2",
    "pdf_link": "http://arxiv.org/pdf/1704.02162v2"
  },
  {
    "api_id": 351,
    "title": "Where computer vision can aid physics: dynamic cloud motion forecasting\n  from satellite images",
    "summary": "This paper describes a new algorithm for solar energy forecasting from a\nsequence of Cloud Optical Depth (COD) images. The algorithm is based on the\nfollowing simple observation: the dynamics of clouds represented by COD images\nresembles the motion (transport) of a density in a fluid flow. This suggests\nthat, to forecast the motion of COD images, it is sufficient to forecast the\nflow. The latter, in turn, can be accomplished by fitting a parametric model of\nthe fluid flow to the COD images observed in the past. Namely, the learning\nphase of the algorithm is composed of the following steps: (i) given a sequence\nof COD images, the snapshots of the optical flow are estimated from two\nconsecutive COD images; (ii) these snapshots are then assimilated into a\nNavier-Stokes Equation (NSE), i.e. an initial velocity field for NSE is\nselected so that the corresponding NSE' solution is as close as possible to the\noptical flow snapshots. The prediction phase consists of utilizing a linear\ntransport equation, which describes the propagation of COD images in the fluid\nflow predicted by NSE, to estimate the future motion of the COD images. The\nalgorithm has been tested on COD images provided by two geostationary\noperational environmental satellites from NOAA serving the west-hemisphere.",
    "published": "2017-09-30T12:55:13Z",
    "updated": "2017-09-30T12:55:13Z",
    "authors": [
      "Sergiy Zhuk",
      "Tigran Tchrakian",
      "Albert Akhriev",
      "Siyuan Lu",
      "Hendrik Hamann"
    ],
    "link": "http://arxiv.org/abs/1710.00194v1",
    "pdf_link": "http://arxiv.org/pdf/1710.00194v1"
  },
  {
    "api_id": 352,
    "title": "Remote Sensing Image Classification with Large Scale Gaussian Processes",
    "summary": "Current remote sensing image classification problems have to deal with an\nunprecedented amount of heterogeneous and complex data sources. Upcoming\nmissions will soon provide large data streams that will make land cover/use\nclassification difficult. Machine learning classifiers can help at this, and\nmany methods are currently available. A popular kernel classifier is the\nGaussian process classifier (GPC), since it approaches the classification\nproblem with a solid probabilistic treatment, thus yielding confidence\nintervals for the predictions as well as very competitive results to\nstate-of-the-art neural networks and support vector machines. However, its\ncomputational cost is prohibitive for large scale applications, and constitutes\nthe main obstacle precluding wide adoption. This paper tackles this problem by\nintroducing two novel efficient methodologies for Gaussian Process (GP)\nclassification. We first include the standard random Fourier features\napproximation into GPC, which largely decreases its computational cost and\npermits large scale remote sensing image classification. In addition, we\npropose a model which avoids randomly sampling a number of Fourier frequencies,\nand alternatively learns the optimal ones within a variational Bayes approach.\nThe performance of the proposed methods is illustrated in complex problems of\ncloud detection from multispectral imagery and infrared sounding data.\nExcellent empirical results support the proposal in both computational cost and\naccuracy.",
    "published": "2017-10-02T10:51:47Z",
    "updated": "2017-10-03T10:40:11Z",
    "authors": [
      "Pablo Morales-Alvarez",
      "Adrian Perez-Suay",
      "Rafael Molina",
      "Gustau Camps-Valls"
    ],
    "link": "http://arxiv.org/abs/1710.00575v2",
    "pdf_link": "http://arxiv.org/pdf/1710.00575v2"
  },
  {
    "api_id": 353,
    "title": "A Fully Convolutional Network for Semantic Labeling of 3D Point Clouds",
    "summary": "When classifying point clouds, a large amount of time is devoted to the\nprocess of engineering a reliable set of features which are then passed to a\nclassifier of choice. Generally, such features - usually derived from the\n3D-covariance matrix - are computed using the surrounding neighborhood of\npoints. While these features capture local information, the process is usually\ntime-consuming, and requires the application at multiple scales combined with\ncontextual methods in order to adequately describe the diversity of objects\nwithin a scene. In this paper we present a 1D-fully convolutional network that\nconsumes terrain-normalized points directly with the corresponding spectral\ndata,if available, to generate point-wise labeling while implicitly learning\ncontextual features in an end-to-end fashion. Our method uses only the\n3D-coordinates and three corresponding spectral features for each point.\nSpectral features may either be extracted from 2D-georeferenced images, as\nshown here for Light Detection and Ranging (LiDAR) point clouds, or extracted\ndirectly for passive-derived point clouds,i.e. from muliple-view imagery. We\ntrain our network by splitting the data into square regions, and use a pooling\nlayer that respects the permutation-invariance of the input points. Evaluated\nusing the ISPRS 3D Semantic Labeling Contest, our method scored second place\nwith an overall accuracy of 81.6%. We ranked third place with a mean F1-score\nof 63.32%, surpassing the F1-score of the method with highest accuracy by\n1.69%. In addition to labeling 3D-point clouds, we also show that our method\ncan be easily extended to 2D-semantic segmentation tasks, with promising\ninitial results.",
    "published": "2017-10-03T22:35:25Z",
    "updated": "2017-10-03T22:35:25Z",
    "authors": [
      "Mohammed Yousefhussien",
      "David J. Kelbe",
      "Emmett J. Ientilucci",
      "Carl Salvaggio"
    ],
    "link": "http://arxiv.org/abs/1710.01408v1",
    "pdf_link": "http://arxiv.org/pdf/1710.01408v1"
  },
  {
    "api_id": 354,
    "title": "Multitask Learning using Task Clustering with Applications to Predictive\n  Modeling and GWAS of Plant Varieties",
    "summary": "Inferring predictive maps between multiple input and multiple output\nvariables or tasks has innumerable applications in data science. Multi-task\nlearning attempts to learn the maps to several output tasks simultaneously with\ninformation sharing between them. We propose a novel multi-task learning\nframework for sparse linear regression, where a full task hierarchy is\nautomatically inferred from the data, with the assumption that the task\nparameters follow a hierarchical tree structure. The leaves of the tree are the\nparameters for individual tasks, and the root is the global model that\napproximates all the tasks. We apply the proposed approach to develop and\nevaluate: (a) predictive models of plant traits using large-scale and automated\nremote sensing data, and (b) GWAS methodologies mapping such derived phenotypes\nin lieu of hand-measured traits. We demonstrate the superior performance of our\napproach compared to other methods, as well as the usefulness of discovering\nhierarchical groupings between tasks. Our results suggest that richer genetic\nmapping can indeed be obtained from the remote sensing data. In addition, our\ndiscovered groupings reveal interesting insights from a plant science\nperspective.",
    "published": "2017-10-04T20:13:21Z",
    "updated": "2017-10-04T20:13:21Z",
    "authors": [
      "Ming Yu",
      "Addie M. Thompson",
      "Karthikeyan Natesan Ramamurthy",
      "Eunho Yang",
      "Aurélie C. Lozano"
    ],
    "link": "http://arxiv.org/abs/1710.01788v1",
    "pdf_link": "http://arxiv.org/pdf/1710.01788v1"
  },
  {
    "api_id": 355,
    "title": "FPGA based Parallelized Architecture of Efficient Graph based Image\n  Segmentation Algorithm",
    "summary": "Efficient and real time segmentation of color images has a variety of\nimportance in many fields of computer vision such as image compression, medical\nimaging, mapping and autonomous navigation. Being one of the most\ncomputationally expensive operation, it is usually done through software imple-\nmentation using high-performance processors. In robotic systems, however, with\nthe constrained platform dimensions and the need for portability, low power\nconsumption and simultaneously the need for real time image segmentation, we\nenvision hardware parallelism as the way forward to achieve higher\nacceleration. Field-programmable gate arrays (FPGAs) are among the best suited\nfor this task as they provide high computing power in a small physical area.\nThey exceed the computing speed of software based implementations by breaking\nthe paradigm of sequential execution and accomplishing more per clock cycle\noperations by enabling hardware level parallelization at an architectural\nlevel. In this paper, we propose three novel architectures of a well known\nEfficient Graph based Image Segmentation algorithm. These proposed\nimplementations optimizes time and power consumption when compared to software\nimplementations. The hybrid design proposed, has notable furtherance of\nacceleration capabilities delivering atleast 2X speed gain over other implemen-\ntations, which henceforth allows real time image segmentation that can be\ndeployed on Mobile Robotic systems.",
    "published": "2017-10-06T02:48:26Z",
    "updated": "2017-10-06T02:48:26Z",
    "authors": [
      "Roopal Nahar",
      "Akanksha Baranwal",
      "K. Madhava Krishna"
    ],
    "link": "http://arxiv.org/abs/1710.02260v1",
    "pdf_link": "http://arxiv.org/pdf/1710.02260v1"
  },
  {
    "api_id": 356,
    "title": "Keynote: Small Neural Nets Are Beautiful: Enabling Embedded Systems with\n  Small Deep-Neural-Network Architectures",
    "summary": "Over the last five years Deep Neural Nets have offered more accurate\nsolutions to many problems in speech recognition, and computer vision, and\nthese solutions have surpassed a threshold of acceptability for many\napplications. As a result, Deep Neural Networks have supplanted other\napproaches to solving problems in these areas, and enabled many new\napplications. While the design of Deep Neural Nets is still something of an art\nform, in our work we have found basic principles of design space exploration\nused to develop embedded microprocessor architectures to be highly applicable\nto the design of Deep Neural Net architectures. In particular, we have used\nthese design principles to create a novel Deep Neural Net called SqueezeNet\nthat requires as little as 480KB of storage for its model parameters. We have\nfurther integrated all these experiences to develop something of a playbook for\ncreating small Deep Neural Nets for embedded systems.",
    "published": "2017-10-07T23:33:31Z",
    "updated": "2017-10-07T23:33:31Z",
    "authors": [
      "Forrest Iandola",
      "Kurt Keutzer"
    ],
    "link": "http://arxiv.org/abs/1710.02759v1",
    "pdf_link": "http://arxiv.org/pdf/1710.02759v1"
  },
  {
    "api_id": 357,
    "title": "Does Normalization Methods Play a Role for Hyperspectral Image\n  Classification?",
    "summary": "For Hyperspectral image (HSI) datasets, each class have their salient feature\nand classifiers classify HSI datasets according to the class's saliency\nfeatures, however, there will be different salient features when use different\nnormalization method. In this letter, we report the effect on classifiers by\ndifferent normalization methods and recommend the best normalization methods\nfor classifier after analyzing the impact of different normalization methods on\nclassifiers. Pavia University datasets, Indian Pines datasets and Kennedy Space\nCenter datasets will apply to several typical classifiers in order to evaluate\nand analysis the impact of different normalization methods on typical\nclassifiers.",
    "published": "2017-10-09T05:08:32Z",
    "updated": "2017-10-09T05:08:32Z",
    "authors": [
      "Faxian Cao",
      "Zhijing Yang",
      "Jinchang Ren",
      "Mengying Jiang",
      "Wing-Kuen Ling"
    ],
    "link": "http://arxiv.org/abs/1710.02939v1",
    "pdf_link": "http://arxiv.org/pdf/1710.02939v1"
  },
  {
    "api_id": 358,
    "title": "Deep learning in remote sensing: a review",
    "summary": "Standing at the paradigm shift towards data-intensive science, machine\nlearning techniques are becoming increasingly important. In particular, as a\nmajor breakthrough in the field, deep learning has proven as an extremely\npowerful tool in many fields. Shall we embrace deep learning as the key to all?\nOr, should we resist a 'black-box' solution? There are controversial opinions\nin the remote sensing community. In this article, we analyze the challenges of\nusing deep learning for remote sensing data analysis, review the recent\nadvances, and provide resources to make deep learning in remote sensing\nridiculously simple to start with. More importantly, we advocate remote sensing\nscientists to bring their expertise into deep learning, and use it as an\nimplicit general model to tackle unprecedented large-scale influential\nchallenges, such as climate change and urbanization.",
    "published": "2017-10-11T08:35:05Z",
    "updated": "2017-10-11T08:35:05Z",
    "authors": [
      "Xiao Xiang Zhu",
      "Devis Tuia",
      "Lichao Mou",
      "Gui-Song Xia",
      "Liangpei Zhang",
      "Feng Xu",
      "Friedrich Fraundorfer"
    ],
    "link": "http://arxiv.org/abs/1710.03959v1",
    "pdf_link": "http://arxiv.org/pdf/1710.03959v1"
  },
  {
    "api_id": 359,
    "title": "Hyperspectral Unmixing: Ground Truth Labeling, Datasets, Benchmark\n  Performances and Survey",
    "summary": "Hyperspectral unmixing (HU) is a very useful and increasingly popular\npreprocessing step for a wide range of hyperspectral applications. However, the\nHU research has been constrained a lot by three factors: (a) the number of\nhyperspectral images (especially the ones with ground truths) are very limited;\n(b) the ground truths of most hyperspectral images are not shared on the web,\nwhich may cause lots of unnecessary troubles for researchers to evaluate their\nalgorithms; (c) the codes of most state-of-the-art methods are not shared,\nwhich may also delay the testing of new methods.\n  Accordingly, this paper deals with the above issues from the following three\nperspectives: (1) as a profound contribution, we provide a general labeling\nmethod for the HU. With it, we labeled up to 15 hyperspectral images, providing\n18 versions of ground truths. To the best of our knowledge, this is the first\npaper to summarize and share up to 15 hyperspectral images and their 18\nversions of ground truths for the HU. Observing that the hyperspectral\nclassification (HyC) has much more standard datasets (whose ground truths are\ngenerally publicly shared) than the HU, we propose an interesting method to\ntransform the HyC datasets for the HU research. (2) To further facilitate the\nevaluation of HU methods under different conditions, we reviewed and\nimplemented the algorithm to generate a complex synthetic hyperspectral image.\nBy tuning the hyper-parameters in the code, we may verify the HU methods from\nfour perspectives. The code would also be shared on the web. (3) To provide a\nstandard comparison, we reviewed up to 10 state-of-the-art HU algorithms, then\nselected the 5 most benchmark HU algorithms, and compared them on the 15 real\nhyperspectral datasets. The experiment results are surely reproducible; the\nimplemented codes would be shared on the web.",
    "published": "2017-08-17T03:35:02Z",
    "updated": "2017-10-11T16:22:06Z",
    "authors": [
      "Feiyun Zhu"
    ],
    "link": "http://arxiv.org/abs/1708.05125v2",
    "pdf_link": "http://arxiv.org/pdf/1708.05125v2"
  },
  {
    "api_id": 360,
    "title": "Measurement Context Extraction from Text: Discovering Opportunities and\n  Gaps in Earth Science",
    "summary": "We propose Marve, a system for extracting measurement values, units, and\nrelated words from natural language text. Marve uses conditional random fields\n(CRF) to identify measurement values and units, followed by a rule-based system\nto find related entities, descriptors and modifiers within a sentence. Sentence\ntokens are represented by an undirected graphical model, and rules are based on\npart-of-speech and word dependency patterns connecting values and units to\ncontextual words. Marve is unique in its focus on measurement context and early\nexperimentation demonstrates Marve's ability to generate high-precision\nextractions with strong recall. We also discuss Marve's role in refining\nmeasurement requirements for NASA's proposed HyspIRI mission, a hyperspectral\ninfrared imaging satellite that will study the world's ecosystems. In general,\nour work with HyspIRI demonstrates the value of semantic measurement\nextractions in characterizing quantitative discussion contained in large\ncorpuses of natural language text. These extractions accelerate broad,\ncross-cutting research and expose scientists new algorithmic approaches and\nexperimental nuances. They also facilitate identification of scientific\nopportunities enabled by HyspIRI leading to more efficient scientific\ninvestment and research.",
    "published": "2017-10-11T21:37:07Z",
    "updated": "2017-10-11T21:37:07Z",
    "authors": [
      "Kyle Hundman",
      "Chris A. Mattmann"
    ],
    "link": "http://arxiv.org/abs/1710.04312v1",
    "pdf_link": "http://arxiv.org/pdf/1710.04312v1"
  },
  {
    "api_id": 361,
    "title": "Linear vs Nonlinear Extreme Learning Machine for Spectral-Spatial\n  Classification of Hyperspectral Image",
    "summary": "As a new machine learning approach, extreme learning machine (ELM) has\nreceived wide attentions due to its good performances. However, when directly\napplied to the hyperspectral image (HSI) classification, the recognition rate\nis too low. This is because ELM does not use the spatial information which is\nvery important for HSI classification. In view of this, this paper proposes a\nnew framework for spectral-spatial classification of HSI by combining ELM with\nloopy belief propagation (LBP). The original ELM is linear, and the nonlinear\nELMs (or Kernel ELMs) are the improvement of linear ELM (LELM). However, based\non lots of experiments and analysis, we found out that the LELM is a better\nchoice than nonlinear ELM for spectral-spatial classification of HSI.\nFurthermore, we exploit the marginal probability distribution that uses the\nwhole information in the HSI and learn such distribution using the LBP. The\nproposed method not only maintain the fast speed of ELM, but also greatly\nimproves the accuracy of classification. The experimental results in the\nwell-known HSI data sets, Indian Pines and Pavia University, demonstrate the\ngood performances of the proposed method.",
    "published": "2017-09-05T06:53:02Z",
    "updated": "2017-10-12T02:16:40Z",
    "authors": [
      "Faxian Cao",
      "Zhijing Yang",
      "Jinchang Ren",
      "Mengying Jiang",
      "Wing-Kuen Ling"
    ],
    "link": "http://arxiv.org/abs/1709.02253v2",
    "pdf_link": "http://arxiv.org/pdf/1709.02253v2"
  },
  {
    "api_id": 362,
    "title": "Hyperspectral band selection using genetic algorithm and support vector\n  machines for early identification of charcoal rot disease in soybean",
    "summary": "Charcoal rot is a fungal disease that thrives in warm dry conditions and\naffects the yield of soybeans and other important agronomic crops worldwide.\nThere is a need for robust, automatic and consistent early detection and\nquantification of disease symptoms which are important in breeding programs for\nthe development of improved cultivars and in crop production for the\nimplementation of disease control measures for yield protection. Current\nmethods of plant disease phenotyping are predominantly visual and hence are\nslow and prone to human error and variation. There has been increasing interest\nin hyperspectral imaging applications for early detection of disease symptoms.\nHowever, the high dimensionality of hyperspectral data makes it very important\nto have an efficient analysis pipeline in place for the identification of\ndisease so that effective crop management decisions can be made. The focus of\nthis work is to determine the minimal number of most effective hyperspectral\nbands that can distinguish between healthy and diseased specimens early in the\ngrowing season. Healthy and diseased hyperspectral data cubes were captured at\n3, 6, 9, 12, and 15 days after inoculation. We utilized inoculated and control\nspecimens from 4 different genotypes. Each hyperspectral image was captured at\n240 different wavelengths in the range of 383 to 1032 nm. We used a combination\nof genetic algorithm as an optimizer and support vector machines as a\nclassifier for identification of maximally effective band combinations. A\nbinary classification between healthy and infected samples using six selected\nband combinations obtained a classification accuracy of 97% and a F1 score of\n0.97 for the infected class. The results demonstrated that these carefully\nchosen bands are more informative than RGB images, and could be used in a\nmultispectral camera for remote identification of charcoal rot infection in\nsoybean.",
    "published": "2017-10-12T18:27:41Z",
    "updated": "2017-10-12T18:27:41Z",
    "authors": [
      "Koushik Nagasubramanian",
      "Sarah Jones",
      "Soumik Sarkar",
      "Asheesh K. Singh",
      "Arti Singh",
      "Baskar Ganapathysubramanian"
    ],
    "link": "http://arxiv.org/abs/1710.04681v1",
    "pdf_link": "http://arxiv.org/pdf/1710.04681v1"
  },
  {
    "api_id": 363,
    "title": "Filmy Cloud Removal on Satellite Imagery with Multispectral Conditional\n  Generative Adversarial Nets",
    "summary": "In this paper, we propose a method for cloud removal from visible light RGB\nsatellite images by extending the conditional Generative Adversarial Networks\n(cGANs) from RGB images to multispectral images. Satellite images have been\nwidely utilized for various purposes, such as natural environment monitoring\n(pollution, forest or rivers), transportation improvement and prompt emergency\nresponse to disasters. However, the obscurity caused by clouds makes it\nunstable to monitor the situation on the ground with the visible light camera.\nImages captured by a longer wavelength are introduced to reduce the effects of\nclouds. Synthetic Aperture Radar (SAR) is such an example that improves\nvisibility even the clouds exist. On the other hand, the spatial resolution\ndecreases as the wavelength increases. Furthermore, the images captured by long\nwavelengths differs considerably from those captured by visible light in terms\nof their appearance. Therefore, we propose a network that can remove clouds and\ngenerate visible light images from the multispectral images taken as inputs.\nThis is achieved by extending the input channels of cGANs to be compatible with\nmultispectral images. The networks are trained to output images that are close\nto the ground truth using the images synthesized with clouds over the ground\ntruth as inputs. In the available dataset, the proportion of images of the\nforest or the sea is very high, which will introduce bias in the training\ndataset if uniformly sampled from the original dataset. Thus, we utilize the\nt-Distributed Stochastic Neighbor Embedding (t-SNE) to improve the problem of\nbias in the training dataset. Finally, we confirm the feasibility of the\nproposed network on the dataset of four bands images, which include three\nvisible light bands and one near-infrared (NIR) band.",
    "published": "2017-10-13T08:26:13Z",
    "updated": "2017-10-13T08:26:13Z",
    "authors": [
      "Kenji Enomoto",
      "Ken Sakurada",
      "Weimin Wang",
      "Hiroshi Fukui",
      "Masashi Matsuoka",
      "Ryosuke Nakamura",
      "Nobuo Kawaguchi"
    ],
    "link": "http://arxiv.org/abs/1710.04835v1",
    "pdf_link": "http://arxiv.org/pdf/1710.04835v1"
  },
  {
    "api_id": 364,
    "title": "Sparse Representation Based Augmented Multinomial Logistic Extreme\n  Learning Machine with Weighted Composite Features for Spectral Spatial\n  Hyperspectral Image Classification",
    "summary": "Although extreme learning machine (ELM) has been successfully applied to a\nnumber of pattern recognition problems, it fails to pro-vide sufficient good\nresults in hyperspectral image (HSI) classification due to two main drawbacks.\nThe first is due to the random weights and bias of ELM, which may lead to\nill-posed problems. The second is the lack of spatial information for\nclassification. To tackle these two problems, in this paper, we propose a new\nframework for ELM based spectral-spatial classification of HSI, where\nprobabilistic modelling with sparse representation and weighted composite\nfeatures (WCF) are employed respectively to derive the op-timized output\nweights and extract spatial features. First, the ELM is represented as a\nconcave logarithmic likelihood function under statistical modelling using the\nmaximum a posteriori (MAP). Second, the sparse representation is applied to the\nLaplacian prior to effi-ciently determine a logarithmic posterior with a unique\nmaximum in order to solve the ill-posed problem of ELM. The variable splitting\nand the augmented Lagrangian are subsequently used to further reduce the\ncomputation complexity of the proposed algorithm and it has been proven a more\nefficient method for speed improvement. Third, the spatial information is\nextracted using the weighted compo-site features (WCFs) to construct the\nspectral-spatial classification framework. In addition, the lower bound of the\nproposed method is derived by a rigorous mathematical proof. Experimental\nresults on two publicly available HSI data sets demonstrate that the proposed\nmethodology outperforms ELM and a number of state-of-the-art approaches.",
    "published": "2017-09-12T11:39:51Z",
    "updated": "2017-10-14T12:25:21Z",
    "authors": [
      "Faxian Cao",
      "Zhijing Yang",
      "Jinchang Ren",
      "Wing-Kuen Ling"
    ],
    "link": "http://arxiv.org/abs/1709.03792v2",
    "pdf_link": "http://arxiv.org/pdf/1709.03792v2"
  },
  {
    "api_id": 365,
    "title": "Using Deep Learning and Satellite Imagery to Quantify the Impact of the\n  Built Environment on Neighborhood Crime Rates",
    "summary": "The built environment has been postulated to have an impact on neighborhood\ncrime rates, however, measures of the built environment can be subjective and\ndiffer across studies leading to varying observations on its association with\ncrime rates. Here, we illustrate an accurate and straightforward approach to\nquantify the impact of the built environment on neighborhood crime rates from\nhigh-resolution satellite imagery. Using geo-referenced crime reports and\nsatellite images for three United States cities, we demonstrate how image\nfeatures consistently identified using a convolutional neural network can\nexplain up to 82% of the variation in neighborhood crime rates. Our results\nsuggest the built environment is a strong predictor of crime rates, and this\ncan lead to structural interventions shown to reduce crime incidence in urban\nsettings.",
    "published": "2017-10-16T03:05:05Z",
    "updated": "2017-10-16T03:05:05Z",
    "authors": [
      "Adyasha Maharana",
      "Quynh C. Nguyen",
      "Elaine O. Nsoesie"
    ],
    "link": "http://arxiv.org/abs/1710.05483v1",
    "pdf_link": "http://arxiv.org/pdf/1710.05483v1"
  },
  {
    "api_id": 366,
    "title": "Intention-Net: Integrating Planning and Deep Learning for Goal-Directed\n  Autonomous Navigation",
    "summary": "How can a delivery robot navigate reliably to a destination in a new office\nbuilding, with minimal prior information? To tackle this challenge, this paper\nintroduces a two-level hierarchical approach, which integrates model-free deep\nlearning and model-based path planning. At the low level, a neural-network\nmotion controller, called the intention-net, is trained end-to-end to provide\nrobust local navigation. The intention-net maps images from a single monocular\ncamera and \"intentions\" directly to robot controls. At the high level, a path\nplanner uses a crude map, e.g., a 2-D floor plan, to compute a path from the\nrobot's current location to the goal. The planned path provides intentions to\nthe intention-net. Preliminary experiments suggest that the learned motion\ncontroller is robust against perceptual uncertainty and by integrating with a\npath planner, it generalizes effectively to new environments and goals.",
    "published": "2017-10-16T11:22:32Z",
    "updated": "2017-10-17T02:24:06Z",
    "authors": [
      "Wei Gao",
      "David Hsu",
      "Wee Sun Lee",
      "Shengmei Shen",
      "Karthikk Subramanian"
    ],
    "link": "http://arxiv.org/abs/1710.05627v2",
    "pdf_link": "http://arxiv.org/pdf/1710.05627v2"
  },
  {
    "api_id": 367,
    "title": "Searching for Exoplanets Using Artificial Intelligence",
    "summary": "In the last decade, over a million stars were monitored to detect transiting\nplanets. Manual interpretation of potential exoplanet candidates is labor\nintensive and subject to human error, the results of which are difficult to\nquantify. Here we present a new method of detecting exoplanet candidates in\nlarge planetary search projects which, unlike current methods uses a neural\nnetwork. Neural networks, also called \"deep learning\" or \"deep nets\" are\ndesigned to give a computer perception into a specific problem by training it\nto recognize patterns. Unlike past transit detection algorithms deep nets learn\nto recognize planet features instead of relying on hand-coded metrics that\nhumans perceive as the most representative. Our convolutional neural network is\ncapable of detecting Earth-like exoplanets in noisy time-series data with a\ngreater accuracy than a least-squares method. Deep nets are highly\ngeneralizable allowing data to be evaluated from different time series after\ninterpolation without compromising performance. As validated by our deep net\nanalysis of Kepler light curves, we detect periodic transits consistent with\nthe true period without any model fitting. Our study indicates that machine\nlearning will facilitate the characterization of exoplanets in future analysis\nof large astronomy data sets.",
    "published": "2017-06-14T05:22:40Z",
    "updated": "2017-10-20T15:59:50Z",
    "authors": [
      "Kyle A. Pearson",
      "Leon Palafox",
      "Caitlin A. Griffith"
    ],
    "link": "http://arxiv.org/abs/1706.04319v2",
    "pdf_link": "http://arxiv.org/pdf/1706.04319v2"
  },
  {
    "api_id": 368,
    "title": "Generalized linear mixing model accounting for endmember variability",
    "summary": "Endmember variability is an important factor for accurately unveiling vital\ninformation relating the pure materials and their distribution in hyperspectral\nimages. Recently, the extended linear mixing model (ELMM) has been proposed as\na modification of the linear mixing model (LMM) to consider endmember\nvariability effects resulting mainly from illumination changes. In this paper,\nwe further generalize the ELMM leading to a new model (GLMM) to account for\nmore complex spectral distortions where different wavelength intervals can be\naffected unevenly. We also extend the existing methodology to jointly estimate\nthe variability and the abundances for the GLMM. Simulations with real and\nsynthetic data show that the unmixing process can benefit from the extra\nflexibility introduced by the GLMM.",
    "published": "2017-10-20T22:46:12Z",
    "updated": "2017-10-20T22:46:12Z",
    "authors": [
      "Tales Imbiriba",
      "Ricardo Augusto Borsoi",
      "José Carlos Moreira Bermudez"
    ],
    "link": "http://arxiv.org/abs/1710.07723v1",
    "pdf_link": "http://arxiv.org/pdf/1710.07723v1"
  },
  {
    "api_id": 369,
    "title": "Estimating the Mass of the Local Group using Machine Learning Applied to\n  Numerical Simulations",
    "summary": "We revisit the estimation of the combined mass of the Milky Way and Andromeda\n(M31), which dominate the mass of the Local Group. We make use of an ensemble\nof 30,190 halo pairs from the Small MultiDark simulation, assuming a\n$\\Lambda$CDM (Cosmological Constant with Cold Dark Matter) cosmology, to\ninvestigate the relationship between the bound mass and parameters\ncharacterising the orbit of the binary and their local environment with the aid\nof machine learning methods (artificial neural networks, ANN). Results from the\nANN are most successful when information about the velocity shear is provided,\nwhich demonstrates the flexibility of machine learning to model physical\nphenomena and readily incorporate new information as it becomes available. The\nresulting estimate for the Local Group mass, when shear information is\nincluded, is $4.9 \\times 10^{12} M_\\odot$, with an error of $\\pm0.8 \\times\n10^{12} M_\\odot$ from the 68% uncertainty in observables, and a 68% confidence\ninterval of $^{+1.3}_{-1.4} \\times 10^{12}M_\\odot$ from the intrinsic scatter\nfrom the differences between the model and simulation masses. We also consider\na recently reported large transverse velocity of M31 relative to the Milky Way,\nand produce an alternative mass estimate of $3.6\\pm0.3\\pm1.4 \\times\n10^{12}M_\\odot$. Although different methods predict similar values for the most\nlikely mass of the LG, application of ANN compared to the Timing Argument\nreduces the scatter in the log mass by over half when tested on samples from\nthe simulation.",
    "published": "2016-06-08T19:24:37Z",
    "updated": "2017-10-26T01:52:43Z",
    "authors": [
      "Michael McLeod",
      "Noam Libeskind",
      "Ofer Lahav",
      "Yehuda Hoffman"
    ],
    "link": "http://arxiv.org/abs/1606.02694v3",
    "pdf_link": "http://arxiv.org/pdf/1606.02694v3"
  },
  {
    "api_id": 370,
    "title": "Data-driven Feature Sampling for Deep Hyperspectral Classification and\n  Segmentation",
    "summary": "The high dimensionality of hyperspectral imaging forces unique challenges in\nscope, size and processing requirements. Motivated by the potential for an\nin-the-field cell sorting detector, we examine a $\\textit{Synechocystis sp.}$\nPCC 6803 dataset wherein cells are grown alternatively in nitrogen rich or\ndeplete cultures. We use deep learning techniques to both successfully classify\ncells and generate a mask segmenting the cells/condition from the background.\nFurther, we use the classification accuracy to guide a data-driven, iterative\nfeature selection method, allowing the design neural networks requiring 90%\nfewer input features with little accuracy degradation.",
    "published": "2017-10-26T22:45:28Z",
    "updated": "2017-10-26T22:45:28Z",
    "authors": [
      "William M. Severa",
      "Jerilyn A. Timlin",
      "Suraj Kholwadwala",
      "Conrad D. James",
      "James B. Aimone"
    ],
    "link": "http://arxiv.org/abs/1710.09934v1",
    "pdf_link": "http://arxiv.org/pdf/1710.09934v1"
  },
  {
    "api_id": 371,
    "title": "Optimal Control of Wireless Computing Networks",
    "summary": "Augmented information (AgI) services allow users to consume information that\nresults from the execution of a chain of service functions that process source\ninformation to create real-time augmented value. Applications include real-time\nanalysis of remote sensing data, real-time computer vision, personalized video\nstreaming, and augmented reality, among others. We consider the problem of\noptimal distribution of AgI services over a wireless computing network, in\nwhich nodes are equipped with both communication and computing resources. We\ncharacterize the wireless computing network capacity region and design a joint\nflow scheduling and resource allocation algorithm that stabilizes the\nunderlying queuing system while achieving a network cost arbitrarily close to\nthe minimum, with a tradeoff in network delay. Our solution captures the unique\nchaining and flow scaling aspects of AgI services, while exploiting the use of\nthe broadcast approach coding scheme over the wireless channel.",
    "published": "2017-10-27T23:58:31Z",
    "updated": "2017-10-27T23:58:31Z",
    "authors": [
      "Hao Feng",
      "Jaime Llorca",
      "Antonia M. Tulino",
      "Andreas F. Molisch"
    ],
    "link": "http://arxiv.org/abs/1710.10356v1",
    "pdf_link": "http://arxiv.org/pdf/1710.10356v1"
  },
  {
    "api_id": 372,
    "title": "Vehicle Routing Problem with Vector Profits (VRPVP) with Max-Min\n  Criterion",
    "summary": "This paper introduces a new routing problem referred to as the vehicle\nrouting problem with vector profits. Given a network composed of nodes\n(depot/sites) and arcs connecting the nodes, the problem determines routes that\ndepart from the depot, visit sites to collect profits, and return to the depot.\nThere are multiple stakeholders interested in the mission and each site is\nassociated with a vector whose k-th element represents the profit value for the\nk-th stakeholder. The objective of the problem is to maximize the profit sum\nfor the least satisfied stakeholder, i.e., the stakeholder with the smallest\ntotal profit value. An approach based on the linear programming relaxation and\ncolumn-generation to solve this max-min type routing problem was developed. Two\ncases studies - the planetary surface exploration and the Rome tour cases -\nwere presented to demonstrate the effectiveness of the proposed problem\nformulation and solution methodology.",
    "published": "2017-10-29T02:04:17Z",
    "updated": "2017-10-29T02:04:17Z",
    "authors": [
      "Dongoo Lee",
      "Jaemyung Ahn"
    ],
    "link": "http://arxiv.org/abs/1710.10550v1",
    "pdf_link": "http://arxiv.org/pdf/1710.10550v1"
  },
  {
    "api_id": 373,
    "title": "Using the quantization error from Self-Organized Map (SOM) output for\n  detecting critical variability in large bodies of image time series in less\n  than a minute",
    "summary": "The quantization error (QE) from SOM applied on time series of spatial\ncontrast images with variable relative amount of white and dark pixel contents,\nas in monochromatic medical images or satellite images, is proven a reliable\nindicator of potentially critical changes in image homogeneity. The QE is shown\nto increase linearly with the variability in spatial contrast contents across\ntime when contrast intensity is kept constant.",
    "published": "2017-10-29T17:05:12Z",
    "updated": "2017-10-29T17:05:12Z",
    "authors": [
      "Birgitta Dresp-Langley",
      "John Mwangi Wandeto"
    ],
    "link": "http://arxiv.org/abs/1710.10648v1",
    "pdf_link": "http://arxiv.org/pdf/1710.10648v1"
  },
  {
    "api_id": 374,
    "title": "Stochastic Subsampling for Factorizing Huge Matrices",
    "summary": "We present a matrix-factorization algorithm that scales to input matrices\nwith both huge number of rows and columns. Learned factors may be sparse or\ndense and/or non-negative, which makes our algorithm suitable for dictionary\nlearning, sparse component analysis, and non-negative matrix factorization. Our\nalgorithm streams matrix columns while subsampling them to iteratively learn\nthe matrix factors. At each iteration, the row dimension of a new sample is\nreduced by subsampling, resulting in lower time complexity compared to a simple\nstreaming algorithm. Our method comes with convergence guarantees to reach a\nstationary point of the matrix-factorization problem. We demonstrate its\nefficiency on massive functional Magnetic Resonance Imaging data (2 TB), and on\npatches extracted from hyperspectral images (103 GB). For both problems, which\ninvolve different penalties on rows and columns, we obtain significant\nspeed-ups compared to state-of-the-art algorithms.",
    "published": "2017-01-19T10:35:01Z",
    "updated": "2017-10-30T09:24:27Z",
    "authors": [
      "Arthur Mensch",
      "Julien Mairal",
      "Bertrand Thirion",
      "Gael Varoquaux"
    ],
    "link": "http://arxiv.org/abs/1701.05363v3",
    "pdf_link": "http://arxiv.org/pdf/1701.05363v3"
  },
  {
    "api_id": 375,
    "title": "Learning End-to-end Multimodal Sensor Policies for Autonomous Navigation",
    "summary": "Multisensory polices are known to enhance both state estimation and target\ntracking. However, in the space of end-to-end sensorimotor control, this\nmulti-sensor outlook has received limited attention. Moreover, systematic ways\nto make policies robust to partial sensor failure are not well explored. In\nthis work, we propose a specific customization of Dropout, called\n\\textit{Sensor Dropout}, to improve multisensory policy robustness and handle\npartial failure in the sensor-set. We also introduce an additional auxiliary\nloss on the policy network in order to reduce variance in the band of potential\nmulti- and uni-sensory policies to reduce jerks during policy switching\ntriggered by an abrupt sensor failure or deactivation/activation. Finally,\nthrough the visualization of gradients, we show that the learned policies are\nconditioned on the same latent states representation despite having diverse\nobservations spaces - a hallmark of true sensor-fusion. Simulation results of\nthe multisensory policy, as visualized in TORCS racing game, can be seen here:\nhttps://youtu.be/QAK2lcXjNZc.",
    "published": "2017-05-30T00:52:24Z",
    "updated": "2017-11-01T02:30:51Z",
    "authors": [
      "Guan-Horng Liu",
      "Avinash Siravuru",
      "Sai Prabhakar",
      "Manuela Veloso",
      "George Kantor"
    ],
    "link": "http://arxiv.org/abs/1705.10422v2",
    "pdf_link": "http://arxiv.org/pdf/1705.10422v2"
  },
  {
    "api_id": 376,
    "title": "Using Deep Learning to Examine the Association between the Built\n  Environment and Neighborhood Adult Obesity Prevalence",
    "summary": "More than one-third of the adult population in the United States is obese.\nObesity has been linked to factors such as, genetics, diet, physical activity\nand the environment. However, evidence indicating associations between the\nbuilt environment and obesity has varied across studies and geographical\ncontexts. Here, we used deep learning and approximately 150,000 high resolution\nsatellite images to extract features of the built environment. We then\ndeveloped linear regression models to consistently quantify the association\nbetween the extracted features and obesity prevalence at the census tract level\nfor six cities in the United States. The extracted features of the built\nenvironment explained 72% to 90% of the variation in obesity prevalence across\ncities. Outof-sample predictions were considerably high with correlations\ngreater than 80% between predicted and true obesity prevalence across all\ncensus tracts. This study supports a strong association between the built\nenvironment and obesity prevalence. Additionally, it also illustrates that\nfeatures of the built environment extracted from satellite images can be useful\nfor studying health indicators, such as obesity. Understanding the association\nbetween specific features of the built environment and obesity prevalence can\nlead to structural changes that could encourage physical activity and decreases\nin obesity prevalence.",
    "published": "2017-11-02T18:51:32Z",
    "updated": "2017-11-02T18:51:32Z",
    "authors": [
      "Adyasha Maharana",
      "Elaine O. Nsoesie"
    ],
    "link": "http://arxiv.org/abs/1711.00885v1",
    "pdf_link": "http://arxiv.org/pdf/1711.00885v1"
  },
  {
    "api_id": 377,
    "title": "Distributed Unmixing of Hyperspectral Data With Sparsity Constraint",
    "summary": "Spectral unmixing (SU) is a data processing problem in hyperspectral remote\nsensing. The significant challenge in the SU problem is how to identify\nendmembers and their weights, accurately. For estimation of signature and\nfractional abundance matrices in a blind problem, nonnegative matrix\nfactorization (NMF) and its developments are used widely in the SU problem. One\nof the constraints which was added to NMF is sparsity constraint that was\nregularized by L 1/2 norm. In this paper, a new algorithm based on distributed\noptimization has been used for spectral unmixing. In the proposed algorithm, a\nnetwork including single-node clusters has been employed. Each pixel in\nhyperspectral images considered as a node in this network. The distributed\nunmixing with sparsity constraint has been optimized with diffusion LMS\nstrategy, and then the update equations for fractional abundance and signature\nmatrices are obtained. Simulation results based on defined performance metrics,\nillustrate advantage of the proposed algorithm in spectral unmixing of\nhyperspectral data compared with other methods. The results show that the AAD\nand SAD of the proposed approach are improved respectively about 6 and 27\npercent toward distributed unmixing in SNR=25dB.",
    "published": "2017-11-03T17:23:49Z",
    "updated": "2017-11-03T17:23:49Z",
    "authors": [
      "Sara Khoshsokhan",
      "Roozbeh Rajabi",
      "Hadi Zayyani"
    ],
    "link": "http://arxiv.org/abs/1711.01249v1",
    "pdf_link": "http://arxiv.org/pdf/1711.01249v1"
  },
  {
    "api_id": 378,
    "title": "On Identification of Distribution Grids",
    "summary": "Large-scale integration of distributed energy resources into residential\ndistribution feeders necessitates careful control of their operation through\npower flow analysis. While the knowledge of the distribution system model is\ncrucial for this type of analysis, it is often unavailable or outdated. The\nrecent introduction of synchrophasor technology in low-voltage distribution\ngrids has created an unprecedented opportunity to learn this model from\nhigh-precision, time-synchronized measurements of voltage and current phasors\nat various locations. This paper focuses on joint estimation of model\nparameters (admittance values) and operational structure of a poly-phase\ndistribution network from the available telemetry data via the lasso, a method\nfor regression shrinkage and selection. We propose tractable convex programs\ncapable of tackling the low rank structure of the distribution system and\ndevelop an online algorithm for early detection and localization of critical\nevents that induce a change in the admittance matrix. The efficacy of these\ntechniques is corroborated through power flow studies on four three-phase\nradial distribution systems serving real household demands.",
    "published": "2017-11-05T03:45:06Z",
    "updated": "2017-11-05T03:45:06Z",
    "authors": [
      "Omid Ardakanian",
      "Vincent W. S. Wong",
      "Roel Dobbe",
      "Steven H. Low",
      "Alexandra von Meier",
      "Claire Tomlin",
      "Ye Yuan"
    ],
    "link": "http://arxiv.org/abs/1711.01526v1",
    "pdf_link": "http://arxiv.org/pdf/1711.01526v1"
  },
  {
    "api_id": 379,
    "title": "Artificial Generation of Big Data for Improving Image Classification: A\n  Generative Adversarial Network Approach on SAR Data",
    "summary": "Very High Spatial Resolution (VHSR) large-scale SAR image databases are still\nan unresolved issue in the Remote Sensing field. In this work, we propose such\na dataset and use it to explore patch-based classification in urban and\nperiurban areas, considering 7 distinct semantic classes. In this context, we\ninvestigate the accuracy of large CNN classification models and pre-trained\nnetworks for SAR imaging systems. Furthermore, we propose a Generative\nAdversarial Network (GAN) for SAR image generation and test, whether the\nsynthetic data can actually improve classification accuracy.",
    "published": "2017-11-06T16:52:51Z",
    "updated": "2017-11-06T16:52:51Z",
    "authors": [
      "Dimitrios Marmanis",
      "Wei Yao",
      "Fathalrahman Adam",
      "Mihai Datcu",
      "Peter Reinartz",
      "Konrad Schindler",
      "Jan Dirk Wegner",
      "Uwe Stilla"
    ],
    "link": "http://arxiv.org/abs/1711.02010v1",
    "pdf_link": "http://arxiv.org/pdf/1711.02010v1"
  },
  {
    "api_id": 380,
    "title": "Hierarchical Bayesian image analysis: from low-level modeling to robust\n  supervised learning",
    "summary": "Within a supervised classification framework, labeled data are used to learn\nclassifier parameters. Prior to that, it is generally required to perform\ndimensionality reduction via feature extraction. These preprocessing steps have\nmotivated numerous research works aiming at recovering latent variables in an\nunsupervised context. This paper proposes a unified framework to perform\nclassification and low-level modeling jointly. The main objective is to use the\nestimated latent variables as features for classification and to incorporate\nsimultaneously supervised information to help latent variable extraction. The\nproposed hierarchical Bayesian model is divided into three stages: a first\nlow-level modeling stage to estimate latent variables, a second stage\nclustering these features into statistically homogeneous groups and a last\nclassification stage exploiting the (possibly badly) labeled data. Performance\nof the model is assessed in the specific context of hyperspectral image\ninterpretation, unifying two standard analysis techniques, namely unmixing and\nclassification.",
    "published": "2017-12-01T15:32:58Z",
    "updated": "2017-12-01T15:32:58Z",
    "authors": [
      "Adrien Lagrange",
      "Mathieu Fauvel",
      "Stéphane May",
      "Nicolas Dobigeon"
    ],
    "link": "http://arxiv.org/abs/1712.00368v1",
    "pdf_link": "http://arxiv.org/pdf/1712.00368v1"
  },
  {
    "api_id": 381,
    "title": "Automatic Discovery and Geotagging of Objects from Street View Imagery",
    "summary": "Many applications such as autonomous navigation, urban planning and asset\nmonitoring, rely on the availability of accurate information about objects and\ntheir geolocations. In this paper we propose to automatically detect and\ncompute the GPS coordinates of recurring stationary objects of interest using\nstreet view imagery. Our processing pipeline relies on two fully convolutional\nneural networks: the first segments objects in the images while the second\nestimates their distance from the camera. To geolocate all the detected objects\ncoherently we propose a novel custom Markov Random Field model to perform\nobjects triangulation. The novelty of the resulting pipeline is the combined\nuse of monocular depth estimation and triangulation to enable automatic mapping\nof complex scenes with multiple visually similar objects of interest. We\nvalidate experimentally the effectiveness of our approach on two object\nclasses: traffic lights and telegraph poles. The experiments report high object\nrecall rates and GPS accuracy within 2 meters, which is comparable with the\nprecision of single-frequency GPS receivers.",
    "published": "2017-08-28T16:54:16Z",
    "updated": "2017-12-01T17:05:02Z",
    "authors": [
      "Vladimir A. Krylov",
      "Eamonn Kenny",
      "Rozenn Dahyot"
    ],
    "link": "http://arxiv.org/abs/1708.08417v2",
    "pdf_link": "http://arxiv.org/pdf/1708.08417v2"
  },
  {
    "api_id": 382,
    "title": "Unsupervised Classification of PolSAR Data Using a Scattering Similarity\n  Measure Derived from a Geodesic Distance",
    "summary": "In this letter, we propose a novel technique for obtaining scattering\ncomponents from Polarimetric Synthetic Aperture Radar (PolSAR) data using the\ngeodesic distance on the unit sphere. This geodesic distance is obtained\nbetween an elementary target and the observed Kennaugh matrix, and it is\nfurther utilized to compute a similarity measure between scattering mechanisms.\nThe normalized similarity measure for each elementary target is then modulated\nwith the total scattering power (Span). This measure is used to categorize\npixels into three categories i.e. odd-bounce, double-bounce and volume,\ndepending on which of the above scattering mechanisms dominate. Then the\nmaximum likelihood classifier of [J.-S. Lee, M. R. Grunes, E. Pottier, and L.\nFerro-Famil, Unsupervised terrain classification preserving polarimetric\nscattering characteristics, IEEE Trans. Geos. Rem. Sens., vol. 42, no. 4, pp.\n722731, April 2004.] based on the complex Wishart distribution is iteratively\nused for each category. Dominant scattering mechanisms are thus preserved in\nthis classification scheme. We show results for L-band AIRSAR and ALOS-2\ndatasets acquired over San Francisco and Mumbai, respectively. The scattering\nmechanisms are better preserved using the proposed methodology than the\nunsupervised classification results using the Freeman-Durden scattering powers\non an orientation angle (OA) corrected PolSAR image. Furthermore, (1) the\nscattering similarity is a completely non-negative quantity unlike the negative\npowers that might occur in double- bounce and odd-bounce scattering component\nunder Freeman Durden decomposition (FDD), and (2) the methodology can be\nextended to more canonical targets as well as for bistatic scattering.",
    "published": "2017-12-01T17:58:42Z",
    "updated": "2017-12-01T17:58:42Z",
    "authors": [
      "Debanshu Ratha",
      "Avik Bhattacharya",
      "Alejandro C. Frery"
    ],
    "link": "http://arxiv.org/abs/1712.00427v1",
    "pdf_link": "http://arxiv.org/pdf/1712.00427v1"
  },
  {
    "api_id": 383,
    "title": "Dialectical Multispectral Classification of Diffusion-Weighted Magnetic\n  Resonance Images as an Alternative to Apparent Diffusion Coefficients Maps to\n  Perform Anatomical Analysis",
    "summary": "Multispectral image analysis is a relatively promising field of research with\napplications in several areas, such as medical imaging and satellite\nmonitoring. A considerable number of current methods of analysis are based on\nparametric statistics. Alternatively, some methods in Computational\nIntelligence are inspired by biology and other sciences. Here we claim that\nPhilosophy can be also considered as a source of inspiration. This work\nproposes the Objective Dialectical Method (ODM): a method for classification\nbased on the Philosophy of Praxis. ODM is instrumental in assembling evolvable\nmathematical tools to analyze multispectral images. In the case study described\nin this paper, multispectral images are composed of diffusion-weighted (DW)\nmagnetic resonance (MR) images. The results are compared to ground-truth images\nproduced by polynomial networks using a morphological similarity index. The\nclassification results are used to improve the usual analysis of the apparent\ndiffusion coefficient map. Such results proved that gray and white matter can\nbe distinguished in DW-MR multispectral analysis and, consequently, DW-MR\nimages can also be used to furnish anatomical information.",
    "published": "2017-12-03T18:23:33Z",
    "updated": "2017-12-03T18:23:33Z",
    "authors": [
      "Wellington Pinheiro dos Santos",
      "Francisco Marcos de Assis",
      "Ricardo Emmanuel de Souza",
      "Plínio Batista dos Santos Filho",
      "Fernando Buarque de Lima Neto"
    ],
    "link": "http://arxiv.org/abs/1712.01697v1",
    "pdf_link": "http://arxiv.org/pdf/1712.01697v1"
  },
  {
    "api_id": 384,
    "title": "Gaussian Process Regression for Arctic Coastal Erosion Forecasting",
    "summary": "Arctic coastal morphology is governed by multiple factors, many of which are\naffected by climatological changes. As the season length for shorefast ice\ndecreases and temperatures warm permafrost soils, coastlines are more\nsusceptible to erosion from storm waves. Such coastal erosion is a concern,\nsince the majority of the population centers and infrastructure in the Arctic\nare located near the coasts. Stakeholders and decision makers increasingly need\nmodels capable of scenario-based predictions to assess and mitigate the effects\nof coastal morphology on infrastructure and land use. Our research uses\nGaussian process models to forecast Arctic coastal erosion along the Beaufort\nSea near Drew Point, AK. Gaussian process regression is a data-driven modeling\nmethodology capable of extracting patterns and trends from data-sparse\nenvironments such as remote Arctic coastlines. To train our model, we use\nannual coastline positions and near-shore summer temperature averages from\nexisting datasets and extend these data by extracting additional coastlines\nfrom satellite imagery. We combine our calibrated models with future climate\nmodels to generate a range of plausible future erosion scenarios. Our results\nshow that the Gaussian process methodology substantially improves yearly\npredictions compared to linear and nonlinear least squares methods, and is\ncapable of generating detailed forecasts suitable for use by decision makers.",
    "published": "2017-12-04T01:01:39Z",
    "updated": "2017-12-04T01:01:39Z",
    "authors": [
      "Matthew Kupilik",
      "Frank Witmer",
      "Euan-Angus MacLeod",
      "Caixia Wang",
      "Tom Ravens"
    ],
    "link": "http://arxiv.org/abs/1712.00867v1",
    "pdf_link": "http://arxiv.org/pdf/1712.00867v1"
  },
  {
    "api_id": 385,
    "title": "Theoretical Validation of Potential Habitability via Analytical and\n  Boosted Tree Methods: An Optimistic Study on Recently Discovered Exoplanets",
    "summary": "Seven Earth-sized planets, TRAPPIST-1 system, were discovered in February\n2017. Three of these planets are in the habitable zone (HZ) of their star,\nmaking them potentially habitable planets a mere 40 light years away. Discovery\nof the closest potentially habitable planet to us just a year before --\nProxima~b, and a realization that Earth-type planets in HZ are a common\noccurrence provides the impetus to the pursuit for life outside the Solar\nSystem. The search for life has two goals: Earth similarity and habitability.\nAn index was recently proposed, Cobb-Douglas Habitability Score (CDHS), based\non Cobb-Douglas production function, which computes the habitability score by\nusing measured and estimated planetary parameters like radius, density, escape\nvelocity and surface temperature of a planet. The proposed metric with\nexponents accounting for metric elasticity, is endowed with analytical\nproperties that ensure global optima and can be scaled to accommodate a finite\nnumber of input parameters. We show that the model is elastic, and the\nconditions on elasticity to ensure global maxima can scale as the number of\npredictor parameters increase. K-Nearest Neighbour classification algorithm,\nembellished with probabilistic herding and thresholding restriction, utilizes\nCDHS scores and labels exoplanets to appropriate classes via feature-learning\nmethods. The algorithm works on top of a decision-theoretical model using the\npower of convex optimization and machine learning. A second approach, based on\na novel feature-learning and tree-building method classifies the same planets\nwithout computing the CDHS of the planets and produces a similar outcome. The\nconvergence of the two different approaches indicates the strength of the\nproposed scheme and the likelihood of the potential habitability of the recent\ndiscoveries.",
    "published": "2017-12-04T12:36:07Z",
    "updated": "2017-12-04T12:36:07Z",
    "authors": [
      "Snehanshu Saha",
      "Suryoday Basak",
      "Kakoli Bora",
      "Margarita Safonova",
      "Surbhi Agrawal",
      "Poulami Sarkar",
      "Jayant Murthy"
    ],
    "link": "http://arxiv.org/abs/1712.01040v1",
    "pdf_link": "http://arxiv.org/pdf/1712.01040v1"
  },
  {
    "api_id": 386,
    "title": "Deep learning for semantic segmentation of remote sensing images with\n  rich spectral content",
    "summary": "With the rapid development of Remote Sensing acquisition techniques, there is\na need to scale and improve processing tools to cope with the observed increase\nof both data volume and richness. Among popular techniques in remote sensing,\nDeep Learning gains increasing interest but depends on the quality of the\ntraining data. Therefore, this paper presents recent Deep Learning approaches\nfor fine or coarse land cover semantic segmentation estimation. Various 2D\narchitectures are tested and a new 3D model is introduced in order to jointly\nprocess the spatial and spectral dimensions of the data. Such a set of networks\nenables the comparison of the different spectral fusion schemes. Besides, we\nalso assess the use of a \" noisy ground truth \" (i.e. outdated and low spatial\nresolution labels) for training and testing the networks.",
    "published": "2017-12-05T12:25:43Z",
    "updated": "2017-12-05T12:25:43Z",
    "authors": [
      "A Hamida",
      "A. Benoît",
      "P. Lambert",
      "L Klein",
      "C Amar",
      "N. Audebert",
      "S. Lefèvre"
    ],
    "link": "http://arxiv.org/abs/1712.01600v1",
    "pdf_link": "http://arxiv.org/pdf/1712.01600v1"
  },
  {
    "api_id": 387,
    "title": "Dense Optical Flow based Change Detection Network Robust to Difference\n  of Camera Viewpoints",
    "summary": "This paper presents a novel method for detecting scene changes from a pair of\nimages with a difference of camera viewpoints using a dense optical flow based\nchange detection network. In the case that camera poses of input images are\nfixed or known, such as with surveillance and satellite cameras, the pixel\ncorrespondence between the images captured at different times can be known.\nHence, it is possible to comparatively accurately detect scene changes between\nthe images by modeling the appearance of the scene. On the other hand, in case\nof cameras mounted on a moving object, such as ground and aerial vehicles, we\nmust consider the spatial correspondence between the images captured at\ndifferent times. However, it can be difficult to accurately estimate the camera\npose or 3D model of a scene, owing to the scene changes or lack of imagery. To\nsolve this problem, we propose a change detection convolutional neural network\nutilizing dense optical flow between input images to improve the robustness to\nthe difference between camera viewpoints. Our evaluation based on the panoramic\nchange detection dataset shows that the proposed method outperforms\nstate-of-the-art change detection algorithms.",
    "published": "2017-12-08T05:05:51Z",
    "updated": "2017-12-08T05:05:51Z",
    "authors": [
      "Ken Sakurada",
      "Weimin Wang",
      "Nobuo Kawaguchi",
      "Ryosuke Nakamura"
    ],
    "link": "http://arxiv.org/abs/1712.02941v1",
    "pdf_link": "http://arxiv.org/pdf/1712.02941v1"
  },
  {
    "api_id": 388,
    "title": "Fine-Grained Object Recognition and Zero-Shot Learning in Remote Sensing\n  Imagery",
    "summary": "Fine-grained object recognition that aims to identify the type of an object\namong a large number of subcategories is an emerging application with the\nincreasing resolution that exposes new details in image data. Traditional fully\nsupervised algorithms fail to handle this problem where there is low\nbetween-class variance and high within-class variance for the classes of\ninterest with small sample sizes. We study an even more extreme scenario named\nzero-shot learning (ZSL) in which no training example exists for some of the\nclasses. ZSL aims to build a recognition model for new unseen categories by\nrelating them to seen classes that were previously learned. We establish this\nrelation by learning a compatibility function between image features extracted\nvia a convolutional neural network and auxiliary information that describes the\nsemantics of the classes of interest by using training samples from the seen\nclasses. Then, we show how knowledge transfer can be performed for the unseen\nclasses by maximizing this function during inference. We introduce a new data\nset that contains 40 different types of street trees in 1-ft spatial resolution\naerial data, and evaluate the performance of this model with manually annotated\nattributes, a natural language model, and a scientific taxonomy as auxiliary\ninformation. The experiments show that the proposed model achieves 14.3%\nrecognition accuracy for the classes with no training examples, which is\nsignificantly better than a random guess accuracy of 6.3% for 16 test classes,\nand three other ZSL algorithms.",
    "published": "2017-12-09T00:44:39Z",
    "updated": "2017-12-09T00:44:39Z",
    "authors": [
      "Gencer Sumbul",
      "Ramazan Gokberk Cinbis",
      "Selim Aksoy"
    ],
    "link": "http://arxiv.org/abs/1712.03323v1",
    "pdf_link": "http://arxiv.org/pdf/1712.03323v1"
  },
  {
    "api_id": 389,
    "title": "Logo Synthesis and Manipulation with Clustered Generative Adversarial\n  Networks",
    "summary": "Designing a logo for a new brand is a lengthy and tedious back-and-forth\nprocess between a designer and a client. In this paper we explore to what\nextent machine learning can solve the creative task of the designer. For this,\nwe build a dataset -- LLD -- of 600k+ logos crawled from the world wide web.\nTraining Generative Adversarial Networks (GANs) for logo synthesis on such\nmulti-modal data is not straightforward and results in mode collapse for some\nstate-of-the-art methods. We propose the use of synthetic labels obtained\nthrough clustering to disentangle and stabilize GAN training. We are able to\ngenerate a high diversity of plausible logos and we demonstrate latent space\nexploration techniques to ease the logo design task in an interactive manner.\nMoreover, we validate the proposed clustered GAN training on CIFAR 10,\nachieving state-of-the-art Inception scores when using synthetic labels\nobtained via clustering the features of an ImageNet classifier. GANs can cope\nwith multi-modal data by means of synthetic labels achieved through clustering,\nand our results show the creative potential of such techniques for logo\nsynthesis and manipulation. Our dataset and models will be made publicly\navailable at https://data.vision.ee.ethz.ch/cvl/lld/.",
    "published": "2017-12-12T17:51:23Z",
    "updated": "2017-12-12T17:51:23Z",
    "authors": [
      "Alexander Sage",
      "Eirikur Agustsson",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "link": "http://arxiv.org/abs/1712.04407v1",
    "pdf_link": "http://arxiv.org/pdf/1712.04407v1"
  },
  {
    "api_id": 390,
    "title": "Automatic Estimation of Ice Bottom Surfaces from Radar Imagery",
    "summary": "Ground-penetrating radar on planes and satellites now makes it practical to\ncollect 3D observations of the subsurface structure of the polar ice sheets,\nproviding crucial data for understanding and tracking global climate change.\nBut converting these noisy readings into useful observations is generally done\nby hand, which is impractical at a continental scale. In this paper, we propose\na computer vision-based technique for extracting 3D ice-bottom surfaces by\nviewing the task as an inference problem on a probabilistic graphical model. We\nfirst generate a seed surface subject to a set of constraints, and then\nincorporate additional sources of evidence to refine it via discrete energy\nminimization. We evaluate the performance of the tracking algorithm on 7\ntopographic sequences (each with over 3000 radar images) collected from the\nCanadian Arctic Archipelago with respect to human-labeled ground truth.",
    "published": "2017-12-21T00:56:47Z",
    "updated": "2017-12-21T00:56:47Z",
    "authors": [
      "Mingze Xu",
      "David J Crandall",
      "Geoffrey C Fox",
      "John D Paden"
    ],
    "link": "http://arxiv.org/abs/1712.07758v1",
    "pdf_link": "http://arxiv.org/pdf/1712.07758v1"
  },
  {
    "api_id": 391,
    "title": "Exploring Models and Data for Remote Sensing Image Caption Generation",
    "summary": "Inspired by recent development of artificial satellite, remote sensing images\nhave attracted extensive attention. Recently, noticeable progress has been made\nin scene classification and target detection.However, it is still not clear how\nto describe the remote sensing image content with accurate and concise\nsentences. In this paper, we investigate to describe the remote sensing images\nwith accurate and flexible sentences. First, some annotated instructions are\npresented to better describe the remote sensing images considering the special\ncharacteristics of remote sensing images. Second, in order to exhaustively\nexploit the contents of remote sensing images, a large-scale aerial image data\nset is constructed for remote sensing image caption. Finally, a comprehensive\nreview is presented on the proposed data set to fully advance the task of\nremote sensing caption. Extensive experiments on the proposed data set\ndemonstrate that the content of the remote sensing image can be completely\ndescribed by generating language descriptions. The data set is available at\nhttps://github.com/201528014227051/RSICD_optimal",
    "published": "2017-12-21T08:45:37Z",
    "updated": "2017-12-21T08:45:37Z",
    "authors": [
      "Xiaoqiang Lu",
      "Binqiang Wang",
      "Xiangtao Zheng",
      "Xuelong Li"
    ],
    "link": "http://arxiv.org/abs/1712.07835v1",
    "pdf_link": "http://arxiv.org/pdf/1712.07835v1"
  },
  {
    "api_id": 392,
    "title": "Improving science yield for NASA Swift with automated planning\n  technologies",
    "summary": "The Swift Gamma-Ray Burst Explorer is a uniquely capable mission, with three\non-board instruments and rapid slewing capabilities. It serves as a\nfast-response satellite observatory for everything from gravitational-wave\ncounterpart searches to cometary science. Swift averages 125 different\nobservations per day, and is consistently over-subscribed, responding to about\none-hundred Target of Oportunity (ToO) requests per month from the general\nastrophysics community, as well as co-pointing and follow-up agreements with\nmany other observatories. Since launch in 2004, the demands put on the\nspacecraft have grown consistently in terms of number and type of targets as\nwell as schedule complexity. To facilitate this growth, various scheduling\ntools and helper technologies have been built by the Swift team to continue\nimproving the scientific yield of the Swift mission. However, these tools have\nbeen used only to assist humans in exploring the local pareto surface and for\nfixing constraint violations. Because of the computational complexity of the\nscheduling task, no automation tool has been able to produce a plan of equal or\nhigher quality than that produced by a well-trained human, given the necessary\ntime constraints. In this proceeding we formalize the Swift Scheduling Problem\nas a dynamic fuzzy Constraint Satisfaction Problem (DF-CSP) and explore the\nglobal solution space. We detail here several approaches towards achieving the\ngoal of surpassing human quality schedules using classical optimization and\nalgorithmic techniques, as well as machine learning and recurrent neural\nnetwork (RNN) methods. We then briefly discuss the increased scientific yield\nand benefit to the wider astrophysics community that would result from the\nfurther development and adoption of these technologies.",
    "published": "2017-12-21T17:44:37Z",
    "updated": "2017-12-21T17:44:37Z",
    "authors": [
      "Aaron Tohuvavohu"
    ],
    "link": "http://arxiv.org/abs/1712.08111v1",
    "pdf_link": "http://arxiv.org/pdf/1712.08111v1"
  },
  {
    "api_id": 393,
    "title": "Classification With an Edge: Improving Semantic Image Segmentation with\n  Boundary Detection",
    "summary": "We present an end-to-end trainable deep convolutional neural network (DCNN)\nfor semantic segmentation with built-in awareness of semantically meaningful\nboundaries. Semantic segmentation is a fundamental remote sensing task, and\nmost state-of-the-art methods rely on DCNNs as their workhorse. A major reason\nfor their success is that deep networks learn to accumulate contextual\ninformation over very large windows (receptive fields). However, this success\ncomes at a cost, since the associated loss of effecive spatial resolution\nwashes out high-frequency details and leads to blurry object boundaries. Here,\nwe propose to counter this effect by combining semantic segmentation with\nsemantically informed edge detection, thus making class-boundaries explicit in\nthe model, First, we construct a comparatively simple, memory-efficient model\nby adding boundary detection to the Segnet encoder-decoder architecture.\nSecond, we also include boundary detection in FCN-type models and set up a\nhigh-end classifier ensemble. We show that boundary detection significantly\nimproves semantic segmentation with CNNs. Our high-end ensemble achieves > 90%\noverall accuracy on the ISPRS Vaihingen benchmark.",
    "published": "2016-12-05T13:12:24Z",
    "updated": "2017-12-21T21:36:14Z",
    "authors": [
      "Dimitrios Marmanis",
      "Konrad Schindler",
      "Jan Dirk Wegner",
      "Silvano Galliani",
      "Mihai Datcu",
      "Uwe Stilla"
    ],
    "link": "http://arxiv.org/abs/1612.01337v2",
    "pdf_link": "http://arxiv.org/pdf/1612.01337v2"
  },
  {
    "api_id": 394,
    "title": "Aerial Spectral Super-Resolution using Conditional Adversarial Networks",
    "summary": "Inferring spectral signatures from ground based natural images has acquired a\nlot of interest in applied deep learning. In contrast to the spectra of ground\nbased images, aerial spectral images have low spatial resolution and suffer\nfrom higher noise interference. In this paper, we train a conditional\nadversarial network to learn an inverse mapping from a trichromatic space to 31\nspectral bands within 400 to 700 nm. The network is trained on AeroCampus, a\nfirst of its kind aerial hyperspectral dataset. AeroCampus consists of high\nspatial resolution color images and low spatial resolution hyperspectral images\n(HSI). Color images synthesized from 31 spectral bands are used to train our\nnetwork. With a baseline root mean square error of 2.48 on the synthesized RGB\ntest data, we show that it is possible to generate spectral signatures in\naerial imagery.",
    "published": "2017-12-23T00:21:20Z",
    "updated": "2017-12-23T00:21:20Z",
    "authors": [
      "Aneesh Rangnekar",
      "Nilay Mokashi",
      "Emmett Ientilucci",
      "Christopher Kanan",
      "Matthew Hoffman"
    ],
    "link": "http://arxiv.org/abs/1712.08690v1",
    "pdf_link": "http://arxiv.org/pdf/1712.08690v1"
  },
  {
    "api_id": 395,
    "title": "Parametric instability and wave turbulence driven by tidal excitation of\n  internal waves",
    "summary": "We investigate the stability of stratified fluid layers undergoing\nhomogeneous and periodic tidal deformation. We first introduce a local model\nwhich allows to study velocity and buoyancy fluctuations in a Lagrangian domain\nperiodically stretched and sheared by the tidal base flow. While keeping the\nkey physical ingredients only, such a model is efficient to simulate planetary\nregimes where tidal amplitudes and dissipation are small. With this model, we\nprove that tidal flows are able to drive parametric subharmonic resonances of\ninternal waves, in a way reminiscent of the elliptical instability in rotating\nfluids. The growth rates computed via Direct Numerical Simulations (DNS) are in\nvery good agreement with WKB analysis and Floquet theory. We also investigate\nthe turbulence driven by this instability mechanism. With spatio-temporal\nanalysis, we show that it is a weak internal wave turbulence occurring at small\nFroude and buoyancy Reynolds numbers. When the gap between the excitation and\nthe Brunt-V\\\"ais\\\"al\\\"a frequencies is increased, the frequency spectrum of\nthis wave turbulence displays a -2 power law reminiscent of the high-frequency\nbranch of the Garett and Munk spectrum (Garrett & Munk 1979) which has been\nmeasured in the oceans. In addition, we find that the mixing efficiency is\naltered compared to what is computed in the context of DNS of stratified\nturbulence excited at small Froude and large buoyancy Reynolds numbers and is\nconsistent with a superposition of waves.",
    "published": "2017-12-23T18:11:14Z",
    "updated": "2017-12-23T18:11:14Z",
    "authors": [
      "Thomas Le Reun",
      "Benjamin Favier",
      "Michael Le Bars"
    ],
    "link": "http://arxiv.org/abs/1712.08815v1",
    "pdf_link": "http://arxiv.org/pdf/1712.08815v1"
  },
  {
    "api_id": 396,
    "title": "Conditional Random Field and Deep Feature Learning for Hyperspectral\n  Image Segmentation",
    "summary": "Image segmentation is considered to be one of the critical tasks in\nhyperspectral remote sensing image processing. Recently, convolutional neural\nnetwork (CNN) has established itself as a powerful model in segmentation and\nclassification by demonstrating excellent performances. The use of a graphical\nmodel such as a conditional random field (CRF) contributes further in capturing\ncontextual information and thus improving the segmentation performance. In this\npaper, we propose a method to segment hyperspectral images by considering both\nspectral and spatial information via a combined framework consisting of CNN and\nCRF. We use multiple spectral cubes to learn deep features using CNN, and then\nformulate deep CRF with CNN-based unary and pairwise potential functions to\neffectively extract the semantic correlations between patches consisting of\nthree-dimensional data cubes. Effective piecewise training is applied in order\nto avoid the computationally expensive iterative CRF inference. Furthermore, we\nintroduce a deep deconvolution network that improves the segmentation masks. We\nalso introduce a new dataset and experimented our proposed method on it along\nwith several widely adopted benchmark datasets to evaluate the effectiveness of\nour method. By comparing our results with those from several state-of-the-art\nmodels, we show the promising potential of our method.",
    "published": "2017-11-13T09:18:25Z",
    "updated": "2017-12-27T06:26:01Z",
    "authors": [
      "Fahim Irfan Alam",
      "Jun Zhou",
      "Alan Wee-Chung Liew",
      "Xiuping Jia",
      "Jocelyn Chanussot",
      "Yongsheng Gao"
    ],
    "link": "http://arxiv.org/abs/1711.04483v2",
    "pdf_link": "http://arxiv.org/pdf/1711.04483v2"
  },
  {
    "api_id": 397,
    "title": "A Multi-Scale and Multi-Depth Convolutional Neural Network for Remote\n  Sensing Imagery Pan-Sharpening",
    "summary": "Pan-sharpening is a fundamental and significant task in the field of remote\nsensing imagery processing, in which high-resolution spatial details from\npanchromatic images are employed to enhance the spatial resolution of\nmulti-spectral (MS) images. As the transformation from low spatial resolution\nMS image to high-resolution MS image is complex and highly non-linear, inspired\nby the powerful representation for non-linear relationships of deep neural\nnetworks, we introduce multi-scale feature extraction and residual learning\ninto the basic convolutional neural network (CNN) architecture and propose the\nmulti-scale and multi-depth convolutional neural network (MSDCNN) for the\npan-sharpening of remote sensing imagery. Both the quantitative assessment\nresults and the visual assessment confirm that the proposed network yields\nhigh-resolution MS images that are superior to the images produced by the\ncompared state-of-the-art methods.",
    "published": "2017-12-28T10:28:38Z",
    "updated": "2017-12-28T10:28:38Z",
    "authors": [
      "Qiangqiang Yuan",
      "Yancong Wei",
      "Xiangchao Meng",
      "Huanfeng Shen",
      "Liangpei Zhang"
    ],
    "link": "http://arxiv.org/abs/1712.09809v1",
    "pdf_link": "http://arxiv.org/pdf/1712.09809v1"
  },
  {
    "api_id": 398,
    "title": "Local Causal States and Discrete Coherent Structures",
    "summary": "Coherent structures form spontaneously in nonlinear spatiotemporal systems\nand are found at all spatial scales in natural phenomena from laboratory\nhydrodynamic flows and chemical reactions to ocean, atmosphere, and planetary\nclimate dynamics. Phenomenologically, they appear as key components that\norganize the macroscopic behaviors in such systems. Despite a century of\neffort, they have eluded rigorous analysis and empirical prediction, with\nprogress being made only recently. As a step in this, we present a formal\ntheory of coherent structures in fully-discrete dynamical field theories. It\nbuilds on the notion of structure introduced by computational mechanics,\ngeneralizing it to a local spatiotemporal setting. The analysis' main tool\nemploys the \\localstates, which are used to uncover a system's hidden\nspatiotemporal symmetries and which identify coherent structures as\nspatially-localized deviations from those symmetries. The approach is\nbehavior-driven in the sense that it does not rely on directly analyzing\nspatiotemporal equations of motion, rather it considers only the spatiotemporal\nfields a system generates. As such, it offers an unsupervised approach to\ndiscover and describe coherent structures. We illustrate the approach by\nanalyzing coherent structures generated by elementary cellular automata,\ncomparing the results with an earlier, dynamic-invariant-set approach that\ndecomposes fields into domains, particles, and particle interactions.",
    "published": "2018-01-01T21:43:18Z",
    "updated": "2018-01-01T21:43:18Z",
    "authors": [
      "Adam Rupe",
      "James P. Crutchfield"
    ],
    "link": "http://arxiv.org/abs/1801.00515v1",
    "pdf_link": "http://arxiv.org/pdf/1801.00515v1"
  },
  {
    "api_id": 399,
    "title": "Fully Optical Spacecraft Communications: Implementing an Omnidirectional\n  PV-Cell Receiver and 8Mb/s LED Visible Light Downlink with Deep Learning\n  Error Correction",
    "summary": "Free space optical communication techniques have been the subject of numerous\ninvestigations in recent years, with multiple missions expected to fly in the\nnear future. Existing methods require high pointing accuracies, drastically\ndriving up overall system cost. Recent developments in LED-based visible light\ncommunication (VLC) and past in-orbit experiments have convinced us that the\ntechnology has reached a critical level of maturity. On these premises, we\npropose a new optical communication system utilizing a VLC downlink and a high\nthroughput, omnidirectional photovoltaic cell receiver system. By performing\nerror-correction via deep learning methods and by utilizing phase-delay\ninterference, the system is able to deliver data rates that match those of\ntraditional laser-based solutions. A prototype of the proposed system has been\nconstructed, demonstrating the scheme to be a feasible alternative to\nlaser-based methods. This creates an opportunity for the full scale development\nof optical communication techniques on small spacecraft as a backup telemetry\nbeacon or as a high throughput link.",
    "published": "2017-09-11T02:51:08Z",
    "updated": "2018-01-03T04:17:19Z",
    "authors": [
      "Sihao Huang",
      "Haowen Lin"
    ],
    "link": "http://arxiv.org/abs/1709.03222v2",
    "pdf_link": "http://arxiv.org/pdf/1709.03222v2"
  },
  {
    "api_id": 400,
    "title": "An Ontology for Satellite Databases",
    "summary": "This paper demonstrates the development of ontology for satellite databases.\nFirst, I create a computational ontology for the Union of Concerned Scientists\n(UCS) Satellite Database (UCSSD for short), called the UCS Satellite Ontology\n(or UCSSO). Second, in developing UCSSO I show that The Space Situational\nAwareness Ontology (SSAO) (Rovetto and Kelso 2016)--an existing space domain\nreference ontology--and related ontology work by the author (Rovetto 2015,\n2016) can be used either (i) with a database-specific local ontology such as\nUCSSO, or (ii) in its stead. In case (i), local ontologies such as UCSSO can\nreuse SSAO terms, perform term mappings, or extend it. In case (ii), the\nauthor's orbital space ontology work, such as the SSAO, is usable by the UCSSD\nand organizations with other space object catalogs, as a reference ontology\nsuite providing a common semantically-rich domain model. The SSAO, UCSSO, and\nthe broader Orbital Space Environment Domain Ontology project is online at\nhttp://purl.org/space-ontology and GitHub. This ontology effort aims, in part,\nto provide accurate formal representations of the domain for various\napplications. Ontology engineering has the potential to facilitate the sharing\nand integration of satellite data from federated databases and sensors for\nsafer spaceflight.",
    "published": "2018-01-06T16:59:49Z",
    "updated": "2018-01-06T16:59:49Z",
    "authors": [
      "Robert J. Rovetto"
    ],
    "link": "http://arxiv.org/abs/1801.02940v1",
    "pdf_link": "http://arxiv.org/pdf/1801.02940v1"
  },
  {
    "api_id": 401,
    "title": "Non-negative Matrix Factorization: Robust Extraction of Extended\n  Structures",
    "summary": "We apply the vectorized Non-negative Matrix Factorization (NMF) method to\npost-processing of direct imaging data for exoplanetary systems such as\ncircumstellar disks. NMF is an iterative approach, which first creates a\nnon-orthogonal and non-negative basis of components using given reference\nimages, then models a target with the components. The constructed model is then\nrescaled with a factor to compensate for the contribution from a disk. We\ncompare NMF with existing methods (classical reference differential imaging\nmethod, and the Karhunen-Lo\\`eve image projection algorithm) using synthetic\ncircumstellar disks, and demonstrate the superiority of NMF: with no need for\nprior selection of references, NMF can detect fainter circumstellar disks,\nbetter preserve low order disk morphology, and does not require forward\nmodeling. As an application to a well-known disk example, we process the\narchival Hubble Space Telescope (HST) STIS coronagraphic observations of\nHD~181327 with different methods and compare them. NMF is able to extract some\ncircumstellar material inside the primary ring for the first time. In the\nappendix, we mathematically investigate the stability of NMF components during\niteration, and the linearity of NMF modeling.",
    "published": "2017-12-29T19:00:00Z",
    "updated": "2018-01-12T01:01:38Z",
    "authors": [
      "Bīn Rén",
      "Laurent Pueyo",
      "Guangtun Ben Zhu",
      "John Debes",
      "Gaspard Duchêne"
    ],
    "link": "http://arxiv.org/abs/1712.10317v2",
    "pdf_link": "http://arxiv.org/pdf/1712.10317v2"
  },
  {
    "api_id": 402,
    "title": "Quantum transport senses community structure in networks",
    "summary": "Quantum time evolution exhibits rich physics, attributable to the interplay\nbetween the density and phase of a wave function. However, unlike classical\nheat diffusion, the wave nature of quantum mechanics has not yet been\nextensively explored in modern data analysis. We propose that the Laplace\ntransform of quantum transport (QT) can be used to construct an ensemble of\nmaps from a given complex network to a circle $S^1$, such that closely-related\nnodes on the network are grouped into sharply concentrated clusters on $S^1$.\nThe resulting QT clustering (QTC) algorithm is as powerful as the\nstate-of-the-art spectral clustering in discerning complex geometric patterns\nand more robust when clusters show strong density variations or heterogeneity\nin size. The observed phenomenon of QTC can be interpreted as a collective\nbehavior of the microscopic nodes that evolve as macroscopic cluster orbitals\nin an effective tight-binding model recapitulating the network. Python source\ncode implementing the algorithm and examples are available at\nhttps://github.com/jssong-lab/QTC.",
    "published": "2017-11-14T07:03:05Z",
    "updated": "2018-01-12T05:52:07Z",
    "authors": [
      "Chenchao Zhao",
      "Jun S. Song"
    ],
    "link": "http://arxiv.org/abs/1711.04979v2",
    "pdf_link": "http://arxiv.org/pdf/1711.04979v2"
  },
  {
    "api_id": 403,
    "title": "Improving Orbit Prediction Accuracy through Supervised Machine Learning",
    "summary": "Due to the lack of information such as the space environment condition and\nresident space objects' (RSOs') body characteristics, current orbit predictions\nthat are solely grounded on physics-based models may fail to achieve required\naccuracy for collision avoidance and have led to satellite collisions already.\nThis paper presents a methodology to predict RSOs' trajectories with higher\naccuracy than that of the current methods. Inspired by the machine learning\n(ML) theory through which the models are learned based on large amounts of\nobserved data and the prediction is conducted without explicitly modeling space\nobjects and space environment, the proposed ML approach integrates\nphysics-based orbit prediction algorithms with a learning-based process that\nfocuses on reducing the prediction errors. Using a simulation-based space\ncatalog environment as the test bed, the paper demonstrates three types of\ngeneralization capability for the proposed ML approach: 1) the ML model can be\nused to improve the same RSO's orbit information that is not available during\nthe learning process but shares the same time interval as the training data; 2)\nthe ML model can be used to improve predictions of the same RSO at future\nepochs; and 3) the ML model based on a RSO can be applied to other RSOs that\nshare some common features.",
    "published": "2018-01-15T15:56:36Z",
    "updated": "2018-01-15T15:56:36Z",
    "authors": [
      "Hao Peng",
      "Xiaoli Bai"
    ],
    "link": "http://arxiv.org/abs/1801.04856v1",
    "pdf_link": "http://arxiv.org/pdf/1801.04856v1"
  },
  {
    "api_id": 404,
    "title": "Soil Property and Class Maps of the Conterminous US at 100 meter Spatial\n  Resolution based on a Compilation of National Soil Point Observations and\n  Machine Learning",
    "summary": "With growing concern for the depletion of soil resources, conventional soil\ndata must be updated to support spatially explicit human-landscape models.\nThree US soil point datasetswere combined with a stack of over 200\nenvironmental datasets to generate complete coverage gridded predictions at 100\nm spatial resolution of soil properties (percent organic C, total N, bulk\ndensity, pH, and percent sand and clay) and US soil taxonomic classes (291\ngreat groups and 78 modified particle size classes) for the conterminous US.\nModels were built using parallelized random forest and gradient boosting\nalgorithms. Soil property predictions were generated at seven standard soil\ndepths (0, 5, 15, 30, 60, 100 and 200 cm). Prediction probability maps for US\nsoil taxonomic classifications were also generated. Model validation results\nindicate an out-of-bag classification accuracy of 60 percent for great groups,\nand 66 percent for modified particle size classes; for soil properties\ncross-validated R-square ranged from 62 percent for total N to 87 percent for\npH. Nine independent validation datasets were used to assess prediction\naccuracies for soil class models and results ranged between 24-58 percent and\n24-93 percent for great group and modified particle size class prediction\naccuracies, respectively. The hybrid \"SoilGrids+\" modeling system that\nincorporates remote sensing data, local predictions of soil properties,\nconventional soil polygon maps, and machine learning opens the possibility for\nupdating conventional soil survey data with machine learning technology to make\nsoil information easier to integrate with spatially explicit models, compared\nto multi-component map units.",
    "published": "2017-04-25T14:48:07Z",
    "updated": "2018-01-16T13:02:47Z",
    "authors": [
      "Amanda Ramcharan",
      "Tomislav Hengl",
      "Travis Nauman",
      "Colby Brungard",
      "Sharon Waltman",
      "Skye Wills",
      "James Thompson"
    ],
    "link": "http://arxiv.org/abs/1705.08323v4",
    "pdf_link": "http://arxiv.org/pdf/1705.08323v4"
  },
  {
    "api_id": 405,
    "title": "Identification of Seed Cells in Multispectral Images for GrowCut\n  Segmentation",
    "summary": "The segmentation of satellite images is a necessary step to perform\nobject-oriented image classification, which has become relevant due to its\napplicability on images with a high spatial resolution. To perform\nobject-oriented image classification, the studied image must first be segmented\nin uniform regions. This segmentation requires manual work by an expert user,\nwho must exhaustively explore the image to establish thresholds that generate\nuseful and representative segments without oversegmenting and without\ndiscarding representative segments. We propose a technique that automatically\nsegments the multispectral image while facing these issues. We identify in the\nimage homogenous zones according to their spectral signatures through the use\nof morphological filters. These homogenous zones are representatives of\ndifferent types of land coverings in the image and are used as seeds for the\nGrowCut multispectral segmentation algorithm. GrowCut is a cellular automaton\nwith competitive region growth, its cells are linked to every pixel in the\nimage through three parameters: the pixel's spectral signature, a label, and a\nstrength factor that represents the strength with which a cell defends its\nlabel. The seed cells possess maximum strength and maintain their state\nthroughout the automaton's evolution. Starting from seed cells, each cell in\nthe image is iteratively attacked by its neighboring cells. When the automaton\nstops updating its states, we obtain a segmented image where each pixel has\ntaken the label of one of its cells. In this paper the algorithm was applied in\nan image acquired by Landsat8 on agricultural land of Calabozo, Guarico,\nVenezuela where there are different types of land coverings: agriculture, urban\nregions, water bodies, and savannas with different degrees of human\nintervention. The segmentation obtained is presented as irregular polygons\nenclosing geographical objects.",
    "published": "2018-01-17T01:57:27Z",
    "updated": "2018-01-17T01:57:27Z",
    "authors": [
      "Wuilan Torres",
      "Antonio Rueda-Toicen"
    ],
    "link": "http://arxiv.org/abs/1801.05525v1",
    "pdf_link": "http://arxiv.org/pdf/1801.05525v1"
  },
  {
    "api_id": 406,
    "title": "Effective Sequential Classifier Training for SVM-based Multitemporal\n  Remote Sensing Image Classification",
    "summary": "The explosive availability of remote sensing images has challenged supervised\nclassification algorithms such as Support Vector Machines (SVM), as training\nsamples tend to be highly limited due to the expensive and laborious task of\nground truthing. The temporal correlation and spectral similarity between\nmultitemporal images have opened up an opportunity to alleviate this problem.\nIn this study, a SVM-based Sequential Classifier Training (SCT-SVM) approach is\nproposed for multitemporal remote sensing image classification. The approach\nleverages the classifiers of previous images to reduce the required number of\ntraining samples for the classifier training of an incoming image. For each\nincoming image, a rough classifier is firstly predicted based on the temporal\ntrend of a set of previous classifiers. The predicted classifier is then\nfine-tuned into a more accurate position with current training samples. This\napproach can be applied progressively to sequential image data, with only a\nsmall number of training samples being required from each image. Experiments\nwere conducted with Sentinel-2A multitemporal data over an agricultural area in\nAustralia. Results showed that the proposed SCT-SVM achieved better\nclassification accuracies compared with two state-of-the-art model transfer\nalgorithms. When training data are insufficient, the overall classification\naccuracy of the incoming image was improved from 76.18% to 94.02% with the\nproposed SCT-SVM, compared with those obtained without the assistance from\nprevious images. These results demonstrate that the leverage of a priori\ninformation from previous images can provide advantageous assistance for later\nimages in multitemporal image classification.",
    "published": "2017-06-15T02:01:44Z",
    "updated": "2018-01-17T02:24:47Z",
    "authors": [
      "Yiqing Guo",
      "Xiuping Jia",
      "David Paull"
    ],
    "link": "http://arxiv.org/abs/1706.04719v2",
    "pdf_link": "http://arxiv.org/pdf/1706.04719v2"
  },
  {
    "api_id": 407,
    "title": "TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image\n  Segmentation",
    "summary": "Pixel-wise image segmentation is demanding task in computer vision. Classical\nU-Net architectures composed of encoders and decoders are very popular for\nsegmentation of medical images, satellite images etc. Typically, neural network\ninitialized with weights from a network pre-trained on a large data set like\nImageNet shows better performance than those trained from scratch on a small\ndataset. In some practical applications, particularly in medicine and traffic\nsafety, the accuracy of the models is of utmost importance. In this paper, we\ndemonstrate how the U-Net type architecture can be improved by the use of the\npre-trained encoder. Our code and corresponding pre-trained weights are\npublicly available at https://github.com/ternaus/TernausNet. We compare three\nweight initialization schemes: LeCun uniform, the encoder with weights from\nVGG11 and full network trained on the Carvana dataset. This network\narchitecture was a part of the winning solution (1st out of 735) in the Kaggle:\nCarvana Image Masking Challenge.",
    "published": "2018-01-17T16:49:10Z",
    "updated": "2018-01-17T16:49:10Z",
    "authors": [
      "Vladimir Iglovikov",
      "Alexey Shvets"
    ],
    "link": "http://arxiv.org/abs/1801.05746v1",
    "pdf_link": "http://arxiv.org/pdf/1801.05746v1"
  },
  {
    "api_id": 408,
    "title": "Upgrading from Gaussian Processes to Student's-T Processes",
    "summary": "Gaussian process priors are commonly used in aerospace design for performing\nBayesian optimization. Nonetheless, Gaussian processes suffer two significant\ndrawbacks: outliers are a priori assumed unlikely, and the posterior variance\nconditioned on observed data depends only on the locations of those data, not\nthe associated sample values. Student's-T processes are a generalization of\nGaussian processes, founded on the Student's-T distribution instead of the\nGaussian distribution. Student's-T processes maintain the primary advantages of\nGaussian processes (kernel function, analytic update rule) with additional\nbenefits beyond Gaussian processes. The Student's-T distribution has higher\nKurtosis than a Gaussian distribution and so outliers are much more likely, and\nthe posterior variance increases or decreases depending on the variance of\nobserved data sample values. Here, we describe Student's-T processes, and\ndiscuss their advantages in the context of aerospace optimization. We show how\nto construct a Student's-T process using a kernel function and how to update\nthe process given new samples. We provide a clear derivation of\noptimization-relevant quantities such as expected improvement, and contrast\nwith the related computations for Gaussian processes. Finally, we compare the\nperformance of Student's-T processes against Gaussian process on canonical test\nproblems in Bayesian optimization, and apply the Student's-T process to the\noptimization of an aerostructural design problem.",
    "published": "2018-01-18T17:56:03Z",
    "updated": "2018-01-18T17:56:03Z",
    "authors": [
      "Brendan D. Tracey",
      "David H. Wolpert"
    ],
    "link": "http://arxiv.org/abs/1801.06147v1",
    "pdf_link": "http://arxiv.org/pdf/1801.06147v1"
  },
  {
    "api_id": 409,
    "title": "Visualization of Hyperspectral Images Using Moving Least Squares",
    "summary": "Displaying the large number of bands in a hyper spectral image on a\ntrichromatic monitor has been an active research topic. The visualized image\nshall convey as much information as possible form the original data and\nfacilitate image interpretation. Most existing methods display HSIs in false\ncolors which contradict with human's experience and expectation. In this paper,\nwe propose a nonlinear approach to visualize an input HSI with natural colors\nby taking advantage of a corresponding RGB image. Our approach is based on\nMoving Least Squares, an interpolation scheme for reconstructing a surface from\na set of control points, which in our case is a set of matching pixels between\nthe HSI and the corresponding RGB image. Based on MLS, the proposed method\nsolves for each spectral signature a unique transformation so that the non\nlinear structure of the HSI can be preserved. The matching pixels between a\npair of HSI and RGB image can be reused to display other HSIs captured b the\nsame imaging sensor with natural colors. Experiments show that the output image\nof the proposed method no only have natural colors but also maintain the visual\ninformation necessary for human analysis.",
    "published": "2018-01-20T07:01:27Z",
    "updated": "2018-01-20T07:01:27Z",
    "authors": [
      "Danping Liao",
      "Siyu Chen",
      "Yuntao Qian"
    ],
    "link": "http://arxiv.org/abs/1801.06635v1",
    "pdf_link": "http://arxiv.org/pdf/1801.06635v1"
  },
  {
    "api_id": 410,
    "title": "Oceanic tides from Earth-like to ocean planets",
    "summary": "Oceanic tides are a major source of tidal dissipation. They drive the\nevolution of planetary systems and the rotational dynamics of planets. However,\n2D models commonly used for the Earth cannot be applied to extrasolar telluric\nplanets hosting potentially deep oceans because they ignore the\nthree-dimensional effects related to the ocean vertical structure. Our goal is\nto investigate in a consistant way the importance of the contribution of\ninternal gravity waves in the oceanic tidal response and to propose a modeling\nallowing to treat a wide range of cases from shallow to deep oceans. A 3D ab\ninitio model is developed to study the dynamics of a global planetary ocean.\nThis model takes into account compressibility, stratification and sphericity\nterms, which are usually ignored in 2D approaches. An analytic solution is\ncomputed and used to study the dependence of the tidal response on the tidal\nfrequency and on the ocean depth and stratification. In the 2D asymptotic\nlimit, we recover the frequency-resonant behaviour due to surface\ninertial-gravity waves identified by early studies. As the ocean depth and\nBrunt-V\\\"ais\\\"al\\\"a frequency increase, the contribution of internal gravity\nwaves grows in importance and the tidal response become three-dimensional. In\nthe case of deep oceans, the stable stratification induces resonances that can\nincrease the tidal dissipation rate by several orders of magnitude. It is thus\nable to affect significantly the evolution time scale of the planetary\nrotation.",
    "published": "2018-01-26T10:23:24Z",
    "updated": "2018-01-26T10:23:24Z",
    "authors": [
      "Pierre Auclair-Desrotour",
      "Stéphane Mathis",
      "Jacques Laskar",
      "Jérémy Leconte"
    ],
    "link": "http://arxiv.org/abs/1801.08742v1",
    "pdf_link": "http://arxiv.org/pdf/1801.08742v1"
  },
  {
    "api_id": 411,
    "title": "A model of orbital angular momentum Li-Fi",
    "summary": "Twisted light has recently gained enormous interest in communication systems.\nThus far, twisted light has not yet been utilized for visible light\ncommunication to transmit data. Here, by exploiting the color and orbital\nangular momentum (OAM) degrees of freedom simultaneously, we construct a much\nhigher-dimensional space spanned by their hybrid mode basis, which further\nincreases the information capacity of twisted light. We build a new visible\nlight communication system using a white light emitting diode, with red, green\nand blue (RGB) colors serving as independent channels and with OAM\nsuperposition states encoding the information. We connect our conceptually new\nRGB-OAM hybrid coding with the specially designed two-dimensional holographic\ngratings based on theta-modulation. After indoor free-space transmission, we\ndecode the color information with an Xcube prism and subsequently decode the\nOAM superposition states with a pattern recognition method based on supervised\nmachine learning. We succeed in demonstrating the transmission of color images\nand a piece of audio with the fidelity over 96%. Our point-to-point scheme with\nhybrid RGB-OAM encoding, not only increases significantly the information\ncapacity of twisted light, but also offers additional security that supplements\nthe traditional broadcasting visible light communications, e.g., Li-Fi.",
    "published": "2018-01-29T03:11:36Z",
    "updated": "2018-01-29T03:11:36Z",
    "authors": [
      "Yuanying Zhang",
      "Jikang Wang",
      "Wuhong Zhang",
      "Shuting Chen",
      "Lixiang Chen"
    ],
    "link": "http://arxiv.org/abs/1801.09353v1",
    "pdf_link": "http://arxiv.org/pdf/1801.09353v1"
  },
  {
    "api_id": 412,
    "title": "Naive Bayes Entrapment Detection for Planetary Rovers",
    "summary": "Entrapment detection is a prerequisite for planetary rovers to perform\nautonomous rescue procedure. In this study, rover entrapment and approximated\nentrapment criteria are formally defined. Entrapment detection using Naive\nBayes classifiers is proposed and discussed along with results from experiments\nwhere the Naive Bayes entrapment detector is applied to AutoKralwer rovers. And\nfinal conclusions and further discussions are presented in the final section.",
    "published": "2018-01-31T17:41:42Z",
    "updated": "2018-01-31T17:41:42Z",
    "authors": [
      "Dicong Qiu"
    ],
    "link": "http://arxiv.org/abs/1801.10571v1",
    "pdf_link": "http://arxiv.org/pdf/1801.10571v1"
  },
  {
    "api_id": 413,
    "title": "The Deflector Selector: A Machine Learning Framework for Prioritizing\n  Hazardous Object Deflection Technology Development",
    "summary": "Several technologies have been proposed for deflecting a hazardous Solar\nSystem object on a trajectory that would otherwise impact the Earth. The\neffectiveness of each technology depends on several characteristics of the\ngiven object, including its orbit and size. The distribution of these\nparameters in the likely population of Earth-impacting objects can thus\ndetermine which of the technologies are most likely to be useful in preventing\na collision with the Earth. None of the proposed deflection technologies has\nbeen developed and fully tested in space. Developing every proposed technology\nis currently prohibitively expensive, so determining now which technologies are\nmost likely to be effective would allow us to prioritize a subset of proposed\ndeflection technologies for funding and development. We present a new model,\nthe Deflector Selector, that takes as its input the characteristics of a\nhazardous object or population of such objects and predicts which technology\nwould be able to perform a successful deflection. The model consists of a\nmachine-learning algorithm trained on data produced by N-body integrations\nsimulating the deflections. We describe the model and present the results of\ntests of the effectiveness of nuclear explosives, kinetic impactors, and\ngravity tractors on three simulated populations of hazardous objects.",
    "published": "2018-02-01T19:01:20Z",
    "updated": "2018-02-01T19:01:20Z",
    "authors": [
      "Erika R. Nesvold",
      "Adam Greenberg",
      "Nicolas Erasmus",
      "Elmarie van Heerden",
      "J. L. Galache",
      "Eric Dahlstrom",
      "Franck Marchis"
    ],
    "link": "http://arxiv.org/abs/1802.00458v1",
    "pdf_link": "http://arxiv.org/pdf/1802.00458v1"
  },
  {
    "api_id": 414,
    "title": "Representation Learning for Resource Usage Prediction",
    "summary": "Creating a model of a computer system that can be used for tasks such as\npredicting future resource usage and detecting anomalies is a challenging\nproblem. Most current systems rely on heuristics and overly simplistic\nassumptions about the workloads and system statistics. These heuristics are\ntypically a one-size-fits-all solution so as to be applicable in a wide range\nof applications and systems environments.\n  With this paper, we present our ongoing work of integrating systems telemetry\nranging from standard resource usage statistics to kernel and library calls of\napplications into a machine learning model. Intuitively, such a ML model\napproximates, at any point in time, the state of a system and allows us to\nsolve tasks such as resource usage prediction and anomaly detection. To achieve\nthis goal, we leverage readily-available information that does not require any\nchanges to the applications run on the system. We train recurrent neural\nnetworks to learn a model of the system under consideration. As a proof of\nconcept, we train models specifically to predict future resource usage of\nrunning applications.",
    "published": "2018-02-02T13:21:13Z",
    "updated": "2018-02-02T13:21:13Z",
    "authors": [
      "Florian Schmidt",
      "Mathias Niepert",
      "Felipe Huici"
    ],
    "link": "http://arxiv.org/abs/1802.00673v1",
    "pdf_link": "http://arxiv.org/pdf/1802.00673v1"
  },
  {
    "api_id": 415,
    "title": "Deep Temporal Clustering : Fully Unsupervised Learning of Time-Domain\n  Features",
    "summary": "Unsupervised learning of time series data, also known as temporal clustering,\nis a challenging problem in machine learning. Here we propose a novel\nalgorithm, Deep Temporal Clustering (DTC), to naturally integrate\ndimensionality reduction and temporal clustering into a single end-to-end\nlearning framework, fully unsupervised. The algorithm utilizes an autoencoder\nfor temporal dimensionality reduction and a novel temporal clustering layer for\ncluster assignment. Then it jointly optimizes the clustering objective and the\ndimensionality reduction objec tive. Based on requirement and application, the\ntemporal clustering layer can be customized with any temporal similarity\nmetric. Several similarity metrics and state-of-the-art algorithms are\nconsidered and compared. To gain insight into temporal features that the\nnetwork has learned for its clustering, we apply a visualization method that\ngenerates a region of interest heatmap for the time series. The viability of\nthe algorithm is demonstrated using time series data from diverse domains,\nranging from earthquakes to spacecraft sensor data. In each case, we show that\nthe proposed algorithm outperforms traditional methods. The superior\nperformance is attributed to the fully integrated temporal dimensionality\nreduction and clustering criterion.",
    "published": "2018-02-04T02:18:25Z",
    "updated": "2018-02-04T02:18:25Z",
    "authors": [
      "Naveen Sai Madiraju",
      "Seid M. Sadat",
      "Dimitry Fisher",
      "Homa Karimabadi"
    ],
    "link": "http://arxiv.org/abs/1802.01059v1",
    "pdf_link": "http://arxiv.org/pdf/1802.01059v1"
  },
  {
    "api_id": 416,
    "title": "Revisiting the Statistics of X-ray Flares in Gamma-ray Bursts",
    "summary": "The statistics of X-ray flares in the afterglow of gamma-ray bursts (GRBs)\nhave been studied extensively without considering the possible different\norigins of each flare. By satisfying six observational criteria, we find a\nsample composed of $16$ long GRBs observed by \\textit{Swift} satellite may\nshare a same origin. By applying the Markov chain Monte Carlo iteration and the\nmachine learning algorithms (locally weighted regression and Gaussian process\nregression), impressively, the flares in these GRBs show strong correlations\nwith the energy released in the prompt emission. These correlations were never\ndiscovered in previous papers, and they could not be well explained by previous\nmodels. These correlations imply that the prompt emission and the X-ray flare\nare not independent, they may be originated following a same sequence. The new\nTHESUS satellite will provide us a larger sample and more detailed spectra to\nrefine the results we obtained in this article.",
    "published": "2018-02-05T21:19:15Z",
    "updated": "2018-02-05T21:19:15Z",
    "authors": [
      "Y. Wang",
      "Y. Aimuratov",
      "R. Moradi",
      "M. Peresano",
      "R. Ruffini",
      "S. Shakeri"
    ],
    "link": "http://arxiv.org/abs/1802.01693v1",
    "pdf_link": "http://arxiv.org/pdf/1802.01693v1"
  },
  {
    "api_id": 417,
    "title": "Estimating regional ground-level PM2.5 directly from satellite\n  top-of-atmosphere reflectance using deep learning",
    "summary": "Almost all remote sensing atmospheric PM2.5 estimation methods need satellite\naerosol optical depth (AOD) products, which are often retrieved from\ntop-of-atmosphere (TOA) reflectance via an atmospheric radiative transfer\nmodel. Then, is it possible to estimate ground-level PM2.5 directly from\nsatellite TOA reflectance without a physical model? In this study, this\nchallenging work are achieved based on a machine learning model. Specifically,\nwe establish the relationship between PM2.5, satellite TOA reflectance,\nobservation angles, and meteorological factors in a deep learning architecture\n(denoted as Ref-PM modeling). Taking the Wuhan Urban Agglomeration (WUA) as a\ncase study, the results demonstrate that compared with the AOD-PM modeling, the\nRef-PM modeling obtains a competitive performance, with out-of-sample\ncross-validated R2 and RMSE values of 0.87 and 9.89 ug/m3 respectively. Also,\nthe TOA-reflectance-derived PM2.5 have a finer resolution and larger spatial\ncoverage than the AOD-derived PM2.5. This work updates the traditional\ncognition of remote sensing PM2.5 estimation and has the potential to promote\nthe application in atmospheric environmental monitoring.",
    "published": "2017-09-18T13:26:25Z",
    "updated": "2018-02-06T08:57:21Z",
    "authors": [
      "Huanfeng Shen",
      "Tongwen Li",
      "Qiangqiang Yuan",
      "Liangpei Zhang"
    ],
    "link": "http://arxiv.org/abs/1709.05912v2",
    "pdf_link": "http://arxiv.org/pdf/1709.05912v2"
  },
  {
    "api_id": 418,
    "title": "Spectral Image Visualization Using Generative Adversarial Networks",
    "summary": "Spectral images captured by satellites and radio-telescopes are analyzed to\nobtain information about geological compositions distributions, distant asters\nas well as undersea terrain. Spectral images usually contain tens to hundreds\nof continuous narrow spectral bands and are widely used in various fields. But\nthe vast majority of those image signals are beyond the visible range, which\ncalls for special visualization technique. The visualizations of spectral\nimages shall convey as much information as possible from the original signal\nand facilitate image interpretation. However, most of the existing visualizatio\nmethods display spectral images in false colors, which contradict with human's\nexperience and expectation. In this paper, we present a novel visualization\ngenerative adversarial network (GAN) to display spectral images in natural\ncolors. To achieve our goal, we propose a loss function which consists of an\nadversarial loss and a structure loss. The adversarial loss pushes our solution\nto the natural image distribution using a discriminator network that is trained\nto differentiate between false-color images and natural-color images. We also\nuse a cycle loss as the structure constraint to guarantee structure\nconsistency. Experimental results show that our method is able to generate\nstructure-preserved and natural-looking visualizations.",
    "published": "2018-02-07T02:23:47Z",
    "updated": "2018-02-07T02:23:47Z",
    "authors": [
      "Siyu Chen",
      "Danping Liao",
      "Yuntao Qian"
    ],
    "link": "http://arxiv.org/abs/1802.02290v1",
    "pdf_link": "http://arxiv.org/pdf/1802.02290v1"
  },
  {
    "api_id": 419,
    "title": "Shallow Transits - Deep Learning I: Feasibility Study of Deep Learning\n  to Detect Periodic Transits of Exoplanets",
    "summary": "Transits of habitable planets around solar-like stars are expected to be\nshallow, and to have long periods, which means low information content. The\ncurrent bottleneck in the detection of such transits is caused in large part by\nthe presence of red (correlated) noise in the light curves obtained from the\ndedicated space telescopes. Based on the groundbreaking results deep learning\nachieves in many signal and image processing applications, we propose to use\ndeep neural networks to solve this problem. We present a feasibility study, in\nwhich we applied a convolutional neural network on a simulated training set.\nThe training set comprised light curves received from a hypothetical\nhigh-cadence space-based telescope. We simulated the red noise by using\nGaussian Processes with a wide variety of hyperparameters. We then tested the\nnetwork on a completely different test set simulated in the same way. Our study\nproves that very difficult cases can indeed be detected. Furthermore, we show\nhow detection trends can be studied, and detection biases be quantified. We\nhave also checked the robustness of the neural-network performance against\npractical artifacts such as outliers and discontinuities, which are known to\naffect space-based high-cadence light curves. Future work will allow us to use\nthe neural networks to characterize the transit model and identify individual\ntransits. This new approach will certainly be an indispensable tool for the\ndetection of habitable planets in the future planet-detection space missions\nsuch as PLATO.",
    "published": "2017-11-08T21:00:11Z",
    "updated": "2018-02-07T12:55:31Z",
    "authors": [
      "Shay Zucker",
      "Raja Giryes"
    ],
    "link": "http://arxiv.org/abs/1711.03163v2",
    "pdf_link": "http://arxiv.org/pdf/1711.03163v2"
  },
  {
    "api_id": 420,
    "title": "Fusing Multiple Multiband Images",
    "summary": "We consider the problem of fusing an arbitrary number of multiband, i.e.,\npanchromatic, multispectral, or hyperspectral, images belonging to the same\nscene. We use the well-known forward observation and linear mixture models with\nGaussian perturbations to formulate the maximum-likelihood estimator of the\nendmember abundance matrix of the fused image. We calculate the Fisher\ninformation matrix for this estimator and examine the conditions for the\nuniqueness of the estimator. We use a vector total-variation penalty term\ntogether with nonnegativity and sum-to-one constraints on the endmember\nabundances to regularize the derived maximum-likelihood estimation problem. The\nregularization facilitates exploiting the prior knowledge that natural images\nare mostly composed of piecewise smooth regions with limited abrupt changes,\ni.e., edges, as well as coping with potential ill-posedness of the fusion\nproblem. We solve the resultant convex optimization problem using the\nalternating direction method of multipliers. We utilize the circular\nconvolution theorem in conjunction with the fast Fourier transform to alleviate\nthe computational complexity of the proposed algorithm. Experiments with\nmultiband images constructed from real hyperspectral datasets reveal the\nsuperior performance of the proposed algorithm in comparison with the\nstate-of-the-art algorithms, which need to be used in tandem to fuse more than\ntwo multiband images.",
    "published": "2017-12-13T00:09:28Z",
    "updated": "2018-07-18T00:39:25Z",
    "authors": [
      "Reza Arablouei"
    ],
    "link": "http://arxiv.org/abs/1712.04575v2",
    "pdf_link": "http://arxiv.org/pdf/1712.04575v2"
  },
  {
    "api_id": 421,
    "title": "Deep Adaptive Proposal Network for Object Detection in Optical Remote\n  Sensing Images",
    "summary": "Object detection is a fundamental and challenging problem in aerial and\nsatellite image analysis. More recently, a two-stage detector Faster R-CNN is\nproposed and demonstrated to be a promising tool for object detection in\noptical remote sensing images, while the sparse and dense characteristic of\nobjects in remote sensing images is complexity. It is unreasonable to treat all\nimages with the same region proposal strategy, and this treatment limits the\nperformance of two-stage detectors. In this paper, we propose a novel and\neffective approach, named deep adaptive proposal network (DAPNet), address this\ncomplexity characteristic of object by learning a new category prior network\n(CPN) on the basis of the existing Faster R-CNN architecture. Moreover, the\ncandidate regions produced by DAPNet model are different from the traditional\nregion proposal network (RPN), DAPNet predicts the detail category of each\ncandidate region. And these candidate regions combine the object number, which\ngenerated by the category prior network to achieve a suitable number of\ncandidate boxes for each image. These candidate boxes can satisfy detection\ntasks in sparse and dense scenes. The performance of the proposed framework has\nbeen evaluated on the challenging NWPU VHR-10 data set. Experimental results\ndemonstrate the superiority of the proposed framework to the state-of-the-art.",
    "published": "2018-07-19T10:10:30Z",
    "updated": "2018-07-19T10:10:30Z",
    "authors": [
      "Lin Cheng",
      "Xu Liu",
      "Lingling Li",
      "Licheng Jiao",
      "Xu Tang"
    ],
    "link": "http://arxiv.org/abs/1807.07327v1",
    "pdf_link": "http://arxiv.org/pdf/1807.07327v1"
  },
  {
    "api_id": 422,
    "title": "Rank Minimization for Snapshot Compressive Imaging",
    "summary": "Snapshot compressive imaging (SCI) refers to compressive imaging systems\nwhere multiple frames are mapped into a single measurement, with video\ncompressive imaging and hyperspectral compressive imaging as two representative\napplications. Though exciting results of high-speed videos and hyperspectral\nimages have been demonstrated, the poor reconstruction quality precludes SCI\nfrom wide applications.This paper aims to boost the reconstruction quality of\nSCI via exploiting the high-dimensional structure in the desired signal. We\nbuild a joint model to integrate the nonlocal self-similarity of\nvideo/hyperspectral frames and the rank minimization approach with the SCI\nsensing process. Following this, an alternating minimization algorithm is\ndeveloped to solve this non-convex problem. We further investigate the special\nstructure of the sampling process in SCI to tackle the computational workload\nand memory issues in SCI reconstruction. Both simulation and real data\n(captured by four different SCI cameras) results demonstrate that our proposed\nalgorithm leads to significant improvements compared with current\nstate-of-the-art algorithms. We hope our results will encourage the researchers\nand engineers to pursue further in compressive imaging for real applications.",
    "published": "2018-07-20T13:44:37Z",
    "updated": "2018-07-20T13:44:37Z",
    "authors": [
      "Yang Liu",
      "Xin Yuan",
      "Jinli Suo",
      "David J. Brady",
      "Qionghai Dai"
    ],
    "link": "http://arxiv.org/abs/1807.07837v1",
    "pdf_link": "http://arxiv.org/pdf/1807.07837v1"
  },
  {
    "api_id": 423,
    "title": "A Trace Lasso Regularized L1-norm Graph Cut for Highly Correlated Noisy\n  Hyperspectral Image",
    "summary": "This work proposes an adaptive trace lasso regularized L1-norm based graph\ncut method for dimensionality reduction of Hyperspectral images, called as\n`Trace Lasso-L1 Graph Cut' (TL-L1GC). The underlying idea of this method is to\ngenerate the optimal projection matrix by considering both the sparsity as well\nas the correlation of the data samples. The conventional L2-norm used in the\nobjective function is sensitive to noise and outliers. Therefore, in this work\nL1-norm is utilized as a robust alternative to L2-norm. Besides, for further\nimprovement of the results, we use a penalty function of trace lasso with the\nL1GC method. It adaptively balances the L2-norm and L1-norm simultaneously by\nconsidering the data correlation along with the sparsity. We obtain the optimal\nprojection matrix by maximizing the ratio of between-class dispersion to\nwithin-class dispersion using L1-norm with trace lasso as the penalty.\nFurthermore, an iterative procedure for this TL-L1GC method is proposed to\nsolve the optimization function. The effectiveness of this proposed method is\nevaluated on two benchmark HSI datasets.",
    "published": "2018-07-22T07:44:56Z",
    "updated": "2018-07-22T07:44:56Z",
    "authors": [
      "Ramanarayan Mohanty",
      "S L Happy",
      "Nilesh Suthar",
      "Aurobinda Routray"
    ],
    "link": "http://arxiv.org/abs/1807.10602v1",
    "pdf_link": "http://arxiv.org/pdf/1807.10602v1"
  },
  {
    "api_id": 424,
    "title": "Region Convolutional Features for Multi-Label Remote Sensing Image\n  Retrieval",
    "summary": "Conventional remote sensing image retrieval (RSIR) systems usually perform\nsingle-label retrieval where each image is annotated by a single label\nrepresenting the most significant semantic content of the image. This\nassumption, however, ignores the complexity of remote sensing images, where an\nimage might have multiple classes (i.e., multiple labels), thus resulting in\nworse retrieval performance. We therefore propose a novel multi-label RSIR\napproach with fully convolutional networks (FCN). In our approach, we first\ntrain a FCN model using a pixel-wise labeled dataset,and the trained FCN is\nthen used to predict the segmentation maps of each image in the considered\narchive. We finally extract region convolutional features of each image based\non its segmentation map.The region features can be either used to perform\nregion-based retrieval or further post-processed to obtain a feature vector for\nsimilarity measure. The experimental results show that our approach achieves\nstate-of-the-art performance in contrast to conventional single-label and\nrecent multi-label RSIR approaches.",
    "published": "2018-07-23T14:04:18Z",
    "updated": "2018-07-23T14:04:18Z",
    "authors": [
      "Weixun Zhou",
      "Xueqing Deng",
      "Zhenfeng Shao"
    ],
    "link": "http://arxiv.org/abs/1807.08634v1",
    "pdf_link": "http://arxiv.org/pdf/1807.08634v1"
  },
  {
    "api_id": 425,
    "title": "Spectral-spatial classification of hyperspectral images: three tricks\n  and a new supervised learning setting",
    "summary": "Spectral-spatial classification of hyperspectral images has been the subject\nof many studies in recent years. In the presence of only very few labeled\npixels, this task becomes challenging. In this paper we address the following\ntwo research questions: 1) Can a simple neural network with just a single\nhidden layer achieve state of the art performance in the presence of few\nlabeled pixels? 2) How is the performance of hyperspectral image classification\nmethods affected when using disjoint train and test sets? We give a positive\nanswer to the first question by using three tricks within a very basic shallow\nConvolutional Neural Network (CNN) architecture: a tailored loss function, and\nsmooth- and label-based data augmentation. The tailored loss function enforces\nthat neighborhood wavelengths have similar contributions to the features\ngenerated during training. A new label-based technique here proposed favors\nselection of pixels in smaller classes, which is beneficial in the presence of\nvery few labeled pixels and skewed class distributions. To address the second\nquestion, we introduce a new sampling procedure to generate disjoint train and\ntest set. Then the train set is used to obtain the CNN model, which is then\napplied to pixels in the test set to estimate their labels. We assess the\nefficacy of the simple neural network method on five publicly available\nhyperspectral images. On these images our method significantly outperforms\nconsidered baselines. Notably, with just 1% of labeled pixels per class, on\nthese datasets our method achieves an accuracy that goes from 86.42%\n(challenging dataset) to 99.52% (easy dataset). Furthermore we show that the\nsimple neural network method improves over other baselines in the new\nchallenging supervised setting. Our analysis substantiates the highly\nbeneficial effect of using the entire image (so train and test data) for\nconstructing a model.",
    "published": "2017-11-15T12:02:57Z",
    "updated": "2018-07-23T16:24:52Z",
    "authors": [
      "Jacopo Acquarelli",
      "Elena Marchiori",
      "Lutgarde M. C. Buydens",
      "Thanh Tran",
      "Twan van Laarhoven"
    ],
    "link": "http://arxiv.org/abs/1711.05512v4",
    "pdf_link": "http://arxiv.org/pdf/1711.05512v4"
  },
  {
    "api_id": 426,
    "title": "Panchromatic Sharpening of Remote Sensing Images Using a Multi-scale\n  Approach",
    "summary": "An ideal fusion method preserves the Spectral information in fused image and\nadds spatial information to it with no spectral distortion. Recently wavelet\nkalman filter method is proposed which uses ARSIS concept to fuses MS and PAN\nimages. This method is applied in a multiscale version, i.e. the variable index\nis scale instead of time. With the aim of fusion we present a more detailed\nstudy on this model and discuss about rationality of its assumptions such as\nfirst order markov model and Gaussian distribution of the posterior density.\nFinally, we propose a method using wavelet Kalman Particle filter to improve\nthe spectral and spatial quality of the fused image. We show that our model is\nmore consistent with natural MS and PAN images. Visual and statistical analyzes\nshow that the proposed algorithm clearly improves the fusion quality in terms\nof: correlation coefficient, ERGAS, UIQI, and Q4; compared to other methods\nincluding IHS, HMP, PCA, A`trous, udWI, udWPC, Adaptive IHS, Improved Adaptive\nPCA and wavelet kalman filter.",
    "published": "2018-07-24T06:02:19Z",
    "updated": "2018-07-24T06:02:19Z",
    "authors": [
      "Hamid Reza Shahdoosti"
    ],
    "link": "http://arxiv.org/abs/1807.08917v1",
    "pdf_link": "http://arxiv.org/pdf/1807.08917v1"
  },
  {
    "api_id": 427,
    "title": "Improved Adaptive Brovey as a New Method for Image Fusion",
    "summary": "An ideal fusion method preserves the Spectral information in fused image and\nadds spatial information to it with no spectral distortion. Among the existing\nfusion algorithms, the contourlet-based fusion method is the most frequently\ndiscussed one in recent publications, because the contourlet has the ability to\ncapture and link the point of discontinuities to form a linear structure. The\nBrovey is a popular pan-sharpening method owing to its efficiency and high\nspatial resolution. This method can be explained by mathematical model of\noptical remote sensing sensors. This study presents a new fusion approach that\nintegrates the advantages of both the Brovey and the cotourlet techniques to\nreduce the color distortion of fusion results. Visual and statistical analyzes\nshow that the proposed algorithm clearly improves the merging quality in terms\nof: correlation coefficient, ERGAS, UIQI, and Q4; compared to fusion methods\nincluding IHS, PCA, Adaptive IHS, and Improved Adaptive PCA.",
    "published": "2018-07-24T06:35:55Z",
    "updated": "2018-07-24T06:35:55Z",
    "authors": [
      "Hamid Reza Shahdoosti"
    ],
    "link": "http://arxiv.org/abs/1807.09610v1",
    "pdf_link": "http://arxiv.org/pdf/1807.09610v1"
  },
  {
    "api_id": 428,
    "title": "Hyperspectral Images Classification Using Energy Profiles of Spatial and\n  Spectral Features",
    "summary": "This paper proposes a spatial feature extraction method based on energy of\nthe features for classification of the hyperspectral data. A proposed\northogonal filter set extracts spatial features with maximum energy from the\nprincipal components and then, a profile is constructed based on these\nfeatures. The important characteristic of the proposed approach is that the\nfilter sets coefficients are extracted from statistical properties of data,\nthus they are more consistent with the type and texture of the remotely sensed\nimages compared with those of other filters such as Gabor. To assess the\nperformance of the proposed feature extraction method, the extracted features\nare fed into a support vector machine (SVM) classifier. Experiments on the\nwidely used hyperspectral images namely, Indian Pines, and Salinas data sets\nreveal that the proposed approach improves the classification results in\ncomparison with some recent spectral spatial classification methods.",
    "published": "2018-07-24T07:52:25Z",
    "updated": "2018-07-24T07:52:25Z",
    "authors": [
      "Hamid Reza Shahdoosti"
    ],
    "link": "http://arxiv.org/abs/1807.08943v1",
    "pdf_link": "http://arxiv.org/pdf/1807.08943v1"
  },
  {
    "api_id": 429,
    "title": "Feature Fusion through Multitask CNN for Large-scale Remote Sensing\n  Image Segmentation",
    "summary": "In recent years, Fully Convolutional Networks (FCN) has been widely used in\nvarious semantic segmentation tasks, including multi-modal remote sensing\nimagery. How to fuse multi-modal data to improve the segmentation performance\nhas always been a research hotspot. In this paper, a novel end-toend fully\nconvolutional neural network is proposed for semantic segmentation of natural\ncolor, infrared imagery and Digital Surface Models (DSM). It is based on a\nmodified DeepUNet and perform the segmentation in a multi-task way. The\nchannels are clustered into groups and processed on different task pipelines.\nAfter a series of segmentation and fusion, their shared features and private\nfeatures are successfully merged together. Experiment results show that the\nfeature fusion network is efficient. And our approach achieves good performance\nin ISPRS Semantic Labeling Contest (2D).",
    "published": "2018-07-24T12:48:15Z",
    "updated": "2018-07-24T12:48:15Z",
    "authors": [
      "Shihao Sun",
      "Lei Yang",
      "Wenjie Liu",
      "Ruirui Li"
    ],
    "link": "http://arxiv.org/abs/1807.09072v1",
    "pdf_link": "http://arxiv.org/pdf/1807.09072v1"
  },
  {
    "api_id": 430,
    "title": "A Novel Deep Neural Network Architecture for Mars Visual Navigation",
    "summary": "In this paper, emerging deep learning techniques are leveraged to deal with\nMars visual navigation problem. Specifically, to achieve precise landing and\nautonomous navigation, a novel deep neural network architecture with double\nbranches and non-recurrent structure is designed, which can represent both\nglobal and local deep features of Martian environment images effectively. By\nemploying this architecture, Mars rover can determine the optimal navigation\npolicy to the target point directly from original Martian environment images.\nMoreover, compared with the existing state-of-the-art algorithm, the training\ntime is reduced by 45.8%. Finally, experiment results demonstrate that the\nproposed deep neural network architecture achieves better performance and\nfaster convergence than the existing ones and generalizes well to unknown\nenvironment.",
    "published": "2018-08-25T09:40:06Z",
    "updated": "2018-08-25T09:40:06Z",
    "authors": [
      "Jiang Zhang",
      "Yuanqing Xia",
      "Ganghui Shen"
    ],
    "link": "http://arxiv.org/abs/1808.08395v1",
    "pdf_link": "http://arxiv.org/pdf/1808.08395v1"
  },
  {
    "api_id": 431,
    "title": "Restoration of Pansharpened Images by Conditional Filtering in the PCA\n  Domain",
    "summary": "Pansharpening techniques aim at fusing low-resolution multispectral (MS)\nimages and high-resolution panchromatic (PAN) images to produce high-resolution\nMS images. Despite significant progress in the field, spectral and spatial\ndistortions might still compromise the quality of the results. We introduce a\nrestoration strategy to mitigate artifacts of fused products. After applying\nthe Principal Component Analysis (PCA) transform to a pansharpened image, the\nchromatic components are filtered conditionally to the geometry of PAN. The\nstructural component is then replaced by the locally histogram-matched PAN for\nspatial enhancement. Experimental results illustrate the efficiency of the\nproposed restoration chain.",
    "published": "2017-10-02T14:13:58Z",
    "updated": "2018-08-25T12:05:02Z",
    "authors": [
      "Joan Duran",
      "Antoni Buades"
    ],
    "link": "http://arxiv.org/abs/1710.00672v3",
    "pdf_link": "http://arxiv.org/pdf/1710.00672v3"
  },
  {
    "api_id": 432,
    "title": "TreeSegNet: Adaptive Tree CNNs for Subdecimeter Aerial Image\n  Segmentation",
    "summary": "For the task of subdecimeter aerial imagery segmentation, fine-grained\nsemantic segmentation results are usually difficult to obtain because of\ncomplex remote sensing content and optical conditions. Recently, convolutional\nneural networks (CNNs) have shown outstanding performance on this task.\nAlthough many deep neural network structures and techniques have been applied\nto improve the accuracy, few have paid attention to better differentiating the\neasily confused classes. In this paper, we propose TreeSegNet which adopts an\nadaptive network to increase the classification rate at the pixelwise level.\nSpecifically, based on the infrastructure of DeepUNet, a Tree-CNN block in\nwhich each node represents a ResNeXt unit is constructed adaptively according\nto the confusion matrix and the proposed TreeCutting algorithm. By transporting\nfeature maps through concatenating connections, the Tree-CNN block fuses\nmultiscale features and learns best weights for the model. In experiments on\nthe ISPRS 2D semantic labeling Potsdam dataset, the results obtained by\nTreeSegNet are better than those of other published state-of-the-art methods.\nDetailed comparison and analysis show that the improvement brought by the\nadaptive Tree-CNN block is significant.",
    "published": "2018-04-29T06:17:00Z",
    "updated": "2018-08-25T16:48:14Z",
    "authors": [
      "Kai Yue",
      "Lei Yang",
      "Ruirui Li",
      "Wei Hu",
      "Fan Zhang",
      "Wei Li"
    ],
    "link": "http://arxiv.org/abs/1804.10879v2",
    "pdf_link": "http://arxiv.org/pdf/1804.10879v2"
  },
  {
    "api_id": 433,
    "title": "A MapReduce based Big-data Framework for Object Extraction from Mosaic\n  Satellite Images",
    "summary": "We propose a framework stitching of vector representations of large scale\nraster mosaic images in distributed computing model. In this way, the negative\neffect of the lack of resources of the central system and scalability problem\ncan be eliminated. The product obtained by this study can be used in\napplications requiring spatial and temporal analysis on big satellite map\nimages. This study also shows that big data frameworks are not only used in\napplications of text-based data mining and machine learning algorithms, but\nalso used in applications of algorithms in image processing. The effectiveness\nof the product realized with this project is also going to be proven by\nscalability and performance tests performed on real world LandSat-8 satellite\nimages.",
    "published": "2018-08-26T10:32:40Z",
    "updated": "2018-08-26T10:32:40Z",
    "authors": [
      "Suleyman Eken",
      "Ahmet Sayar"
    ],
    "link": "http://arxiv.org/abs/1808.08528v1",
    "pdf_link": "http://arxiv.org/pdf/1808.08528v1"
  },
  {
    "api_id": 434,
    "title": "Scale Drift Correction of Camera Geo-Localization using Geo-Tagged\n  Images",
    "summary": "Camera geo-localization from a monocular video is a fundamental task for\nvideo analysis and autonomous navigation. Although 3D reconstruction is a key\ntechnique to obtain camera poses, monocular 3D reconstruction in a large\nenvironment tends to result in the accumulation of errors in rotation,\ntranslation, and especially in scale: a problem known as scale drift. To\novercome these errors, we propose a novel framework that integrates incremental\nstructure from motion (SfM) and a scale drift correction method utilizing\ngeo-tagged images, such as those provided by Google Street View. Our correction\nmethod begins by obtaining sparse 6-DoF correspondences between the\nreconstructed 3D map coordinate system and the world coordinate system, by\nusing geo-tagged images. Then, it corrects scale drift by applying pose graph\noptimization over Sim(3) constraints and bundle adjustment. Experimental\nevaluations on large-scale datasets show that the proposed framework not only\nsufficiently corrects scale drift, but also achieves accurate geo-localization\nin a kilometer-scale environment.",
    "published": "2018-08-26T12:43:34Z",
    "updated": "2018-08-26T12:43:34Z",
    "authors": [
      "Kazuya Iwami",
      "Satoshi Ikehata",
      "Kiyoharu Aizawa"
    ],
    "link": "http://arxiv.org/abs/1808.08544v1",
    "pdf_link": "http://arxiv.org/pdf/1808.08544v1"
  },
  {
    "api_id": 435,
    "title": "Convolutional Neural Networks for Aerial Vehicle Detection and\n  Recognition",
    "summary": "This paper investigates the problem of aerial vehicle recognition using a\ntext-guided deep convolutional neural network classifier. The network receives\nan aerial image and a desired class, and makes a yes or no output by matching\nthe image and the textual description of the desired class. We train and test\nour model on a synthetic aerial dataset and our desired classes consist of the\ncombination of the class types and colors of the vehicles. This strategy helps\nwhen considering more classes in testing than in training.",
    "published": "2018-08-26T14:29:57Z",
    "updated": "2018-08-26T14:29:57Z",
    "authors": [
      "Amir Soleimani",
      "Nasser M. Nasrabadi",
      "Elias Griffith",
      "Jason Ralph",
      "Simon Maskell"
    ],
    "link": "http://arxiv.org/abs/1808.08560v1",
    "pdf_link": "http://arxiv.org/pdf/1808.08560v1"
  },
  {
    "api_id": 436,
    "title": "Vectorization of Large Amounts of Raster Satellite Images in a\n  Distributed Architecture Using HIPI",
    "summary": "Vectorization process focus on grouping pixels of a raster image into raw\nline segments, and forming lines, polylines or poligons. To vectorize massive\nraster images regarding resource and performane problems, weuse a distributed\nHIPI image processing interface based on MapReduce approach. Apache Hadoop is\nplaced at the core of the framework. To realize such a system, we first define\nmapper function, and then its input and output formats. In this paper, mappers\nconvert raster mosaics into vector counterparts. Reduc functions are not needed\nfor vectorization. Vector representations of raster images is expected to give\nbetter performance in distributed computations by reducing the negative effects\nof bandwidth problem and horizontal scalability analysis is done.",
    "published": "2018-09-01T18:46:57Z",
    "updated": "2018-09-01T18:46:57Z",
    "authors": [
      "Suleyman Eken",
      "Eray Aydin",
      "Ahmet Sayar"
    ],
    "link": "http://arxiv.org/abs/1809.00235v1",
    "pdf_link": "http://arxiv.org/pdf/1809.00235v1"
  },
  {
    "api_id": 437,
    "title": "Identifying Land Patterns from Satellite Imagery in Amazon Rainforest\n  using Deep Learning",
    "summary": "The Amazon rainforests have been suffering widespread damage, both via\nnatural and artificial means. Every minute, it is estimated that the world\nloses forest cover the size of 48 football fields. Deforestation in the Amazon\nrainforest has led to drastically reduced biodiversity, loss of habitat,\nclimate change, and other biological losses. In this respect, it has become\nessential to track how the nature of these forests change over time. Image\nclassification using deep learning can help speed up this process by removing\nthe manual task of classifying each image. Here, it is shown how convolutional\nneural networks can be used to track changes in land patterns in the Amazon\nrainforests. In this work, a testing accuracy of 96.71% was obtained. This can\nhelp governments and other agencies to track changes in land patterns more\neffectively and accurately.",
    "published": "2018-09-02T14:06:39Z",
    "updated": "2018-09-02T14:06:39Z",
    "authors": [
      "Somnath Rakshit",
      "Soumyadeep Debnath",
      "Dhiman Mondal"
    ],
    "link": "http://arxiv.org/abs/1809.00340v1",
    "pdf_link": "http://arxiv.org/pdf/1809.00340v1"
  },
  {
    "api_id": 438,
    "title": "Estimating Small Differences in Car-Pose from Orbits",
    "summary": "Distinction among nearby poses and among symmetries of an object is\nchallenging. In this paper, we propose a unified, group-theoretic approach to\ntackle both. Different from existing works which directly predict absolute\npose, our method measures the pose of an object relative to another pose, i.e.,\nthe pose difference. The proposed method generates the complete orbit of an\nobject from a single view of the object with respect to the subgroup of SO(3)\nof rotations around the z-axis, and compares the orbit of the object with\nanother orbit using a novel orbit metric to estimate the pose difference. The\ngenerated orbit in the latent space records all the differences in pose in the\noriginal observational space, and as a result, the method is capable of finding\nsubtle differences in pose. We demonstrate the effectiveness of the proposed\nmethod on cars, where identifying the subtle pose differences is vital.",
    "published": "2018-09-03T21:17:59Z",
    "updated": "2018-09-03T21:17:59Z",
    "authors": [
      "Berkay Kicanaoglu",
      "Ran Tao",
      "Arnold W. M. Smeulders"
    ],
    "link": "http://arxiv.org/abs/1809.00720v1",
    "pdf_link": "http://arxiv.org/pdf/1809.00720v1"
  },
  {
    "api_id": 439,
    "title": "Superresolution of Noisy Remotely Sensed Images Through Directional\n  Representations",
    "summary": "We develop an algorithm for single-image superresolution of remotely sensed\ndata, based on the discrete shearlet transform. The shearlet transform extracts\ndirectional features of signals, and is known to provide near-optimally sparse\nrepresentations for a broad class of images. This often leads to superior\nperformance in edge detection and image representation when compared to\nisotropic frames. We justify the use of shearlets mathematically, before\npresenting a denoising single-image superresolution algorithm that combines the\nshearlet transform with sparse mixing estimators (SME). Our algorithm is\ncompared with a variety of single-image superresolution methods, including\nwavelet SME superresolution. Our numerical results demonstrate competitive\nperformance in terms of PSNR and SSIM.",
    "published": "2016-02-27T09:33:07Z",
    "updated": "2018-09-04T12:06:44Z",
    "authors": [
      "Wojciech Czaja",
      "James M. Murphy",
      "Daniel Weinberg"
    ],
    "link": "http://arxiv.org/abs/1602.08575v2",
    "pdf_link": "http://arxiv.org/pdf/1602.08575v2"
  },
  {
    "api_id": 440,
    "title": "A Novel Learning-based Global Path Planning Algorithm for Planetary\n  Rovers",
    "summary": "Autonomous path planning algorithms are significant to planetary exploration\nrovers, since relying on commands from Earth will heavily reduce their\nefficiency of executing exploration missions. This paper proposes a novel\nlearning-based algorithm to deal with global path planning problem for\nplanetary exploration rovers. Specifically, a novel deep convolutional neural\nnetwork with double branches (DB-CNN) is designed and trained, which can plan\npath directly from orbital images of planetary surfaces without implementing\nenvironment mapping. Moreover, the planning procedure requires no prior\nknowledge about planetary surface terrains. Finally, experimental results\ndemonstrate that DB-CNN achieves better performance on global path planning and\nfaster convergence during training compared with the existing Value Iteration\nNetwork (VIN).",
    "published": "2018-11-23T15:20:03Z",
    "updated": "2018-11-23T15:20:03Z",
    "authors": [
      "Jiang Zhang",
      "Yuanqing Xia",
      "Ganghui Shen"
    ],
    "link": "http://arxiv.org/abs/1811.10437v1",
    "pdf_link": "http://arxiv.org/pdf/1811.10437v1"
  },
  {
    "api_id": 441,
    "title": "IDD: A Dataset for Exploring Problems of Autonomous Navigation in\n  Unconstrained Environments",
    "summary": "While several datasets for autonomous navigation have become available in\nrecent years, they tend to focus on structured driving environments. This\nusually corresponds to well-delineated infrastructure such as lanes, a small\nnumber of well-defined categories for traffic participants, low variation in\nobject or background appearance and strict adherence to traffic rules. We\npropose IDD, a novel dataset for road scene understanding in unstructured\nenvironments where the above assumptions are largely not satisfied. It consists\nof 10,004 images, finely annotated with 34 classes collected from 182 drive\nsequences on Indian roads. The label set is expanded in comparison to popular\nbenchmarks such as Cityscapes, to account for new classes. It also reflects\nlabel distributions of road scenes significantly different from existing\ndatasets, with most classes displaying greater within-class diversity.\nConsistent with real driving behaviours, it also identifies new classes such as\ndrivable areas besides the road. We propose a new four-level label hierarchy,\nwhich allows varying degrees of complexity and opens up possibilities for new\ntraining methods. Our empirical study provides an in-depth analysis of the\nlabel characteristics. State-of-the-art methods for semantic segmentation\nachieve much lower accuracies on our dataset, demonstrating its distinction\ncompared to Cityscapes. Finally, we propose that our dataset is an ideal\nopportunity for new problems such as domain adaptation, few-shot learning and\nbehaviour prediction in road scenes.",
    "published": "2018-11-26T06:29:26Z",
    "updated": "2018-11-26T06:29:26Z",
    "authors": [
      "Girish Varma",
      "Anbumani Subramanian",
      "Anoop Namboodiri",
      "Manmohan Chandraker",
      "C V Jawahar"
    ],
    "link": "http://arxiv.org/abs/1811.10200v1",
    "pdf_link": "http://arxiv.org/pdf/1811.10200v1"
  },
  {
    "api_id": 442,
    "title": "Accurate Spectral Super-resolution from Single RGB Image Using\n  Multi-scale CNN",
    "summary": "Different from traditional hyperspectral super-resolution approaches that\nfocus on improving the spatial resolution, spectral super-resolution aims at\nproducing a high-resolution hyperspectral image from the RGB observation with\nsuper-resolution in spectral domain. However, it is challenging to accurately\nreconstruct a high-dimensional continuous spectrum from three discrete\nintensity values at each pixel, since too much information is lost during the\nprocedure where the latent hyperspectral image is downsampled (e.g., with x10\nscaling factor) in spectral domain to produce an RGB observation. To address\nthis problem, we present a multi-scale deep convolutional neural network (CNN)\nto explicitly map the input RGB image into a hyperspectral image. Through\nsymmetrically downsampling and upsampling the intermediate feature maps in a\ncascading paradigm, the local and non-local image information can be jointly\nencoded for spectral representation, ultimately improving the spectral\nreconstruction accuracy. Extensive experiments on a large hyperspectral dataset\ndemonstrate the effectiveness of the proposed method.",
    "published": "2018-06-10T02:32:02Z",
    "updated": "2018-11-29T08:59:39Z",
    "authors": [
      "Yiqi Yan",
      "Lei Zhang",
      "Jun Li",
      "Wei Wei",
      "Yanning Zhang"
    ],
    "link": "http://arxiv.org/abs/1806.03575v3",
    "pdf_link": "http://arxiv.org/pdf/1806.03575v3"
  },
  {
    "api_id": 443,
    "title": "FliPer: Classifying TESS pulsating stars",
    "summary": "The recently launched NASA Transiting Exoplanet Survey Satellite (TESS)\nmission is going to collect lightcurves for a few hundred million of stars and\nwe expect to increase the number of pulsating stars to analyze compared to the\nfew thousand stars observed by the CoRoT, $\\textit{Kepler}$ and K2 missions.\nHowever, most of the TESS targets have not yet been properly classified and\ncharacterized. In order to improve the analysis of the TESS data, it is crucial\nto determine the type of stellar pulsations in a timely manner. We propose an\nautomatic method to classify stars attending to their pulsation properties, in\nparticular, to identify solar-like pulsators among all TESS targets. It relies\non the use of the global amount of power contained in the power spectrum\n(already known as the FliPer method) as a key parameter, along with the\neffective temperature, to feed into a machine learning classifier. Our study,\nbased on TESS simulated datasets, shows that we are able to classify pulsators\nwith a $98\\%$ accuracy.",
    "published": "2018-11-29T13:49:28Z",
    "updated": "2018-11-29T13:49:28Z",
    "authors": [
      "L. Bugnet",
      "R. A. García",
      "G. R. Davies",
      "S. Mathur",
      "O. J. Hall",
      "B. M. Rendle"
    ],
    "link": "http://arxiv.org/abs/1811.12140v1",
    "pdf_link": "http://arxiv.org/pdf/1811.12140v1"
  },
  {
    "api_id": 444,
    "title": "Practical optimal registration of terrestrial LiDAR scan pairs",
    "summary": "Point cloud registration is a fundamental problem in 3D scanning. In this\npaper, we address the frequent special case of registering terrestrial LiDAR\nscans (or, more generally, levelled point clouds). Many current solutions still\nrely on the Iterative Closest Point (ICP) method or other heuristic procedures,\nwhich require good initializations to succeed and/or provide no guarantees of\nsuccess. On the other hand, exact or optimal registration algorithms can\ncompute the best possible solution without requiring initializations; however,\nthey are currently too slow to be practical in realistic applications.\n  Existing optimal approaches ignore the fact that in routine use the relative\nrotations between scans are constrained to the azimuth, via the built-in level\ncompensation in LiDAR scanners. We propose a novel, optimal and computationally\nefficient registration method for this 4DOF scenario. Our approach operates on\ncandidate 3D keypoint correspondences, and contains two main steps: (1) a\ndeterministic selection scheme that significantly reduces the candidate\ncorrespondence set in a way that is guaranteed to preserve the optimal\nsolution; and (2) a fast branch-and-bound (BnB) algorithm with a novel\npolynomial-time subroutine for 1D rotation search, that quickly finds the\noptimal alignment for the reduced set. We demonstrate the practicality of our\nmethod on realistic point clouds from multiple LiDAR surveys.",
    "published": "2018-11-25T06:36:28Z",
    "updated": "2018-11-30T04:45:42Z",
    "authors": [
      "Zhipeng Cai",
      "Tat-Jun Chin",
      "Alvaro Parra Bustos",
      "Konrad Schindler"
    ],
    "link": "http://arxiv.org/abs/1811.09962v3",
    "pdf_link": "http://arxiv.org/pdf/1811.09962v3"
  },
  {
    "api_id": 445,
    "title": "Mapping Informal Settlements in Developing Countries with\n  Multi-resolution, Multi-spectral Data",
    "summary": "Detecting and mapping informal settlements encompasses several of the United\nNations sustainable development goals. This is because informal settlements are\nhome to the most socially and economically vulnerable people on the planet.\nThus, understanding where these settlements are is of paramount importance to\nboth government and non-government organizations (NGOs), such as the United\nNations Children's Fund (UNICEF), who can use this information to deliver\neffective social and economic aid. We propose two effective methods for\ndetecting and mapping the locations of informal settlements. One uses only\nlow-resolution (LR), freely available, Sentinel-2 multispectral satellite\nimagery with noisy annotations, whilst the other is a deep learning approach\nthat uses only costly very-high-resolution (VHR) satellite imagery. To our\nknowledge, we are the first to map informal settlements successfully with\nlow-resolution satellite imagery. We extensively evaluate and compare the\nproposed methods. Please find additional material at\nhttps://frontierdevelopmentlab.github.io/informal-settlements/.",
    "published": "2018-11-30T10:38:37Z",
    "updated": "2018-11-30T10:38:37Z",
    "authors": [
      "Patrick Helber",
      "Bradley Gram-Hansen",
      "Indhu Varatharajan",
      "Faiza Azam",
      "Alejandro Coca-Castro",
      "Veronika Kopackova",
      "Piotr Bilinski"
    ],
    "link": "http://arxiv.org/abs/1812.00812v1",
    "pdf_link": "http://arxiv.org/pdf/1812.00812v1"
  },
  {
    "api_id": 446,
    "title": "SiftingGAN: Generating and Sifting Labeled Samples to Improve the Remote\n  Sensing Image Scene Classification Baseline in vitro",
    "summary": "Lack of annotated samples greatly restrains the direct application of deep\nlearning in remote sensing image scene classification. Although researches have\nbeen done to tackle this issue by data augmentation with various image\ntransformation operations, they are still limited in quantity and diversity.\nRecently, the advent of the unsupervised learning based generative adversarial\nnetworks (GANs) bring us a new way to generate augmented samples. However, such\nGAN-generated samples are currently only served for training GANs model itself\nand for improving the performance of the discriminator in GANs internally (in\nvivo). It becomes a question of serious doubt whether the GAN-generated samples\ncan help better improve the scene classification performance of other deep\nlearning networks (in vitro), compared with the widely used transformed\nsamples. To answer this question, this paper proposes a SiftingGAN approach to\ngenerate more numerous, more diverse and more authentic labeled samples for\ndata augmentation. SiftingGAN extends traditional GAN framework with an\nOnline-Output method for sample generation, a Generative-Model-Sifting method\nfor model sifting, and a Labeled-Sample-Discriminating method for sample\nsifting. Experiments on the well-known AID dataset demonstrate that the\nproposed SiftingGAN method can not only effectively improve the performance of\nthe scene classification baseline that is achieved without data augmentation,\nbut also significantly excels the comparison methods based on traditional\ngeometric/radiometric transformation operations.",
    "published": "2018-09-13T14:26:12Z",
    "updated": "2018-11-30T16:28:26Z",
    "authors": [
      "Dongao Ma",
      "Ping Tang",
      "Lijun Zhao"
    ],
    "link": "http://arxiv.org/abs/1809.04985v4",
    "pdf_link": "http://arxiv.org/pdf/1809.04985v4"
  },
  {
    "api_id": 447,
    "title": "A Dynamic Network and Representation LearningApproach for Quantifying\n  Economic Growth fromSatellite Imagery",
    "summary": "Quantifying the improvement in human living standard, as well as the city\ngrowth in developing countries, is a challenging problem due to the lack of\nreliable economic data. Therefore, there is a fundamental need for alternate,\nlargely unsupervised, computational methods that can estimate the economic\nconditions in the developing regions. To this end, we propose a new network\nscience- and representation learning-based approach that can quantify economic\nindicators and visualize the growth of various regions. More precisely, we\nfirst create a dynamic network drawn out of high-resolution nightlight\nsatellite images. We then demonstrate that using representation learning to\nmine the resulting network, our proposed approach can accurately predict\nspatial gross economic expenditures over large regions. Our method, which\nrequires only nightlight images and limited survey data, can capture\ncity-growth, as well as how people's living standard is changing; this can\nultimately facilitate the decision makers' understanding of growth without\nheavily relying on expensive and time-consuming surveys.",
    "published": "2018-12-01T04:20:21Z",
    "updated": "2018-12-01T04:20:21Z",
    "authors": [
      "Jiqian Dong",
      "Gopaljee Atulya",
      "Kartikeya Bhardwaj",
      "Radu Marculescu"
    ],
    "link": "http://arxiv.org/abs/1812.00141v1",
    "pdf_link": "http://arxiv.org/pdf/1812.00141v1"
  },
  {
    "api_id": 448,
    "title": "Convolutional LSTMs for Cloud-Robust Segmentation of Remote Sensing\n  Imagery",
    "summary": "Clouds frequently cover the Earth's surface and pose an omnipresent challenge\nto optical Earth observation methods. The vast majority of remote sensing\napproaches either selectively choose single cloud-free observations or employ a\npre-classification strategy to identify and mask cloudy pixels. We follow a\ndifferent strategy and treat cloud coverage as noise that is inherent to the\nobserved satellite data. In prior work, we directly employed a straightforward\n\\emph{convolutional long short-term memory} network for vegetation\nclassification without explicit cloud filtering and achieved state-of-the-art\nclassification accuracies. In this work, we investigate this cloud-robustness\nfurther by visualizing internal cell activations and performing an ablation\nexperiment on datasets of different cloud coverage. In the visualizations of\nnetwork states, we identified some cells in which modulation and input gates\nclosed on cloudy pixels. This indicates that the network has internalized a\ncloud-filtering mechanism without being specifically trained on cloud labels.\nOverall, our results question the necessity of sophisticated pre-processing\npipelines for multi-temporal deep learning approaches.",
    "published": "2018-10-28T17:58:22Z",
    "updated": "2018-12-02T11:30:38Z",
    "authors": [
      "Marc Rußwurm",
      "Marco Körner"
    ],
    "link": "http://arxiv.org/abs/1811.02471v2",
    "pdf_link": "http://arxiv.org/pdf/1811.02471v2"
  },
  {
    "api_id": 449,
    "title": "Training for 'Unstable' CNN Accelerator:A Case Study on FPGA",
    "summary": "With the great advancements of convolution neural networks(CNN), CNN\naccelerators are increasingly developed and deployed in the major computing\nsystems.To make use of the CNN accelerators, CNN models are trained via the\noff-line training systems such as Caffe, Pytorch and Tensorflow on multi-core\nCPUs and GPUs first and then compiled to the target accelerators. Although the\ntwo-step process seems to be natural and has been widely applied, it assumes\nthat the accelerators' behavior can be fully modeled on CPUs and GPUs. This\ndoes not hold true and the behavior of the CNN accelerators is un-deterministic\nwhen the circuit works at 'unstable' mode when it is overclocked or is affected\nby the environment like fault-prone aerospace. The exact behaviors of the\naccelerators are determined by both the chip fabrication and the working\nenvironment or status. In this case, applying the conventional off-line\ntraining result to the accelerators directly may lead to considerable accuracy\nloss.\n  To address this problem, we propose to train for the 'unstable' CNN\naccelerator and have the 'un-determined behavior' learned together with the\ndata in the same framework. Basically, it starts from the off-line trained\nmodel and then integrates the uncertain circuit behaviors into the CNN models\nthrough additional accelerator-specific training. The fine-tuned training makes\nthe CNN models less sensitive to the circuit uncertainty. We apply the design\nmethod to both an overclocked CNN accelerator and a faulty accelerator.\nAccording to our experiments on a subset of ImageNet, the accelerator-specific\ntraining can improve the top 5 accuracy up to 3.4% and 2.4% on average when the\nCNN accelerator is at extreme overclocking. When the accelerator is exposed to\na faulty environment, the top 5 accuracy improves up to 6.8% and 4.28% on\naverage under the most severe fault injection.",
    "published": "2018-12-02T11:45:07Z",
    "updated": "2018-12-02T11:45:07Z",
    "authors": [
      "KouZi Xing"
    ],
    "link": "http://arxiv.org/abs/1812.01689v1",
    "pdf_link": "http://arxiv.org/pdf/1812.01689v1"
  },
  {
    "api_id": 450,
    "title": "Bayesian Deep Learning for Exoplanet Atmospheric Retrieval",
    "summary": "Over the past decade, the study of extrasolar planets has evolved rapidly\nfrom plain detection and identification to comprehensive categorization and\ncharacterization of exoplanet systems and their atmospheres. Atmospheric\nretrieval, the inverse modeling technique used to determine an exoplanetary\natmosphere's temperature structure and composition from an observed spectrum,\nis both time-consuming and compute-intensive, requiring complex algorithms that\ncompare thousands to millions of atmospheric models to the observational data\nto find the most probable values and associated uncertainties for each model\nparameter. For rocky, terrestrial planets, the retrieved atmospheric\ncomposition can give insight into the surface fluxes of gaseous species\nnecessary to maintain the stability of that atmosphere, which may in turn\nprovide insight into the geological and/or biological processes active on the\nplanet. These atmospheres contain many molecules, some of them biosignatures,\nspectral fingerprints indicative of biological activity, which will become\nobservable with the next generation of telescopes. Runtimes of traditional\nretrieval models scale with the number of model parameters, so as more\nmolecular species are considered, runtimes can become prohibitively long.\nRecent advances in machine learning (ML) and computer vision offer new ways to\nreduce the time to perform a retrieval by orders of magnitude, given a\nsufficient data set to train with. Here we present an ML-based retrieval\nframework called Intelligent exoplaNet Atmospheric RetrievAl (INARA) that\nconsists of a Bayesian deep learning model for retrieval and a data set of\n3,000,000 synthetic rocky exoplanetary spectra generated using the NASA\nPlanetary Spectrum Generator. Our work represents the first ML retrieval model\nfor rocky, terrestrial exoplanets and the first synthetic data set of\nterrestrial spectra generated at this scale.",
    "published": "2018-11-08T13:03:08Z",
    "updated": "2018-12-02T13:01:22Z",
    "authors": [
      "Frank Soboczenski",
      "Michael D. Himes",
      "Molly D. O'Beirne",
      "Simone Zorzan",
      "Atilim Gunes Baydin",
      "Adam D. Cobb",
      "Yarin Gal",
      "Daniel Angerhausen",
      "Massimo Mascaro",
      "Giada N. Arney",
      "Shawn D. Domagal-Goldman"
    ],
    "link": "http://arxiv.org/abs/1811.03390v2",
    "pdf_link": "http://arxiv.org/pdf/1811.03390v2"
  },
  {
    "api_id": 451,
    "title": "Towards Spectral Estimation from a Single RGB Image in the Wild",
    "summary": "In contrast to the current literature, we address the problem of estimating\nthe spectrum from a single common trichromatic RGB image obtained under\nunconstrained settings (e.g. unknown camera parameters, unknown scene radiance,\nunknown scene contents). For this we use a reference spectrum as provided by a\nhyperspectral image camera, and propose efficient deep learning solutions for\nsensitivity function estimation and spectral reconstruction from a single RGB\nimage. We further expand the concept of spectral reconstruction such that to\nwork for RGB images taken in the wild and propose a solution based on a\nconvolutional network conditioned on the estimated sensitivity function.\nBesides the proposed solutions, we study also generic and sensitivity\nspecialized models and discuss their limitations. We achieve state-of-the-art\ncompetitive results on the standard example-based spectral reconstruction\nbenchmarks: ICVL, CAVE, NUS and NTIRE. Moreover, our experiments show that, for\nthe first time, accurate spectral estimation from a single RGB image in the\nwild is within our reach.",
    "published": "2018-12-03T14:58:26Z",
    "updated": "2018-12-03T14:58:26Z",
    "authors": [
      "Berk Kaya",
      "Yigit Baran Can",
      "Radu Timofte"
    ],
    "link": "http://arxiv.org/abs/1812.00805v1",
    "pdf_link": "http://arxiv.org/pdf/1812.00805v1"
  },
  {
    "api_id": 452,
    "title": "Ladder Networks for Semi-Supervised Hyperspectral Image Classification",
    "summary": "We used the Ladder Network [Rasmus et al. (2015)] to perform Hyperspectral\nImage Classification in a semi-supervised setting. The Ladder Network\ndistinguishes itself from other semi-supervised methods by jointly optimizing a\nsupervised and unsupervised cost. In many settings this has proven to be more\nsuccessful than other semi-supervised techniques, such as pretraining using\nunlabeled data. We furthermore show that the convolutional Ladder Network\noutperforms most of the current techniques used in hyperspectral image\nclassification and achieves new state-of-the-art performance on the Pavia\nUniversity dataset given only 5 labeled data points per class.",
    "published": "2018-12-04T05:24:47Z",
    "updated": "2018-12-04T05:24:47Z",
    "authors": [
      "Julian Büchel",
      "Okan Ersoy"
    ],
    "link": "http://arxiv.org/abs/1812.01222v1",
    "pdf_link": "http://arxiv.org/pdf/1812.01222v1"
  },
  {
    "api_id": 453,
    "title": "Rare Event Detection using Disentangled Representation Learning",
    "summary": "This paper presents a novel method for rare event detection from an image\npair with class-imbalanced datasets. A straightforward approach for event\ndetection tasks is to train a detection network from a large-scale dataset in\nan end-to-end manner. However, in many applications such as building change\ndetection on satellite images, few positive samples are available for the\ntraining. Moreover, scene image pairs contain many trivial events, such as in\nillumination changes or background motions. These many trivial events and the\nclass imbalance problem lead to false alarms for rare event detection. In order\nto overcome these difficulties, we propose a novel method to learn disentangled\nrepresentations from only low-cost negative samples. The proposed method\ndisentangles different aspects in a pair of observations: variant and invariant\nfactors that represent trivial events and image contents, respectively. The\neffectiveness of the proposed approach is verified by the quantitative\nevaluations on four change detection datasets, and the qualitative analysis\nshows that the proposed method can acquire the representations that disentangle\nrare events from trivial ones.",
    "published": "2018-12-04T09:05:34Z",
    "updated": "2018-12-04T09:05:34Z",
    "authors": [
      "Ryuhei Hamaguchi",
      "Ken Sakurada",
      "Ryosuke Nakamura"
    ],
    "link": "http://arxiv.org/abs/1812.01285v1",
    "pdf_link": "http://arxiv.org/pdf/1812.01285v1"
  },
  {
    "api_id": 454,
    "title": "Multi$^{\\mathbf{3}}$Net: Segmenting Flooded Buildings via Fusion of\n  Multiresolution, Multisensor, and Multitemporal Satellite Imagery",
    "summary": "We propose a novel approach for rapid segmentation of flooded buildings by\nfusing multiresolution, multisensor, and multitemporal satellite imagery in a\nconvolutional neural network. Our model significantly expedites the generation\nof satellite imagery-based flood maps, crucial for first responders and local\nauthorities in the early stages of flood events. By incorporating multitemporal\nsatellite imagery, our model allows for rapid and accurate post-disaster damage\nassessment and can be used by governments to better coordinate medium- and\nlong-term financial assistance programs for affected areas. The network\nconsists of multiple streams of encoder-decoder architectures that extract\nspatiotemporal information from medium-resolution images and spatial\ninformation from high-resolution images before fusing the resulting\nrepresentations into a single medium-resolution segmentation map of flooded\nbuildings. We compare our model to state-of-the-art methods for building\nfootprint segmentation as well as to alternative fusion approaches for the\nsegmentation of flooded buildings and find that our model performs best on both\ntasks. We also demonstrate that our model produces highly accurate segmentation\nmaps of flooded buildings using only publicly available medium-resolution data\ninstead of significantly more detailed but sparsely available very\nhigh-resolution data. We release the first open-source dataset of fully\npreprocessed and labeled multiresolution, multispectral, and multitemporal\nsatellite images of disaster sites along with our source code.",
    "published": "2018-12-05T00:05:01Z",
    "updated": "2018-12-05T00:05:01Z",
    "authors": [
      "Tim G. J. Rudner",
      "Marc Rußwurm",
      "Jakub Fil",
      "Ramona Pelich",
      "Benjamin Bischke",
      "Veronika Kopackova",
      "Piotr Bilinski"
    ],
    "link": "http://arxiv.org/abs/1812.01756v1",
    "pdf_link": "http://arxiv.org/pdf/1812.01756v1"
  },
  {
    "api_id": 455,
    "title": "Efficient and Robust Machine Learning for Real-World Systems",
    "summary": "While machine learning is traditionally a resource intensive task, embedded\nsystems, autonomous navigation and the vision of the Internet-of-Things fuel\nthe interest in resource efficient approaches. These approaches require a\ncarefully chosen trade-off between performance and resource consumption in\nterms of computation and energy. On top of this, it is crucial to treat\nuncertainty in a consistent manner in all but the simplest applications of\nmachine learning systems. In particular, a desideratum for any real-world\nsystem is to be robust in the presence of outliers and corrupted data, as well\nas being `aware' of its limits, i.e.\\ the system should maintain and provide an\nuncertainty estimate over its own predictions. These complex demands are among\nthe major challenges in current machine learning research and key to ensure a\nsmooth transition of machine learning technology into every day's applications.\nIn this article, we provide an overview of the current state of the art of\nmachine learning techniques facilitating these real-world requirements. First\nwe provide a comprehensive review of resource-efficiency in deep neural\nnetworks with focus on techniques for model size reduction, compression and\nreduced precision. These techniques can be applied during training or as\npost-processing and are widely used to reduce both computational complexity and\nmemory footprint. As most (practical) neural networks are limited in their ways\nto treat uncertainty, we contrast them with probabilistic graphical models,\nwhich readily serve these desiderata by means of probabilistic inference. In\nthat way, we provide an extensive overview of the current state-of-the-art of\nrobust and efficient machine learning for real-world systems.",
    "published": "2018-12-05T21:47:23Z",
    "updated": "2018-12-05T21:47:23Z",
    "authors": [
      "Franz Pernkopf",
      "Wolfgang Roth",
      "Matthias Zoehrer",
      "Lukas Pfeifenberger",
      "Guenther Schindler",
      "Holger Froening",
      "Sebastian Tschiatschek",
      "Robert Peharz",
      "Matthew Mattina",
      "Zoubin Ghahramani"
    ],
    "link": "http://arxiv.org/abs/1812.02240v1",
    "pdf_link": "http://arxiv.org/pdf/1812.02240v1"
  },
  {
    "api_id": 456,
    "title": "Urban-Rural Environmental Gradient in a Developing City: Testing ENVI\n  GIS Functionality",
    "summary": "The research performs urban ecosystem analysis supported by ENVI GIS by\nintegrated studies on land cover types and geospatial modeling of Taipei city.\nThe paper deals with the role of anthropogenic pressure on the structure of the\nlandscape and change of land cover types. Methods included assessment of the\nimpact from anthropogenic activities on the natural ecosystems, evaluation of\nthe rate and scale of landscape dynamics using remote sensing data and GIS. The\nresearch aims to assist environmentalists and city planners to evaluate\nstrategies for specific objectives of urban development in Taiwan, China.",
    "published": "2018-12-06T02:10:53Z",
    "updated": "2018-12-06T02:10:53Z",
    "authors": [
      "Polina Lemenkova"
    ],
    "link": "http://arxiv.org/abs/1812.10378v1",
    "pdf_link": "http://arxiv.org/pdf/1812.10378v1"
  },
  {
    "api_id": 457,
    "title": "Topology, homogeneity and scale factors for object detection:\n  application of eCognition software for urban mapping using multispectral\n  satellite image",
    "summary": "The research scope of this paper is to apply spatial object based image\nanalysis (OBIA) method for processing panchromatic multispectral image covering\nstudy area of Brussels for urban mapping. The aim is to map different land\ncover types and more specifically, built-up areas from the very high resolution\n(VHR) satellite image using OBIA approach. A case study covers urban landscapes\nin the eastern areas of the city of Brussels, Belgium. Technically, this\nresearch was performed in eCognition raster processing software demonstrating\nexcellent results of image segmentation and classification. The tools embedded\nin eCognition enabled to perform image segmentation and objects classification\nprocesses in a semi-automated regime, which is useful for the city planning,\nspatial analysis and urban growth analysis. The combination of the OBIA method\ntogether with technical tools of the eCognition demonstrated applicability of\nthis method for urban mapping in densely populated areas, e.g. in megapolis and\ncapital cities. The methodology included multiresolution segmentation and\nclassification of the created objects.",
    "published": "2018-12-06T02:24:48Z",
    "updated": "2018-12-06T02:24:48Z",
    "authors": [
      "Polina Lemenkova"
    ],
    "link": "http://arxiv.org/abs/1901.00726v1",
    "pdf_link": "http://arxiv.org/pdf/1901.00726v1"
  },
  {
    "api_id": 458,
    "title": "Assigning a Grade: Accurate Measurement of Road Quality Using Satellite\n  Imagery",
    "summary": "Roads are critically important infrastructure to societal and economic\ndevelopment, with huge investments made by governments every year. However,\nmethods for monitoring those investments tend to be time-consuming, laborious,\nand expensive, placing them out of reach for many developing regions. In this\nwork, we develop a model for monitoring the quality of road infrastructure\nusing satellite imagery. For this task, we harness two trends: the increasing\navailability of high-resolution, often-updated satellite imagery, and the\nenormous improvement in speed and accuracy of convolutional neural\nnetwork-based methods for performing computer vision tasks. We employ a unique\ndataset of road quality information on 7000km of roads in Kenya combined with\n50cm resolution satellite imagery. We create models for a binary classification\ntask as well as a comprehensive 5-category classification task, with accuracy\nscores of 88 and 73 percent respectively. We also provide evidence of the\nrobustness of our methods with challenging held-out scenarios, though we note\nsome improvement is still required for confident analysis of a never before\nseen road. We believe these results are well-positioned to have substantial\nimpact on a broad set of transport applications.",
    "published": "2018-12-01T01:43:26Z",
    "updated": "2018-12-06T02:38:23Z",
    "authors": [
      "Gabriel Cadamuro",
      "Aggrey Muhebwa",
      "Jay Taneja"
    ],
    "link": "http://arxiv.org/abs/1812.01699v2",
    "pdf_link": "http://arxiv.org/pdf/1812.01699v2"
  },
  {
    "api_id": 459,
    "title": "Random mesh projectors for inverse problems",
    "summary": "We propose a new learning-based approach to solve ill-posed inverse problems\nin imaging. We address the case where ground truth training samples are rare\nand the problem is severely ill-posed - both because of the underlying physics\nand because we can only get few measurements. This setting is common in\ngeophysical imaging and remote sensing. We show that in this case the common\napproach to directly learn the mapping from the measured data to the\nreconstruction becomes unstable. Instead, we propose to first learn an ensemble\nof simpler mappings from the data to projections of the unknown image into\nrandom piecewise-constant subspaces. We then combine the projections to form a\nfinal reconstruction by solving a deconvolution-like problem. We show\nexperimentally that the proposed method is more robust to measurement noise and\ncorruptions not seen during training than a directly learned inverse.",
    "published": "2018-05-29T21:36:05Z",
    "updated": "2018-12-06T04:31:08Z",
    "authors": [
      "Sidharth Gupta",
      "Konik Kothari",
      "Maarten V. de Hoop",
      "Ivan Dokmanić"
    ],
    "link": "http://arxiv.org/abs/1805.11718v3",
    "pdf_link": "http://arxiv.org/pdf/1805.11718v3"
  },
  {
    "api_id": 460,
    "title": "Randomized Tensor Ring Decomposition and Its Application to Large-scale\n  Data Reconstruction",
    "summary": "Dimensionality reduction is an essential technique for multi-way large-scale\ndata, i.e., tensor. Tensor ring (TR) decomposition has become popular due to\nits high representation ability and flexibility. However, the traditional TR\ndecomposition algorithms suffer from high computational cost when facing\nlarge-scale data. In this paper, taking advantages of the recently proposed\ntensor random projection method, we propose two TR decomposition algorithms. By\nemploying random projection on every mode of the large-scale tensor, the TR\ndecomposition can be processed at a much smaller scale. The simulation\nexperiment shows that the proposed algorithms are $4-25$ times faster than\ntraditional algorithms without loss of accuracy, and our algorithms show\nsuperior performance in deep learning dataset compression and hyperspectral\nimage reconstruction experiments compared to other randomized algorithms.",
    "published": "2019-01-07T03:01:06Z",
    "updated": "2019-01-07T03:01:06Z",
    "authors": [
      "Longhao Yuan",
      "Chao Li",
      "Jianting Cao",
      "Qibin Zhao"
    ],
    "link": "http://arxiv.org/abs/1901.01652v1",
    "pdf_link": "http://arxiv.org/pdf/1901.01652v1"
  },
  {
    "api_id": 461,
    "title": "Star formation rates and stellar masses from machine learning",
    "summary": "Star-formation activity is a key property to probe the structure formation\nand hence characterise the large-scale structures of the universe. This\ninformation can be deduced from the star formation rate (SFR) and the stellar\nmass (Mstar), both of which, but especially the SFR, are very complex to\nestimate. Determining these quantities from UV, optical, or IR luminosities\nrelies on complex modeling and on priors on galaxy types. We propose a method\nbased on the machine-learning algorithm Random Forest to estimate the SFR and\nthe Mstar of galaxies at redshifts in the range 0.01<z<0.3, independent of\ntheir type. The machine-learning algorithm takes as inputs the redshift, WISE\nluminosities, and WISE colours in near-IR, and is trained on spectra-extracted\nSFR and Mstar from the SDSS MPA-JHU DR8 catalogue as outputs. We show that our\nalgorithm can accurately estimate SFR and Mstar with scatters of sigma_SFR=0.38\ndex and sigma_Mstar=0.16 dex for SFR and stellar mass, respectively, and that\nit is unbiased with respect to redshift or galaxy type. The full-sky coverage\nof the WISE satellite allows us to characterise the star-formation activity of\nall galaxies outside the Galactic mask with spectroscopic redshifts in the\nrange 0.01<z<0.3. The method can also be applied to photometric-redshift\ncatalogues, with best scatters of sigma_SFR=0.42 dex and sigma_Mstar=0.24 dex\nobtained in the redshift range 0.1<z<0.3.",
    "published": "2019-01-07T17:27:37Z",
    "updated": "2019-01-07T17:27:37Z",
    "authors": [
      "V. Bonjean",
      "N. Aghanim",
      "P. Salomé",
      "A. Beelen",
      "M. Douspis",
      "E. Soubrié"
    ],
    "link": "http://arxiv.org/abs/1901.01932v1",
    "pdf_link": "http://arxiv.org/pdf/1901.01932v1"
  },
  {
    "api_id": 462,
    "title": "Towards a Decentralized, Autonomous Multiagent Framework for Mitigating\n  Crop Loss",
    "summary": "We propose a generalized decision-theoretic system for a heterogeneous team\nof autonomous agents who are tasked with online identification of\nphenotypically expressed stress in crop fields.. This system employs four\ndistinct types of agents, specific to four available sensor modalities:\nsatellites (Layer 3), uninhabited aerial vehicles (L2), uninhabited ground\nvehicles (L1), and static ground-level sensors (L0). Layers 3, 2, and 1 are\ntasked with performing image processing at the available resolution of the\nsensor modality and, along with data generated by layer 0 sensors, identify\nerroneous differences that arise over time. Our goal is to limit the use of the\nmore computationally and temporally expensive subsequent layers. Therefore,\nfrom layer 3 to 1, each layer only investigates areas that previous layers have\nidentified as potentially afflicted by stress. We introduce a reinforcement\nlearning technique based on Perkins' Monte Carlo Exploring Starts for a\ngeneralized Markovian model for each layer's decision problem, and label the\nsystem the Agricultural Distributed Decision Framework (ADDF). As our domain is\nreal-world and online, we illustrate implementations of the two major\ncomponents of our system: a clustering-based image processing methodology and a\ntwo-layer POMDP implementation.",
    "published": "2019-01-07T19:44:44Z",
    "updated": "2019-01-07T19:44:44Z",
    "authors": [
      "Roi Ceren",
      "Shannon Quinn",
      "Glen Raines"
    ],
    "link": "http://arxiv.org/abs/1901.02035v1",
    "pdf_link": "http://arxiv.org/pdf/1901.02035v1"
  },
  {
    "api_id": 463,
    "title": "Spherical CNNs on Unstructured Grids",
    "summary": "We present an efficient convolution kernel for Convolutional Neural Networks\n(CNNs) on unstructured grids using parameterized differential operators while\nfocusing on spherical signals such as panorama images or planetary signals. To\nthis end, we replace conventional convolution kernels with linear combinations\nof differential operators that are weighted by learnable parameters.\nDifferential operators can be efficiently estimated on unstructured grids using\none-ring neighbors, and learnable parameters can be optimized through standard\nback-propagation. As a result, we obtain extremely efficient neural networks\nthat match or outperform state-of-the-art network architectures in terms of\nperformance but with a significantly lower number of network parameters. We\nevaluate our algorithm in an extensive series of experiments on a variety of\ncomputer vision and climate science tasks, including shape classification,\nclimate pattern segmentation, and omnidirectional image semantic segmentation.\nOverall, we present (1) a novel CNN approach on unstructured grids using\nparameterized differential operators for spherical signals, and (2) we show\nthat our unique kernel parameterization allows our model to achieve the same or\nhigher accuracy with significantly fewer network parameters.",
    "published": "2019-01-07T19:56:19Z",
    "updated": "2019-01-07T19:56:19Z",
    "authors": [
      "Chiyu \"Max\" Jiang",
      "Jingwei Huang",
      "Karthik Kashinath",
      " Prabhat",
      "Philip Marcus",
      "Matthias Niessner"
    ],
    "link": "http://arxiv.org/abs/1901.02039v1",
    "pdf_link": "http://arxiv.org/pdf/1901.02039v1"
  },
  {
    "api_id": 464,
    "title": "Translating SAR to Optical Images for Assisted Interpretation",
    "summary": "Despite the advantages of all-weather and all-day high-resolution imaging,\nSAR remote sensing images are much less viewed and used by general people\nbecause human vision is not adapted to microwave scattering phenomenon.\nHowever, expert interpreters can be trained by compare side-by-side SAR and\noptical images to learn the translation rules from SAR to optical. This paper\nattempts to develop machine intelligence that are trainable with large-volume\nco-registered SAR and optical images to translate SAR image to optical version\nfor assisted SAR interpretation. A novel reciprocal GAN scheme is proposed for\nthis translation task. It is trained and tested on both spaceborne GF-3 and\nairborne UAVSAR images. Comparisons and analyses are presented for datasets of\ndifferent resolutions and polarizations. Results show that the proposed\ntranslation network works well under many scenarios and it could potentially be\nused for assisted SAR interpretation.",
    "published": "2019-01-08T08:48:47Z",
    "updated": "2019-01-08T08:48:47Z",
    "authors": [
      "Shilei Fu",
      "Feng Xu",
      "Ya-Qiu Jin"
    ],
    "link": "http://arxiv.org/abs/1901.03749v1",
    "pdf_link": "http://arxiv.org/pdf/1901.03749v1"
  },
  {
    "api_id": 465,
    "title": "Stereoscopic Dark Flash for Low-light Photography",
    "summary": "In this work, we present a camera configuration for acquiring \"stereoscopic\ndark flash\" images: a simultaneous stereo pair in which one camera is a\nconventional RGB sensor, but the other camera is sensitive to near-infrared and\nnear-ultraviolet instead of R and B. When paired with a \"dark\" flash (i.e., one\nhaving near-infrared and near-ultraviolet light, but no visible light) this\ncamera allows us to capture the two images in a flash/no-flash image pair at\nthe same time, all while not disturbing any human subjects or onlookers with a\ndazzling visible flash. We present a hardware prototype of this camera that\napproximates an idealized camera, and we present an imaging procedure that let\nus acquire dark flash stereo pairs that closely resemble those we would get\nfrom that idealized camera. We then present a technique for fusing these stereo\npairs, first by performing registration and warping, and then by using recent\nadvances in hyperspectral image fusion and deep learning to produce a final\nimage. Because our camera configuration and our data acquisition process allow\nus to capture true low-noise long exposure RGB images alongside our dark flash\nstereo pairs, our learned model can be trained end-to-end to produce a fused\nimage that retains the color and tone of a real RGB image while having the\nlow-noise properties of a flash image.",
    "published": "2019-01-05T05:26:27Z",
    "updated": "2019-01-09T04:25:37Z",
    "authors": [
      "Jian Wang",
      "Tianfan Xue",
      "Jonathan T. Barron",
      "Jiawen Chen"
    ],
    "link": "http://arxiv.org/abs/1901.01370v2",
    "pdf_link": "http://arxiv.org/pdf/1901.01370v2"
  },
  {
    "api_id": 466,
    "title": "Learnable Manifold Alignment (LeMA) : A Semi-supervised Cross-modality\n  Learning Framework for Land Cover and Land Use Classification",
    "summary": "In this paper, we aim at tackling a general but interesting cross-modality\nfeature learning question in remote sensing community --- can a limited amount\nof highly-discrimin-ative (e.g., hyperspectral) training data improve the\nperformance of a classification task using a large amount of\npoorly-discriminative (e.g., multispectral) data? Traditional semi-supervised\nmanifold alignment methods do not perform sufficiently well for such problems,\nsince the hyperspectral data is very expensive to be largely collected in a\ntrade-off between time and efficiency, compared to the multispectral data. To\nthis end, we propose a novel semi-supervised cross-modality learning framework,\ncalled learnable manifold alignment (LeMA). LeMA learns a joint graph structure\ndirectly from the data instead of using a given fixed graph defined by a\nGaussian kernel function. With the learned graph, we can further capture the\ndata distribution by graph-based label propagation, which enables finding a\nmore accurate decision boundary. Additionally, an optimization strategy based\non the alternating direction method of multipliers (ADMM) is designed to solve\nthe proposed model. Extensive experiments on two hyperspectral-multispectral\ndatasets demonstrate the superiority and effectiveness of the proposed method\nin comparison with several state-of-the-art methods.",
    "published": "2019-01-09T17:22:36Z",
    "updated": "2019-01-09T17:22:36Z",
    "authors": [
      "Danfeng Hong",
      "Naoto Yokoya",
      "Nan Ge",
      "Jocelyn Chanussot",
      "Xiao Xiang Zhu"
    ],
    "link": "http://arxiv.org/abs/1901.02838v1",
    "pdf_link": "http://arxiv.org/pdf/1901.02838v1"
  },
  {
    "api_id": 467,
    "title": "A machine learning approach for identification and classification of\n  symbiotic stars using 2MASS and WISE",
    "summary": "In this second paper in a series of papers based on the most-up-to-date\ncatalogue of symbiotic stars (SySts), we present a new approach for identifying\nand distinguishing SySts from other Halpha emitters in photometric surveys\nusing machine learning algorithms such as classification tree, linear\ndiscriminant analysis, and K-nearest neighbour. The motivation behind of this\nwork is to seek for possible colour indices in the regime of near- and\nmid-infrared covered by the 2MASS and WISE surveys. A number of diagnostic\ncolour-colour diagrams are generated for all the known Galactic SySts and\nseveral classes of stellar objects that mimic SySts such as planetary nebulae,\npost-AGB, Mira, single K and M giants, cataclysmic variables, Be, AeBe, YSO,\nweak and classical T Tauri stars, and Wolf-Rayet. The classification tree\nalgorithm unveils that primarily J-H, W1-W4 and Ks-W3 and secondarily H-W2,\nW1-W2 and W3-W4 are ideal colour indices to identify SySts. Linear discriminant\nanalysis method is also applied to determine the linear combination of 2MASS\nand AllWISE magnitudes that better distinguish SySts. The probability of a\nsource being a SySt is determined using the K-nearest neighbour method on the\nLDA components. By applying our classification tree model to the list of\ncandidate SySts (Paper I), the IPHAS list of candidate SySts, and the DR2\nVPHAS+ catalogue, we find 125 (72 new candidates) sources that pass our\ncriteria while we also recover 90 per cent of the known Galactic SySts.",
    "published": "2019-01-10T05:02:15Z",
    "updated": "2019-01-10T05:02:15Z",
    "authors": [
      "Stavros Akras",
      "Marcelo L. Leal-Ferreira",
      "Lizette Guzman-Ramirez",
      "Gerardo Ramos-Larios"
    ],
    "link": "http://arxiv.org/abs/1901.03016v1",
    "pdf_link": "http://arxiv.org/pdf/1901.03016v1"
  },
  {
    "api_id": 468,
    "title": "Multispectral and Hyperspectral Image Fusion by MS/HS Fusion Net",
    "summary": "Hyperspectral imaging can help better understand the characteristics of\ndifferent materials, compared with traditional image systems. However, only\nhigh-resolution multispectral (HrMS) and low-resolution hyperspectral (LrHS)\nimages can generally be captured at video rate in practice. In this paper, we\npropose a model-based deep learning approach for merging an HrMS and LrHS\nimages to generate a high-resolution hyperspectral (HrHS) image. In specific,\nwe construct a novel MS/HS fusion model which takes the observation models of\nlow-resolution images and the low-rankness knowledge along the spectral mode of\nHrHS image into consideration. Then we design an iterative algorithm to solve\nthe model by exploiting the proximal gradient method. And then, by unfolding\nthe designed algorithm, we construct a deep network, called MS/HS Fusion Net,\nwith learning the proximal operators and model parameters by convolutional\nneural networks. Experimental results on simulated and real data substantiate\nthe superiority of our method both visually and quantitatively as compared with\nstate-of-the-art methods along this line of research.",
    "published": "2019-01-10T17:16:59Z",
    "updated": "2019-01-10T17:16:59Z",
    "authors": [
      "Qi Xie",
      "Minghao Zhou",
      "Qian Zhao",
      "Deyu Meng",
      "Wangmeng Zuo",
      "Zongben Xu"
    ],
    "link": "http://arxiv.org/abs/1901.03281v1",
    "pdf_link": "http://arxiv.org/pdf/1901.03281v1"
  },
  {
    "api_id": 469,
    "title": "A deep learning approach to solar-irradiance forecasting in sky-videos",
    "summary": "Ahead-of-time forecasting of incident solar-irradiance on a panel is\nindicative of expected energy yield and is essential for efficient grid\ndistribution and planning. Traditionally, these forecasts are based on\nmeteorological physics models whose parameters are tuned by coarse-grained\nradiometric tiles sensed from geo-satellites. This research presents a novel\napplication of deep neural network approach to observe and estimate short-term\nweather effects from videos. Specifically, we use time-lapsed videos\n(sky-videos) obtained from upward facing wide-lensed cameras (sky-cameras) to\ndirectly estimate and forecast solar irradiance. We introduce and present\nresults on two large publicly available datasets obtained from weather stations\nin two regions of North America using relatively inexpensive optical hardware.\nThese datasets contain over a million images that span for 1 and 12 years\nrespectively, the largest such collection to our knowledge. Compared to\nsatellite based approaches, the proposed deep learning approach significantly\nreduces the normalized mean-absolute-percentage error for both nowcasting, i.e.\nprediction of the solar irradiance at the instance the frame is captured, as\nwell as forecasting, ahead-of-time irradiance prediction for a duration for\nupto 4 hours.",
    "published": "2019-01-15T15:24:36Z",
    "updated": "2019-01-15T15:24:36Z",
    "authors": [
      "Talha A. Siddiqui",
      "Samarth Bharadwaj",
      "Shivkumar Kalyanaraman"
    ],
    "link": "http://arxiv.org/abs/1901.04881v1",
    "pdf_link": "http://arxiv.org/pdf/1901.04881v1"
  },
  {
    "api_id": 470,
    "title": "Progressively Growing Generative Adversarial Networks for High\n  Resolution Semantic Segmentation of Satellite Images",
    "summary": "Machine learning has proven to be useful in classification and segmentation\nof images. In this paper, we evaluate a training methodology for pixel-wise\nsegmentation on high resolution satellite images using progressive growing of\ngenerative adversarial networks. We apply our model to segmenting building\nrooftops and compare these results to conventional methods for rooftop\nsegmentation. We present our findings using the SpaceNet version 2 dataset.\nProgressive GAN training achieved a test accuracy of 93% compared to 89% for\ntraditional GAN training.",
    "published": "2019-02-12T19:39:07Z",
    "updated": "2019-02-12T19:39:07Z",
    "authors": [
      "Edward Collier",
      "Kate Duffy",
      "Sangram Ganguly",
      "Geri Madanguit",
      "Subodh Kalia",
      "Gayaka Shreekant",
      "Ramakrishna Nemani",
      "Andrew Michaelis",
      "Shuang Li",
      "Auroop Ganguly",
      "Supratik Mukhopadhyay"
    ],
    "link": "http://arxiv.org/abs/1902.04604v1",
    "pdf_link": "http://arxiv.org/pdf/1902.04604v1"
  },
  {
    "api_id": 471,
    "title": "KINN: Incorporating Expert Knowledge in Neural Networks",
    "summary": "The promise of ANNs to automatically discover and extract useful\nfeatures/patterns from data without dwelling on domain expertise although seems\nhighly promising but comes at the cost of high reliance on large amount of\naccurately labeled data, which is often hard to acquire and formulate\nespecially in time-series domains like anomaly detection, natural disaster\nmanagement, predictive maintenance and healthcare. As these networks completely\nrely on data and ignore a very important modality i.e. expert, they are unable\nto harvest any benefit from the expert knowledge, which in many cases is very\nuseful. In this paper, we try to bridge the gap between these data driven and\nexpert knowledge based systems by introducing a novel framework for\nincorporating expert knowledge into the network (KINN). Integrating expert\nknowledge into the network has three key advantages: (a) Reduction in the\namount of data needed to train the model, (b) provision of a lower bound on the\nperformance of the resulting classifier by obtaining the best of both worlds,\nand (c) improved convergence of model parameters (model converges in smaller\nnumber of epochs). Although experts are extremely good in solving different\ntasks, there are some trends and patterns, which are usually hidden only in the\ndata. Therefore, KINN employs a novel residual knowledge incorporation scheme,\nwhich can automatically determine the quality of the predictions made by the\nexpert and rectify it accordingly by learning the trends/patterns from data.\nSpecifically, the method tries to use information contained in one modality to\ncomplement information missed by the other. We evaluated KINN on a real world\ntraffic flow prediction problem. KINN significantly superseded performance of\nboth the expert and as well as the base network (LSTM in this case) when\nevaluated in isolation, highlighting its superiority for the task.",
    "published": "2019-02-15T00:41:28Z",
    "updated": "2019-02-15T00:41:28Z",
    "authors": [
      "Muhammad Ali Chattha",
      "Shoaib Ahmed Siddiqui",
      "Muhammad Imran Malik",
      "Ludger van Elst",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "link": "http://arxiv.org/abs/1902.05653v1",
    "pdf_link": "http://arxiv.org/pdf/1902.05653v1"
  },
  {
    "api_id": 472,
    "title": "Enhancing Remote Sensing Image Retrieval with Triplet Deep Metric\n  Learning Network",
    "summary": "With the rapid growing of remotely sensed imagery data, there is a high\ndemand for effective and efficient image retrieval tools to manage and exploit\nsuch data. In this letter, we present a novel content-based remote sensing\nimage retrieval method based on Triplet deep metric learning convolutional\nneural network (CNN). By constructing a Triplet network with metric learning\nobjective function, we extract the representative features of the images in a\nsemantic space in which images from the same class are close to each other\nwhile those from different classes are far apart. In such a semantic space,\nsimple metric measures such as Euclidean distance can be used directly to\ncompare the similarity of images and effectively retrieve images of the same\nclass. We also investigate a supervised and an unsupervised learning methods\nfor reducing the dimensionality of the learned semantic features. We present\ncomprehensive experimental results on two publicly available remote sensing\nimage retrieval datasets and show that our method significantly outperforms\nstate-of-the-art.",
    "published": "2019-02-15T14:29:02Z",
    "updated": "2019-02-15T14:29:02Z",
    "authors": [
      "Rui Cao",
      "Qian Zhang",
      "Jiasong Zhu",
      "Qing Li",
      "Qingquan Li",
      "Bozhi Liu",
      "Guoping Qiu"
    ],
    "link": "http://arxiv.org/abs/1902.05818v1",
    "pdf_link": "http://arxiv.org/pdf/1902.05818v1"
  },
  {
    "api_id": 473,
    "title": "Multiple Instance Choquet Integral Classifier Fusion and Regression for\n  Remote Sensing Applications",
    "summary": "In classifier (or regression) fusion the aim is to combine the outputs of\nseveral algorithms to boost overall performance. Standard supervised fusion\nalgorithms often require accurate and precise training labels. However,\naccurate labels may be difficult to obtain in many remote sensing applications.\nThis paper proposes novel classification and regression fusion models that can\nbe trained given ambiguosly and imprecisely labeled training data in which\ntraining labels are associated with sets of data points (i.e., \"bags\") instead\nof individual data points (i.e., \"instances\") following a multiple instance\nlearning framework. Experiments were conducted based on the proposed algorithms\non both synthetic data and applications such as target detection and crop yield\nprediction given remote sensing data. The proposed algorithms show effective\nclassification and regression performance.",
    "published": "2018-03-11T21:39:45Z",
    "updated": "2019-02-18T17:34:57Z",
    "authors": [
      "Xiaoxiao Du",
      "Alina Zare"
    ],
    "link": "http://arxiv.org/abs/1803.04048v2",
    "pdf_link": "http://arxiv.org/pdf/1803.04048v2"
  },
  {
    "api_id": 474,
    "title": "Sparsity Constrained Distributed Unmixing of Hyperspectral Data",
    "summary": "Spectral unmixing (SU) is a technique to characterize mixed pixels in\nhyperspectral images measured by remote sensors. Most of the spectral unmixing\nalgorithms are developed using the linear mixing models. To estimate endmembers\nand fractional abundance matrices in a blind problem, nonnegative matrix\nfactorization (NMF) and its developments are widely used in the SU problem. One\nof the constraints which was added to NMF is sparsity, that was regularized by\nLq norm. In this paper, a new algorithm based on distributed optimization is\nsuggested for spectral unmixing. In the proposed algorithm, a network including\nsingle-node clusters is employed. Each pixel in the hyperspectral images is\nconsidered as a node in this network. The sparsity constrained distributed\nunmixing is optimized with diffusion least mean p-power (LMP) strategy, and\nthen the update equations for fractional abundance and signature matrices are\nobtained. Afterwards the proposed algorithm is analyzed for different values of\nLMP power and Lq norms. Simulation results based on defined performance metrics\nillustrate the advantage of the proposed algorithm in spectral unmixing of\nhyperspectral data compared with other methods.",
    "published": "2019-02-20T15:16:06Z",
    "updated": "2019-02-20T15:16:06Z",
    "authors": [
      "Sara Khoshsokhan",
      "Roozbeh Rajabi",
      "Hadi Zayyani"
    ],
    "link": "http://arxiv.org/abs/1902.07593v1",
    "pdf_link": "http://arxiv.org/pdf/1902.07593v1"
  },
  {
    "api_id": 475,
    "title": "Deep Discriminative Representation Learning with Attention Map for Scene\n  Classification",
    "summary": "Learning powerful discriminative features for remote sensing image scene\nclassification is a challenging computer vision problem. In the past, most\nclassification approaches were based on handcrafted features. However, most\nrecent approaches to remote sensing scene classification are based on\nConvolutional Neural Networks (CNNs). The de facto practice when learning these\nCNN models is only to use original RGB patches as input with training performed\non large amounts of labeled data (ImageNet). In this paper, we show class\nactivation map (CAM) encoded CNN models, codenamed DDRL-AM, trained using\noriginal RGB patches and attention map based class information provide\ncomplementary information to the standard RGB deep models. To the best of our\nknowledge, we are the first to investigate attention information encoded CNNs.\nAdditionally, to enhance the discriminability, we further employ a recently\ndeveloped object function called \"center loss,\" which has proved to be very\nuseful in face recognition. Finally, our framework provides attention guidance\nto the model in an end-to-end fashion. Extensive experiments on two benchmark\ndatasets show that our approach matches or exceeds the performance of other\nmethods.",
    "published": "2019-02-21T11:09:18Z",
    "updated": "2019-02-21T11:09:18Z",
    "authors": [
      "Jun Li",
      "Daoyu Lin",
      "Yang Wang",
      "Guangluan Xu",
      "Chibiao Ding"
    ],
    "link": "http://arxiv.org/abs/1902.07967v1",
    "pdf_link": "http://arxiv.org/pdf/1902.07967v1"
  },
  {
    "api_id": 476,
    "title": "Blind Hyperspectral-Multispectral Image Fusion via Graph Laplacian\n  Regularization",
    "summary": "Fusing a low-resolution hyperspectral image (HSI) and a high-resolution\nmultispectral image (MSI) of the same scene leads to a super-resolution image\n(SRI), which is information rich spatially and spectrally. In this paper, we\nsuper-resolve the HSI using the graph Laplacian defined on the MSI. Unlike many\nexisting works, we don't assume prior knowledge about the spatial degradation\nfrom SRI to HSI, nor a perfectly aligned HSI and MSI pair. Our algorithm\nprogressively alternates between finding the blur kernel and fusing HSI with\nMSI, generating accurate estimations of the blur kernel and the SRI at\nconvergence. Experiments on various datasets demonstrate the advantages of the\nproposed algorithm in the quality of fusion and its capability in dealing with\nunknown spatial degradation.",
    "published": "2019-02-21T19:27:59Z",
    "updated": "2019-02-21T19:27:59Z",
    "authors": [
      "Chandrajit Bajaj",
      "Tianming Wang"
    ],
    "link": "http://arxiv.org/abs/1902.08224v1",
    "pdf_link": "http://arxiv.org/pdf/1902.08224v1"
  },
  {
    "api_id": 477,
    "title": "Rapid Classification of TESS Planet Candidates with Convolutional Neural\n  Networks",
    "summary": "Accurately and rapidly classifying exoplanet candidates from transit surveys\nis a goal of growing importance as the data rates from space-based survey\nmissions increases. This is especially true for NASA's TESS mission which\ngenerates thousands of new candidates each month. Here we created the first\ndeep learning model capable of classifying TESS planet candidates. We adapted\nthe neural network model of Ansdell et al. (2018) to TESS data. We then trained\nand tested this updated model on 4 sectors of high-fidelity, pixel-level\nsimulations data created using the Lilith simulator and processed using the\nfull TESS SPOC pipeline. We find our model performs very well on our simulated\ndata, with 97% average precision and 92% accuracy on planets in the 2-class\nmodel. This accuracy is also boosted by another ~4% if planets found at the\nwrong periods are included. We also performed 3- and 4-class classification of\nplanets, blended & target eclipsing binaries, and non-astrophysical false\npositives, which have slightly lower average precision and planet accuracies,\nbut are useful for follow-up decisions. When applied to real TESS data, 61% of\nTCEs coincident with currently published TOIs are recovered as planets, 4% more\nare suggested to be EBs, and we propose a further 200 TCEs as planet\ncandidates.",
    "published": "2019-02-22T16:10:23Z",
    "updated": "2019-02-22T16:10:23Z",
    "authors": [
      "Hugh P. Osborn",
      "Megan Ansdell",
      "Yani Ioannou",
      "Michele Sasdelli",
      "Daniel Angerhausen",
      "Douglas A. Caldwell",
      "Jon M. Jenkins",
      "Chedy Räissi",
      "Jeffrey C. Smith"
    ],
    "link": "http://arxiv.org/abs/1902.08544v1",
    "pdf_link": "http://arxiv.org/pdf/1902.08544v1"
  },
  {
    "api_id": 478,
    "title": "Constraining the Thermal Properties of Planetary Surfaces using Machine\n  Learning: Application to Airless Bodies",
    "summary": "We present a new method for the determination of the surface properties of\nairless bodies from measurements of the emitted infrared flux. Our approach\nuses machine learning techniques to train, validate, and test a neural network\nrepresentation of the thermophysical behavior of the atmosphereless body given\nshape model, illumination and observational geometry of the remote sensors. The\nnetworks are trained on a dataset of thermal simulations of the emitted\ninfrared flux for different values of surface rock abundance, roughness, and\nvalues of the thermal inertia of the regolith and of the rock components. These\nsurrogate models are then employed to retrieve the surface thermal properties\nby Markov Chain Monte Carlo Bayesian inversion of observed infrared fluxes. We\napply the method to the inversion of simulated infrared fluxes of asteroid\n(101195) Bennu -- according to a geometry of observations similar to those\nplanned for NASA's OSIRIS-REx mission -- and infrared observations of asteroid\n(25143) Itokawa. In both cases, the surface properties of the asteroid -- such\nas surface roughness, thermal inertia of the regolith and rock component, and\nrelative rock abundance -- are retrieved; the contribution from the regolith\nand rock components are well separated. For the case of Itokawa, we retrieve a\nrock abundance of about 85% for pebbles larger than the diurnal skin depth,\nwhich is about 2 cm. The thermal inertia of the rock is found to be lower than\nthe expected value for LL chondrites, indicating that the rocks on Itokawa\ncould be fractured. The average thermal inertia of the surface is around 750 $J\ns^{-1/2} K^{-1} m^{-2}$ and the measurement of thermal inertia of the regolith\ncorresponds to an average regolith particle diameter of about 10 mm,\nconsistently with in situ measurements as well as results from previous\nstudies.",
    "published": "2019-02-22T19:00:16Z",
    "updated": "2019-02-22T19:00:16Z",
    "authors": [
      "Saverio Cambioni",
      "Marco Delbo",
      "Andrew J. Ryan",
      "Roberto Furfaro",
      "Erik Asphaug"
    ],
    "link": "http://arxiv.org/abs/1902.08631v1",
    "pdf_link": "http://arxiv.org/pdf/1902.08631v1"
  },
  {
    "api_id": 479,
    "title": "Tiling and Stitching Segmentation Output for Remote Sensing: Basic\n  Challenges and Recommendations",
    "summary": "In this work we consider the application of convolutional neural networks\n(CNNs) for pixel-wise labeling (a.k.a., semantic segmentation) of remote\nsensing imagery (e.g., aerial color or hyperspectral imagery). Remote sensing\nimagery is usually stored in the form of very large images, referred to as\n\"tiles\", which are too large to be segmented directly using most CNNs and their\nassociated hardware. As a result, during label inference, smaller sub-images,\ncalled \"patches\", are processed individually and then \"stitched\" (concatenated)\nback together to create a tile-sized label map. This approach suffers from\ncomputational ineffiency and can result in discontinuities at output\nboundaries. We propose a simple alternative approach in which the input size of\nthe CNN is dramatically increased only during label inference. This does not\navoid stitching altogether, but substantially mitigates its limitations. We\nevaluate the performance of the proposed approach against a vonventional\nstitching approach using two popular segmentation CNN models and two\nlarge-scale remote sensing imagery datasets. The results suggest that the\nproposed approach substantially reduces label inference time, while also\nyielding modest overall label accuracy increases. This approach contributed to\nour wining entry (overall performance) in the INRIA building labeling\ncompetition.",
    "published": "2018-05-30T20:34:07Z",
    "updated": "2019-02-25T14:44:09Z",
    "authors": [
      "Bohao Huang",
      "Daniel Reichman",
      "Leslie M. Collins",
      "Kyle Bradbury",
      "Jordan M. Malof"
    ],
    "link": "http://arxiv.org/abs/1805.12219v3",
    "pdf_link": "http://arxiv.org/pdf/1805.12219v3"
  },
  {
    "api_id": 480,
    "title": "Determination of chaotic behaviour in time series generated by charged\n  particle motion around magnetized Schwarzschild black holes",
    "summary": "We study behaviour of ionized region of a Keplerian disk orbiting a\nSchwarzschild black hole immersed in an asymptotically uniform magnetic field.\nIn dependence on the magnetic parameter ${\\cal B}$, and inclination angle\n$\\theta$ of the disk plane with respect to the magnetic field direction, the\ncharged particles of the ionized disk can enter three regimes: a) regular\noscillatory motion, b) destruction due to capture by the magnetized black hole,\nc) chaotic regime of the motion. In order to study transition between the\nregular and chaotic type of the charged particle motion, we generate time\nseries of the solution of equations of motion under various conditions, and\nstudy them by non-linear (box counting, correlation dimension, Lyapunov\nexponent, recurrence analysis, machine learning) methods of chaos\ndetermination. We demonstrate that the machine learning method appears to be\nthe most efficient in determining the chaotic region of the $\\theta-r$ space.\nWe show that the chaotic character of the ionized particle motion increases\nwith the inclination angle. For the inclination angles $\\theta \\sim 0$ whole\nthe ionized internal part of the Keplerian disk is captured by the black hole.",
    "published": "2019-05-03T13:57:56Z",
    "updated": "2019-05-03T13:57:56Z",
    "authors": [
      "Radim Pánis",
      "Martin Kološ",
      "Zdeněk Stuchlík"
    ],
    "link": "http://arxiv.org/abs/1905.01186v1",
    "pdf_link": "http://arxiv.org/pdf/1905.01186v1"
  },
  {
    "api_id": 481,
    "title": "Mapping Missing Population in Rural India: A Deep Learning Approach with\n  Satellite Imagery",
    "summary": "Millions of people worldwide are absent from their country's census.\nAccurate, current, and granular population metrics are critical to improving\ngovernment allocation of resources, to measuring disease control, to responding\nto natural disasters, and to studying any aspect of human life in these\ncommunities. Satellite imagery can provide sufficient information to build a\npopulation map without the cost and time of a government census. We present two\nConvolutional Neural Network (CNN) architectures which efficiently and\neffectively combine satellite imagery inputs from multiple sources to\naccurately predict the population density of a region. In this paper, we use\nsatellite imagery from rural villages in India and population labels from the\n2011 SECC census. Our best model achieves better performance than previous\npapers as well as LandScan, a community standard for global population\ndistribution.",
    "published": "2019-05-04T18:33:22Z",
    "updated": "2019-05-04T18:33:22Z",
    "authors": [
      "Wenjie Hu",
      "Jay Harshadbhai Patel",
      "Zoe-Alanah Robert",
      "Paul Novosad",
      "Samuel Asher",
      "Zhongyi Tang",
      "Marshall Burke",
      "David Lobell",
      "Stefano Ermon"
    ],
    "link": "http://arxiv.org/abs/1905.02196v1",
    "pdf_link": "http://arxiv.org/pdf/1905.02196v1"
  },
  {
    "api_id": 482,
    "title": "Deep Convolutional Neural Network-Based Autonomous Drone Navigation",
    "summary": "This paper presents a novel approach for aerial drone autonomous navigation\nalong predetermined paths using only visual input form an onboard camera and\nwithout reliance on a Global Positioning System (GPS). It is based on using a\ndeep Convolutional Neural Network (CNN) combined with a regressor to output the\ndrone steering commands. Furthermore, multiple auxiliary navigation paths that\nform a navigation envelope are used for data augmentation to make the system\nadaptable to real-life deployment scenarios. The approach is suitable for\nautomating drone navigation in applications that exhibit regular trips or\nvisits to same locations such as environmental and desertification monitoring,\nparcel/aid delivery and drone-based wireless internet delivery. In this case,\nthe proposed algorithm replaces human operators, enhances accuracy of GPS-based\nmap navigation, alleviates problems related to GPS-spoofing and enables\nnavigation in GPS-denied environments. Our system is tested in two scenarios\nusing the Unreal Engine-based AirSim plugin for drone simulation with promising\nresults of average cross track distance less than 1.4 meters and mean waypoints\nminimum distance of less than 1 meter.",
    "published": "2019-05-05T11:25:24Z",
    "updated": "2019-05-05T11:25:24Z",
    "authors": [
      "K. Amer",
      "M. Samy",
      "M. Shaker",
      "M. ElHelw"
    ],
    "link": "http://arxiv.org/abs/1905.01657v1",
    "pdf_link": "http://arxiv.org/pdf/1905.01657v1"
  },
  {
    "api_id": 483,
    "title": "GETNET: A General End-to-end Two-dimensional CNN Framework for\n  Hyperspectral Image Change Detection",
    "summary": "Change detection (CD) is an important application of remote sensing, which\nprovides timely change information about large-scale Earth surface. With the\nemergence of hyperspectral imagery, CD technology has been greatly promoted, as\nhyperspectral data with the highspectral resolution are capable of detecting\nfiner changes than using the traditional multispectral imagery. Nevertheless,\nthe high dimension of hyperspectral data makes it difficult to implement\ntraditional CD algorithms. Besides, endmember abundance information at subpixel\nlevel is often not fully utilized. In order to better handle high dimension\nproblem and explore abundance information, this paper presents a General\nEnd-to-end Two-dimensional CNN (GETNET) framework for hyperspectral image\nchange detection (HSI-CD). The main contributions of this work are threefold:\n1) Mixed-affinity matrix that integrates subpixel representation is introduced\nto mine more cross-channel gradient features and fuse multi-source information;\n2) 2-D CNN is designed to learn the discriminative features effectively from\nmulti-source data at a higher level and enhance the generalization ability of\nthe proposed CD algorithm; 3) A new HSI-CD data set is designed for the\nobjective comparison of different methods. Experimental results on real\nhyperspectral data sets demonstrate the proposed method outperforms most of the\nstate-of-the-arts.",
    "published": "2019-05-05T11:36:53Z",
    "updated": "2019-05-05T11:36:53Z",
    "authors": [
      "Qi Wang",
      "Zhenghang Yuan",
      "Qian Du",
      "Xuelong Li"
    ],
    "link": "http://arxiv.org/abs/1905.01662v1",
    "pdf_link": "http://arxiv.org/pdf/1905.01662v1"
  },
  {
    "api_id": 484,
    "title": "Understanding urban landuse from the above and ground perspectives: a\n  deep learning, multimodal solution",
    "summary": "Landuse characterization is important for urban planning. It is traditionally\nperformed with field surveys or manual photo interpretation, two practices that\nare time-consuming and labor-intensive. Therefore, we aim to automate landuse\nmapping at the urban-object level with a deep learning approach based on data\nfrom multiple sources (or modalities). We consider two image modalities:\noverhead imagery from Google Maps and ensembles of ground-based pictures\n(side-views) per urban-object from Google Street View (GSV). These modalities\nbring complementary visual information pertaining to the urban-objects. We\npropose an end-to-end trainable model, which uses OpenStreetMap annotations as\nlabels. The model can accommodate a variable number of GSV pictures for the\nground-based branch and can also function in the absence of ground pictures at\nprediction time. We test the effectiveness of our model over the area of\n\\^Ile-de-France, France, and test its generalization abilities on a set of\nurban-objects from the city of Nantes, France. Our proposed multimodal\nConvolutional Neural Network achieves considerably higher accuracies than\nmethods that use a single image modality, making it suitable for automatic\nlanduse map updates. Additionally, our approach could be easily scaled to\nmultiple cities, because it is based on data sources available for many cities\nworldwide.",
    "published": "2019-05-05T21:36:59Z",
    "updated": "2019-05-05T21:36:59Z",
    "authors": [
      "Shivangi Srivastava",
      "John E. Vargas-Muñoz",
      "Devis Tuia"
    ],
    "link": "http://arxiv.org/abs/1905.01752v1",
    "pdf_link": "http://arxiv.org/pdf/1905.01752v1"
  },
  {
    "api_id": 485,
    "title": "Machine Learning Based Routing Congestion Prediction in FPGA High-Level\n  Synthesis",
    "summary": "High-level synthesis (HLS) shortens the development time of hardware designs\nand enables faster design space exploration at a higher abstraction level.\nOptimization of complex applications in HLS is challenging due to the effects\nof implementation issues such as routing congestion. Routing congestion\nestimation is absent or inaccurate in existing HLS design methods and tools.\nEarly and accurate congestion estimation is of great benefit to guide the\noptimization in HLS and improve the efficiency of implementation. However,\nroutability, a serious concern in FPGA designs, has been difficult to evaluate\nin HLS without analyzing post-implementation details after Place and Route. To\nthis end, we propose a novel method to predict routing congestion in HLS using\nmachine learning and map the expected congested regions in the design to the\nrelevant high-level source code. This is greatly beneficial in early\nidentification of routability oriented bottlenecks in the high-level source\ncode without running time-consuming register-transfer level (RTL)\nimplementation flow. Experiments demonstrate that our approach accurately\nestimates vertical and horizontal routing congestion with errors of 6.71% and\n10.05% respectively. By presenting Face Detection application as a case study,\nwe show that by discovering the bottlenecks in high-level source code, routing\ncongestion can be easily and quickly resolved compared to the efforts involved\nin RTL implementation and design feedback.",
    "published": "2019-05-06T06:33:22Z",
    "updated": "2019-05-06T06:33:22Z",
    "authors": [
      "Jieru Zhao",
      "Tingyuan Liang",
      "Sharad Sinha",
      "Wei Zhang"
    ],
    "link": "http://arxiv.org/abs/1905.03852v1",
    "pdf_link": "http://arxiv.org/pdf/1905.03852v1"
  },
  {
    "api_id": 486,
    "title": "Sdf-GAN: Semi-supervised Depth Fusion with Multi-scale Adversarial\n  Networks",
    "summary": "Refining raw disparity maps from different algorithms to exploit their\ncomplementary advantages is still challenging. Uncertainty estimation and\ncomplex disparity relationships among pixels limit the accuracy and robustness\nof existing methods and there is no standard method for fusion of different\nkinds of depth data. In this paper, we introduce a new method to fuse disparity\nmaps from different sources, while incorporating supplementary information\n(intensity, gradient, etc.) into a refiner network to better refine raw\ndisparity inputs. A discriminator network classifies disparities at different\nreceptive fields and scales. Assuming a Markov Random Field for the refined\ndisparity map produces better estimates of the true disparity distribution.\nBoth fully supervised and semi-supervised versions of the algorithm are\nproposed. The approach includes a more robust loss function to inpaint invalid\ndisparity values and requires much less labeled data to train in the\nsemi-supervised learning mode. The algorithm can be generalized to fuse depths\nfrom different kinds of depth sources. Experiments explored different fusion\nopportunities: stereo-monocular fusion, stereo-ToF fusion and stereo-stereo\nfusion. The experiments show the superiority of the proposed algorithm compared\nwith the most recent algorithms on public synthetic datasets (Scene Flow,\nSYNTH3, our synthetic garden dataset) and real datasets (Kitti2015 dataset and\nTrimbot2020 Garden dataset).",
    "published": "2018-03-18T13:17:16Z",
    "updated": "2019-05-06T15:48:51Z",
    "authors": [
      "Can Pu",
      "Runzi Song",
      "Radim Tylecek",
      "Nanbo Li",
      "Robert B Fisher"
    ],
    "link": "http://arxiv.org/abs/1803.06657v3",
    "pdf_link": "http://arxiv.org/pdf/1803.06657v3"
  },
  {
    "api_id": 487,
    "title": "Credit Card Fraud Detection in e-Commerce: An Outlier Detection Approach",
    "summary": "Often the challenge associated with tasks like fraud and spam detection is\nthe lack of all likely patterns needed to train suitable supervised learning\nmodels. This problem accentuates when the fraudulent patterns are not only\nscarce, they also change over time. Change in fraudulent pattern is because\nfraudsters continue to innovate novel ways to circumvent measures put in place\nto prevent fraud. Limited data and continuously changing patterns makes\nlearning significantly difficult. We hypothesize that good behavior does not\nchange with time and data points representing good behavior have consistent\nspatial signature under different groupings. Based on this hypothesis we are\nproposing an approach that detects outliers in large data sets by assigning a\nconsistency score to each data point using an ensemble of clustering methods.\nOur main contribution is proposing a novel method that can detect outliers in\nlarge datasets and is robust to changing patterns. We also argue that area\nunder the ROC curve, although a commonly used metric to evaluate outlier\ndetection methods is not the right metric. Since outlier detection problems\nhave a skewed distribution of classes, precision-recall curves are better\nsuited because precision compares false positives to true positives (outliers)\nrather than true negatives (inliers) and therefore is not affected by the\nproblem of class imbalance. We show empirically that area under the\nprecision-recall curve is a better than ROC as an evaluation metric. The\nproposed approach is tested on the modified version of the Landsat satellite\ndataset, the modified version of the ann-thyroid dataset and a large real world\ncredit card fraud detection dataset available through Kaggle where we show\nsignificant improvement over the baseline methods.",
    "published": "2018-11-06T07:06:38Z",
    "updated": "2019-05-07T00:00:30Z",
    "authors": [
      "Utkarsh Porwal",
      "Smruthi Mukund"
    ],
    "link": "http://arxiv.org/abs/1811.02196v2",
    "pdf_link": "http://arxiv.org/pdf/1811.02196v2"
  },
  {
    "api_id": 488,
    "title": "Design Space Exploration via Answer Set Programming Modulo Theories",
    "summary": "The design of embedded systems, that are ubiquitously used in mobile devices\nand cars, is becoming continuously more complex such that efficient\nsystem-level design methods are becoming crucial. My research aims at\ndeveloping systems that help the designer express the complex design problem in\na declarative way and explore the design space to obtain divers sets of\nsolutions with desirable properties. To that end, we employ knowledge\nrepresentation and reasoning capabilities of ASP in combination with background\ntheories. As a result, for the first time, we proposed a sophisticated\nmethodology that allows for the direct integration of multi-objective\noptimization of non-linear objectives into ASP. This includes unique results of\ndiverse sub-problems covered in several publications which I will present in\nthis work.",
    "published": "2019-05-07T08:44:47Z",
    "updated": "2019-05-07T08:44:47Z",
    "authors": [
      "Philipp Wanko"
    ],
    "link": "http://arxiv.org/abs/1905.05248v1",
    "pdf_link": "http://arxiv.org/pdf/1905.05248v1"
  },
  {
    "api_id": 489,
    "title": "Bayesian Optimization using Deep Gaussian Processes",
    "summary": "Bayesian Optimization using Gaussian Processes is a popular approach to deal\nwith the optimization of expensive black-box functions. However, because of the\na priori on the stationarity of the covariance matrix of classic Gaussian\nProcesses, this method may not be adapted for non-stationary functions involved\nin the optimization problem. To overcome this issue, a new Bayesian\nOptimization approach is proposed. It is based on Deep Gaussian Processes as\nsurrogate models instead of classic Gaussian Processes. This modeling technique\nincreases the power of representation to capture the non-stationarity by simply\nconsidering a functional composition of stationary Gaussian Processes,\nproviding a multiple layer structure. This paper proposes a new algorithm for\nGlobal Optimization by coupling Deep Gaussian Processes and Bayesian\nOptimization. The specificities of this optimization method are discussed and\nhighlighted with academic test cases. The performance of the proposed algorithm\nis assessed on analytical test cases and an aerospace design optimization\nproblem and compared to the state-of-the-art stationary and non-stationary\nBayesian Optimization approaches.",
    "published": "2019-05-07T11:07:53Z",
    "updated": "2019-05-07T11:07:53Z",
    "authors": [
      "Ali Hebbal",
      "Loic Brevault",
      "Mathieu Balesdent",
      "El-Ghazali Talbi",
      "Nouredine Melab"
    ],
    "link": "http://arxiv.org/abs/1905.03350v1",
    "pdf_link": "http://arxiv.org/pdf/1905.03350v1"
  },
  {
    "api_id": 490,
    "title": "Generative Adversarial Networks and Conditional Random Fields for\n  Hyperspectral Image Classification",
    "summary": "In this paper, we address the hyperspectral image (HSI) classification task\nwith a generative adversarial network and conditional random field (GAN-CRF)\n-based framework, which integrates a semi-supervised deep learning and a\nprobabilistic graphical model, and make three contributions. First, we design\nfour types of convolutional and transposed convolutional layers that consider\nthe characteristics of HSIs to help with extracting discriminative features\nfrom limited numbers of labeled HSI samples. Second, we construct\nsemi-supervised GANs to alleviate the shortage of training samples by adding\nlabels to them and implicitly reconstructing real HSI data distribution through\nadversarial training. Third, we build dense conditional random fields (CRFs) on\ntop of the random variables that are initialized to the softmax predictions of\nthe trained GANs and are conditioned on HSIs to refine classification maps.\nThis semi-supervised framework leverages the merits of discriminative and\ngenerative models through a game-theoretical approach. Moreover, even though we\nused very small numbers of labeled training HSI samples from the two most\nchallenging and extensively studied datasets, the experimental results\ndemonstrated that spectral-spatial GAN-CRF (SS-GAN-CRF) models achieved\ntop-ranking accuracy for semi-supervised HSI classification.",
    "published": "2019-05-12T01:13:35Z",
    "updated": "2019-05-12T01:13:35Z",
    "authors": [
      "Zilong Zhong",
      "Jonathan Li",
      "David A. Clausi",
      "Alexander Wong"
    ],
    "link": "http://arxiv.org/abs/1905.04621v1",
    "pdf_link": "http://arxiv.org/pdf/1905.04621v1"
  },
  {
    "api_id": 491,
    "title": "Programmable Spectrometry -- Per-pixel Classification of Materials using\n  Learned Spectral Filters",
    "summary": "Many materials have distinct spectral profiles. This facilitates estimation\nof the material composition of a scene at each pixel by first acquiring its\nhyperspectral image, and subsequently filtering it using a bank of spectral\nprofiles. This process is inherently wasteful since only a set of linear\nprojections of the acquired measurements contribute to the classification task.\nWe propose a novel programmable camera that is capable of producing images of a\nscene with an arbitrary spectral filter. We use this camera to optically\nimplement the spectral filtering of the scene's hyperspectral image with the\nbank of spectral profiles needed to perform per-pixel material classification.\nThis provides gains both in terms of acquisition speed --- since only the\nrelevant measurements are acquired --- and in signal-to-noise ratio --- since\nwe invariably avoid narrowband filters that are light inefficient. Given\ntraining data, we use a range of classical and modern techniques including SVMs\nand neural networks to identify the bank of spectral profiles that facilitate\nmaterial classification. We verify the method in simulations on standard\ndatasets as well as real data using a lab prototype of the camera.",
    "published": "2019-05-13T00:20:31Z",
    "updated": "2019-05-13T00:20:31Z",
    "authors": [
      "Vishwanath Saragadam",
      "Aswin C. Sankaranarayanan"
    ],
    "link": "http://arxiv.org/abs/1905.04815v1",
    "pdf_link": "http://arxiv.org/pdf/1905.04815v1"
  },
  {
    "api_id": 492,
    "title": "A census of $ρ$ Oph candidate members from Gaia DR2",
    "summary": "The Ophiuchus cloud complex is one of the best laboratories to study the\nearlier stages of the stellar and protoplanetary disc evolution. The wealth of\naccurate astrometric measurements contained in the Gaia Data Release 2 can be\nused to update the census of Ophiuchus member candidates. We seek to find\npotential new members of Ophiuchus and identify those surrounded by a\ncircumstellar disc. We constructed a control sample composed of 188 bona fide\nOphiuchus members. Using this sample as a reference we applied three different\ndensity-based machine learning clustering algorithms (DBSCAN, OPTICS, and\nHDBSCAN) to a sample drawn from the Gaia catalogue centred on the Ophiuchus\ncloud. The clustering analysis was applied in the five astrometric dimensions\ndefined by the three-dimensional Cartesian space and the proper motions in\nright ascension and declination. The three clustering algorithms systematically\nidentify a similar set of candidate members in a main cluster with astrometric\nproperties consistent with those of the control sample. The increased\nflexibility of the OPTICS and HDBSCAN algorithms enable these methods to\nidentify a secondary cluster. We constructed a common sample containing 391\nmember candidates including 166 new objects, which have not yet been discussed\nin the literature. By combining the Gaia data with 2MASS and WISE photometry,\nwe built the spectral energy distributions from 0.5 to $22\\microm$ for a subset\nof 48 objects and found a total of 41 discs, including 11 Class II and 1 Class\nIII new discs. Density-based clustering algorithms are a promising tool to\nidentify candidate members of star forming regions in large astrometric\ndatabases. If confirmed, the candidate members discussed in this work would\nrepresent an increment of roughly 40% of the current census of Ophiuchus.",
    "published": "2019-02-20T15:37:05Z",
    "updated": "2019-05-13T12:04:49Z",
    "authors": [
      "H. Cánovas",
      "C. Cantero",
      "L. Cieza",
      "A. Bombrun",
      "U. Lammers",
      "B. Merín",
      "A. Mora",
      "Á. Ribas",
      "D. Ruíz-Rodríguez"
    ],
    "link": "http://arxiv.org/abs/1902.07600v2",
    "pdf_link": "http://arxiv.org/pdf/1902.07600v2"
  },
  {
    "api_id": 493,
    "title": "Theoretical rotation-vibration spectroscopy of {\\it cis}- and {\\it\n  trans}-diphosphene (P$_2$H$_2$) and the deuterated species P$_2$HD",
    "summary": "Growing astronomical interest in phosphorous (P) chemistry is stimulating the\nsearch for new interstellar P-bearing molecules; a task requiring detailed\nknowledge of the microwave and infrared molecular spectrum. In this work, we\npresent comprehensive rotation-vibration line lists of the \\cis- and\n\\trans-isomers of diphosphene (P$_2$H$_2$). The line lists have been generated\nusing robust, first-principles methodologies based on newly computed,\nhigh-level \\ai\\ potential energy and dipole moment surfaces. Transitions are\nconsidered between states with energies up to $8000$~cm$^{-1}$ and total\nangular momentum $J\\leq25$. These are the first-ever line lists to be reported\nfor P$_2$H$_2$ and they should significantly facilitate future spectroscopic\ncharacterization of this system. The deuterated species \\trans-P$_2$HD and the\neffect of its dynamic dipole moment on the rovibrational spectrum is also\ndiscussed.",
    "published": "2019-05-13T12:12:42Z",
    "updated": "2019-05-13T12:12:42Z",
    "authors": [
      "Alec Owens",
      "Sergei N. Yurchenko"
    ],
    "link": "http://arxiv.org/abs/1905.04990v1",
    "pdf_link": "http://arxiv.org/pdf/1905.04990v1"
  },
  {
    "api_id": 494,
    "title": "A novel statistical metric learning for hyperspectral image\n  classification",
    "summary": "In this paper, a novel statistical metric learning is developed for\nspectral-spatial classification of the hyperspectral image. First, the standard\nvariance of the samples of each class in each batch is used to decrease the\nintra-class variance within each class. Then, the distances between the means\nof different classes are used to penalize the inter-class variance of the\ntraining samples. Finally, the standard variance between the means of different\nclasses is added as an additional diversity term to repulse different classes\nfrom each other. Experiments have conducted over two real-world hyperspectral\nimage datasets and the experimental results have shown the effectiveness of the\nproposed statistical metric learning.",
    "published": "2019-05-13T15:28:15Z",
    "updated": "2019-05-13T15:28:15Z",
    "authors": [
      "Zhiqiang Gong",
      "Ping Zhong",
      "Weidong Hu",
      "Zixuan Xiao",
      "Xuping Yin"
    ],
    "link": "http://arxiv.org/abs/1905.05087v1",
    "pdf_link": "http://arxiv.org/pdf/1905.05087v1"
  },
  {
    "api_id": 495,
    "title": "Multi-scale Dynamic Graph Convolutional Network for Hyperspectral Image\n  Classification",
    "summary": "Convolutional Neural Network (CNN) has demonstrated impressive ability to\nrepresent hyperspectral images and to achieve promising results in\nhyperspectral image classification. However, traditional CNN models can only\noperate convolution on regular square image regions with fixed size and\nweights, so they cannot universally adapt to the distinct local regions with\nvarious object distributions and geometric appearances. Therefore, their\nclassification performances are still to be improved, especially in class\nboundaries. To alleviate this shortcoming, we consider employing the recently\nproposed Graph Convolutional Network (GCN) for hyperspectral image\nclassification, as it can conduct the convolution on arbitrarily structured\nnon-Euclidean data and is applicable to the irregular image regions represented\nby graph topological information. Different from the commonly used GCN models\nwhich work on a fixed graph, we enable the graph to be dynamically updated\nalong with the graph convolution process, so that these two steps can be\nbenefited from each other to gradually produce the discriminative embedded\nfeatures as well as a refined graph. Moreover, to comprehensively deploy the\nmulti-scale information inherited by hyperspectral images, we establish\nmultiple input graphs with different neighborhood scales to extensively exploit\nthe diversified spectral-spatial correlations at multiple scales. Therefore,\nour method is termed 'Multi-scale Dynamic Graph Convolutional Network' (MDGCN).\nThe experimental results on three typical benchmark datasets firmly demonstrate\nthe superiority of the proposed MDGCN to other state-of-the-art methods in both\nqualitative and quantitative aspects.",
    "published": "2019-05-14T14:27:37Z",
    "updated": "2019-05-14T14:27:37Z",
    "authors": [
      "Sheng Wan",
      "Chen Gong",
      "Ping Zhong",
      "Bo Du",
      "Lefei Zhang",
      "Jian Yang"
    ],
    "link": "http://arxiv.org/abs/1905.06133v1",
    "pdf_link": "http://arxiv.org/pdf/1905.06133v1"
  },
  {
    "api_id": 496,
    "title": "Evolution of the gravity offset of mixed modes in RGB stars",
    "summary": "Observations of mixed modes in evolved low-mass stars enable us to probe the\nproperties of not only the outer envelope of these stars, but also their deep\nlayers. Among the seismic parameters associated with mixed modes, the gravity\noffset, denoted with $\\varepsilon_{\\rm g}$, is expected to reveal information\non the boundaries of the inner buoyancy resonant cavity. This parameter was\nrecently measured for hundreds of stars observed by the Kepler satellite and\nits value was shown to change during the evolution on the red giant branch. In\nthis article, we theoretically investigate the reasons for such a variation in\nterms of structure properties. Using available asymptotic analyses and a simple\nmodel of the Brunt-V\\\"ais\\\"al\\\"a and Lamb frequencies, we derived an analytical\nexpression of $\\varepsilon_{\\rm g}$ for dipolar modes and compared its\npredictions to observations. First, we show that the asymptotic value of\n$\\varepsilon_{\\rm g}$ well agrees with the mean value observed at the beginning\nof the ascent of the red giant branch, which results from the high density\ncontrast between the helium core and the base of the convective envelope.\nSecond, we demonstrate that the predicted value also explains the sharp\ndecrease in $\\varepsilon_{\\rm g}$ observed for the more luminous red giant\nstars of the sample. This rapid drop turns out to occur just before the\nluminosity bump and result from the kink of the Brunt-V\\\"ais\\\"al\\\"a frequency\nnear the upper turning point associated with the buoyancy cavity as stars\nevolve and this latter becomes close to the base of the convective envelope.The\nobserved variation in $\\varepsilon_{\\rm g}$ and its link with the internal\nproperties on the red giant branch are now globally understood. This motivates\nfurther analyses of the potential of this parameter as a seismic diagnosis of\nthe region located between the helium core and the convective envelope.",
    "published": "2019-05-14T16:07:43Z",
    "updated": "2019-05-14T16:07:43Z",
    "authors": [
      "C. Pinçon",
      "M. Takata",
      "B. Mosser"
    ],
    "link": "http://arxiv.org/abs/1905.05691v1",
    "pdf_link": "http://arxiv.org/pdf/1905.05691v1"
  },
  {
    "api_id": 497,
    "title": "Semi-supervised Learning with Graphs: Covariance Based Superpixels For\n  Hyperspectral Image Classification",
    "summary": "In this paper, we present a graph-based semi-supervised framework for\nhyperspectral image classification. We first introduce a novel superpixel\nalgorithm based on the spectral covariance matrix representation of pixels to\nprovide a better representation of our data. We then construct a superpixel\ngraph, based on carefully considered feature vectors, before performing\nclassification. We demonstrate, through a set of experimental results using two\nbenchmarking datasets, that our approach outperforms three state-of-the-art\nclassification frameworks, especially when an extremely small amount of\nlabelled data is used.",
    "published": "2019-01-14T11:18:27Z",
    "updated": "2019-05-14T18:23:41Z",
    "authors": [
      "Philip Sellars",
      "Angelica Aviles-Rivero",
      "Nicolas Papadakis",
      "David Coomes",
      "Anita Faul",
      "Carola-Bibane Schönlieb"
    ],
    "link": "http://arxiv.org/abs/1901.04240v4",
    "pdf_link": "http://arxiv.org/pdf/1901.04240v4"
  },
  {
    "api_id": 498,
    "title": "Identifying Exoplanets with Deep Learning III: Automated Triage and\n  Vetting of TESS Candidates",
    "summary": "NASA's Transiting Exoplanet Survey Satellite (TESS) presents us with an\nunprecedented volume of space-based photometric observations that must be\nanalyzed in an efficient and unbiased manner. With at least $\\sim1,000,000$ new\nlight curves generated every month from full frame images alone, automated\nplanet candidate identification has become an attractive alternative to human\nvetting. Here we present a deep learning model capable of performing triage and\nvetting on TESS candidates. Our model is modified from an existing neural\nnetwork designed to automatically classify Kepler candidates, and is the first\nneural network to be trained and tested on real TESS data. In triage mode, our\nmodel can distinguish transit-like signals (planet candidates and eclipsing\nbinaries) from stellar variability and instrumental noise with an average\nprecision (the weighted mean of precisions over all classification thresholds)\nof 97.0% and an accuracy of 97.4%. In vetting mode, the model is trained to\nidentify only planet candidates with the help of newly added scientific domain\nknowledge, and achieves an average precision of 69.3% and an accuracy of 97.8%.\nWe apply our model on new data from Sector 6, and present 288 new signals that\nreceived the highest scores in triage and vetting and were also identified as\nplanet candidates by human vetters. We also provide a homogeneously classified\nset of TESS candidates suitable for future training.",
    "published": "2019-04-04T18:04:19Z",
    "updated": "2019-05-14T19:15:22Z",
    "authors": [
      "Liang Yu",
      "Andrew Vanderburg",
      "Chelsea Huang",
      "Christopher J. Shallue",
      "Ian J. M. Crossfield",
      "B. Scott Gaudi",
      "Tansu Daylan",
      "Anne Dattilo",
      "David J. Armstrong",
      "George R. Ricker",
      "Roland K. Vanderspek",
      "David W. Latham",
      "Sara Seager",
      "Jason Dittmann",
      "John P. Doty",
      "Ana Glidden",
      "Samuel N. Quinn"
    ],
    "link": "http://arxiv.org/abs/1904.02726v2",
    "pdf_link": "http://arxiv.org/pdf/1904.02726v2"
  },
  {
    "api_id": 499,
    "title": "Constrained low-tubal-rank tensor recovery for hyperspectral images\n  mixed noise removal by bilateral random projections",
    "summary": "In this paper, we propose a novel low-tubal-rank tensor recovery model, which\ndirectly constrains the tubal rank prior for effectively removing the mixed\nGaussian and sparse noise in hyperspectral images. The constraints of\ntubal-rank and sparsity can govern the solution of the denoised tensor in the\nrecovery procedure. To solve the constrained low-tubal-rank model, we develop\nan iterative algorithm based on bilateral random projections to efficiently\nsolve the proposed model. The advantage of random projections is that the\napproximation of the low-tubal-rank tensor can be obtained quite accurately in\nan inexpensive manner. Experimental examples for hyperspectral image denoising\nare presented to demonstrate the effectiveness and efficiency of the proposed\nmethod.",
    "published": "2019-05-15T04:20:12Z",
    "updated": "2019-05-15T04:20:12Z",
    "authors": [
      "Hao Zhang",
      "Xi-Le Zhao",
      "Tai-Xiang Jiang",
      "Michael Kwok-Po Ng"
    ],
    "link": "http://arxiv.org/abs/1905.05941v1",
    "pdf_link": "http://arxiv.org/pdf/1905.05941v1"
  },
  {
    "api_id": 500,
    "title": "Unsupervised Segmentation of Hyperspectral Images Using 3D Convolutional\n  Autoencoders",
    "summary": "Hyperspectral image analysis has become an important topic widely researched\nby the remote sensing community. Classification and segmentation of such\nimagery help understand the underlying materials within a scanned scene, since\nhyperspectral images convey a detailed information captured in a number of\nspectral bands. Although deep learning has established the state of the art in\nthe field, it still remains challenging to train well-generalizing models due\nto the lack of ground-truth data. In this letter, we tackle this problem and\npropose an end-to-end approach to segment hyperspectral images in a fully\nunsupervised way. We introduce a new deep architecture which couples 3D\nconvolutional autoencoders with clustering. Our multi-faceted experimental\nstudy---performed over benchmark and real-life data---revealed that our\napproach delivers high-quality segmentation without any prior class labels.",
    "published": "2019-07-20T22:17:10Z",
    "updated": "2019-07-20T22:17:10Z",
    "authors": [
      "Jakub Nalepa",
      "Michal Myller",
      "Yasuteru Imai",
      "Ken-ichi Honda",
      "Tomomi Takeda",
      "Marek Antoniak"
    ],
    "link": "http://arxiv.org/abs/1907.08870v1",
    "pdf_link": "http://arxiv.org/pdf/1907.08870v1"
  },
  {
    "api_id": 501,
    "title": "City-scale Road Extraction from Satellite Imagery",
    "summary": "Automated road network extraction from remote sensing imagery remains a\nsignificant challenge despite its importance in a broad array of applications.\nTo this end, we leverage recent open source advances and the high quality\nSpaceNet dataset to explore road network extraction at scale, an approach we\ncall City-scale Road Extraction from Satellite Imagery (CRESI). Specifically,\nwe create an algorithm to extract road networks directly from imagery over\ncity-scale regions, which can subsequently be used for routing purposes. We\nquantify the performance of our algorithm with the APLS and TOPO\ngraph-theoretic metrics over a diverse 608 square kilometer test area covering\nfour cities. We find an aggregate score of APLS = 0.73, and a TOPO score of\n0.58 (a significant improvement over existing methods). Inference speed is 160\nsquare kilometers per hour on modest hardware. Finally, we demonstrate that one\ncan use the extracted road network for any number of applications, such as\noptimized routing.",
    "published": "2019-04-22T14:36:57Z",
    "updated": "2019-07-22T16:00:47Z",
    "authors": [
      "Adam Van Etten"
    ],
    "link": "http://arxiv.org/abs/1904.09901v2",
    "pdf_link": "http://arxiv.org/pdf/1904.09901v2"
  },
  {
    "api_id": 502,
    "title": "Satellite-Net: Automatic Extraction of Land Cover Indicators from\n  Satellite Imagery by Deep Learning",
    "summary": "In this paper we address the challenge of land cover classification for\nsatellite images via Deep Learning (DL). Land Cover aims to detect the physical\ncharacteristics of the territory and estimate the percentage of land occupied\nby a certain category of entities: vegetation, residential buildings,\nindustrial areas, forest areas, rivers, lakes, etc. DL is a new paradigm for\nBig Data analytics and in particular for Computer Vision. The application of DL\nin images classification for land cover purposes has a great potential owing to\nthe high degree of automation and computing performance. In particular, the\ninvention of Convolution Neural Networks (CNNs) was a fundament for the\nadvancements in this field. In [1], the Satellite Task Team of the UN Global\nWorking Group describes the results achieved so far with respect to the use of\nearth observation for Official Statistics. However, in that study, CNNs have\nnot yet been explored for automatic classification of imagery. This work\ninvestigates the usage of CNNs for the estimation of land cover indicators,\nproviding evidence of the first promising results. In particular, the paper\nproposes a customized model, called Satellite-Net, able to reach an accuracy\nlevel up to 98% on test sets.",
    "published": "2019-07-22T16:50:35Z",
    "updated": "2019-07-22T16:50:35Z",
    "authors": [
      "Eleonora Bernasconi",
      "Francesco Pugliese",
      "Diego Zardetto",
      "Monica Scannapieco"
    ],
    "link": "http://arxiv.org/abs/1907.09423v1",
    "pdf_link": "http://arxiv.org/pdf/1907.09423v1"
  },
  {
    "api_id": 503,
    "title": "Spatial sensitivity analysis for urban land use prediction with\n  physics-constrained conditional generative adversarial networks",
    "summary": "Accurately forecasting urban development and its environmental and climate\nimpacts critically depends on realistic models of the spatial structure of the\nbuilt environment, and of its dependence on key factors such as population and\neconomic development. Scenario simulation and sensitivity analysis, i.e.,\npredicting how changes in underlying factors at a given location affect\nurbanization outcomes at other locations, is currently not achievable at a\nlarge scale with traditional urban growth models, which are either too\nsimplistic, or depend on detailed locally-collected socioeconomic data that is\nnot available in most places. Here we develop a framework to estimate, purely\nfrom globally-available remote-sensing data and without parametric assumptions,\nthe spatial sensitivity of the (\\textit{static}) rate of change of urban sprawl\nto key macroeconomic development indicators. We formulate this spatial\nregression problem as an image-to-image translation task using conditional\ngenerative adversarial networks (GANs), where the gradients necessary for\ncomparative static analysis are provided by the backpropagation algorithm used\nto train the model. This framework allows to naturally incorporate physical\nconstraints, e.g., the inability to build over water bodies. To validate the\nspatial structure of model-generated built environment distributions, we use\nspatial statistics commonly used in urban form analysis. We apply our method to\na novel dataset comprising of layers on the built environment, nightlighs\nmeasurements (a proxy for economic development and energy use), and population\ndensity for the world's most populous 15,000 cities.",
    "published": "2019-07-22T19:32:43Z",
    "updated": "2019-07-22T19:32:43Z",
    "authors": [
      "Adrian Albert",
      "Jasleen Kaur",
      "Emanuele Strano",
      "Marta Gonzalez"
    ],
    "link": "http://arxiv.org/abs/1907.09543v1",
    "pdf_link": "http://arxiv.org/pdf/1907.09543v1"
  },
  {
    "api_id": 504,
    "title": "Data Analysis of Wireless Networks Using Classification Techniques",
    "summary": "In the last decade, there has been a great technological advance in the\ninfrastructure of mobile technologies. The increase in the use of wireless\nlocal area networks and the use of satellite services are also noticed. The\nhigh utilization rate of mobile devices for various purposes makes clear the\nneed to track wireless networks to ensure the integrity and confidentiality of\nthe information transmitted. Therefore, it is necessary to quickly and\nefficiently identify the normal and abnormal traffic of such networks, so that\nadministrators can take action. This work aims to analyze classification\ntechniques in relation to data from Wireless Networks, using some classes of\nanomalies pre-established according to some defined criteria of the MAC layer.\nFor data analysis, WEKA Data Mining software (Waikato Environment for Knowledge\nAnalysis) is used. The classification algorithms present a success rate in the\nclassification of viable data, being indicated in the use of intrusion\ndetection systems for wireless networks.",
    "published": "2019-07-22T22:16:59Z",
    "updated": "2019-07-22T22:16:59Z",
    "authors": [
      "Daniel Rosa Canêdo",
      "Alexandre Ricardo Soares Romariz"
    ],
    "link": "http://arxiv.org/abs/1908.07329v1",
    "pdf_link": "http://arxiv.org/pdf/1908.07329v1"
  },
  {
    "api_id": 505,
    "title": "The EREBOS project -- Investigating the effect of substellar and\n  low-mass stellar companions on late stellar evolution",
    "summary": "Eclipsing post-common envelope binaries are highly important for resolving\nthe poorly understood, very short-lived common envelope phase. Most hot\nsubdwarfs (sdO/Bs) are the bare He-burning cores of red giants which have lost\nalmost all of their hydrogen envelopes. This mass loss is often triggered by\ncommon envelope interactions with close stellar or even sub-stellar companions.\nIn the recently published catalog of eclipsing binaries in the Galactic Bulge\nand in the ATLAS survey, we discovered 161 new eclipsing systems showing a\nreflection effect by visual inspection of the light curves and using a\nmachine-learning algorithm. The EREBOS (Eclipsing Reflection Effect Binaries\nfrom Optical Surveys) project aims at analyzing all newly discovered eclipsing\nbinaries with reflection effect based on a spectroscopic and photometric follow\nup. To constrain the nature of the primary we derived the absolute magnitude\nand the reduced proper motion of all our targets with the help of the\nparallaxes and proper motions measured by the Gaia mission and compared those\nto the Gaia white dwarf catalogue. For a sub-set of our targets with observed\nspectra the nature could be derived by measuring the atmospheric parameter of\nthe primary confirming that less than 10\\% of our systems are not sdO/Bs with\ncool companions but white dwarfs or central stars of planetary nebula. This\nlarge sample of eclipsing hot subdwarfs with cool companions allowed us to\nderive a significant period distribution for hot subdwarfs with cool companions\nfor the first time showing that the period distribution is much broader than\npreviously thought and ideally suited to find the lowest mass companions to hot\nsubdwarf stars. In the future several new photometric surveys will be carried\nout, which will increase the sample of this project even more giving the\npotential to test many aspects of common envelope theory and binary evolution.",
    "published": "2019-07-23T14:09:06Z",
    "updated": "2019-07-23T14:09:06Z",
    "authors": [
      "V. Schaffenroth",
      "B. N. Barlow",
      "S. Geier",
      "M. Vu{č}ković",
      "D. Kilkenny",
      "M. Wolz",
      "T. Kupfer",
      "U. Heber",
      "H. Drechsel",
      "S. Kimeswenger",
      "T. Marsh",
      "M. Wolf",
      "I. Pelisoli",
      "J. Freudenthal",
      "S. Dreizler",
      "S. Kreuzer",
      "E. Ziegerer"
    ],
    "link": "http://arxiv.org/abs/1907.09892v1",
    "pdf_link": "http://arxiv.org/pdf/1907.09892v1"
  },
  {
    "api_id": 506,
    "title": "Image Super-Resolution Using a Wavelet-based Generative Adversarial\n  Network",
    "summary": "In this paper, we consider the problem of super-resolution recons-truction.\nThis is a hot topic because super-resolution reconstruction has a wide range of\napplications in the medical field, remote sensing monitoring, and criminal\ninvestigation. Compared with traditional algorithms, the current\nsuper-resolution reconstruction algorithm based on deep learning greatly\nimproves the clarity of reconstructed pictures. Existing work like\nSuper-Resolution Using a Generative Adversarial Network (SRGAN) can effectively\nrestore the texture details of the image. However, experimentally verified that\nthe texture details of the image recovered by the SRGAN are not robust. In\norder to get super-resolution reconstructed images with richer high-frequency\ndetails, we improve the network structure and propose a super-resolution\nreconstruction algorithm combining wavelet transform and Generative Adversarial\nNetwork. The proposed algorithm can efficiently reconstruct high-resolution\nimages with rich global information and local texture details. We have trained\nour model by PyTorch framework and VOC2012 dataset, and tested it by Set5,\nSet14, BSD100 and Urban100 test datasets.",
    "published": "2019-07-24T02:44:41Z",
    "updated": "2019-07-24T02:44:41Z",
    "authors": [
      "Qi Zhang",
      "Huafeng Wang",
      "Sichen Yang"
    ],
    "link": "http://arxiv.org/abs/1907.10213v1",
    "pdf_link": "http://arxiv.org/pdf/1907.10213v1"
  },
  {
    "api_id": 507,
    "title": "Heat Transfer Prediction for Methane in Regenerative Cooling Channels\n  with Neural Networks",
    "summary": "Methane is considered being a good choice as a propellant for future reusable\nlaunch systems. However, the heat transfer prediction for supercritical methane\nflowing in cooling channels of a regeneratively cooled combustion chamber is\nchallenging. Because accurate heat transfer predictions are essential to design\nreliable and efficient cooling systems, heat transfer modeling is a fundamental\nissue to address. Advanced computational fluid dynamics (CFD) calculations\nachieve sufficient accuracy, but the associated computational cost prevents an\nefficient integration in optimization loops. Surrogate models based on\nartificial neural networks (ANNs) offer a great speed advantage. It is shown\nthat an ANN, trained on data extracted from samples of CFD simulations, is able\nto predict the maximum wall temperature along straight rocket engine cooling\nchannels using methane with convincing precision. The combination of the ANN\nmodel with simple relations for pressure drop and enthalpy rise results in a\ncomplete reduced order model, which can be used for numerically efficient\ndesign space exploration and optimization.",
    "published": "2019-07-24T16:49:09Z",
    "updated": "2019-07-24T16:49:09Z",
    "authors": [
      "Günther Waxenegger-Wilfing",
      "Kai Dresia",
      "Jan Christian Deeken",
      "Michael Oschwald"
    ],
    "link": "http://arxiv.org/abs/1907.11281v1",
    "pdf_link": "http://arxiv.org/pdf/1907.11281v1"
  },
  {
    "api_id": 508,
    "title": "Practical Design Space Exploration",
    "summary": "Multi-objective optimization is a crucial matter in computer systems design\nspace exploration because real-world applications often rely on a trade-off\nbetween several objectives. Derivatives are usually not available or\nimpractical to compute and the feasibility of an experiment can not always be\ndetermined in advance. These problems are particularly difficult when the\nfeasible region is relatively small, and it may be prohibitive to even find a\nfeasible experiment, let alone an optimal one.\n  We introduce a new methodology and corresponding software framework,\nHyperMapper 2.0, which handles multi-objective optimization, unknown\nfeasibility constraints, and categorical/ordinal variables. This new\nmethodology also supports injection of the user prior knowledge in the search\nwhen available. All of these features are common requirements in computer\nsystems but rarely exposed in existing design space exploration systems. The\nproposed methodology follows a white-box model which is simple to understand\nand interpret (unlike, for example, neural networks) and can be used by the\nuser to better understand the results of the automatic search.\n  We apply and evaluate the new methodology to the automatic static tuning of\nhardware accelerators within the recently introduced Spatial programming\nlanguage, with minimization of design run-time and compute logic under the\nconstraint of the design fitting in a target field-programmable gate array\nchip. Our results show that HyperMapper 2.0 provides better Pareto fronts\ncompared to state-of-the-art baselines, with better or competitive hypervolume\nindicator and with 8x improvement in sampling budget for most of the benchmarks\nexplored.",
    "published": "2018-10-11T20:23:57Z",
    "updated": "2019-07-24T22:33:56Z",
    "authors": [
      "Luigi Nardi",
      "David Koeplinger",
      "Kunle Olukotun"
    ],
    "link": "http://arxiv.org/abs/1810.05236v3",
    "pdf_link": "http://arxiv.org/pdf/1810.05236v3"
  },
  {
    "api_id": 509,
    "title": "Deep Reinforcement Learning for Time Optimal Velocity Control using\n  Prior Knowledge",
    "summary": "Autonomous navigation has recently gained great interest in the field of\nreinforcement learning. However, little attention was given to the time optimal\nvelocity control problem, i.e. controlling a vehicle such that it travels at\nthe maximal speed without becoming dynamically unstable (roll-over or sliding).\n  Time optimal velocity control can be solved numerically using existing\nmethods that are based on optimal control and vehicle dynamics. In this paper,\nwe use deep reinforcement learning to generate the time optimal velocity\ncontrol. Furthermore, we use the numerical solution to further improve the\nperformance of the reinforcement learner. It is shown that the reinforcement\nlearner outperforms the numerically derived solution, and that the hybrid\napproach (combining learning with the numerical solution) speeds up the\ntraining process.",
    "published": "2018-11-28T15:14:39Z",
    "updated": "2019-07-25T08:06:45Z",
    "authors": [
      "Gabriel Hartmann",
      "Zvi Shiller",
      "Amos Azaria"
    ],
    "link": "http://arxiv.org/abs/1811.11615v3",
    "pdf_link": "http://arxiv.org/pdf/1811.11615v3"
  },
  {
    "api_id": 510,
    "title": "Application of Different Simulated Spectral Data and Machine Learning to\n  Estimate the Chlorophyll a Concentration of Several Inland Waters",
    "summary": "Water quality is of great importance for humans and for the environment and\nhas to be monitored continuously. It is determinable through proxies such as\nthe chlorophyll a concentration, which can be monitored by remote sensing\ntechniques. This study focuses on the trade-off between the spatial and the\nspectral resolution of six simulated satellite-based data sets when estimating\nthe chlorophyll a concentration with supervised machine learning models. The\ninitial dataset for the spectral simulation of the satellite missions contains\nspectrometer data and measured chlorophyll a concentration of 13 different\ninland waters. Focusing on the regression performance, it appears that the\nmachine learning models achieve almost as good results with the simulated\nSentinel data as with the simulated hyperspectral data. Regarding the\napplicability, the Sentinel 2 mission is the best choice for small inland\nwaters due to its high spatial and temporal resolution in combination with a\nsuitable spectral resolution.",
    "published": "2019-05-29T16:14:52Z",
    "updated": "2019-08-21T08:43:01Z",
    "authors": [
      "Philipp M. Maier",
      "Sina Keller"
    ],
    "link": "http://arxiv.org/abs/1905.12563v2",
    "pdf_link": "http://arxiv.org/pdf/1905.12563v2"
  },
  {
    "api_id": 511,
    "title": "Importance of spatial predictor variable selection in machine learning\n  applications -- Moving from data reproduction to spatial prediction",
    "summary": "Machine learning algorithms find frequent application in spatial prediction\nof biotic and abiotic environmental variables. However, the characteristics of\nspatial data, especially spatial autocorrelation, are widely ignored. We\nhypothesize that this is problematic and results in models that can reproduce\ntraining data but are unable to make spatial predictions beyond the locations\nof the training samples. We assume that not only spatial validation strategies\nbut also spatial variable selection is essential for reliable spatial\npredictions. We introduce two case studies that use remote sensing to predict\nland cover and the leaf area index for the \"Marburg Open Forest\", an open\nresearch and education site of Marburg University, Germany. We use the machine\nlearning algorithm Random Forests to train models using non-spatial and spatial\ncross-validation strategies to understand how spatial variable selection\naffects the predictions. Our findings confirm that spatial cross-validation is\nessential in preventing overoptimistic model performance. We further show that\nhighly autocorrelated predictors (such as geolocation variables, e.g. latitude,\nlongitude) can lead to considerable overfitting and result in models that can\nreproduce the training data but fail in making spatial predictions. The problem\nbecomes apparent in the visual assessment of the spatial predictions that show\nclear artefacts that can be traced back to a misinterpretation of the spatially\nautocorrelated predictors by the algorithm. Spatial variable selection could\nautomatically detect and remove such variables that lead to overfitting,\nresulting in reliable spatial prediction patterns and improved statistical\nspatial model performance. We conclude that in addition to spatial validation,\na spatial variable selection must be considered in spatial predictions of\necological data to produce reliable predictions.",
    "published": "2019-08-21T11:47:38Z",
    "updated": "2019-08-21T11:47:38Z",
    "authors": [
      "Hanna Meyer",
      "Christoph Reudenbach",
      "Stephan Wöllauer",
      "Thomas Nauss"
    ],
    "link": "http://arxiv.org/abs/1908.07805v1",
    "pdf_link": "http://arxiv.org/pdf/1908.07805v1"
  },
  {
    "api_id": 512,
    "title": "Building change detection based on multi-scale filtering and grid\n  partition",
    "summary": "Building change detection is of great significance in high resolution remote\nsensing applications. Multi-index learning, one of the state-of-the-art\nbuilding change detection methods, still has drawbacks like incapability to\nfind change types directly and heavy computation consumption of MBI. In this\npaper, a two-stage building change detection method is proposed to address\nthese problems. In the first stage, a multi-scale filtering building index\n(MFBI) is calculated to detect building areas in each temporal with fast speed\nand moderate accuracy. In the second stage, images and the corresponding\nbuilding maps are partitioned into grids. In each grid, the ratio of building\nareas in time T2 and time T1 is calculated. Each grid is classified into one of\nthe three change patterns, i.e., significantly increase, significantly decrease\nand approximately unchanged. Exhaustive experiments indicate that the proposed\nmethod can detect building change types directly and outperform the current\nmulti-index learning method.",
    "published": "2019-08-22T01:38:47Z",
    "updated": "2019-08-22T01:38:47Z",
    "authors": [
      "Qi Bi",
      "Kun Qin",
      "Han Zhang",
      "Wenjun Han",
      "Zhili Li",
      "Kai Xu"
    ],
    "link": "http://arxiv.org/abs/1908.08164v1",
    "pdf_link": "http://arxiv.org/pdf/1908.08164v1"
  },
  {
    "api_id": 513,
    "title": "Spectral Embedding Norm: Looking Deep into the Spectrum of the Graph\n  Laplacian",
    "summary": "The extraction of clusters from a dataset which includes multiple clusters\nand a significant background component is a non-trivial task of practical\nimportance. In image analysis this manifests for example in anomaly detection\nand target detection. The traditional spectral clustering algorithm, which\nrelies on the leading $K$ eigenvectors to detect $K$ clusters, fails in such\ncases. In this paper we propose the {\\it spectral embedding norm} which sums\nthe squared values of the first $I$ normalized eigenvectors, where $I$ can be\nsignificantly larger than $K$. We prove that this quantity can be used to\nseparate clusters from the background in unbalanced settings, including extreme\ncases such as outlier detection. The performance of the algorithm is not\nsensitive to the choice of $I$, and we demonstrate its application on synthetic\nand real-world remote sensing and neuroimaging datasets.",
    "published": "2018-10-25T02:51:54Z",
    "updated": "2019-08-22T19:38:40Z",
    "authors": [
      "Xiuyuan Cheng",
      "Gal Mishne"
    ],
    "link": "http://arxiv.org/abs/1810.10695v2",
    "pdf_link": "http://arxiv.org/pdf/1810.10695v2"
  },
  {
    "api_id": 514,
    "title": "Machine Learning Approach for Solar Wind Categorization",
    "summary": "Solar wind classification is conducive to understand the physical processes\nongoing at the Sun and solar wind evolution in the interplanetary space, and\nfurthermore, it is helpful for early warning of space weather events. With\nrapid developments in the field of artificial intelligence, machine learning\napproaches are increasingly being used for pattern recognition. In this study,\nan approach from machine learning perspectives is developed to automatically\nclassify the solar wind at 1 AU into four types: coronal-hole-origin,\nstreamer-belt-origin, sector-reversal-region-origin, and ejecta. By exhaustive\nenumeration, an eight-dimensional scheme ($B_T$, $N_P$, $T_P$, $V_P$,\n$N_{\\alpha p}$, $T_{exp}/T_P$, $S_p$, and $M_f$) is found to perform the best\namong 8191 combinations of 13 solar wind parameters. 10 popular supervised\nmachine learning models, namely $k$ Nearest Neighbors (KNN), Support Vector\nMachines with linear and Radial Basic Function kernels, Decision Tree, Random\nForest, Adaptive Boosting, Neural Network, Gaussian Naive Bayes, Quadratic\nDiscriminant Analysis, and Extreme Gradient Boosting, are applied to the\nlabeled solar wind data sets. Among them, KNN classifier obtains the highest\noverall classification accuracy, 92.8%. It significantly improves the accuracy\nby 9.6% over existing manual schemes. No solar wind composition measurements\nare needed, permitting our classification scheme to be applied to most solar\nwind spacecraft data. Besides, two application examples indicate that solar\nwind classification is helpful for the risk evaluation of predicted magnetic\nstorms and surface charging of geosynchronous spacecrafts.",
    "published": "2018-11-06T12:39:25Z",
    "updated": "2019-08-23T01:25:48Z",
    "authors": [
      "Hui Li",
      "Chi Wang",
      "Cui Tu",
      "Fei Xu"
    ],
    "link": "http://arxiv.org/abs/1811.02323v2",
    "pdf_link": "http://arxiv.org/pdf/1811.02323v2"
  },
  {
    "api_id": 515,
    "title": "Model-free Control of Chaos with Continuous Deep Q-learning",
    "summary": "The OGY method is one of control methods for a chaotic system. In the method,\nwe have to calculate a stabilizing periodic orbit embedded in its chaotic\nattractor. Thus, we cannot use this method in the case where a precise\nmathematical model of the chaotic system cannot be identified. In this case,\nthe delayed feedback control proposed by Pyragas is useful. However, even in\nthe delayed feedback control, we need the mathematical model to determine a\nfeedback gain that stabilizes the periodic orbit. To overcome this problem, we\npropose a model-free reinforcement learning algorithm to the design of a\ncontroller for the chaotic system. In recent years, model-free reinforcement\nlearning algorithms with deep neural networks have been paid much attention to.\nThose algorithms make it possible to control complex systems. However, it is\nknown that model-free reinforcement learning algorithms are not efficient\nbecause learners must explore their control policies over the entire state\nspace. Moreover, model-free reinforcement learning algorithms with deep neural\nnetworks have the disadvantage in taking much time to learn their control\noptimal policies. Thus, we propose a data-based control policy consisting of\ntwo steps, where we determine a region including the stabilizing periodic orbit\nfirst, and make the controller learn an optimal control policy for its\nstabilization. In the proposed method, the controller efficiently explores its\ncontrol policy only in the region.",
    "published": "2019-07-16T09:14:43Z",
    "updated": "2019-08-24T13:58:22Z",
    "authors": [
      "Junya Ikemoto",
      "Toshimitsu Ushio"
    ],
    "link": "http://arxiv.org/abs/1907.07775v3",
    "pdf_link": "http://arxiv.org/pdf/1907.07775v3"
  },
  {
    "api_id": 516,
    "title": "Deriving a Quantitative Relationship Between Resolution and Human\n  Classification Error",
    "summary": "For machine learning perception problems, human-level classification\nperformance is used as an estimate of top algorithm performance. Thus, it is\nimportant to understand as precisely as possible the factors that impact\nhuman-level performance. Knowing this 1) provides a benchmark for model\nperformance, 2) tells a project manager what type of data to obtain for human\nlabelers in order to get accurate labels, and 3) enables ground-truth\nanalysis--largely conducted by humans--to be carried out smoothly. In this\nempirical study, we explored the relationship between resolution and human\nclassification performance using the MNIST data set down-sampled to various\nresolutions. The quantitative heuristic we derived could prove useful for\npredicting machine model performance, predicting data storage requirements, and\nsaving valuable resources in the deployment of machine learning projects. It\nalso has the potential to be used in a wide variety of fields such as remote\nsensing, medical imaging, scientific imaging, and astronomy.",
    "published": "2019-08-24T18:34:13Z",
    "updated": "2019-08-24T18:34:13Z",
    "authors": [
      "Josiah I. Clark",
      "Caroline A. Clark"
    ],
    "link": "http://arxiv.org/abs/1908.09183v1",
    "pdf_link": "http://arxiv.org/pdf/1908.09183v1"
  },
  {
    "api_id": 517,
    "title": "A Convolutional Neural Network with Mapping Layers for Hyperspectral\n  Image Classification",
    "summary": "In this paper, we propose a convolutional neural network with mapping layers\n(MCNN) for hyperspectral image (HSI) classification. The proposed mapping\nlayers map the input patch into a low dimensional subspace by multilinear\nalgebra. We use our mapping layers to reduce the spectral and spatial\nredundancy and maintain most energy of the input. The feature extracted by our\nmapping layers can also reduce the number of following convolutional layers for\nfeature extraction. Our MCNN architecture avoids the declining accuracy with\nincreasing layers phenomenon of deep learning models for HSI classification and\nalso saves the training time for its effective mapping layers. Furthermore, we\nimpose the 3-D convolutional kernel on convolutional layer to extract the\nspectral-spatial features for HSI. We tested our MCNN on three datasets of\nIndian Pines, University of Pavia and Salinas, and we achieved the\nclassification accuracy of 98.3%, 99.5% and 99.3%, respectively. Experimental\nresults demonstrate that the proposed MCNN can significantly improve the\nclassification accuracy and save much time consumption.",
    "published": "2019-08-26T08:42:26Z",
    "updated": "2019-08-26T08:42:26Z",
    "authors": [
      "Rui Li",
      "Zhibin Pan",
      "Yang Wang",
      "Ping Wang"
    ],
    "link": "http://arxiv.org/abs/1908.09526v1",
    "pdf_link": "http://arxiv.org/pdf/1908.09526v1"
  },
  {
    "api_id": 518,
    "title": "Error Bounded Foreground and Background Modeling for Moving Object\n  Detection in Satellite Videos",
    "summary": "Detecting moving objects from ground-based videos is commonly achieved by\nusing background subtraction techniques. Low-rank matrix decomposition inspires\na set of state-of-the-art approaches for this task. It is integrated with\nstructured sparsity regularization to achieve background subtraction in the\ndeveloped method of Low-rank and Structured Sparse Decomposition (LSD).\nHowever, when this method is applied to satellite videos where spatial\nresolution is poor and targets' contrast to the background is low, its\nperformance is limited as the data no longer fits adequately either the\nforeground structure or the background model. In this paper, we handle these\nunexplained data explicitly and address the moving target detection from space\nas one of the pioneer studies. We propose a technique by extending the\ndecomposition formulation with bounded errors, named Extended Low-rank and\nStructured Sparse Decomposition (E-LSD). This formulation integrates low-rank\nbackground, structured sparse foreground and their residuals in a matrix\ndecomposition problem. We provide an effective solution by introducing an\nalternative treatment and adopting the direct extension of Alternating\nDirection Method of Multipliers (ADMM). The proposed E-LSD was validated on two\nsatellite videos, and experimental results demonstrate the improvement in\nbackground modeling with boosted moving object detection precision over\nstate-of-the-art methods.",
    "published": "2019-08-26T09:06:07Z",
    "updated": "2019-08-26T09:06:07Z",
    "authors": [
      "Junpeng Zhang",
      "Xiuping Jia",
      "Jiankun Hu"
    ],
    "link": "http://arxiv.org/abs/1908.09539v1",
    "pdf_link": "http://arxiv.org/pdf/1908.09539v1"
  },
  {
    "api_id": 519,
    "title": "Threat determination for radiation detection from the Remote Sensing\n  Laboratory",
    "summary": "The ability to search for radiation sources is of interest to the Homeland\nSecurity community. The hope is to find any radiation sources which may pose a\nreasonable chance for harm in a terrorist act. The best chance of success for\nsearch operations generally comes with fielding as many detection systems as\npossible. In doing this, the hoped for encounter with the threat source will\ninevitably be buried in an even larger number of encounters with\nnon-threatening radiation sources commonly used for many medical and industrial\nuse. The problem then becomes effectively filtering the non-threatening\nsources, and presenting the human-in-the-loop with a modest list of potential\nthreats. Our approach is to field a collection of detection systems which\nutilize soft-sensing algorithms for the purpose of discriminating potential\nthreat and non-threat objects, based on a variety of machine learning\ntechniques.",
    "published": "2019-08-27T13:44:34Z",
    "updated": "2019-08-27T13:44:34Z",
    "authors": [
      "William P. Ford",
      "Emma Hague",
      "Tom McCullough",
      "Eric Moore",
      "Johanna Turk"
    ],
    "link": "http://arxiv.org/abs/1908.11207v1",
    "pdf_link": "http://arxiv.org/pdf/1908.11207v1"
  },
  {
    "api_id": 520,
    "title": "DeepSUM: Deep neural network for Super-resolution of Unregistered\n  Multitemporal images",
    "summary": "Recently, convolutional neural networks (CNN) have been successfully applied\nto many remote sensing problems. However, deep learning techniques for\nmulti-image super-resolution from multitemporal unregistered imagery have\nreceived little attention so far. This work proposes a novel CNN-based\ntechnique that exploits both spatial and temporal correlations to combine\nmultiple images. This novel framework integrates the spatial registration task\ndirectly inside the CNN, and allows to exploit the representation learning\ncapabilities of the network to enhance registration accuracy. The entire\nsuper-resolution process relies on a single CNN with three main stages: shared\n2D convolutions to extract high-dimensional features from the input images; a\nsubnetwork proposing registration filters derived from the high-dimensional\nfeature representations; 3D convolutions for slow fusion of the features from\nmultiple images. The whole network can be trained end-to-end to recover a\nsingle high resolution image from multiple unregistered low resolution images.\nThe method presented in this paper is the winner of the PROBA-V\nsuper-resolution challenge issued by the European Space Agency.",
    "published": "2019-07-15T13:21:43Z",
    "updated": "2020-01-15T10:49:54Z",
    "authors": [
      "Andrea Bordone Molini",
      "Diego Valsesia",
      "Giulia Fracastoro",
      "Enrico Magli"
    ],
    "link": "http://arxiv.org/abs/1907.06490v2",
    "pdf_link": "http://arxiv.org/pdf/1907.06490v2"
  },
  {
    "api_id": 521,
    "title": "DeepSUM++: Non-local Deep Neural Network for Super-Resolution of\n  Unregistered Multitemporal Images",
    "summary": "Deep learning methods for super-resolution of a remote sensing scene from\nmultiple unregistered low-resolution images have recently gained attention\nthanks to a challenge proposed by the European Space Agency. This paper\npresents an evolution of the winner of the challenge, showing how incorporating\nnon-local information in a convolutional neural network allows to exploit\nself-similar patterns that provide enhanced regularization of the\nsuper-resolution problem. Experiments on the dataset of the challenge show\nimproved performance over the state-of-the-art, which does not exploit\nnon-local information.",
    "published": "2020-01-15T11:17:19Z",
    "updated": "2020-01-15T11:17:19Z",
    "authors": [
      "Andrea Bordone Molini",
      "Diego Valsesia",
      "Giulia Fracastoro",
      "Enrico Magli"
    ],
    "link": "http://arxiv.org/abs/2001.06342v1",
    "pdf_link": "http://arxiv.org/pdf/2001.06342v1"
  },
  {
    "api_id": 522,
    "title": "Towards Deep Unsupervised SAR Despeckling with Blind-Spot Convolutional\n  Neural Networks",
    "summary": "SAR despeckling is a problem of paramount importance in remote sensing, since\nit represents the first step of many scene analysis algorithms. Recently, deep\nlearning techniques have outperformed classical model-based despeckling\nalgorithms. However, such methods require clean ground truth images for\ntraining, thus resorting to synthetically speckled optical images since clean\nSAR images cannot be acquired. In this paper, inspired by recent works on\nblind-spot denoising networks, we propose a self-supervised Bayesian\ndespeckling method. The proposed method is trained employing only noisy images\nand can therefore learn features of real SAR images rather than synthetic data.\nWe show that the performance of the proposed network is very close to the\nsupervised training approach on synthetic data and competitive on real data.",
    "published": "2020-01-15T12:21:12Z",
    "updated": "2020-01-15T12:21:12Z",
    "authors": [
      "Andrea Bordone Molini",
      "Diego Valsesia",
      "Giulia Fracastoro",
      "Enrico Magli"
    ],
    "link": "http://arxiv.org/abs/2001.05264v1",
    "pdf_link": "http://arxiv.org/pdf/2001.05264v1"
  },
  {
    "api_id": 523,
    "title": "Flood Detection On Low Cost Orbital Hardware",
    "summary": "Satellite imaging is a critical technology for monitoring and responding to\nnatural disasters such as flooding. Despite the capabilities of modern\nsatellites, there is still much to be desired from the perspective of first\nresponse organisations like UNICEF. Two main challenges are rapid access to\ndata, and the ability to automatically identify flooded regions in images. We\ndescribe a prototypical flood segmentation system, identifying cloud, water and\nland, that could be deployed on a constellation of small satellites, performing\nprocessing on board to reduce downlink bandwidth by 2 orders of magnitude. We\ntarget PhiSat-1, part of the FSSCAT mission, which is planned to be launched by\nthe European Space Agency (ESA) near the start of 2020 as a proof of concept\nfor this new technology.",
    "published": "2019-10-04T13:29:46Z",
    "updated": "2020-01-15T21:03:29Z",
    "authors": [
      "Gonzalo Mateo-Garcia",
      "Silviu Oprea",
      "Lewis Smith",
      "Josh Veitch-Michaelis",
      "Guy Schumann",
      "Yarin Gal",
      "Atılım Güneş Baydin",
      "Dietmar Backes"
    ],
    "link": "http://arxiv.org/abs/1910.03019v3",
    "pdf_link": "http://arxiv.org/pdf/1910.03019v3"
  },
  {
    "api_id": 524,
    "title": "A Little Fog for a Large Turn",
    "summary": "Small, carefully crafted perturbations called adversarial perturbations can\neasily fool neural networks. However, these perturbations are largely additive\nand not naturally found. We turn our attention to the field of Autonomous\nnavigation wherein adverse weather conditions such as fog have a drastic effect\non the predictions of these systems. These weather conditions are capable of\nacting like natural adversaries that can help in testing models. To this end,\nwe introduce a general notion of adversarial perturbations, which can be\ncreated using generative models and provide a methodology inspired by\nCycle-Consistent Generative Adversarial Networks to generate adversarial\nweather conditions for a given image. Our formulation and results show that\nthese images provide a suitable testbed for steering models used in Autonomous\nnavigation models. Our work also presents a more natural and general definition\nof Adversarial perturbations based on Perceptual Similarity.",
    "published": "2020-01-16T15:09:48Z",
    "updated": "2020-01-16T15:09:48Z",
    "authors": [
      "Harshitha Machiraju",
      "Vineeth N Balasubramanian"
    ],
    "link": "http://arxiv.org/abs/2001.05873v1",
    "pdf_link": "http://arxiv.org/pdf/2001.05873v1"
  },
  {
    "api_id": 525,
    "title": "Software-defined Design Space Exploration for an Efficient DNN\n  Accelerator Architecture",
    "summary": "Deep neural networks (DNNs) have been shown to outperform conventional\nmachine learning algorithms across a wide range of applications, e.g., image\nrecognition, object detection, robotics, and natural language processing.\nHowever, the high computational complexity of DNNs often necessitates extremely\nfast and efficient hardware. The problem gets worse as the size of neural\nnetworks grows exponentially. As a result, customized hardware accelerators\nhave been developed to accelerate DNN processing without sacrificing model\naccuracy. However, previous accelerator design studies have not fully\nconsidered the characteristics of the target applications, which may lead to\nsub-optimal architecture designs. On the other hand, new DNN models have been\ndeveloped for better accuracy, but their compatibility with the underlying\nhardware accelerator is often overlooked. In this article, we propose an\napplication-driven framework for architectural design space exploration of DNN\naccelerators. This framework is based on a hardware analytical model of\nindividual DNN operations. It models the accelerator design task as a\nmulti-dimensional optimization problem. We demonstrate that it can be\nefficaciously used in application-driven accelerator architecture design. Given\na target DNN, the framework can generate efficient accelerator design solutions\nwith optimized performance and area. Furthermore, we explore the opportunity to\nuse the framework for accelerator configuration optimization under simultaneous\ndiverse DNN applications. The framework is also capable of improving neural\nnetwork models to best fit the underlying hardware resources.",
    "published": "2019-03-18T19:03:50Z",
    "updated": "2020-01-16T20:44:29Z",
    "authors": [
      "Ye Yu",
      "Yingmin Li",
      "Shuai Che",
      "Niraj K. Jha",
      "Weifeng Zhang"
    ],
    "link": "http://arxiv.org/abs/1903.07676v2",
    "pdf_link": "http://arxiv.org/pdf/1903.07676v2"
  },
  {
    "api_id": 526,
    "title": "CNN-based InSAR Denoising and Coherence Metric",
    "summary": "Interferometric Synthetic Aperture Radar (InSAR) imagery for estimating\nground movement, based on microwaves reflected off ground targets is gaining\nincreasing importance in remote sensing. However, noise corrupts microwave\nreflections received at satellite and contaminates the signal's wrapped phase.\nWe introduce Convolutional Neural Networks (CNNs) to this problem domain and\nshow the effectiveness of autoencoder CNN architectures to learn InSAR image\ndenoising filters in the absence of clean ground truth images, and for artefact\nreduction in estimated coherence through intelligent preprocessing of training\ndata. We compare our results with four established methods to illustrate\nsuperiority of proposed method.",
    "published": "2020-01-20T03:20:29Z",
    "updated": "2020-01-20T03:20:29Z",
    "authors": [
      "Subhayan Mukherjee",
      "Aaron Zimmer",
      "Navaneeth Kamballur Kottayil",
      "Xinyao Sun",
      "Parwant Ghuman",
      "Irene Cheng"
    ],
    "link": "http://arxiv.org/abs/2001.06954v1",
    "pdf_link": "http://arxiv.org/pdf/2001.06954v1"
  },
  {
    "api_id": 527,
    "title": "CNN-based InSAR Coherence Classification",
    "summary": "Interferometric Synthetic Aperture Radar (InSAR) imagery based on microwaves\nreflected off ground targets is becoming increasingly important in remote\nsensing for ground movement estimation. However, the reflections are\ncontaminated by noise, which distorts the signal's wrapped phase. Demarcation\nof image regions based on degree of contamination (\"coherence\") is an important\ncomponent of the InSAR processing pipeline. We introduce Convolutional Neural\nNetworks (CNNs) to this problem domain and show their effectiveness in\nimproving coherence-based demarcation and reducing misclassifications in\ncompletely incoherent regions through intelligent preprocessing of training\ndata. Quantitative and qualitative comparisons prove superiority of proposed\nmethod over three established methods.",
    "published": "2020-01-20T03:25:38Z",
    "updated": "2020-01-20T03:25:38Z",
    "authors": [
      "Subhayan Mukherjee",
      "Aaron Zimmer",
      "Xinyao Sun",
      "Parwant Ghuman",
      "Irene Cheng"
    ],
    "link": "http://arxiv.org/abs/2001.06956v1",
    "pdf_link": "http://arxiv.org/pdf/2001.06956v1"
  },
  {
    "api_id": 528,
    "title": "DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion\n  Frames",
    "summary": "We present Decentralized Distributed Proximal Policy Optimization (DD-PPO), a\nmethod for distributed reinforcement learning in resource-intensive simulated\nenvironments. DD-PPO is distributed (uses multiple machines), decentralized\n(lacks a centralized server), and synchronous (no computation is ever stale),\nmaking it conceptually simple and easy to implement. In our experiments on\ntraining virtual robots to navigate in Habitat-Sim, DD-PPO exhibits near-linear\nscaling -- achieving a speedup of 107x on 128 GPUs over a serial\nimplementation. We leverage this scaling to train an agent for 2.5 Billion\nsteps of experience (the equivalent of 80 years of human experience) -- over 6\nmonths of GPU-time training in under 3 days of wall-clock time with 64 GPUs.\n  This massive-scale training not only sets the state of art on Habitat\nAutonomous Navigation Challenge 2019, but essentially solves the task\n--near-perfect autonomous navigation in an unseen environment without access to\na map, directly from an RGB-D camera and a GPS+Compass sensor. Fortuitously,\nerror vs computation exhibits a power-law-like distribution; thus, 90% of peak\nperformance is obtained relatively early (at 100 million steps) and relatively\ncheaply (under 1 day with 8 GPUs). Finally, we show that the scene\nunderstanding and navigation policies learned can be transferred to other\nnavigation tasks -- the analog of ImageNet pre-training + task-specific\nfine-tuning for embodied AI. Our model outperforms ImageNet pre-trained CNNs on\nthese transfer tasks and can serve as a universal resource (all models and code\nare publicly available).",
    "published": "2019-11-01T13:07:37Z",
    "updated": "2020-01-20T04:18:58Z",
    "authors": [
      "Erik Wijmans",
      "Abhishek Kadian",
      "Ari Morcos",
      "Stefan Lee",
      "Irfan Essa",
      "Devi Parikh",
      "Manolis Savva",
      "Dhruv Batra"
    ],
    "link": "http://arxiv.org/abs/1911.00357v2",
    "pdf_link": "http://arxiv.org/pdf/1911.00357v2"
  },
  {
    "api_id": 529,
    "title": "Spectral Pyramid Graph Attention Network for Hyperspectral Image\n  Classification",
    "summary": "Convolutional neural networks (CNN) have made significant advances in\nhyperspectral image (HSI) classification. However, standard convolutional\nkernel neglects the intrinsic connections between data points, resulting in\npoor region delineation and small spurious predictions. Furthermore, HSIs have\na unique continuous data distribution along the high dimensional spectrum\ndomain - much remains to be addressed in characterizing the spectral contexts\nconsidering the prohibitively high dimensionality and improving reasoning\ncapability in light of the limited amount of labelled data. This paper presents\na novel architecture which explicitly addresses these two issues. Specifically,\nwe design an architecture to encode the multiple spectral contextual\ninformation in the form of spectral pyramid of multiple embedding spaces. In\neach spectral embedding space, we propose graph attention mechanism to\nexplicitly perform interpretable reasoning in the spatial domain based on the\nconnection in spectral feature space. Experiments on three HSI datasets\ndemonstrate that the proposed architecture can significantly improve the\nclassification accuracy compared with the existing methods.",
    "published": "2020-01-20T13:49:43Z",
    "updated": "2020-01-20T13:49:43Z",
    "authors": [
      "Tinghuai Wang",
      "Guangming Wang",
      "Kuan Eeik Tan",
      "Donghui Tan"
    ],
    "link": "http://arxiv.org/abs/2001.07108v1",
    "pdf_link": "http://arxiv.org/pdf/2001.07108v1"
  },
  {
    "api_id": 530,
    "title": "SMOKE: Single-Stage Monocular 3D Object Detection via Keypoint\n  Estimation",
    "summary": "Estimating 3D orientation and translation of objects is essential for\ninfrastructure-less autonomous navigation and driving. In case of monocular\nvision, successful methods have been mainly based on two ingredients: (i) a\nnetwork generating 2D region proposals, (ii) a R-CNN structure predicting 3D\nobject pose by utilizing the acquired regions of interest. We argue that the 2D\ndetection network is redundant and introduces non-negligible noise for 3D\ndetection. Hence, we propose a novel 3D object detection method, named SMOKE,\nin this paper that predicts a 3D bounding box for each detected object by\ncombining a single keypoint estimate with regressed 3D variables. As a second\ncontribution, we propose a multi-step disentangling approach for constructing\nthe 3D bounding box, which significantly improves both training convergence and\ndetection accuracy. In contrast to previous 3D detection techniques, our method\ndoes not require complicated pre/post-processing, extra data, and a refinement\nstage. Despite of its structural simplicity, our proposed SMOKE network\noutperforms all existing monocular 3D detection methods on the KITTI dataset,\ngiving the best state-of-the-art result on both 3D object detection and Bird's\neye view evaluation. The code will be made publicly available.",
    "published": "2020-02-24T08:15:36Z",
    "updated": "2020-02-24T08:15:36Z",
    "authors": [
      "Zechen Liu",
      "Zizhang Wu",
      "Roland Tóth"
    ],
    "link": "http://arxiv.org/abs/2002.10111v1",
    "pdf_link": "http://arxiv.org/pdf/2002.10111v1"
  },
  {
    "api_id": 531,
    "title": "OptComNet: Optimized Neural Networks for Low-Complexity Channel\n  Estimation",
    "summary": "The use of machine learning methods to tackle challenging physical layer\nsignal processing tasks has attracted significant attention. In this work, we\nfocus on the use of neural networks (NNs) to perform pilot-assisted channel\nestimation in an OFDM system in order to avoid the challenging task of\nestimating the channel covariance matrix. In particular, we perform a\nsystematic design-space exploration of NN configurations, quantization, and\npruning in order to improve feedforward NN architectures that are typically\nused in the literature for the channel estimation task. We show that choosing\nan appropriate NN architecture is crucial to reduce the complexity of\nNN-assisted channel estimation methods. Moreover, we demonstrate that,\nsimilarly to other applications and domains, careful quantization and pruning\ncan lead to significant complexity reduction with a negligible performance\ndegradation. Finally, we show that using a solution with multiple distinct NNs\ntrained for different signal-to-noise ratios interestingly leads to lower\noverall computational complexity and storage requirements, while achieving a\nbetter performance with respect to using a single NN trained for the entire SNR\nrange.",
    "published": "2020-02-24T19:13:26Z",
    "updated": "2020-02-24T19:13:26Z",
    "authors": [
      "Michel van Lier",
      "Alexios Balatsoukas-Stimming",
      "Henk Corporaaal",
      "Zoran Zivkovic"
    ],
    "link": "http://arxiv.org/abs/2002.10493v1",
    "pdf_link": "http://arxiv.org/pdf/2002.10493v1"
  },
  {
    "api_id": 532,
    "title": "Domain Adaptation for Robot Predictive Maintenance Systems",
    "summary": "Industrial robots play an increasingly important role in a growing number of\nfields. For example, robotics is used to increase productivity while reducing\ncosts in various aspects of manufacturing. Since robots are often set up in\nproduction lines, the breakdown of a single robot has a negative impact on the\nentire process, in the worst case bringing the whole line to a halt until the\nissue is resolved, leading to substantial financial losses due to the\nunforeseen downtime. Therefore, predictive maintenance systems based on the\ninternal signals of robots have gained attention as an essential component of\nrobotics service offerings. The main shortcoming of existing predictive\nmaintenance algorithms is that the extracted features typically differ\nsignificantly from the learnt model when the operation of the robot changes,\nincurring false alarms. In order to mitigate this problem, predictive\nmaintenance algorithms require the model to be retrained with normal data of\nthe new operation. In this paper, we propose a novel solution based on transfer\nlearning to pass the knowledge of the trained model from one operation to\nanother in order to prevent the need for retraining and to eliminate such false\nalarms. The deployment of the proposed unsupervised transfer learning algorithm\non real-world datasets demonstrates that the algorithm can not only distinguish\nbetween operation and mechanical condition change, it further yields a sharper\ndeviation from the trained model in case of a mechanical condition change and\nthus detects mechanical issues with higher confidence.",
    "published": "2018-09-23T16:29:29Z",
    "updated": "2020-02-24T19:37:38Z",
    "authors": [
      "Arash Golibagh Mahyari",
      "Thomas Locker"
    ],
    "link": "http://arxiv.org/abs/1809.08626v3",
    "pdf_link": "http://arxiv.org/pdf/1809.08626v3"
  },
  {
    "api_id": 533,
    "title": "Simple Regret Minimization for Contextual Bandits",
    "summary": "There are two variants of the classical multi-armed bandit (MAB) problem that\nhave received considerable attention from machine learning researchers in\nrecent years: contextual bandits and simple regret minimization. Contextual\nbandits are a sub-class of MABs where, at every time step, the learner has\naccess to side information that is predictive of the best arm. Simple regret\nminimization assumes that the learner only incurs regret after a pure\nexploration phase. In this work, we study simple regret minimization for\ncontextual bandits. Motivated by applications where the learner has separate\ntraining and autonomous modes, we assume that the learner experiences a pure\nexploration phase, where feedback is received after every action but no regret\nis incurred, followed by a pure exploitation phase in which regret is incurred\nbut there is no feedback. We present the Contextual-Gap algorithm and establish\nperformance guarantees on the simple regret, i.e., the regret during the pure\nexploitation phase. Our experiments examine a novel application to adaptive\nsensor selection for magnetic field estimation in interplanetary spacecraft,\nand demonstrate considerable improvement over algorithms designed to minimize\nthe cumulative regret.",
    "published": "2018-10-17T03:17:26Z",
    "updated": "2020-02-25T20:13:42Z",
    "authors": [
      "Aniket Anand Deshmukh",
      "Srinagesh Sharma",
      "James W. Cutler",
      "Mark Moldwin",
      "Clayton Scott"
    ],
    "link": "http://arxiv.org/abs/1810.07371v2",
    "pdf_link": "http://arxiv.org/pdf/1810.07371v2"
  },
  {
    "api_id": 534,
    "title": "Super-Resolving Commercial Satellite Imagery Using Realistic Training\n  Data",
    "summary": "In machine learning based single image super-resolution, the degradation\nmodel is embedded in training data generation. However, most existing satellite\nimage super-resolution methods use a simple down-sampling model with a fixed\nkernel to create training images. These methods work fine on synthetic data,\nbut do not perform well on real satellite images. We propose a realistic\ntraining data generation model for commercial satellite imagery products, which\nincludes not only the imaging process on satellites but also the post-process\non the ground. We also propose a convolutional neural network optimized for\nsatellite images. Experiments show that the proposed training data generation\nmodel is able to improve super-resolution performance on real satellite images.",
    "published": "2020-02-26T01:18:51Z",
    "updated": "2020-02-26T01:18:51Z",
    "authors": [
      "Xiang Zhu",
      "Hossein Talebi",
      "Xinwei Shi",
      "Feng Yang",
      "Peyman Milanfar"
    ],
    "link": "http://arxiv.org/abs/2002.11248v1",
    "pdf_link": "http://arxiv.org/pdf/2002.11248v1"
  },
  {
    "api_id": 535,
    "title": "Solar Flare Intensity Prediction with Machine Learning Models",
    "summary": "We develop a mixed Long Short Term Memory (LSTM) regression model to predict\nthe maximum solar flare intensity within a 24-hour time window 0$\\sim$24,\n6$\\sim$30, 12$\\sim$36 and 24$\\sim$48 hours ahead of time using 6, 12, 24 and 48\nhours of data (predictors) for each Helioseismic and Magnetic Imager (HMI)\nActive Region Patch (HARP). The model makes use of (1) the Space-weather HMI\nActive Region Patch (SHARP) parameters as predictors and (2) the exact flare\nintensities instead of class labels recorded in the Geostationary Operational\nEnvironmental Satellites (GOES) data set, which serves as the source of the\nresponse variables. Compared to solar flare classification, the model offers us\nmore detailed information about the exact maximum flux level, i.e. intensity,\nfor each occurrence of a flare. We also consider classification models built on\ntop of the regression model and obtain better results in solar flare\nclassifications. Our results suggest that the most efficient time period for\npredicting the solar activity is within 24 hours before the prediction time\nusing the SHARP parameters and the LSTM model.",
    "published": "2019-12-12T18:36:16Z",
    "updated": "2020-02-26T05:43:26Z",
    "authors": [
      "Zhenbang Jiao",
      "Hu Sun",
      "Xiantong Wang",
      "Ward Manchester",
      "Tamas Gombosi",
      "Alfred Hero",
      "Yang Chen"
    ],
    "link": "http://arxiv.org/abs/1912.06120v2",
    "pdf_link": "http://arxiv.org/pdf/1912.06120v2"
  },
  {
    "api_id": 536,
    "title": "Development of an advanced Compton telescope for MeV-range gamma-ray\n  astronomy",
    "summary": "An advanced Compton telescope appears to be the best instrument concept for\nthe next generation gamma-ray space observatory in the MeV range. A first\nprototype of advanced Compton telescope is being developed to match the\nconstraints of a nano satellite mission, with the scientific objective of\nmeasuring gamma-ray burst prompt emission polarization. Our instrumental\ndevelopments for this project are focusing on the position-sensitive\ncalorimeter module, made of a monolithic inorganic CeBr$_3$ scintillator read\nby a pixelated photodetector. 3D position reconstruction is obtained by\ndeep-learning algorithms that have been optimized down to an uncertainty of 2\nmm for each spatial direction.",
    "published": "2020-02-26T16:11:03Z",
    "updated": "2020-02-26T16:11:03Z",
    "authors": [
      "Adrien Laviron",
      "Valentin Gourlaouen",
      "Clarisse Hamadache",
      "Corentin Hiver",
      "Jürgen Kiener",
      "Jean Peyré",
      "Vincent Tatischeff"
    ],
    "link": "http://arxiv.org/abs/2002.11586v1",
    "pdf_link": "http://arxiv.org/pdf/2002.11586v1"
  },
  {
    "api_id": 537,
    "title": "Learning Navigation Costs from Demonstration in Partially Observable\n  Environments",
    "summary": "This paper focuses on inverse reinforcement learning (IRL) to enable safe and\nefficient autonomous navigation in unknown partially observable environments.\nThe objective is to infer a cost function that explains expert-demonstrated\nnavigation behavior while relying only on the observations and state-control\ntrajectory used by the expert. We develop a cost function representation\ncomposed of two parts: a probabilistic occupancy encoder, with recurrent\ndependence on the observation sequence, and a cost encoder, defined over the\noccupancy features. The representation parameters are optimized by\ndifferentiating the error between demonstrated controls and a control policy\ncomputed from the cost encoder. Such differentiation is typically computed by\ndynamic programming through the value function over the whole state space. We\nobserve that this is inefficient in large partially observable environments\nbecause most states are unexplored. Instead, we rely on a closed-form\nsubgradient of the cost-to-go obtained only over a subset of promising states\nvia an efficient motion-planning algorithm such as A* or RRT. Our experiments\nshow that our model exceeds the accuracy of baseline IRL algorithms in robot\nnavigation tasks, while substantially improving the efficiency of training and\ntest-time inference.",
    "published": "2020-02-26T17:15:10Z",
    "updated": "2020-02-26T17:15:10Z",
    "authors": [
      "Tianyu Wang",
      "Vikas Dhiman",
      "Nikolay Atanasov"
    ],
    "link": "http://arxiv.org/abs/2002.11637v1",
    "pdf_link": "http://arxiv.org/pdf/2002.11637v1"
  },
  {
    "api_id": 538,
    "title": "Proceedings 8th International Workshop on Theorem Proving Components for\n  Educational Software",
    "summary": "This EPTCS volume contains the proceedings of the ThEdu'19 workshop, promoted\non August 25, 2019, as a satellite event of CADE-27, in Natal, Brazil.\nRepresenting the eighth installment of the ThEdu series, ThEdu'19 was a vibrant\nworkshop, with an invited talk by Sarah Winkler, four contributions, and the\nfirst edition of a Geometry Automated Provers Competition. After the workshop\nan open call for papers was issued and attracted seven submissions, six of\nwhich have been accepted by the reviewers, and collected in the present\npost-proceedings volume.\n  The ThEdu series pursues the smooth transition from an intuitive way of doing\nmathematics at secondary school to a more formal approach to the subject in\nSTEM education, while favoring software support for this transition by\nexploiting the power of theorem-proving technologies.\n  The volume editors hope that this collection of papers will further promote\nthe development of theorem-proving-based software, and that it will collaborate\non improving mutual understanding between computer mathematicians and\nstakeholders in education.",
    "published": "2020-02-27T03:10:08Z",
    "updated": "2020-02-27T03:10:08Z",
    "authors": [
      "Pedro Quaresma",
      "Walther Neuper",
      "João Marcos"
    ],
    "link": "http://arxiv.org/abs/2002.11895v1",
    "pdf_link": "http://arxiv.org/pdf/2002.11895v1"
  },
  {
    "api_id": 539,
    "title": "Inferring Nighttime Satellite Imagery from Human Mobility",
    "summary": "Nighttime lights satellite imagery has been used for decades as a uniform,\nglobal source of data for studying a wide range of socioeconomic factors.\nRecently, another more terrestrial source is producing data with similarly\nuniform global coverage: anonymous and aggregated smart phone location. This\ndata, which measures the movement patterns of people and populations rather\nthan the light they produce, could prove just as valuable in decades to come.\nIn fact, since human mobility is far more directly related to the socioeconomic\nvariables being predicted, it has an even greater potential. Additionally,\nsince cell phone locations can be aggregated in real time while preserving\nindividual user privacy, it will be possible to conduct studies that would\npreviously have been impossible because they require data from the present. Of\ncourse, it will take quite some time to establish the new techniques necessary\nto apply human mobility data to problems traditionally studied with satellite\nimagery and to conceptualize and develop new real time applications. In this\nstudy we demonstrate that it is possible to accelerate this process by\ninferring artificial nighttime satellite imagery from human mobility data,\nwhile maintaining a strong differential privacy guarantee. We also show that\nthese artificial maps can be used to infer socioeconomic variables, often with\ngreater accuracy than using actual satellite imagery. Along the way, we find\nthat the relationship between mobility and light emissions is both nonlinear\nand varies considerably around the globe. Finally, we show that models based on\nhuman mobility can significantly improve our understanding of society at a\nglobal scale.",
    "published": "2020-02-28T14:25:11Z",
    "updated": "2020-02-28T14:25:11Z",
    "authors": [
      "Brian Dickinson",
      "Gourab Ghoshal",
      "Xerxes Dotiwalla",
      "Adam Sadilek",
      "Henry Kautz"
    ],
    "link": "http://arxiv.org/abs/2003.07691v1",
    "pdf_link": "http://arxiv.org/pdf/2003.07691v1"
  },
  {
    "api_id": 540,
    "title": "HybridDNN: A Framework for High-Performance Hybrid DNN Accelerator\n  Design and Implementation",
    "summary": "To speedup Deep Neural Networks (DNN) accelerator design and enable effective\nimplementation, we propose HybridDNN, a framework for building high-performance\nhybrid DNN accelerators and delivering FPGA-based hardware implementations.\nNovel techniques include a highly flexible and scalable architecture with a\nhybrid Spatial/Winograd convolution (CONV) Processing Engine (PE), a\ncomprehensive design space exploration tool, and a complete design flow to\nfully support accelerator design and implementation. Experimental results show\nthat the accelerators generated by HybridDNN can deliver 3375.7 and 83.3 GOPS\non a high-end FPGA (VU9P) and an embedded FPGA (PYNQ-Z1), respectively, which\nachieve a 1.8x higher performance improvement compared to the state-of-art\naccelerator designs. This demonstrates that HybridDNN is flexible and scalable\nand can target both cloud and embedded hardware platforms with vastly different\nresource constraints.",
    "published": "2020-04-08T04:28:38Z",
    "updated": "2020-04-08T04:28:38Z",
    "authors": [
      "Hanchen Ye",
      "Xiaofan Zhang",
      "Zhize Huang",
      "Gengsheng Chen",
      "Deming Chen"
    ],
    "link": "http://arxiv.org/abs/2004.03804v1",
    "pdf_link": "http://arxiv.org/pdf/2004.03804v1"
  },
  {
    "api_id": 541,
    "title": "Change Detection in Heterogeneous Optical and SAR Remote Sensing Images\n  via Deep Homogeneous Feature Fusion",
    "summary": "Change detection in heterogeneous remote sensing images is crucial for\ndisaster damage assessment. Recent methods use homogenous transformation, which\ntransforms the heterogeneous optical and SAR remote sensing images into the\nsame feature space, to achieve change detection. Such transformations mainly\noperate on the low-level feature space and may corrupt the semantic content,\ndeteriorating the performance of change detection. To solve this problem, this\npaper presents a new homogeneous transformation model termed deep homogeneous\nfeature fusion (DHFF) based on image style transfer (IST). Unlike the existing\nmethods, the DHFF method segregates the semantic content and the style features\nin the heterogeneous images to perform homogeneous transformation. The\nseparation of the semantic content and the style in homogeneous transformation\nprevents the corruption of image semantic content, especially in the regions of\nchange. In this way, the detection performance is improved with accurate\nhomogeneous transformation. Furthermore, we present a new iterative IST (IIST)\nstrategy, where the cost function in each IST iteration measures and thus\nmaximizes the feature homogeneity in additional new feature subspaces for\nchange detection. After that, change detection is accomplished accurately on\nthe original and the transformed images that are in the same feature space.\nReal remote sensing images acquired by SAR and optical satellites are utilized\nto evaluate the performance of the proposed method. The experiments demonstrate\nthat the proposed DHFF method achieves significant improvement for change\ndetection in heterogeneous optical and SAR remote sensing images, in terms of\nboth accuracy rate and Kappa index.",
    "published": "2020-04-08T06:27:37Z",
    "updated": "2020-04-08T06:27:37Z",
    "authors": [
      "Xiao Jiang",
      "Gang Li",
      "Yu Liu",
      "Xiao-Ping Zhang",
      "You He"
    ],
    "link": "http://arxiv.org/abs/2004.03830v1",
    "pdf_link": "http://arxiv.org/pdf/2004.03830v1"
  },
  {
    "api_id": 542,
    "title": "Super-resolution of multispectral satellite images using convolutional\n  neural networks",
    "summary": "Super-resolution aims at increasing image resolution by algorithmic means and\nhas progressed over the recent years due to advances in the fields of computer\nvision and deep learning. Convolutional Neural Networks based on a variety of\narchitectures have been applied to the problem, e.g. autoencoders and residual\nnetworks. While most research focuses on the processing of photographs\nconsisting only of RGB color channels, little work can be found concentrating\non multi-band, analytic satellite imagery. Satellite images often include a\npanchromatic band, which has higher spatial resolution but lower spectral\nresolution than the other bands. In the field of remote sensing, there is a\nlong tradition of applying pan-sharpening to satellite images, i.e. bringing\nthe multispectral bands to the higher spatial resolution by merging them with\nthe panchromatic band. To our knowledge there are so far no approaches to\nsuper-resolution which take advantage of the panchromatic band. In this paper\nwe propose a method to train state-of-the-art CNNs using pairs of\nlower-resolution multispectral and high-resolution pan-sharpened image tiles in\norder to create super-resolved analytic images. The derived quality metrics\nshow that the method improves information content of the processed images. We\ncompare the results created by four CNN architectures, with RedNet30 performing\nbest.",
    "published": "2020-02-03T07:06:36Z",
    "updated": "2020-04-08T06:30:47Z",
    "authors": [
      "M. U. Müller",
      "N. Ekhtiari",
      "R. M. Almeida",
      "C. Rieke"
    ],
    "link": "http://arxiv.org/abs/2002.00580v2",
    "pdf_link": "http://arxiv.org/pdf/2002.00580v2"
  },
  {
    "api_id": 543,
    "title": "S2A: Wasserstein GAN with Spatio-Spectral Laplacian Attention for\n  Multi-Spectral Band Synthesis",
    "summary": "Intersection of adversarial learning and satellite image processing is an\nemerging field in remote sensing. In this study, we intend to address synthesis\nof high resolution multi-spectral satellite imagery using adversarial learning.\nGuided by the discovery of attention mechanism, we regulate the process of band\nsynthesis through spatio-spectral Laplacian attention. Further, we use\nWasserstein GAN with gradient penalty norm to improve training and stability of\nadversarial learning. In this regard, we introduce a new cost function for the\ndiscriminator based on spatial attention and domain adaptation loss. We\ncritically analyze the qualitative and quantitative results compared with\nstate-of-the-art methods using widely adopted evaluation metrics. Our\nexperiments on datasets of three different sensors, namely LISS-3, LISS-4, and\nWorldView-2 show that attention learning performs favorably against\nstate-of-the-art methods. Using the proposed method we provide an additional\ndata product in consistent with existing high resolution bands. Furthermore, we\nsynthesize over 4000 high resolution scenes covering various terrains to\nanalyze scientific fidelity. At the end, we demonstrate plausible large scale\nreal world applications of the synthesized band.",
    "published": "2020-04-08T08:07:00Z",
    "updated": "2020-04-08T08:07:00Z",
    "authors": [
      "Litu Rout",
      "Indranil Misra",
      "S Manthira Moorthi",
      "Debajyoti Dhar"
    ],
    "link": "http://arxiv.org/abs/2004.03867v1",
    "pdf_link": "http://arxiv.org/pdf/2004.03867v1"
  },
  {
    "api_id": 544,
    "title": "Monte-Carlo Siamese Policy on Actor for Satellite Image Super Resolution",
    "summary": "In the past few years supervised and adversarial learning have been widely\nadopted in various complex computer vision tasks. It seems natural to wonder\nwhether another branch of artificial intelligence, commonly known as\nReinforcement Learning (RL) can benefit such complex vision tasks. In this\nstudy, we explore the plausible usage of RL in super resolution of remote\nsensing imagery. Guided by recent advances in super resolution, we propose a\ntheoretical framework that leverages the benefits of supervised and\nreinforcement learning. We argue that a straightforward implementation of RL is\nnot adequate to address ill-posed super resolution as the action variables are\nnot fully known. To tackle this issue, we propose to parameterize action\nvariables by matrices, and train our policy network using Monte-Carlo sampling.\nWe study the implications of parametric action space in a model-free\nenvironment from theoretical and empirical perspective. Furthermore, we analyze\nthe quantitative and qualitative results on both remote sensing and non-remote\nsensing datasets. Based on our experiments, we report considerable improvement\nover state-of-the-art methods by encapsulating supervised models in a\nreinforcement learning framework.",
    "published": "2020-04-08T08:39:08Z",
    "updated": "2020-04-08T08:39:08Z",
    "authors": [
      "Litu Rout",
      "Saumyaa Shah",
      "S Manthira Moorthi",
      "Debajyoti Dhar"
    ],
    "link": "http://arxiv.org/abs/2004.03879v1",
    "pdf_link": "http://arxiv.org/pdf/2004.03879v1"
  },
  {
    "api_id": 545,
    "title": "Comparison of Evolving Granular Classifiers applied to Anomaly Detection\n  for Predictive Maintenance in Computing Centers",
    "summary": "Log-based predictive maintenance of computing centers is a main concern\nregarding the worldwide computing grid that supports the CERN (European\nOrganization for Nuclear Research) physics experiments. A log, as\nevent-oriented adhoc information, is quite often given as unstructured big\ndata. Log data processing is a time-consuming computational task. The goal is\nto grab essential information from a continuously changeable grid environment\nto construct a classification model. Evolving granular classifiers are suited\nto learn from time-varying log streams and, therefore, perform online\nclassification of the severity of anomalies. We formulated a 4-class online\nanomaly classification problem, and employed time windows between landmarks and\ntwo granular computing methods, namely, Fuzzy-set-Based evolving Modeling\n(FBeM) and evolving Granular Neural Network (eGNN), to model and monitor\nlogging activity rate. The results of classification are of utmost importance\nfor predictive maintenance because priority can be given to specific time\nintervals in which the classifier indicates the existence of high or medium\nseverity anomalies.",
    "published": "2020-04-08T14:08:50Z",
    "updated": "2020-04-08T14:08:50Z",
    "authors": [
      "Leticia Decker",
      "Daniel Leite",
      "Fabio Viola",
      "Daniele Bonacorsi"
    ],
    "link": "http://arxiv.org/abs/2005.04156v1",
    "pdf_link": "http://arxiv.org/pdf/2005.04156v1"
  },
  {
    "api_id": 546,
    "title": "The GeoLifeCLEF 2020 Dataset",
    "summary": "Understanding the geographic distribution of species is a key concern in\nconservation. By pairing species occurrences with environmental features,\nresearchers can model the relationship between an environment and the species\nwhich may be found there. To facilitate research in this area, we present the\nGeoLifeCLEF 2020 dataset, which consists of 1.9 million species observations\npaired with high-resolution remote sensing imagery, land cover data, and\naltitude, in addition to traditional low-resolution climate and soil variables.\nWe also discuss the GeoLifeCLEF 2020 competition, which aims to use this\ndataset to advance the state-of-the-art in location-based species\nrecommendation.",
    "published": "2020-04-08T18:30:00Z",
    "updated": "2020-04-08T18:30:00Z",
    "authors": [
      "Elijah Cole",
      "Benjamin Deneu",
      "Titouan Lorieul",
      "Maximilien Servajean",
      "Christophe Botella",
      "Dan Morris",
      "Nebojsa Jojic",
      "Pierre Bonnet",
      "Alexis Joly"
    ],
    "link": "http://arxiv.org/abs/2004.04192v1",
    "pdf_link": "http://arxiv.org/pdf/2004.04192v1"
  },
  {
    "api_id": 547,
    "title": "A single image deep learning approach to restoration of corrupted remote\n  sensing products",
    "summary": "Remote sensing images are used for a variety of analyses, from agricultural\nmonitoring, to disaster relief, to resource planning, among others. The images\ncan be corrupted due to a number of reasons, including instrument errors and\nnatural obstacles such as clouds. We present here a novel approach for\nreconstruction of missing information in such cases using only the corrupted\nimage as the input. The Deep Image Prior methodology eliminates the need for a\npre-trained network or an image database. It is shown that the approach easily\nbeats the performance of traditional single-image methods.",
    "published": "2020-04-08T19:11:32Z",
    "updated": "2020-04-08T19:11:32Z",
    "authors": [
      "Anna Petrovskaia",
      "Raghavendra B. Jana",
      "Ivan V. Oseledets"
    ],
    "link": "http://arxiv.org/abs/2004.04209v1",
    "pdf_link": "http://arxiv.org/pdf/2004.04209v1"
  },
  {
    "api_id": 548,
    "title": "Learning Pose Estimation for UAV Autonomous Navigation andLanding Using\n  Visual-Inertial Sensor Data",
    "summary": "In this work, we propose a new learning approach for autonomous navigation\nand landing of an Unmanned-Aerial-Vehicle (UAV). We develop a multimodal fusion\nof deep neural architectures for visual-inertial odometry. We train the model\nin an end-to-end fashion to estimate the current vehicle pose from streams of\nvisual and inertial measurements. We first evaluate the accuracy of our\nestimation by comparing the prediction of the model to traditional algorithms\non the publicly available EuRoC MAV dataset. The results illustrate a $25 \\%$\nimprovement in estimation accuracy over the baseline. Finally, we integrate the\narchitecture in the closed-loop flight control system of Airsim - a plugin\nsimulator for Unreal Engine - and we provide simulation results for autonomous\nnavigation and landing.",
    "published": "2019-12-10T06:37:30Z",
    "updated": "2020-04-09T11:18:55Z",
    "authors": [
      "Francesca Baldini",
      "Animashree Anandkumar",
      "Richard M. Murray"
    ],
    "link": "http://arxiv.org/abs/1912.04527v2",
    "pdf_link": "http://arxiv.org/pdf/1912.04527v2"
  },
  {
    "api_id": 549,
    "title": "Multi-Granularity Canonical Appearance Pooling for Remote Sensing Scene\n  Classification",
    "summary": "Recognising remote sensing scene images remains challenging due to large\nvisual-semantic discrepancies. These mainly arise due to the lack of detailed\nannotations that can be employed to align pixel-level representations with\nhigh-level semantic labels. As the tagging process is labour-intensive and\nsubjective, we hereby propose a novel Multi-Granularity Canonical Appearance\nPooling (MG-CAP) to automatically capture the latent ontological structure of\nremote sensing datasets. We design a granular framework that allows\nprogressively cropping the input image to learn multi-grained features. For\neach specific granularity, we discover the canonical appearance from a set of\npre-defined transformations and learn the corresponding CNN features through a\nmaxout-based Siamese style architecture. Then, we replace the standard CNN\nfeatures with Gaussian covariance matrices and adopt the proper matrix\nnormalisations for improving the discriminative power of features. Besides, we\nprovide a stable solution for training the eigenvalue-decomposition function\n(EIG) in a GPU and demonstrate the corresponding back-propagation using matrix\ncalculus. Extensive experiments have shown that our framework can achieve\npromising results in public remote sensing scene datasets.",
    "published": "2020-04-09T11:24:00Z",
    "updated": "2020-04-09T11:24:00Z",
    "authors": [
      "S. Wang",
      "Y. Guan",
      "L. Shao"
    ],
    "link": "http://arxiv.org/abs/2004.04491v1",
    "pdf_link": "http://arxiv.org/pdf/2004.04491v1"
  }
]